<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>放肆的青春</title>
  
  <subtitle>要变得和大叔一样强</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://xym-loveit.github.io/"/>
  <updated>2018-04-20T07:22:00.500Z</updated>
  <id>http://xym-loveit.github.io/</id>
  
  <author>
    <name>xym</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用Dockerfile创建镜像</title>
    <link href="http://xym-loveit.github.io/2018/04/20/%E4%BD%BF%E7%94%A8Dockerfile%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F/"/>
    <id>http://xym-loveit.github.io/2018/04/20/使用Dockerfile创建镜像/</id>
    <published>2018-04-20T02:18:05.000Z</published>
    <updated>2018-04-20T07:22:00.500Z</updated>
    
    <content type="html"><![CDATA[<p><code>Dockerfile</code>是一个文本格式的配置文件，用户可以使用<code>Dockerfile</code>来快速创建自定义的镜像。</p><h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><p><code>Dockerfile</code>由一行行命令语句组成，并且支持以<code>#</code>开头的注释行。<br>一般而言，<code>Dockerfile</code>分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#一个nginx dockerfile例子</span><br><span class="line">#基础镜像</span><br><span class="line">FROM ubuntu</span><br><span class="line">#维护者信息</span><br><span class="line">MAINTAINER xym xym@126.com</span><br><span class="line">#镜像操作指令</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y nginx</span><br><span class="line">RUN echo &quot;daemon off;&quot; &gt; /etc/nginx/nginx.conf</span><br><span class="line">#容器启动时执行指令</span><br><span class="line">CMD /usr/sbin/nginx</span><br></pre></td></tr></table></figure></p><p>其中一开始必须指明所基于的镜像名称，接下来一般是说明维护信息。后面则是镜像操作指令，例如RUN指令，RUN指令将对镜像执行跟随的命令。每运行一条RUN指令，镜像就添加新的一层，并提交。最后是CMD指令，用来指定运行容器时的操作命令。</p><h2 id="指令说明"><a href="#指令说明" class="headerlink" title="指令说明"></a>指令说明</h2><p>指令的一般格式为<code>INSTRUCTION arguments</code>，指令包括<code>FROM</code>、<code>MAINTAINER</code>、<code>RUN</code>等。</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_8b1-i_epub.jpg" alt="http://op7wplti1.bkt.clouddn.com/1900654235_8b1-i_epub.jpg"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_8b1x-i_epub.jpg" alt="http://op7wplti1.bkt.clouddn.com/1900654235_8b1x-i_epub.jpg"></p><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p>指定所创建镜像的基础镜像，如果本地不存在，则默认会去<code>Docker Hub</code>下载指定镜像。</p><p>命令格式：<code>FROM &lt;image&gt;</code> or <code>FROM &lt;image&gt;:&lt;tag&gt;</code> or <code>FROM &lt;image&gt;@&lt;digest&gt;</code></p><p>任何<code>Dockerfile</code>中的第一条指令必须为FROM指令。并且，如果在同一个<code>Dockerfile</code>中创建多个镜像，可以使用多个FROM指令（每个镜像一次）。 </p><h3 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h3><p>指定维护者信息，格式为 <code>MAINTAINER &lt;name&gt;</code>。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAINTAINER  image_creator@docker.com</span><br></pre></td></tr></table></figure></p><p>该信息会写入生成镜像的Author属性域中，可以使用 <code>docker inspect imageName/imageId</code>查看。 </p><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p>运行指定命令，格式为：<code>RUN &lt;command&gt;</code> 或 <code>RUN [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</code>。注意，后一个指令会被解析为<code>json</code>数组，因此必须使用双引号。</p><p>前者默认将在<code>shell</code>终端中运行命令，即<code>/bin/sh-c</code>;后者则使用<code>exec</code>执行，不会启动shell环境。<br>指定使用其他终端类型可以使用第二种方式实现，例如：<code>RUN [&quot;bin/bash&quot;,&quot;-c&quot;,&quot;echo hello&quot;]</code>。</p><p>每条RUN指令将在当前镜像的基础上执行指定指令，并提交为新的镜像。当命令较长时可以使用”\”来换行。</p><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p>CMD指令用来指定启动容器时默认执行的命令。它支持三种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//使用exec执行，是推荐的使用方式</span><br><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line"></span><br><span class="line">//在/bin/sh中执行，提供给需要交互的应用</span><br><span class="line">CMD command param1 param2</span><br><span class="line"></span><br><span class="line">//提供给ENTRYPOINT的默认参数</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;]</span><br></pre></td></tr></table></figure></p><p>每个<code>Dockerfile</code>只能有一条CMD命令，如果指定了多条命令，只有最后一条会被执行。<br>如果用户启动容器时手动指定了运行的命令（作为run的参数），则会覆盖掉CMD指定的命令。</p><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p>LABEL指令用来指定生成镜像的元数据标签信息。<br>命令格式：<code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;...</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL author=&quot;xym&quot; author_email=xxx@126.com</span><br></pre></td></tr></table></figure></p><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><p>声明镜像内的服务所监听的端口。</p><p>命令格式：<code>EXPOSE &lt;port&gt;[&lt;port&gt;...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE 22 80 8443</span><br></pre></td></tr></table></figure></p><p>该命令只是起到声明作用，并不会自动完成端口映射。在启动容器时需要使用<code>-P</code>，Docker主机会自动分配一个宿主机的临时端口转发到指定的端口；使用<code>-p</code>，则可以具体指定哪个宿主机的本地端口会映射过来。</p><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p>指定环境变量，在镜像生成过程中会被后续RUN指令使用，在镜像启动的容器中也会存在。</p><p>命令格式：<code>ENV &lt;key&gt; &lt;value&gt;</code> or <code>ENV &lt;key&gt;=&lt;value&gt;</code></p><p>指令指定的环境变量在运行中可以被覆盖掉，如<code>docker run --env &lt;key&gt;=&lt;value&gt; built_image</code></p><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><p>该命令将复制指定的<code>&lt;src&gt;</code>路径下的内容到容器中的<code>&lt;dest&gt;</code>路径下。</p><p>命令格式：<code>ADD &lt;src&gt; &lt;dest&gt;</code></p><p>其中<code>&lt;src&gt;</code>可以是<code>Dockerfile</code>所在目录的一个相对路径（文件或目录），也可以是一个URL，还可以是一个tar文件（如果为<code>tar</code>文件，会自动解压到<code>&lt;dest&gt;</code>路径下）。<code>&lt;dest&gt;</code>可以是镜像内的路径，或者相对于工作目录（<code>WORKDIR</code>）的相对路径。</p><p>路径支持正则格式：<code>ADD *.c /code/</code></p><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p>格式为<code>COPY &lt;src&gt; &lt;dest&gt;</code></p><p>复制本地主机的<code>&lt;src&gt;</code>（为<code>Dockerfile</code>所在目录的相对路径、文件或者目录）下的内容到镜像中的<code>&lt;dest&gt;</code>下。目标路径不存在时，会自动创建。路径同样支持正则表达式。当使用本地目录为源目录时，推荐使用<code>COPY</code>。</p><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><p>指定镜像的默认入口命令，该入口命令会在启动容器时作为根命令执行，所有传入值作为该命令的参数。<br>支持两种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]（exec调用执行）</span><br><span class="line">ENTRYPOINT command param1 param2（shell中执行）</span><br></pre></td></tr></table></figure></p><p>此时，<code>CMD</code>指令指定值将作为根命令的参数。<br>每个Dockerfile中只能有一个<code>ENTRYPOINT</code>，当指定多个时，只有最后一个有效。在运行时，可以被<code>--entrypoint</code>参数覆盖掉，如<code>docker run --entrypoint</code></p><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p>创建一个数据卷挂载点。格式为<code>VOLUME [&quot;/data&quot;]</code>，可以从本地主机或其他容器挂载数据卷，一般用来存放数据库和需要保存的数据等。</p><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><p>指定运行容器时的用户名和UID，后续的RUN等指令也会使用指定的用户身份。<br>格式为：<code>USER daemon</code></p><p>当服务不需要管理员权限时，可以通过该命令指定运行用户，并且可以在之前创建所需要的用户。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres</span><br></pre></td></tr></table></figure></p><p>要临时获取管理员权限可以使用<code>gosu</code>或<code>sudo</code></p><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p>为后续的<code>RUN/CMD/ENTRYPOINT</code>指令配置工作目录。</p><p>格式为：<code>WORKDIR /path/to/workdir</code><br>可以使用多个<code>WORKDIR</code>指令，后续命令如果参数是相对路径，后续命令如果是相对路径，则会基于之前命令指定的路径。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure></p><p>则最终路径为<code>/a/b/c</code></p><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><p>指定一些镜像内使用的的参数（例如版本号信息等），这些参数在执行<code>docker build</code>命令时以<code>--build-arg&lt;varname&gt;=&lt;value&gt;</code>格式传入。格式为<code>ARG &lt;name&gt;=[&lt;default value&gt;]</code>，则可以用<code>docker build --build-arg &lt;name&gt;=&lt;value&gt; .</code>来指定参数值。</p><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><p>配置当所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作指令。格式为：<code>ONBUILD [INSTRUCTION]</code></p><p>例如：Dockerfile使用了如下的内容创建了镜像<code>image-A</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line">ONBUILD ADD . /app/src</span><br><span class="line">ONBUILD RUN /usr/local/bin/python-build --dir /app/src</span><br><span class="line">[...]</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line">如果基于`image-A`创建新的镜像时，新的Dockerfile中使用`FROM image-A`指定基础镜像，会自动执行`ONBUILD`指令的内容，等价于在后面添加了两条指令：</span><br></pre></td></tr></table></figure></p><p>FROM image-A</p><p>#自动执行onbuild指定的命令<br>ADD . /app/src<br>RUN /usr/local/bin/python-build –dir /app/src</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">使用`ONBUILD`指令的镜像，推荐在标签中注明，例如：`ruby:1.9-onbuild`</span><br><span class="line"></span><br><span class="line">### STOPSIGNAL</span><br><span class="line">指定所创建镜像启动的容器接受退出的信号值，例如：  </span><br><span class="line">`STOPSIGNAL signal`</span><br><span class="line"></span><br><span class="line">### HEALTHCHECK</span><br><span class="line">配置所启动容器如何进行健康检查（如何判断健康与否），自Docker1.12开始支持。</span><br><span class="line"></span><br><span class="line">格式有两种：</span><br><span class="line"></span><br><span class="line">`HEALTHCHECK [OPTIONS] CMD command`</span><br><span class="line"></span><br><span class="line">根据所执行命令返回值是否为0来判断；</span><br><span class="line">`HEALTHCHECK NONE`禁止基础镜像中的健康检查。</span><br><span class="line"></span><br><span class="line">OPTIONS支持：</span><br><span class="line"></span><br><span class="line">* --interval=DURATION（默认为30s）：过多久检查一次；</span><br><span class="line">* --timeout=DURATION（默认为30s）：每次检查等待结果的超时；</span><br><span class="line">* --retries=N（默认为3）：如果失败了，重试几次才最终确定失败。</span><br><span class="line"></span><br><span class="line">### SHELL</span><br><span class="line">指定其他命令使用`shell`时的默认shell类型。默认值为`[&quot;/bin/sh&quot;,&quot;-c&quot;]`</span><br><span class="line"></span><br><span class="line">注意：对于`Windows`系统，建议在Dockerfile开头添加`#escape=`来指定转义信息。</span><br><span class="line"></span><br><span class="line">## 创建镜像</span><br><span class="line">编写完成`Dockerfile`之后，可以通过`docker build`命令来创建镜像。基本格式为`docker build [选项] 内容路径`，该命令将读取指定路径下（包括子目录）的Dockerfile，并将该路径下的所有内容发送给Docker服务端，由服务端来创建镜像。因此除非生成镜像需要，否则一般建议放置Dockerfile的目录为空目录。有两点经验：</span><br><span class="line"></span><br><span class="line">* 如果使用非内容路径下的Dockerfile，可以通过-f选项来指定其路径</span><br><span class="line">* 要指定生成镜像的标签信息，可以使用-t选项</span><br><span class="line"></span><br><span class="line">例如，指定Dockerfile所在路径为`/tmp/docker_builder/`,并且希望生成镜像标签为`build_repo/first_image`,可以使用下面命令：</span><br></pre></td></tr></table></figure><p>docker build -t build_repo/first_image /tmp/docker_builder/</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 使用.dockerignore文件</span><br><span class="line">可以通过`.dockerignore`文件（每一行添加一条匹配模式）来让`Docker`忽略匹配模式路径下的目录和文件。例如：</span><br></pre></td></tr></table></figure><h1 id="comment"><a href="#comment" class="headerlink" title="comment"></a>comment</h1><p><em>/temp</em><br><em>/</em>/temp<em><br>tmp?<br>~</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 编写Dockerfile的指导原则</span><br><span class="line">* 精简镜像用途：尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂，多功能的镜像；</span><br><span class="line">* 选用合适的基础镜像：过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的`debian`镜像；</span><br><span class="line">* 提供足够清晰的命令注释和维护者信息：Dockerfile也是一种代码，需要考虑方便后续扩展和他人使用；</span><br><span class="line">* 正确使用版本：使用明确的版本号信息，如：1.0，2.0而非latest，将避免内容不一致可能引发的惨案；</span><br><span class="line">* 减少镜像层数：如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；</span><br><span class="line">* 及时删除临时文件和缓存文件：特别是在执行apt-get指令后，/var/cache/apt/下面会缓存一些安装包；</span><br><span class="line">* 提高生成速度：如合理使用缓存，减少内容目录下的文件，或使用`.dockerignore`文件指定等。</span><br><span class="line">* 调整合理的指令顺序：在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用</span><br><span class="line">* 减少外部源的干扰：如果确实要从外部引入数据，需要指定持久地址，并带有版本信息，让他人可以重复而不出错</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 优良的镜像</span><br><span class="line"></span><br><span class="line">### BUSYBOX</span><br><span class="line">BusyBox是一个集成了100多个最常见的`Liunx`命令和工具（如：cat/echo/grep/mount/telnet等）的精简工具箱。它只有几MB的大小，很方便进行各种快速验证，被誉为“Linux系统的瑞士军刀”。BusyBox可以运行于多款POSIX环境的操作系统中，如Liunx（包括Andrid）、Hurd、FreeBSD等。</span><br></pre></td></tr></table></figure><p>//查询busybox镜像<br>docker search busybox</p><p>//下载busybox镜像<br>docker pull busybox</p><p>//使用busybox创建容器<br>docker run -it –name my_busybox busybox</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Alpine</span><br><span class="line">Alpine操作系统是一个面向安全的轻型Linux发行版。Alpine是由非商业组织维护的支持广泛场景的Linux发行版，它特别为资深/重度Liunx用户而优化，关注安全、性能和资源效能。Alpine镜像适用于更多常用场景，并且是一个优秀的可以适用于生产的基础环境。</span><br></pre></td></tr></table></figure><p>//查询busybox镜像<br>docker search alpine</p><p>//下载busybox镜像<br>docker pull alpine</p><p>//使用busybox创建容器<br>docker run -it –name my_alpine alpine</p><p><code>`</code></p><h3 id="Debian-Ubuntu"><a href="#Debian-Ubuntu" class="headerlink" title="Debian/Ubuntu"></a>Debian/Ubuntu</h3><h3 id="CentOS-Fedora"><a href="#CentOS-Fedora" class="headerlink" title="CentOS/Fedora"></a>CentOS/Fedora</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;Dockerfile&lt;/code&gt;是一个文本格式的配置文件，用户可以使用&lt;code&gt;Dockerfile&lt;/code&gt;来快速创建自定义的镜像。&lt;/p&gt;
&lt;h2 id=&quot;基本结构&quot;&gt;&lt;a href=&quot;#基本结构&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Docker镜像构建文件Dockerfile及相关命令介绍</title>
    <link href="http://xym-loveit.github.io/2018/04/19/Docker%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E6%96%87%E4%BB%B6Dockerfile%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D/"/>
    <id>http://xym-loveit.github.io/2018/04/19/Docker镜像构建文件Dockerfile及相关命令介绍/</id>
    <published>2018-04-19T07:22:20.000Z</published>
    <updated>2018-04-19T08:41:24.476Z</updated>
    
    <content type="html"><![CDATA[<p>使用<code>docker build</code>命令或使用<code>Docker Hub</code>的自动构建功能构建Docker镜像时，都需要一个<code>Dockerfile</code>文件。<code>Dockerfile</code>文件是一个由一系列构建指令组成的文本文件，<code>docker build</code>命令会根据这些构建指令完成<code>Docker</code>镜像的构建。本文将会介绍<code>Dockerfile</code>文件，及其中使用的构建指令。</p><h2 id="Dockerfile文件使用"><a href="#Dockerfile文件使用" class="headerlink" title="Dockerfile文件使用"></a>Dockerfile文件使用</h2><p><code>docker build</code>命令会根据<code>Dockerfile</code>文件及上下文构建新<code>Docker镜像</code>。构建上下文是指Dockerfile所在的本地路径或一个URL（Git仓库地址）。构建上下文环境会被递归处理，所以，构建所指定的路径还包括了子目录，而URL还包括了其中指定的子模块。</p><h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p>将当前目录做为构建上下文时，可以像下面这样使用docker build命令构建镜像：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker build .</span><br><span class="line">Sending build context to Docker daemon  6.51 MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>说明：构建会在Docker后台守护进程（daemon）中执行，而不是<code>CLI</code>中。构建前，构建进程会将全部内容（递归）发送到守护进程。大多情况下，应该将一个空目录作为构建上下文环境，并将<code>Dockerfile</code>文件放在该目录下。</p><p>在构建上下文中使用的<code>Dockerfile</code>文件，是一个构建指令文件。为了提高构建性能，可以通过<code>.dockerignore</code>文件排除上下文目录下，不需要的文件和目录。</p><p><code>Dockerfile</code>一般位于构建上下文的根目录下，也可以通过<code>-f</code>指定该文件的位置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -f /path/to/a/Dockerfile .</span><br></pre></td></tr></table></figure><p>构建时，还可以通过-t参数指定构建成后，镜像的仓库、标签等：</p><h3 id="镜像标签"><a href="#镜像标签" class="headerlink" title="镜像标签"></a>镜像标签</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t shykes/myapp .</span><br></pre></td></tr></table></figure><p>如果存在多个仓库下，或使用多个镜像标签，就可以使用多个<code>-t</code>参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .</span><br></pre></td></tr></table></figure><p>在Docker守护进程执行<code>Dockerfile</code>中的指令前，首先会对<code>Dockerfile</code>进行语法检查，有语法错误时会返回：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t test/myapp .</span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">Error response from daemon: Unknown instruction: RUNCMD</span><br></pre></td></tr></table></figure><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>Docker 守护进程会一条一条的执行<code>Dockerfile</code>中的指令，而且会在每一步提交并生成一个新镜像，最后会输出最终镜像的ID。生成完成后，Docker 守护进程会自动清理你发送的上下文。</p><p><code>Dockerfile</code>文件中的每条指令会被独立执行，并会创建一个新镜像，<code>RUN cd /tmp</code>等命令不会对下条指令产生影响。</p><p>Docker 会重用已生成的中间镜像，以加速<code>docker build</code>的构建速度。以下是一个使用了缓存镜像的执行过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t svendowideit/ambassador .</span><br><span class="line">Sending build context to Docker daemon 15.36 kB</span><br><span class="line">Step 1/4 : FROM alpine:3.2</span><br><span class="line"> ---&gt; 31f630c65071</span><br><span class="line">Step 2/4 : MAINTAINER SvenDowideit@home.org.au</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 2a1c91448f5f</span><br><span class="line">Step 3/4 : RUN apk update &amp;&amp;      apk add socat &amp;&amp;        rm -r /var/cache/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 21ed6e7fbb73</span><br><span class="line">Step 4/4 : CMD env | grep _TCP= | (sed &apos;s/.*_PORT_\([0-9]*\)_TCP=tcp:\/\/\(.*\):\(.*\)/socat -t 100000000 TCP4-LISTEN:\1,fork,reuseaddr TCP4:\2:\3 \&amp;/&apos; &amp;&amp; echo wait) | sh</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 7ea8aef582cc</span><br><span class="line">Successfully built 7ea8aef582cc</span><br></pre></td></tr></table></figure><p>构建缓存仅会使用本地父生成链上的镜像。如果不想使用本地缓存的镜像，也可以通过<code>--cache-from</code>指定缓存。指定后将再不使用本地生成的镜像链，而是从镜像仓库中下载。</p><h3 id="寻找缓存的逻辑"><a href="#寻找缓存的逻辑" class="headerlink" title="寻找缓存的逻辑"></a>寻找缓存的逻辑</h3><p>Docker 寻找缓存的逻辑其实就是树型结构根据 <code>Dockerfile</code> 指令遍历子节点的过程。下图可以说明这个逻辑。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> FROM base_image:version           Dockerfile:</span><br><span class="line">           +----------+                FROM base_image:version</span><br><span class="line">           |base image|                RUN cmd1  --&gt; use cache because we found base image</span><br><span class="line">           +-----X----+                RUN cmd11 --&gt; use cache because we found cmd1</span><br><span class="line">                / \</span><br><span class="line">               /   \</span><br><span class="line">       RUN cmd1     RUN cmd2           Dockerfile:</span><br><span class="line">       +------+     +------+           FROM base_image:version</span><br><span class="line">       |image1|     |image2|           RUN cmd2  --&gt; use cache because we found base image</span><br><span class="line">       +---X--+     +------+           RUN cmd21 --&gt; not use cache because there&apos;s no child node</span><br><span class="line">          / \                                        running cmd21, so we build a new image here</span><br><span class="line">         /   \</span><br><span class="line">RUN cmd11     RUN cmd12</span><br><span class="line">+-------+     +-------+</span><br><span class="line">|image11|     |image12|</span><br><span class="line">+-------+     +-------+</span><br></pre></td></tr></table></figure><p>大部分指令可以根据上述逻辑去寻找缓存，除了 <code>ADD</code> 和 <code>COPY</code> 。这两个指令会复制文件内容到镜像内，除了指令相同以外，Docker 还会检查每个文件内容校验(不包括最后修改时间和最后访问时间)，如果校验不一致，则不会使用缓存。</p><p>除了这两个命令，Docker 并不会去检查容器内的文件内容，比如 <code>RUN apt-get -y update</code>，每次执行时文件可能都不一样，但是 Docker 认为命令一致，会继续使用缓存。这样一来，以后构建时都不会再重新运行<code>apt-get -y update</code>。</p><p>如果 Docker 没有找到当前指令的缓存，则会构建一个新的镜像，并且之后的所有指令都不会再去寻找缓存。</p><h2 id="Dockerfile文件格式"><a href="#Dockerfile文件格式" class="headerlink" title="Dockerfile文件格式"></a>Dockerfile文件格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Comment</span><br><span class="line">INSTRUCTION arguments</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 注释</span><br><span class="line">指令 参数</span><br></pre></td></tr></table></figure><p><code>Dockerfile</code>文件中指令不区分大小写，但为了更易区分，约定使用<strong>大写</strong>形式。</p><p><code>Docker</code> 会依次执行<code>Dockerfile</code>中的指令，<strong>文件中的第一条指令必须是FROM，FROM指令用于指定一个基础镜像</strong>。</p><p>以#开头的行，Docker会认为是注释。但#出现在指令参数中时，则不是注释。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Comment</span><br><span class="line">RUN echo &apos;we are running some # of cool things&apos;</span><br></pre></td></tr></table></figure><h2 id="Dockerfile中使用指令"><a href="#Dockerfile中使用指令" class="headerlink" title="Dockerfile中使用指令"></a>Dockerfile中使用指令</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p><code>FROM</code>指令用于指定其后构建新镜像所使用的基础镜像。FROM指令必是<code>Dockerfile</code>文件中的首条命令，启动构建流程后，Docker将会基于该镜像构建新镜像，<code>FROM</code>后的命令也会基于这个基础镜像。</p><p><code>FROM</code>语法格式为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;</span><br></pre></td></tr></table></figure></p><p>或<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p><p>或<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;:&lt;digest&gt;</span><br></pre></td></tr></table></figure></p><p>通过<code>FROM</code>指定的镜像，可以是任何有效的基础镜像。FROM有以下限制：</p><ul><li>FROM必须是Dockerfile中第一条非注释命令</li><li>在一个Dockerfile文件中创建多个镜像时，FROM可以多次出现。只需在每个新命令FROM之前，记录提交上次的镜像ID。</li><li>tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像</li></ul><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p><code>RUN</code>用于在镜像容器中执行命令，其有以下两种命令执行方式：</p><h4 id="shell执行"><a href="#shell执行" class="headerlink" title="shell执行"></a>shell执行</h4><p>在这种方式会在<code>shell</code>中执行命令，Linux下默认使用<code>/bin/sh -c</code>，Windows下使用<code>cmd /S /C</code>。</p><p>注意：通过<code>SHELL</code>命令修改RUN所使用的默认shell<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN &lt;command&gt;</span><br></pre></td></tr></table></figure></p><h4 id="exec执行"><a href="#exec执行" class="headerlink" title="exec执行"></a>exec执行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><p><code>RUN</code>可以执行任何命令，然后在当前镜像上创建一个新层并提交。提交后的结果镜像将会用在<code>Dockerfile</code>文件的下一步。</p><p>通过<code>RUN</code>执行多条命令时，可以通过<code>\</code>换行执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN /bin/bash -c &apos;source $HOME/.bashrc; \</span><br><span class="line">echo $HOME&apos;</span><br></pre></td></tr></table></figure><p>也可以在同一行中，通过分号分隔命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN /bin/bash -c &apos;source $HOME/.bashrc; echo $HOME&apos;</span><br></pre></td></tr></table></figure></p><p><code>RUN</code>指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定<code>--no-cache</code>参数，如：<code>docker build --no-cache</code>。</p><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p><code>CMD</code>用于指定在容器启动时所要执行的命令。<code>CMD</code>有以下三种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line">CMD command param1 param2</span><br></pre></td></tr></table></figure></p><p><code>CMD</code>不同于<code>RUN</code>，<code>CMD</code>用于指定在容器启动时所要执行的命令，而<code>RUN</code>用于指定镜像构建时所要执行的命令。</p><p><code>CMD</code>与<code>RUN</code>在功能实现上也有相似之处。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker run -t -i itbilu/static_web_server /bin/true</span><br></pre></td></tr></table></figure></p><p>等价于：</p><p>cmd [“/bin/true”]</p><p>CMD在Dockerfile文件中仅可指定一次，指定多次时，会覆盖前的指令。</p><p>另外，<code>docker run</code>命令也会覆盖<code>Dockerfile</code>中CMD命令。如果<code>docker run</code>运行容器时，使用了<code>Dockerfile</code>中CMD相同的命令，就会覆盖<code>Dockerfile</code>中的CMD命令。</p><p>如，我们在构建镜像的<code>Dockerfile</code>文件中使用了如下指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;/bin/bash&quot;]</span><br></pre></td></tr></table></figure></p><p>使用<code>docker build</code>构建一个新镜像，镜像名为<code>itbilu/test</code>。构建完成后，使用这个镜像运行一个新容器，运行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t itbilu/test</span><br><span class="line">root@e3597c81aef4:/#</span><br></pre></td></tr></table></figure><p>在使用<code>docker run</code>运行容器时，我们并没有在命令结尾指定会在容器中执行的命令，这时Docker就会执行在<code>Dockerfile</code>的CMD中指定的命令。</p><p>如果不想使用CMD中指定的命令，就可以在<code>docker run</code>命令的结尾指定所要运行的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t itbilu/test /bin/ps</span><br><span class="line">  PID TTY          TIME CMD</span><br><span class="line">    1 ?        00:00:00 ps</span><br></pre></td></tr></table></figure></p><p>这时，docker run结尾指定的<code>/bin/ps</code>命令覆盖了<code>Dockerfile</code>的CMD中指定的命令。</p><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><p><code>ENTRYPOINT</code>用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过<code>ENTRYPOINT</code>指定的程序都会被设置为默认程序。<code>ENTRYPOINT</code>有以下两种形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br><span class="line">ENTRYPOINT command param1 param2</span><br></pre></td></tr></table></figure><p><code>ENTRYPOINT</code>与<code>CMD</code>非常类似，不同的是通过<code>docker run</code>执行的命令不会覆盖<code>ENTRYPOINT</code>，而<code>docker run</code>命令中指定的任何参数，都会被当做参数再次传递给<code>ENTRYPOINT</code>。<code>Dockerfile</code>中只允许有一个<code>ENTRYPOINT</code>命令，多指定时会覆盖前面的设置，而只执行最后的<code>ENTRYPOINT</code>指令。</p><p><code>docker run</code>运行容器时指定的参数都会被传递给<code>ENTRYPOINT</code>，且会覆盖CMD命令指定的参数。如，执行<code>docker run &lt;image&gt; -d</code>时，<code>-d</code>参数将被传递给入口点。</p><p>也可以通过<code>docker run --entrypoint</code>重写<code>ENTRYPOINT</code>入口点。</p><p>如：可以像下面这样指定一个容器执行程序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;/usr/bin/nginx&quot;]</span><br></pre></td></tr></table></figure></p><p>完整构建代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Version: 0.0.3</span><br><span class="line">FROM ubuntu:16.04</span><br><span class="line">MAINTAINER 何民三 &quot;cn.liuht@gmail.com&quot;</span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN apt-get install -y nginx</span><br><span class="line">RUN echo &apos;Hello World, 我是个容器&apos; \ </span><br><span class="line">   &gt; /var/www/html/index.html</span><br><span class="line">ENTRYPOINT [&quot;/usr/sbin/nginx&quot;]</span><br><span class="line">EXPOSE 8</span><br></pre></td></tr></table></figure><p>使用<code>docker build</code>构建镜像，并将镜像指定为<code>itbilu/test</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker build -t=&quot;itbilu/test&quot; .</span><br></pre></td></tr></table></figure></p><p>构建完成后，使用<code>itbilu/test</code>启动一个容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t  itbilu/test -g &quot;daemon off;&quot;</span><br></pre></td></tr></table></figure></p><p>在运行容器时，我们使用了<code>-g &quot;daemon off;&quot;</code>，这个参数将会被传递给<code>ENTRYPOINT</code>，最终在容器中执行的命令为<code>/usr/sbin/nginx -g &quot;daemon off;&quot;</code>。</p><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p><code>LABEL</code>用于为镜像添加元数据，元数以键值对的形式指定：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</span><br></pre></td></tr></table></figure></p><p>使用<code>LABEL</code>指定元数据时，一条<code>LABEL</code>指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条<code>LABEL</code>指令指定，以免生成过多的中间镜像。</p><p>如，通过<code>LABEL</code>指定一些元数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot;</span><br></pre></td></tr></table></figure></p><p>指定后可以通过<code>docker inspect</code>查看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$sudo docker inspect itbilu/test</span><br><span class="line">&quot;Labels&quot;: &#123;</span><br><span class="line">    &quot;version&quot;: &quot;1.0&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;这是一个Web服务器&quot;,</span><br><span class="line">    &quot;by&quot;: &quot;IT笔录&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><p>注意：<code>Dockerfile</code>中还有个<code>MAINTAINER</code>命令，该命令用于指定镜像作者。但<code>MAINTAINER</code>并不推荐使用，更推荐使用<code>LABEL</code>来指定镜像作者。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL maintainer=&quot;itbilu.com&quot;</span><br></pre></td></tr></table></figure></p><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><p><code>EXPOSE</code>用于指定容器在运行时监听的端口：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;...]</span><br></pre></td></tr></table></figure></p><p><code>EXPOSE</code>并不会让容器的端口访问到主机。要使其可访问，需要在<code>docker run</code>运行容器时通过<code>-p</code>来发布这些端口，或通过<code>-P</code>参数来发布<code>EXPOSE</code>导出的所有端口。</p><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p><code>ENV</code>用于设置环境变量，其有以下两种设置形式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV &lt;key&gt; &lt;value&gt;</span><br><span class="line">ENV &lt;key&gt;=&lt;value&gt; ...</span><br></pre></td></tr></table></figure></p><p>如，通过<code>ENV</code>设置一个环境变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENV ITBILU_PATH /home/itbilu/</span><br></pre></td></tr></table></figure></p><p>设置后，这个环境变量在<code>ENV</code>命令后都可以使用。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKERDIR $ITBILU_PATH</span><br></pre></td></tr></table></figure></p><p>这些环境变量不仅可以构建镜像过程使用，使用该镜像创建的容器中也可以使用。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -i -t  itbilu/test </span><br><span class="line">root@196ca123c0c3:/# cd $ITBILU_PATH</span><br><span class="line">root@196ca123c0c3:/home/itbilu#</span><br></pre></td></tr></table></figure></p><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><p><code>ADD</code>用于复制构建环境中的文件或目录到镜像中。其有以下两种使用方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure></p><p>通过<code>ADD</code>复制文件时，需要通过<code>&lt;src&gt;</code>指定源文件位置，并通过<code>&lt;dest&gt;</code>来指定目标位置。<code>&lt;src&gt;</code>可以是一个构建上下文中的文件或目录，也可以是一个<code>URL</code>，但不能访问构建上下文之外的文件或目录。</p><p>如，通过<code>ADD</code>复制一个网络文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD http://wordpress.org/latest.zip $ITBILU_PATH</span><br></pre></td></tr></table></figure></p><p>在上例中，<code>$ITBILU_PATH</code>是我们使用<code>ENV</code>指定的一个环境变量。</p><p>另外，如果使用的是本地归档文件（<code>gzip、bzip2、xz</code>）时，Docker会自动进行解包操作，类似使用<code>tar -x</code>。</p><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p><code>COPY</code>同样用于复制构建环境中的文件或目录到镜像中。其有以下两种使用方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COPY &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure></p><p><code>COPY</code>指令非常类似于<code>ADD</code>，不同点在于<code>COPY</code>只会复制构建目录下的文件，不能使用<code>URL</code>也不会进行解压操作。</p><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p><code>VOLUME</code>用于创建挂载点，即向基于所构建镜像创始的容器添加卷：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [&quot;/data&quot;]</span><br></pre></td></tr></table></figure></p><p>一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：</p><ul><li>卷可以容器间共享和重用</li><li>容器并不一定要和其它容器共享卷</li><li>修改卷后会立即生效</li><li>对卷的修改不会对镜像产生影响</li><li>卷会一直存在，直到没有任何容器在使用它</li></ul><p><code>VOLUME</code>让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。</p><p>如，通过<code>VOLUME</code>创建一个挂载点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV ITBILU_PATH /home/itbilu/</span><br><span class="line">VOLUME [$ITBILU_PATH]</span><br></pre></td></tr></table></figure></p><p>构建的镜像，并指定镜像名为<code>itbilu/test</code>。构建镜像后，使用新构建的运行一个容器。运行容器时，需<code>-v</code>参将能本地目录绑定到容器的卷（挂载点）上，以使容器可以访问宿主机的数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t -v ~/code/itbilu:/home/itbilu/  itbilu/test </span><br><span class="line">root@31b0fac536c4:/# cd /home/itbilu/</span><br><span class="line">root@31b0fac536c4:/home/itbilu# ls</span><br><span class="line">README.md  app.js  bin  config.js  controller  db  demo  document  lib  minify.js  node_modules  package.json  public  routes  test  views</span><br></pre></td></tr></table></figure></p><p>如上所示，我们已经可以容器的<code>/home/itbilu/</code>目录下访问到宿主机<code>~/code/itbilu</code>目录下的数据了。</p><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><p><code>USER</code>用于指定运行镜像所使用的用户：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER daemon</span><br></pre></td></tr></table></figure></p><p>使用<code>USER</code>指定用户时，可以使用用户名、UID或GID，或是两者的组合。以下都是合法的指定试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">USER user</span><br><span class="line">USER user:group</span><br><span class="line">USER uid</span><br><span class="line">USER uid:gid</span><br><span class="line">USER user:gid</span><br><span class="line">USER uid:group</span><br></pre></td></tr></table></figure></p><p>使用<code>USER</code>指定用户后，<code>Dockerfile</code>中其后的命令<code>RUN</code>、<code>CMD</code>、<code>ENTRYPOINT</code>都将使用该用户。镜像构建完成后，通过<code>docker run</code>运行容器时，可以通过<code>-u</code>参数来覆盖所指定的用户。</p><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p><code>WORKDIR</code>用于在容器内设置一个工作目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /path/to/workdir</span><br></pre></td></tr></table></figure></p><p>通过<code>WORKDIR</code>设置工作目录后，<code>Dockerfile</code>中其后的命令<code>RUN</code>、<code>CMD</code>、<code>ENTRYPOINT</code>、<code>ADD</code>、<code>COPY</code>等命令都会在该目录下执行。</p><p>如，使用<code>WORKDIR</code>设置工作目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure></p><p>在以上示例中，<code>pwd</code>最终将会在<code>/a/b/c</code>目录中执行。</p><p>在使用<code>docker run</code>运行容器时，可以通过<code>-w</code>参数覆盖构建时所设置的工作目录。</p><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><p><code>ARG</code>用于指定传递给构建运行时的变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARG &lt;name&gt;[=&lt;default value&gt;]</span><br></pre></td></tr></table></figure></p><p>如，通过<code>ARG</code>指定两个变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ARG site</span><br><span class="line">ARG build_user=IT笔录</span><br></pre></td></tr></table></figure></p><p>以上我们指定了<code>site</code>和<code>build_user</code>两个变量，其中<code>build_user</code>指定了默认值。在使用<code>docker build</code>构建镜像时，可以通过<code>--build-arg &lt;varname&gt;=&lt;value&gt;</code>参数来指定或重设置这些变量的值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker build --build-arg site=itiblu.com -t itbilu/test .</span><br></pre></td></tr></table></figure></p><p>这样我们构建了<code>itbilu/test</code>镜像，其中<code>site</code>会被设置为<code>itbilu.com</code>，由于没有指定<code>build_user</code>，其值将是默认值IT笔录。</p><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><p><code>ONBUILD</code>用于设置镜像触发器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONBUILD [INSTRUCTION]</span><br></pre></td></tr></table></figure></p><p>当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。</p><p>如，当镜像被使用时，可能需要做一些处理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line">ONBUILD ADD . /app/src</span><br><span class="line">ONBUILD RUN /usr/local/bin/python-build --dir /app/src</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure></p><h3 id="STOPSIGNAL"><a href="#STOPSIGNAL" class="headerlink" title="STOPSIGNAL"></a>STOPSIGNAL</h3><p><code>STOPSIGNAL</code>用于设置停止容器所要发送的系统调用信号：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">STOPSIGNAL signal</span><br></pre></td></tr></table></figure></p><p>所使用的信号必须是内核系统调用表中的合法的值，如：<code>9</code>、<code>SIGKILL</code>。</p><h3 id="SHELL"><a href="#SHELL" class="headerlink" title="SHELL"></a>SHELL</h3><p><code>SHELL</code>用于设置执行命令（<code>shell</code>式）所使用的的默认shell类型：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHELL [&quot;executable&quot;, &quot;parameters&quot;]</span><br></pre></td></tr></table></figure></p><p><code>SHELL</code>在Windows环境下比较有用，Windows下通常会有cmd和powershell两种shell，可能还会有sh。这时就可以通过SHELL来指定所使用的shell类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">FROM microsoft/windowsservercore</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C echo default</span><br><span class="line">RUN echo default</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C powershell -command Write-Host default</span><br><span class="line">RUN powershell -command Write-Host default</span><br><span class="line"></span><br><span class="line"># Executed as powershell -command Write-Host hello</span><br><span class="line">SHELL [&quot;powershell&quot;, &quot;-command&quot;]</span><br><span class="line">RUN Write-Host hello</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C echo hello</span><br><span class="line">SHELL [&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;]</span><br><span class="line">RUN echo hello</span><br></pre></td></tr></table></figure><blockquote><p>原文链接：<a href="https://itbilu.com/linux/docker/VyhM5wPuz.html" target="_blank" rel="noopener">https://itbilu.com/linux/docker/VyhM5wPuz.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      Dockerfile镜像构建文件命令详解，方便查阅。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Dockerfile命令" scheme="http://xym-loveit.github.io/tags/Dockerfile%E5%91%BD%E4%BB%A4/"/>
    
      <category term="Dockerfile命令详解" scheme="http://xym-loveit.github.io/tags/Dockerfile%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    
      <category term="FROM命令" scheme="http://xym-loveit.github.io/tags/FROM%E5%91%BD%E4%BB%A4/"/>
    
      <category term="RUN命令" scheme="http://xym-loveit.github.io/tags/RUN%E5%91%BD%E4%BB%A4/"/>
    
      <category term="CMD命令" scheme="http://xym-loveit.github.io/tags/CMD%E5%91%BD%E4%BB%A4/"/>
    
      <category term="ADD命令" scheme="http://xym-loveit.github.io/tags/ADD%E5%91%BD%E4%BB%A4/"/>
    
      <category term="COPY命令" scheme="http://xym-loveit.github.io/tags/COPY%E5%91%BD%E4%BB%A4/"/>
    
      <category term="ENTRYPOINT命令" scheme="http://xym-loveit.github.io/tags/ENTRYPOINT%E5%91%BD%E4%BB%A4/"/>
    
      <category term="ENV命令" scheme="http://xym-loveit.github.io/tags/ENV%E5%91%BD%E4%BB%A4/"/>
    
      <category term="ONBUILD命令" scheme="http://xym-loveit.github.io/tags/ONBUILD%E5%91%BD%E4%BB%A4/"/>
    
      <category term="ARG命令" scheme="http://xym-loveit.github.io/tags/ARG%E5%91%BD%E4%BB%A4/"/>
    
      <category term="WORKDIR命令，LABEL命令" scheme="http://xym-loveit.github.io/tags/WORKDIR%E5%91%BD%E4%BB%A4%EF%BC%8CLABEL%E5%91%BD%E4%BB%A4/"/>
    
      <category term="EXPOSE命令" scheme="http://xym-loveit.github.io/tags/EXPOSE%E5%91%BD%E4%BB%A4/"/>
    
      <category term="VOLUME命令" scheme="http://xym-loveit.github.io/tags/VOLUME%E5%91%BD%E4%BB%A4/"/>
    
      <category term="USER命令" scheme="http://xym-loveit.github.io/tags/USER%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Docker 配置加速器</title>
    <link href="http://xym-loveit.github.io/2018/04/19/Docker-%E9%85%8D%E7%BD%AE%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
    <id>http://xym-loveit.github.io/2018/04/19/Docker-配置加速器/</id>
    <published>2018-04-19T01:51:10.000Z</published>
    <updated>2018-04-19T02:13:46.890Z</updated>
    
    <content type="html"><![CDATA[<p>在国内使用Docker Hub有个很大的问题就是速度太慢，pull一个image要很久，幸亏国内有个组织解决了这个问题——DaoCloud。在<a href="http://www.daocloud.io/#" target="_blank" rel="noopener">DaoCloud</a>上注册一个帐号，找到它的加速器页面，根据提示进行操作即可。</p><p>进入<a href="http://www.daocloud.io/mirror#accelerator-doc" target="_blank" rel="noopener">加速器</a>页面</p><p><img src="http://op7wplti1.bkt.clouddn.com/daocloud_%E5%8A%A0%E9%80%9F%E5%99%A8.png" alt="daocloud加速器"></p><p><img src="http://op7wplti1.bkt.clouddn.com/%E5%8A%A0%E9%80%9F%E9%85%8D%E7%BD%AE.png" alt="daocloud配置"></p>]]></content>
    
    <summary type="html">
    
      Docker加速器配置
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Docker加速器配置" scheme="http://xym-loveit.github.io/tags/Docker%E5%8A%A0%E9%80%9F%E5%99%A8%E9%85%8D%E7%BD%AE/"/>
    
      <category term="daocloud加速器" scheme="http://xym-loveit.github.io/tags/daocloud%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Hexo在遇到特殊符号时出现解析报错</title>
    <link href="http://xym-loveit.github.io/2018/04/17/Hexo%E5%9C%A8%E9%81%87%E5%88%B0%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%E6%97%B6%E5%87%BA%E7%8E%B0%E8%A7%A3%E6%9E%90%E6%8A%A5%E9%94%99/"/>
    <id>http://xym-loveit.github.io/2018/04/17/Hexo在遇到特殊符号时出现解析报错/</id>
    <published>2018-04-16T16:00:35.000Z</published>
    <updated>2018-04-16T16:09:18.975Z</updated>
    
    <content type="html"><![CDATA[<h2 id="hexo-在遇到-““-符号时出现解析报错"><a href="#hexo-在遇到-““-符号时出现解析报错" class="headerlink" title="hexo 在遇到 ““ 符号时出现解析报错"></a>hexo 在遇到 “{{“ 符号时出现解析报错</h2><p>最近在更新一篇文章后，无论是 hexo g 生成，还是 hexo s 预览都会报解析错误， 大致如下，后面还有很长的信息，就不贴了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">Template render error: unexpected token: .</span><br><span class="line">    at Object._prettifyError (D:\workspace\IdeaProjects\myHexo\node_modules\nunjucks\src\lib.js:35:11)</span><br><span class="line">    at Template.render (D:\workspace\IdeaProjects\myHexo\node_modules\nunjucks\src\environment.js:526:21)</span><br></pre></td></tr></table></figure><p>而把那篇文章移除后一切又是正常的。从错误上来看基本可以判断是模板解析错误，从 unexpected token: . 又看不出来具体是哪里出错，一直找不到原因。</p><p>今天查找资料发现有人遇到和我类似的问题，但报的是 <code>unexpected token: }}</code> 的错误。搜索一下我那篇文章，果然有好几处带有 <code>}}</code> 符号。尝试着把几处符号删除，果然正常了。看来问题真的出在 }} 上面。</p><p>直接说解决方案吧，参考别人的解决方法是在 }} 中间加一个空格，但因为我的是有部分教程含义的文章，所以并不想这样误导人。于是去 github 上找解决方案。</p><p>github 上给出的方法是在需要显示 }} 符号的地方加上 <code>{% raw %}{% endraw %}</code> 标签，标记这部分不需要解析。例如文章中可能会出现 <code></code> 的片段，写成 <code>{% raw %}{{ something }}{% endraw %}</code> 就可以了。</p><p>虽然有点麻烦，但也算临时解决了这个问题，这是个已知 bug ，希望后续的版本能修复吧，毕竟使用太多 hexo 专属的标签对博客以后的迁移、改版什么的来说还是很麻烦的。</p><p>本文链接: <a href="https://icewing.cc/post/hexo-bug-of-quot.html" target="_blank" rel="noopener">https://icewing.cc/post/hexo-bug-of-quot.html</a></p>]]></content>
    
    <summary type="html">
    
      Hexo使用解析问题
    
    </summary>
    
      <category term="hexo笔记" scheme="http://xym-loveit.github.io/categories/hexo%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="hexo小技巧" scheme="http://xym-loveit.github.io/tags/hexo%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>Docker 端口映射与容器互联</title>
    <link href="http://xym-loveit.github.io/2018/04/16/Docker-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/"/>
    <id>http://xym-loveit.github.io/2018/04/16/Docker-端口映射与容器互联/</id>
    <published>2018-04-16T08:11:59.000Z</published>
    <updated>2018-04-16T15:56:45.507Z</updated>
    
    <content type="html"><![CDATA[<p>在实践中会经常碰到需要多个服务组件容器共同协作的情况，这往往需要多个容器之间能够互相访问到对方的服务。除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。</p><h2 id="端口映射实现访问容器"><a href="#端口映射实现访问容器" class="headerlink" title="端口映射实现访问容器"></a>端口映射实现访问容器</h2><h3 id="1、从外部访问容器应用"><a href="#1、从外部访问容器应用" class="headerlink" title="1、从外部访问容器应用"></a>1、从外部访问容器应用</h3><p>在启动容器的时候，如果不指定对应的参数，在容器外部是无法通过网络来访问容器内的网络应用和服务的。当容器中运行一些网络应用，要让外部访问这些应用时，可以通过<code>-p</code>或<code>-P</code>参数来指定端口映射。当使用<code>-P</code>（大写的）标记时，Docker会随机映射一个端口到内部容器开放的网络端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -d -P training/webapp python app.py</span><br><span class="line">f2c1a06b94b49de281b403fa339d5975be5dd6fae662c664b300540c851c3565</span><br><span class="line"></span><br><span class="line">//ps命令后发现本地主机的32783被映射到了容器的5000端口。访问宿主主机的32783端口即可访问容器内的web应用</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                          PORTS                     NAMES</span><br><span class="line">f2c1a06b94b4        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 2 seconds                    0.0.0.0:32783-&gt;5000/tcp   inspiring_hawking</span><br><span class="line"></span><br><span class="line">//同样使用docker logs命令来查看应用信息</span><br><span class="line">[root@xxx ~]# docker logs -f  f2c</span><br><span class="line">Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</span><br><span class="line">172.17.0.1 - - [14/Apr/2018 16:13:50] &quot;GET / HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure><p><code>-p</code>（小写的）可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IP:HostPort:ContainerPort|IP::ContainerPort|HostPort:ContainerPort</span><br></pre></td></tr></table></figure><h3 id="2、映射所有接口地址"><a href="#2、映射所有接口地址" class="headerlink" title="2、映射所有接口地址"></a>2、映射所有接口地址</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">//使用HostPort:ContainerPort格式将本地的5000端口映射到容器的5000端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 training/webapp python app.py</span><br><span class="line">22c0bc271d46033c16f9ebdbc60ebf78938a1a0710bcede98afd15f887a92968</span><br><span class="line"></span><br><span class="line">//查看容器，注意端口映射栏</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                    NAMES</span><br><span class="line">22c0bc271d46        training/webapp     &quot;python app.py&quot;          8 seconds ago       Up 7 seconds                0.0.0.0:5000-&gt;5000/tcp   confident_saha</span><br><span class="line"></span><br><span class="line">//多次使用-p标记可以绑定多个端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 -p 8080:80  training/webapp python app.py</span><br><span class="line">c18177c0e1ec3a40c175cec0b7c165d8e0ff9576087c1734293e890357152919</span><br><span class="line"></span><br><span class="line">//查看容器，注意端口映射栏</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                                          NAMES</span><br><span class="line">c18177c0e1ec        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 2 seconds                0.0.0.0:5000-&gt;5000/tcp, 0.0.0.0:8080-&gt;80/tcp   suspicious_swartz</span><br></pre></td></tr></table></figure><h3 id="3、映射到指定地址的指定端口"><a href="#3、映射到指定地址的指定端口" class="headerlink" title="3、映射到指定地址的指定端口"></a>3、映射到指定地址的指定端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//只有自己访问自己</span><br><span class="line">[root@xxx ~]# docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py </span><br><span class="line">4da1f3ed9ee27026b9929e2b96ebd422e2bf6ab212b07ab8fbb8339c322fef70</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                      NAMES</span><br><span class="line">4da1f3ed9ee2        training/webapp     &quot;python app.py&quot;          4 seconds ago       Up 4 seconds                127.0.0.1:5000-&gt;5000/tcp   affectionate_elion</span><br></pre></td></tr></table></figure><h3 id="4、映射到指定地址的任意端口"><a href="#4、映射到指定地址的任意端口" class="headerlink" title="4、映射到指定地址的任意端口"></a>4、映射到指定地址的任意端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">//使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机会自动分配一个端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 127.0.0.1::5000 training/webapp python app.py</span><br><span class="line">ed9497ef017e2e90fac7e783c92ccde2f59c14f62d429190cb24c0dfa43eeefb</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                         PORTS                       NAMES</span><br><span class="line">ed9497ef017e        training/webapp     &quot;python app.py&quot;          5 seconds ago       Up 4 seconds                   127.0.0.1:32768-&gt;5000/tcp   wonderful_yonath</span><br><span class="line"></span><br><span class="line">//还可以使用udp标记来指定udp端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000/udp training/webapp python app.py</span><br><span class="line">4880a7d119f226591ad1b99ad0324d55d8e2caa98a399c9f426e6757fc7491c5</span><br><span class="line">[root@xym ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                         PORTS                              NAMES</span><br><span class="line">4880a7d119f2        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 3 seconds                   5000/tcp, 0.0.0.0:5000-&gt;5000/udp   gracious_williams</span><br><span class="line">b5257d2e</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">### 5、查看映射端口配置</span><br><span class="line"></span><br><span class="line">使用`docker port`命令来查看当前映射的端口配置，也可以查看到绑定的地址：</span><br></pre></td></tr></table></figure><p>[root@xxx ~]# docker port priceless_franklin 5000<br>0.0.0.0:5000</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 互联机制实现便捷互访</span><br><span class="line"></span><br><span class="line">容器的互联（linking）是一种让多个容器中应用进行快速交互的方式。它会在源和接受容器之间创建连接关系，接受容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址。</span><br><span class="line"></span><br><span class="line">### 1、自定义容器命名</span><br><span class="line"></span><br><span class="line">连接系统依据容器名称来执行。因此，首先需要定义好一个好记的容器名字。虽然当创建容器的时候，系统默认会分配一个名字，但自定义容器名字有两个好处：</span><br><span class="line"></span><br><span class="line">* 自定义的名字比较好记，比如一个web应用容器，我们可以给它起个名字叫web ，一目了然。</span><br><span class="line">* 当要连接其他容器时，即便重启，也可以使用容器名而不用改变，比如连接web容器到db容器。</span><br></pre></td></tr></table></figure><p>//使用–name参数自定义容器名称<br>[root@xxx ~]# docker run -d -p 5000:5000 –name web training/webapp python app.py<br>757d2ee95be01e2c509426c52bf5b4176ff7199eb654b5854ddf0e9b8412c044</p><p>//查看运行容器，注意NAMES栏<br>[root@xxx ~]# docker ps -l<br>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES<br>757d2ee95be0        training/webapp     “python app.py”     5 seconds ago       Up 4 seconds        0.0.0.0:5000-&gt;5000/tcp   web</p><p>//还可使用inspect –format “{{.Name}}“获取容器名字<br>[root@xxx ~]# docker inspect –format “{{.Name}}“ 757d2ee95be<br>/web</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在执行`docker run`的时候如果添加了`--rm`标记，则容器在终止后会立即删除。注意`--rm`和`-d`参数不能同时使用。</span><br><span class="line"></span><br><span class="line">### 2、容器互联</span><br><span class="line"></span><br><span class="line">使用`--link`参数可以让容器之间安全地进行交互。</span><br></pre></td></tr></table></figure><p>//创建一个db容器<br>[root@xxx ~]# docker run -d –name db training/postgres<br>Unable to find image ‘training/postgres:latest’ locally<br>latest: Pulling from training/postgres<br>a3ed95caeb02: Pull complete<br>6e71c809542e: Pull complete<br>2978d9af87ba: Pull complete<br>e1bca35b062f: Pull complete<br>500b6decf741: Pull complete<br>74b14ef2151f: Pull complete<br>7afd5ed3826e: Pull complete<br>3c69bb244f5e: Pull complete<br>d86f9ec5aedf: Pull complete<br>010fabf20157: Pull complete<br>Digest: sha256:a945dc6dcfbc8d009c3d972931608344b76c2870ce796da00a827bd50791907e<br>Status: Downloaded newer image for training/postgres:latest<br>3b48a3a82a86a52244527112a4a03e98e951c8edcdaedb3b63bc1a0775ac0315</p><p>//删除原来的web容器<br>[root@xxx ~]# docker rm -f web<br>web</p><p>//重建web容器，并让它连接到db容器,–link参数的格式为–link name:alias，其中name是要连接的容器名称，alias是这个连接的别名<br>[root@xxx ~]# docker run -d -P –name web –link db:db training/webapp python app.py<br>ca82ea2a2e5ad9b407d5c80fcfd6cd01f7e03be46864e5058b539075e858c626</p><p>//查看运行容器<br>[root@xxx ~]# docker ps<br>CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                     NAMES<br>ca82ea2a2e5a        training/webapp     “python app.py”          22 seconds ago       Up 21 seconds       0.0.0.0:32784-&gt;5000/tcp   web<br>3b48a3a82a86        training/postgres   “su postgres -c ‘/us…”   About a minute ago   Up About a minute   5432/tcp                  db</p><p>//查看接受容器(web)连接信息<br>[root@xxx ~]# docaker inspect –format “{{.HostConfig.Links}}“ web<br>[/db:/web/db]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Docker相当于在两个互联的容器之间创建了一个虚机通道，而且不用映射他们的端口在宿主主机上。在启动db容器的时候并没有使用`-p`和`-P`标记，从而避免了暴露数据库服务端口到外部网路上。</span><br><span class="line"></span><br><span class="line">Docker通过两种方式为容器公开连接信息：</span><br><span class="line"></span><br><span class="line">* 更新环境变量</span><br><span class="line">* 更新`/etc/hosts`文件</span><br><span class="line"></span><br><span class="line">使用env命令来查看web容器的环境变量：</span><br></pre></td></tr></table></figure><p>[root@xxx ~]# docker run –rm –name web2 –link db:db training/webapp env<br>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin<br>HOSTNAME=6f8232ea8d36<br>DB_PORT=tcp://172.17.0.3:5432<br>DB_PORT_5432_TCP=tcp://172.17.0.3:5432<br>DB_PORT_5432_TCP_ADDR=172.17.0.3<br>DB_PORT_5432_TCP_PORT=5432<br>DB_PORT_5432_TCP_PROTO=tcp<br>DB_NAME=/web2/db<br>DB_ENV_PG_VERSION=9.3<br>HOME=/root</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">其中`DB_`开头的环境变量时提供web容器连接db容器使用的，前缀采用大写的连接别名。除了环境变量之外，Docker还添加host信息到子容器的`/etc/hosts`文件，下面是子容器web的hosts文件：</span><br></pre></td></tr></table></figure><p>//创建容器，并进入bash<br>[root@xxx ~]# docker run -it –rm –link db:db training/webapp /bin/bash</p><p>//查看hosts配置<br>root@d64fd0fa99f0:/opt/webapp# cat /etc/hosts<br>172.17.0.3    db 3b48a3a82a86<br>172.17.0.4    d64fd0fa99f0</p><p>//查看db容器，发现其将容器id作为主机名<br>root@3b48a3a82a86:/# cat /etc/hosts<br>127.0.0.1    localhost<br>172.17.0.3    3b48a3a82a86</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这里有两个hosts信息，第一个是db容器的IP、主机名和容器id，第二个是web容器，web容器使用自己的id作为默认主机名。</span><br></pre></td></tr></table></figure><p>//安装ping命令<br>root@d64fd0fa99f0:/opt/webapp# apt-get install inetutils-ping<br>Unpacking inetutils-ping (2:1.9.2-1) …<br>Setting up inetutils-ping (2:1.9.2-1) …</p><p>//执行ping命令，测试与db容器的连通性<br>root@d64fd0fa99f0:/opt/webapp# ping db<br>PING db (172.17.0.3): 56 data bytes<br>64 bytes from 172.17.0.3: icmp_seq=0 ttl=64 time=0.267 ms<br>64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.314 ms<br>64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.260 ms<br>64 bytes from 172.17.0.3: icmp_seq=3 ttl=64 time=0.131 ms</p><p><code>`</code></p>]]></content>
    
    <summary type="html">
    
      Docker入门指南,端口映射和容器互联。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="docker容器端口映射" scheme="http://xym-loveit.github.io/tags/docker%E5%AE%B9%E5%99%A8%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84/"/>
    
      <category term="Pp命" scheme="http://xym-loveit.github.io/tags/Pp%E5%91%BD/"/>
    
      <category term="link选项" scheme="http://xym-loveit.github.io/tags/link%E9%80%89%E9%A1%B9/"/>
    
      <category term="容器互联原理" scheme="http://xym-loveit.github.io/tags/%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Hexo 跳过指定文件的渲染</title>
    <link href="http://xym-loveit.github.io/2018/04/16/Hexo-%E8%B7%B3%E8%BF%87%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9A%84%E6%B8%B2%E6%9F%93/"/>
    <id>http://xym-loveit.github.io/2018/04/16/Hexo-跳过指定文件的渲染/</id>
    <published>2018-04-16T06:52:03.000Z</published>
    <updated>2018-04-16T06:56:58.866Z</updated>
    
    <content type="html"><![CDATA[<p>关于hexo的<code>_config.yml</code>配置，官方文档中：</p><blockquote><p>skip_render：跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。</p></blockquote><p>但并没有说明具体该怎么配置，一番折腾后得以解决：</p><p>如果要跳过source文件夹下的<code>test.html</code>，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test.html</span><br></pre></td></tr></table></figure></p><p>注意，千万不要手贱加上个<code>/</code>写成<code>/test.html</code>，这里只能填相对于source文件夹的相对路径。</p><p>如果要忽略source下的test文件夹下所有文件，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test/*</span><br></pre></td></tr></table></figure></p><p>如果要忽略source下的test文件夹下<code>.html</code>文件，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">skip_render: test/*.html</span><br></pre></td></tr></table></figure></p><p>如果要忽略source下的test文件夹下所有文件和目录，可以这样配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test/**</span><br></pre></td></tr></table></figure><p>如果要忽略多个路径的文件或目录，可以这样配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skip_render:</span><br><span class="line">    - test.html</span><br><span class="line">    - test/*</span><br></pre></td></tr></table></figure><p><strong>Tips:</strong></p><p><a href="https://github.com/hexojs/hexo/issues/1146" target="_blank" rel="noopener">如何不处理source目录下某个子目录的所有文件，仅仅是将其copy到public目录中对应目录？</a></p>]]></content>
    
    <summary type="html">
    
      Hexo使用小技巧
    
    </summary>
    
      <category term="hexo笔记" scheme="http://xym-loveit.github.io/categories/hexo%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="hexo小技巧" scheme="http://xym-loveit.github.io/tags/hexo%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>Docker 数据管理</title>
    <link href="http://xym-loveit.github.io/2018/04/15/Docker-%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://xym-loveit.github.io/2018/04/15/Docker-数据管理/</id>
    <published>2018-04-15T11:04:53.000Z</published>
    <updated>2018-04-16T04:44:34.177Z</updated>
    
    <content type="html"><![CDATA[<p>在生产环境中使用Docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及到容器的数据管理操作。</p><p>容器中管理数据主要有两种方式：</p><p>数据卷（Data volumes）：容器内数据直接映射到本地主机环境；<br>数据卷容器（Data Volume Containers）：使用特定容器维护数据卷；</p><p>本文首先介绍如果在容器内创建数据卷，并且把本地的目录或文件挂载到容器内的数据卷中。接下来，会介绍如何使用数据卷容器，在容器和主机、容器和容器之间共享数据，并实现数据的备份和恢复。</p><h2 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h2><p>数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于linux中的mount操作。</p><p>数据卷可以提供很多有用的特性：  </p><ul><li>数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便</li><li>对数据卷内数据的修改会立马生效，无论是容器内操作还是本机操作</li><li>对数据卷的更新不会影响镜像，解耦了应用和数据</li><li>卷会一直存在，直到没有容器使用，可以安全的卸载它</li></ul><h3 id="1、在容器内创建一个数据卷"><a href="#1、在容器内创建一个数据卷" class="headerlink" title="1、在容器内创建一个数据卷"></a>1、在容器内创建一个数据卷</h3><p>在用<code>docker run</code>命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//使用training/webapp镜像创建一个web（name参数指定容器名称）容器，并创建一个数据卷挂载到容器的/webapp目录（-v 指定创建的数据卷）</span><br><span class="line">// -P参数是将容器服务暴露的端口自动映射到本地主机的临时端口上，python app.py(为执行的命令COMMAND和其对应的参数ARG)</span><br><span class="line">[root@xxx ~]# docker run -d -P --name web -v /webapp training/webapp python app.py</span><br><span class="line">Unable to find image &apos;training/webapp:latest&apos; locally</span><br><span class="line">latest: Pulling from training/webapp</span><br><span class="line">e190868d63f8: Pull complete </span><br><span class="line">909cd34c6fd7: Pull complete </span><br><span class="line">0b9bfabab7c1: Pull complete </span><br><span class="line">a3ed95caeb02: Pull complete </span><br><span class="line">10bbbc0fc0ff: Pull complete </span><br><span class="line">fca59b508e9f: Pull complete </span><br><span class="line">e7ae2541b15b: Pull complete </span><br><span class="line">9dd97ef58ce9: Pull complete </span><br><span class="line">a4c1b0cb7af7: Pull complete </span><br><span class="line">Digest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d</span><br><span class="line">Status: Downloaded newer image for training/webapp:latest</span><br><span class="line">e7816725b3d075b56410c9d64543a4febfe965e9a5d7cc1c8ea82c92c966f030</span><br><span class="line"></span><br><span class="line">//查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hub.c.163.com/public/ubuntu                       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">training/webapp                                   latest              6fae60ef3446        2 years ago         349MB  </span><br><span class="line"></span><br><span class="line">//查看运行态的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">e7816725b3d0        training/webapp     &quot;python app.py&quot;     21 seconds ago      Up 20 seconds       0.0.0.0:32768-&gt;5000/tcp   web</span><br></pre></td></tr></table></figure><h3 id="2、挂载一个主机目录作为数据卷"><a href="#2、挂载一个主机目录作为数据卷" class="headerlink" title="2、挂载一个主机目录作为数据卷"></a>2、挂载一个主机目录作为数据卷</h3><p>使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷（推荐方式）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//使用-v /src/webapp:/opt/webapp 加载主机/src/webapp目录到容器的/opt/webapp目录，python为command命令，app.py为运行参数</span><br><span class="line">[root@xxx webapp]# docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py</span><br><span class="line">1e0d2372472f8697a65c7da879a8807cf048bc4601b7136e354e4b0c87a7126f</span><br><span class="line"></span><br><span class="line">//查看运行的容器</span><br><span class="line">[root@xxx webapp]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">1e0d2372472f        training/webapp     &quot;python app.py&quot;     4 seconds ago       Up 3 seconds        0.0.0.0:32781-&gt;5000/tcp   web</span><br></pre></td></tr></table></figure><p>这个功能在进行测试的时候非常方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器中运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在,Docker会自动创建</p><p>Docker挂载数据卷的默认权限是读写（rw），用户也可以通过<code>ro</code>指定为只读。加了<code>ro</code>之后，容器内对所挂载数据卷内的数据就无法修改了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</span><br><span class="line">f5d7d04aa46c50db6696efa8554a9d344bbd3f13eb077be3c680a1ac89d509a0</span><br></pre></td></tr></table></figure><h3 id="3、挂载一个本地主机文件作为数据卷"><a href="#3、挂载一个本地主机文件作为数据卷" class="headerlink" title="3、挂载一个本地主机文件作为数据卷"></a>3、挂载一个本地主机文件作为数据卷</h3><p><code>-v</code>参数，也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//使用-v ~/.bash_history:/.bash_history，这样就可以记录在容器中输入过的命令历史了</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash</span><br><span class="line">root@43e50ea02e35:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">root@43e50ea02e35:/# history </span><br><span class="line">    1  ls</span><br><span class="line">    2  history</span><br></pre></td></tr></table></figure><p>挂载文件引起的问题：使用文件编辑工具，包括<code>vi</code>或者<code>sed --in-place</code>的时候，可能会造成文件<code>inode</code>的改变，从Docker1.1.0起，这会导致报错误信息。所以推荐的方式是直接挂载文件所在目录。</p><h2 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h2><p>如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。</p><p>首先创建一个数据卷容器<code>dbdata</code>,并在其中创建一个数据卷挂载到<code>/dbdata</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//创建一个数据卷容器</span><br><span class="line">[root@xxx ~]# docker run -it -v /dbdata --name dbdata ubuntu</span><br><span class="line"></span><br><span class="line">//查看目录</span><br><span class="line">root@d4bb57243d45:/# ls</span><br><span class="line">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p><p>然后，可以在其他容器中使用<code>--volumes-from</code>来挂载<code>dbdata</code>容器中的数据卷，例如创建<code>db1</code>和<code>db2</code>两个容器，并从<code>dbdata</code>容器挂载数据卷：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 创建2个容器挂载dbdata容器中的数据卷</span><br><span class="line">[root@xxx ~]# docker run -it --volumes-from dbdata --name db1 ubuntu</span><br><span class="line">[root@xxx ~]# docker run -it --volumes-from dbdata --name db2 ubuntu</span><br></pre></td></tr></table></figure><p>此时，容器db1和容器db2都挂载同一个数据卷到相同的<code>dbdata</code>目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。例如，在<code>dbdata</code>容器中创建一个<code>test</code>文件,在<code>db1</code>容器中可能查看到它：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在dbdata容器的数据卷中创建文件a</span><br><span class="line">root@9e90f695bcb8:/dbdata# touch a</span><br><span class="line">root@9e90f695bcb8:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root   14 Apr 14 10:02 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:01 ../</span><br><span class="line">-rw-r--r--.  1 root root    0 Apr 14 10:02 a</span><br><span class="line"></span><br><span class="line">//在db1容器中查看数据卷目录dbdata，也发现了文件a</span><br><span class="line">root@ab4426a23cb4:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root    6 Apr 14 10:01 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:02 ../</span><br><span class="line">root@ab4426a23cb4:/dbdata# ls     </span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">//db2结果和db1一样</span><br><span class="line">root@b4bea0f56613:/# cd dbdata/</span><br><span class="line">root@b4bea0f56613:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root   14 Apr 14 10:02 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:03 ../</span><br><span class="line">-rw-r--r--.  1 root root    0 Apr 14 10:02 a</span><br></pre></td></tr></table></figure><p>可以多次使用<code>--volumes-from</code>参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。  </p><p>使用<code>--volumes-from</code>参数所挂载数据卷的容器自身并不需要保持在运行状态。如果删除了挂载容器（包括dbdata、db1和bd2），数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显示使用<code>docker rm -v</code>命令来指定同时删除关联的数据卷。</p><h2 id="利用数据卷容器迁移数据"><a href="#利用数据卷容器迁移数据" class="headerlink" title="利用数据卷容器迁移数据"></a>利用数据卷容器迁移数据</h2><p>可以使用数据卷容器对其中的数据卷进行备份、恢复、以实现数据的迁移。</p><h3 id="1、备份"><a href="#1、备份" class="headerlink" title="1、备份"></a>1、备份</h3><p>使用如下命令来备份<code>dbdata</code>数据卷容器内的数据卷：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar -zcvf /backup/backup.tar /dbdata</span><br><span class="line">tar: Removing leading `/&apos; from member names</span><br><span class="line">/dbdata/</span><br><span class="line">/dbdata/a</span><br><span class="line"></span><br><span class="line">[root@xxx ~]#</span><br></pre></td></tr></table></figure><p>分析命令：  </p><ul><li>利用ubuntu镜像创建一个容器worker。对应命令参数：<code>docker run --name worker ubuntu</code></li><li>使用<code>--volumes-from dbdata</code>参数来让<code>worker</code>容器挂载<code>dbdata</code>容器的数据卷(即dbdata)。对应命令参数：<code>--volumes-from dbdata</code></li><li>使用 <code>-v $(pwd):/backup</code>参数来挂载本地的当前目录到<code>woker</code>容器的<code>/backup</code>目录。对应命令参数：<code>-v $(pwd):/backup</code></li><li><code>worker</code>容器启动后，使用<code>tar -zcvf /backup/backup.tar /dbdata</code>命令来将<code>/dbdata</code>下内容备份为容器内的<code>/backup/backup.tar</code>,即宿主主机当前目录下的<code>backup.tar</code>。</li></ul><h3 id="2、恢复"><a href="#2、恢复" class="headerlink" title="2、恢复"></a>2、恢复</h3><p>如果要将数据恢复到一个容器，可以按照下面步骤操作。首先创建一个带有数据卷的容器<code>dbdata2</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v /dbdata --name dbdata2 ubuntu /bin/bash</span><br></pre></td></tr></table></figure><p>然后创建另一个新的容器，挂载<code>dbdata2</code>的容器，并使用<code>untar</code>解压备份文件到所挂载的容器中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker run --volumes-from dbdata2 -v $(pwd):/backup busybox untar /backup/backup.tar</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Docker入门指南，通过数据卷（-v参数）和数据卷容器（--volumes-from参数）来做数据管理（使用数据卷容器做数据卷的备份和恢复）。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="docker数据管理" scheme="http://xym-loveit.github.io/tags/docker%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"/>
    
      <category term="-v选项" scheme="http://xym-loveit.github.io/tags/v%E9%80%89%E9%A1%B9/"/>
    
      <category term="--volumes-from选项" scheme="http://xym-loveit.github.io/tags/volumes-from%E9%80%89%E9%A1%B9/"/>
    
      <category term="数据卷备份" scheme="http://xym-loveit.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8D%B7%E5%A4%87%E4%BB%BD/"/>
    
      <category term="数据卷恢复" scheme="http://xym-loveit.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8D%B7%E6%81%A2%E5%A4%8D/"/>
    
  </entry>
  
  <entry>
    <title>Docker 基本操作之仓库</title>
    <link href="http://xym-loveit.github.io/2018/04/15/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E4%BB%93%E5%BA%93/"/>
    <id>http://xym-loveit.github.io/2018/04/15/Docker-基本操作之仓库/</id>
    <published>2018-04-15T07:43:29.000Z</published>
    <updated>2018-04-15T10:00:40.619Z</updated>
    
    <content type="html"><![CDATA[<p>仓库（Repository）是集中存放镜像的地方，分为公共仓库和私有仓库。一个容易与之混淆的概念是注册服务器（Registry）。实际上注册服务器是存放仓库的具体服务器，一个注册服务器上可以有多个仓库，而每个仓库下面可以有多个镜像。从这方面来说，可将仓库看做一个具体的项目或目录。例如对于仓库地址<code>private-docker.com/ubuntu</code>来说,<code>private-docker.com</code>是注册服务器地址，<code>ubuntu</code>是仓库名。</p><h2 id="Docker-Hub公共镜像"><a href="#Docker-Hub公共镜像" class="headerlink" title="Docker Hub公共镜像"></a>Docker Hub公共镜像</h2><p>访问地址：<a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a></p><h3 id="1、登录仓库"><a href="#1、登录仓库" class="headerlink" title="1、登录仓库"></a>1、登录仓库</h3><p>命令格式：<code>docker login [OPTIONS] [SERVER]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --password string   Password</span><br><span class="line">      --password-stdin    Take the password from stdin</span><br><span class="line">  -u, --username string   Username</span><br><span class="line">  </span><br><span class="line">//通过存储的登录信息，直接确认登录  </span><br><span class="line">[root@xxx ~]# docker login</span><br><span class="line">Authenticating with existing credentials...</span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><h3 id="2、基本操作"><a href="#2、基本操作" class="headerlink" title="2、基本操作"></a>2、基本操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查找官方仓库中的镜像，搜索关键词centos</span><br><span class="line">[root@xxx ~]# docker search centos</span><br><span class="line">NAME                               DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">centos                             The official build of CentOS.                   4188                [OK]                </span><br><span class="line">ansible/centos7-ansible            Ansible on Centos7                              108                                     [OK]</span><br><span class="line">jdeathe/centos-ssh                 CentOS-6 6.9 x86_64 / CentOS-7 7.4.1708 x86_…   94                                      [OK]</span><br><span class="line">consol/centos-xfce-vnc             Centos container with &quot;headless&quot; VNC session…   52                                      [OK]</span><br><span class="line">imagine10255/centos6-lnmp-php56    centos6-lnmp-php56                              40                                      [OK]</span><br><span class="line">tutum/centos                       Simple CentOS docker image with SSH access      38                                      </span><br><span class="line">gluster/gluster-centos             Official GlusterFS Image [ CentOS-7 +  Glust…   26                                      [OK]</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">//下载centos镜像</span><br><span class="line">[root@xxx ~]# docker pull centos</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">469cfcc7a4b3: Pull complete </span><br><span class="line">Digest: sha256:989b936d56b1ace20ddf855a301741e52abca38286382cba7f44443210e96d16</span><br><span class="line">Status: Downloaded newer image for centos:latest</span><br></pre></td></tr></table></figure><p>根据search结果，可将镜像资源分为两类。一种是类似centos这样的镜像，称为基础或根镜像。这些镜像是由docker公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。还有一种类型，比如<code>ansible/centos7-ansible</code>镜像，它是由docker用户ansible创建并维护的，带有用户名称前缀，表明是某用户下的某仓库。可以通过用户名称前缀<code>user_name/镜像名</code>来指定使用某个用户提供的镜像。另外，在查找的时候通过-s N参数可以指定仅显示评价为N星级以上的镜像。</p><h3 id="3、自动创建"><a href="#3、自动创建" class="headerlink" title="3、自动创建"></a>3、自动创建</h3><p>自动创建（Automated Builds）功能对于需要经常升级镜像内程序来说，十分方便。有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。而自动创建允许用户通过Docker Hub指定跟踪一个目标网站（目前支持Github或Bitbucket）上的项目，一旦项目发生新的提交，则自动执行创建。</p><p>要配置自动创建，包括如下步骤：</p><ul><li>1)创建并登陆Docker Hub，以及目标网站；在目标网站中连接账户到Docker Hub。</li><li>2)在Docker Hub中配置一个“自定创建”</li><li>3)选取一个目标网站中的项目（需要含Dockerfile）和分支；</li><li>4)指定Dockerfile位置，并提交创建</li></ul><p>之后，可以在Docker Hub的“自动创建”页面中跟踪每次创建的状态。</p><h2 id="国内时速云镜像"><a href="#国内时速云镜像" class="headerlink" title="国内时速云镜像"></a>国内时速云镜像</h2><p>访问地址：<a href="https://hub.tenxcloud.com/" target="_blank" rel="noopener">https://hub.tenxcloud.com/</a></p><h3 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//下载镜像</span><br><span class="line">[root@xxx ~]# docker pull index.tenxcloud.com/tenxcloud/centos</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from tenxcloud/centos</span><br><span class="line">a3ed95caeb02: Pull complete </span><br><span class="line">5989106db7fb: Pull complete </span><br><span class="line">c9d12ea9fc45: Pull complete </span><br><span class="line">68317fcc0aa1: Pull complete </span><br><span class="line">83ef48200e63: Pull complete </span><br><span class="line">c6eb26bf54de: Pull complete </span><br><span class="line">1bcf3170bbc2: Pull complete </span><br><span class="line">Digest: sha256:190cbd5234c4aad993b852d5f118ecfba5499adc6f752026938bce0eca754b0c</span><br><span class="line">Status: Downloaded newer image for index.tenxcloud.com/tenxcloud/centos:latest</span><br><span class="line"></span><br><span class="line">//查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xymtest                                           0.1                 8a758d16a99b        22 hours ago        113MB</span><br><span class="line">ubuntu                                            latest              c9d990395902        32 hours ago        113MB</span><br><span class="line">centos                                            latest              e934aafc2206        7 days ago          199MB</span><br><span class="line">registry                                          latest              d1fd7d86a825        3 months ago        33.3MB</span><br><span class="line">index.tenxcloud.com/tenxcloud/centos              latest              6e7516266d96        23 months ago       310MB</span><br></pre></td></tr></table></figure><h2 id="搭建本地私有仓库"><a href="#搭建本地私有仓库" class="headerlink" title="搭建本地私有仓库"></a>搭建本地私有仓库</h2><h3 id="1、使用registry镜像创建私有仓库"><a href="#1、使用registry镜像创建私有仓库" class="headerlink" title="1、使用registry镜像创建私有仓库"></a>1、使用registry镜像创建私有仓库</h3><p>安装Docker后，可以通过官方提供的<code>registry</code>镜像来简单搭建一套本地私有仓库环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在本地启动registry镜像，作为私有服务器，监听5000端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 registry</span><br><span class="line">Unable to find image &apos;registry:latest&apos; locally</span><br><span class="line">latest: Pulling from library/registry</span><br><span class="line">81033e7c1d6a: Pull complete </span><br><span class="line">b235084c2315: Pull complete </span><br><span class="line">c692f3a6894b: Pull complete </span><br><span class="line">ba2177f3a70e: Pull complete </span><br><span class="line">a8d793620947: Pull complete </span><br><span class="line">Digest: sha256:672d519d7fd7bbc7a448d17956ebeefe225d5eb27509d8dc5ce67ecb4a0bce54</span><br><span class="line">Status: Downloaded newer image for registry:latest</span><br><span class="line">67083c200be2f6a043377a9b4d69af24d0ba9c58a140b753634f5be4ede67464</span><br></pre></td></tr></table></figure><p>这将自动下载并启动一个<code>registry</code>容器，创建本地的私有仓库服务。默认情况下，会将仓库创建在容器的<code>/tmp/registry</code>目录下。可以通过-v参数来将镜像文件存放在本地的指定路径。例如以下实例将上传的镜像放到<code>/opt/data/registry</code>目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在本地启动registry镜像，作为私有服务器，监听5000端口,并指定本地目录数据卷/opt/data/registry，映射容器内/tmp/registry目录</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry</span><br><span class="line">5b9a1ad53352c4e3a6f5bf7d70ef9a6d573cb4da064fb24f8f406444d125555c</span><br></pre></td></tr></table></figure><h3 id="2、管理私有仓库"><a href="#2、管理私有仓库" class="headerlink" title="2、管理私有仓库"></a>2、管理私有仓库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//标记镜像</span><br><span class="line">[root@xxx ~]# docker tag xymtest:0.1 192.168.206.128:5000/test</span><br><span class="line"></span><br><span class="line">//上传镜像</span><br><span class="line">[root@xxx ~]# docker push 192.168.206.128:5000/test</span><br><span class="line">The push refers to repository [192.168.206.128:5000/test]</span><br><span class="line">Get https://192.168.206.128:5000/v2/: http: server gave HTTP response to HTTPS client</span><br><span class="line"></span><br><span class="line">//编辑daemon.json,配置，&quot;insecure-registries&quot;:[&quot;192.168.206.128:5000&quot;]，表示信任这个私有仓库，不进行安全证书检查</span><br><span class="line">[root@xxx docker]# pwd</span><br><span class="line">/etc/docker</span><br><span class="line">[root@xxx docker]# cat daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  //表示信任这个私有仓库，不进行安全证书检查</span><br><span class="line">  &quot;insecure-registries&quot;:[&quot;192.168.206.128:5000&quot;],</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://4vehewku.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//重启docker 服务</span><br><span class="line">[root@xxx docker]# systemctl restart docker</span><br><span class="line"></span><br><span class="line">//推送本地镜像到私有仓库</span><br><span class="line">[root@xxx docker]# docker push 192.168.206.128:5000/test</span><br><span class="line">The push refers to repository [192.168.206.128:5000/test]</span><br><span class="line">6d7697f5e458: Pushed </span><br><span class="line">a8de0e025d94: Pushed </span><br><span class="line">a5e66470b281: Pushed </span><br><span class="line">ac7299292f8b: Pushed </span><br><span class="line">e1a9a6284d0d: Pushed </span><br><span class="line">fccbfa2912f0: Pushed </span><br><span class="line">latest: digest: sha256:46d25028e0eb194348b8b1256b1375238b44116a018de67f3318a1bb9954ee9d size: 1564</span><br><span class="line"></span><br><span class="line">//下载刚刚上传的，私有仓库镜像</span><br><span class="line">[root@xxx docker]# docker pull 192.168.206.128:5000/test</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from test</span><br><span class="line">Digest: sha256:46d25028e0eb194348b8b1256b1375238b44116a018de67f3318a1bb9954ee9d</span><br><span class="line">Status: Downloaded newer image for 192.168.206.128:5000/test:latest</span><br></pre></td></tr></table></figure><p>如果要使用安全证书，我们也可以从较知名的CA服务商（如<code>verisign</code>）申请公开的<code>SSL/TLS</code>证书，或者使用<code>openssl</code>等软件自行生成。</p>]]></content>
    
    <summary type="html">
    
      Docker入门指南，仓库概念及基本操作。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="pull命令" scheme="http://xym-loveit.github.io/tags/pull%E5%91%BD%E4%BB%A4/"/>
    
      <category term="search命令" scheme="http://xym-loveit.github.io/tags/search%E5%91%BD%E4%BB%A4/"/>
    
      <category term="docker仓库" scheme="http://xym-loveit.github.io/tags/docker%E4%BB%93%E5%BA%93/"/>
    
      <category term="login命令" scheme="http://xym-loveit.github.io/tags/login%E5%91%BD%E4%BB%A4/"/>
    
      <category term="本地搭建私有仓库配置" scheme="http://xym-loveit.github.io/tags/%E6%9C%AC%E5%9C%B0%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E9%85%8D%E7%BD%AE/"/>
    
      <category term="时速云镜像仓库" scheme="http://xym-loveit.github.io/tags/%E6%97%B6%E9%80%9F%E4%BA%91%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Docker 基本操作之容器</title>
    <link href="http://xym-loveit.github.io/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E5%AE%B9%E5%99%A8/"/>
    <id>http://xym-loveit.github.io/2018/04/13/Docker-基本操作之容器/</id>
    <published>2018-04-13T11:42:56.000Z</published>
    <updated>2018-04-16T16:11:22.620Z</updated>
    
    <content type="html"><![CDATA[<p>容器是Docker的另一个核心概念。简单来说，容器时镜像的一个运行实例。所不同的是，镜像是静态只读文件，而容器带有运行时需要的可写文件层。如果认为虚拟机是模拟运行的一整套操作系统（包括内核、应用运行环境和其他系统环境）和跑在上面的应用，那么Docker容器就是独立运行的一个（或一组）应用，以及它们必须的运行环境。</p><h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><h3 id="1、新建容器"><a href="#1、新建容器" class="headerlink" title="1、新建容器"></a>1、新建容器</h3><p>命令格式：<code>docker create [OPTIONS] IMAGE [COMMAND] [ARG...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --add-host list                  Add a custom host-to-IP mapping (host:ip)</span><br><span class="line">  -a, --attach list                    Attach to STDIN, STDOUT or STDERR</span><br><span class="line">      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)</span><br><span class="line">      --blkio-weight-device list       Block IO weight (relative device weight) (default [])</span><br><span class="line">      --cap-add list                   Add Linux capabilities</span><br><span class="line">      ...</span><br></pre></td></tr></table></figure><p>Create命令和后续的run命令支持的选项都十分复杂，主要包括如下几大类：与容器运行模式相关、与容器和环境配置相关、与容器资源限制和安全保护相关。</p><p>Create命令与容器运行模式相关的选项见下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b1-i_epub.jpg" alt="Create命令与容器运行模式相关的选项"></p><p>Create命令与容器环境和配置相关选项如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b2-i_epub.jpg" alt="Create命令与容器环境和配置相关选项1"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b2x-i_epub.jpg" alt="Create命令与容器环境和配置相关选项2"></p><p>Create命令与容器资源限制和安全保护相关选项如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b3-i_epub.jpg" alt="Create命令与容器资源限制和安全保护相关选项1"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b3x-i_epub.jpg" alt="Create命令与容器资源限制和安全保护相关选项2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//根据镜像创建一个容器</span><br><span class="line">[root@xxx /]# docker create -it registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04 </span><br><span class="line">d26cbeecf22d92fdff515a9bb8146521c8e4c6ea76cf7baab5abebb4b31dfc52</span><br><span class="line"></span><br><span class="line">//查看docker本地所有容器,注意状态为Created</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   8 seconds ago       Created                                 practical_wright</span><br><span class="line"></span><br><span class="line">//使用start启动docker容器</span><br><span class="line">[root@xxx /]# docker start d26</span><br><span class="line">d26</span><br><span class="line"></span><br><span class="line">//查看docker本地所有容器,注意状态为Up</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   41 seconds ago      Up 2 seconds                            practical_wright</span><br></pre></td></tr></table></figure><p>其他比较重要的选项还包括：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-l，--label=[]：以键值对方式指定容器的标签信息;</span><br><span class="line"></span><br><span class="line">--label-file=[]：从文件读取标签信息。</span><br></pre></td></tr></table></figure><h3 id="2、启动容器"><a href="#2、启动容器" class="headerlink" title="2、启动容器"></a>2、启动容器</h3><p>命令格式：<code>docker start [OPTIONS] CONTAINER [CONTAINER...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Exited</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS                       PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   14 minutes ago      Exited (137) 5 seconds ago                       practical_wright</span><br><span class="line"></span><br><span class="line">//使用start启动容器</span><br><span class="line">[root@xxx /]# docker start d26cb</span><br><span class="line">d26cb</span><br><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Up</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   14 minutes ago      Up 2 seconds</span><br></pre></td></tr></table></figure><h3 id="3、新建并启动容器"><a href="#3、新建并启动容器" class="headerlink" title="3、新建并启动容器"></a>3、新建并启动容器</h3><p>除了创建容器后通过start命令来启动，也可以直接新建并启动容器。所需要的命令主要为<code>docker run</code>,等价于先执行<code>docker create</code>命令，再执行<code>docker start</code>命令。<br>例如，下面的命令输出一个“Hello World”，之后容器自动终止：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//创建容器并执行一个输出命令</span><br><span class="line">[root@xxx /]# docker run ubuntu:latest /bin/echo &quot;Hello World&quot;</span><br><span class="line">Hello World</span><br><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Exited</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">3fa47db4c105        ubuntu:latest       &quot;/bin/echo &apos;Hello Wo…&quot;   8 seconds ago       Exited (0) 7 seconds ago                       elated_goldwasser</span><br></pre></td></tr></table></figure><p>这跟在本地直接执行<code>/bin/echo &quot;Hello World&quot;</code>几乎感觉不出任何区别。当利用<code>docker run</code>来创建并启动容器时，Docker在后台运行的标准操作：  </p><ul><li>检查本地是否存在指定的镜像，不存在就从共有仓库下载；</li><li>利用镜像创建容器，并启动该容器；</li><li>分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层；</li><li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中；</li><li>从网桥的地址池配置一个IP地址给容器；</li><li>执行用户指定的应用程序</li><li>执行完毕后容器被自动终止</li></ul><p>启动一个终端，并允许用户进行交互：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//其中-t选项当Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。</span><br><span class="line">[root@xxx /]# docker run -it ubuntu:latest /bin/bash</span><br><span class="line">root@21536661367e:/# pwd</span><br><span class="line">/</span><br><span class="line"></span><br><span class="line">//用户可以在交互模式下输入系统命令进行操作</span><br><span class="line">root@21536661367e:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line"></span><br><span class="line">//用户可以在交互模式下输入系统命令进行操作，使用ps可以看到系统只运行了bash应用，并没有运行其他无关的进程</span><br><span class="line">root@21536661367e:/# ps</span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line">     1 pts/0    00:00:00 bash</span><br><span class="line">    10 pts/0    00:00:00 ps</span><br><span class="line">    </span><br><span class="line">//用户可以输入exit或ctrl+d来退出容器</span><br><span class="line">root@21536661367e:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@xxx /]#</span><br></pre></td></tr></table></figure><p>对于所创建的bash容器，当使用exit命令退出之后，容器就自动处于退出（Exited）状态了。这是因为对Docker容器来说，当运行的应用退出后，容器也就没有必要继续运行了。<br>某些时候，执行<code>docker run</code>会出错，因为命令无法正常执行容器会直接退出，此时可以查看退出的错误代码。  </p><ul><li>125：Docker daemon执行出错，例如指定了不支持的Docker命令参数；</li><li>126：所指定的命令无法执行，例如权限出错。</li><li>127：容器内命令无法找到；</li></ul><p>命令执行出错后，会默认返回错误码。</p><h3 id="4、守护态运行"><a href="#4、守护态运行" class="headerlink" title="4、守护态运行"></a>4、守护态运行</h3><p>更多的时候，需要让Docker容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加-d参数来实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//-d参数以后台模式启动Docker，返回容器id</span><br><span class="line">[root@xxx ~]# docker run -d ubuntu:latest /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;</span><br><span class="line">5d4cfe5b4b6109fd8df8717fcd87790e7692f70d7e8e8d7590ba4c269f6dd717</span><br><span class="line"></span><br><span class="line">//通过docker ps查看运行的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   13 seconds ago      Up 12 seconds                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//使用docker logs命令获取容器输出信息</span><br><span class="line">[root@xxx ~]# docker logs 5d4c</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><h2 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h2><p>命令格式：<code>docker stop [OPTIONS] CONTAINER [CONTAINER...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -t, --time int   Seconds to wait for stop before killing it (default 10)</span><br></pre></td></tr></table></figure></p><p>原理：首先向容器发送SIGTERM信号,等待一段超时时间（默认10秒）后，再发送SIGKILL信号来终止容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//终止前</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   16 minutes ago      Up 16 minutes                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//发送终止命令</span><br><span class="line">[root@xxx ~]# docker stop 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//终止后状态为Exited</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                        PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   18 minutes ago      Exited (137) 56 seconds ago                       thirsty_lewin</span><br></pre></td></tr></table></figure></p><ul><li>使用<code>docker kill</code>命令会直接发送SIGKILL信号来强行终止容器。</li><li>当容器中指定的应用终结时，容器也会自动终止。</li><li>使用<code>docker start</code>可以重新启动处于终止状态的容器。</li><li>使用<code>docker restart</code>命令会将一个运行态的容器先终止，然后再重新启动</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//重新启动已终止的容器</span><br><span class="line">[root@xxx ~]# docker start 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   25 minutes ago      Up 6 seconds                            thirsty_lewin</span><br><span class="line"></span><br><span class="line">//发送SIGKILL信号来强行终止容器</span><br><span class="line">[root@xxx ~]# docker kill 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line"></span><br><span class="line">//重启容器</span><br><span class="line">[root@xxx ~]# docker restart 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   25 minutes ago      Up 1 second                             thirsty_lewin</span><br></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><p>在使用-d参数时，容器启动后会进入后台，用户无法看到容器中的信息，也无法操作。这个时候如果要进入容器进行操作，有三种方法：</p><h3 id="1、使用attach命令"><a href="#1、使用attach命令" class="headerlink" title="1、使用attach命令"></a>1、使用attach命令</h3><p>命令格式：<code>docker attach [OPTIONS] CONTAINER</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --detach-keys string   指定退出attach模式的快捷键序列，默认是ctrl+q ctrl+p;</span><br><span class="line">      --no-stdin             是否关闭标准输入，默认是保持打开</span><br><span class="line">      --sig-proxy            是否代理收到的系统信号给应用进程，默认为true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -itd ubuntu /bin/bash</span><br><span class="line">3535fd6c5ccab3c4d4737c1385ac18c36bd190c129c70c664fbf8c62a1707e67</span><br><span class="line">[root@xxx ~]# docker attach 3535</span><br><span class="line">root@3535fd6c5cca:/# </span><br><span class="line">root@3535fd6c5cca:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p><p>attach命令缺点：当多个窗口同时用attach命令连到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时，其他窗口也无法执行操作了。</p><h3 id="2、使用exec命令（exec命令用于从外部运行容器内部的命令）"><a href="#2、使用exec命令（exec命令用于从外部运行容器内部的命令）" class="headerlink" title="2、使用exec命令（exec命令用于从外部运行容器内部的命令）"></a>2、使用exec命令（exec命令用于从外部运行容器内部的命令）</h3><p>命令格式：<code>docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -d, --detach               以后台模式运行命令</span><br><span class="line">      --detach-keys string   Override the key sequence for detaching a container</span><br><span class="line">  -e, --env list             设置环境变量</span><br><span class="line">  -i, --interactive          打开标准输入接受用户输入命令，默认为false</span><br><span class="line">      --privileged           Give extended privileges to the command</span><br><span class="line">  -t, --tty                  分配一个伪终端，默认为false</span><br><span class="line">  -u, --user string          执行命令的用户名或ID</span><br><span class="line">  -w, --workdir string       Working directory inside the container</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up About a minute                       thirsty_lewin</span><br><span class="line"></span><br><span class="line">//使用exec进入后台运行的镜像中</span><br><span class="line">[root@xxx ~]# docker exec -it thirsty_lewin /bin/bash</span><br><span class="line">root@5d4cfe5b4b61:/#</span><br></pre></td></tr></table></figure></p><p>通过以上可以看出，一个bash终端被打开了，在不影响容器内其他应用的前提下，用户可以很容易与容器进行交互。</p><p>注意：通过指定<code>-it</code>参数来保持标准输入打开，并且分配一个伪终端。通过<code>exec</code>命令对容器执行操作是最为推荐的方式。</p><h3 id="3、使用第三方nsenter工具"><a href="#3、使用第三方nsenter工具" class="headerlink" title="3、使用第三方nsenter工具"></a>3、使用第三方<code>nsenter</code>工具</h3><p>在<code>util-linux</code>软件包版本2.23+中包含<code>nsenter</code>工具，如果系统中的<code>util-linux</code>包没有该命令，可以按照下面方式从源码安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ cd /emp;curl https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/v2.32/util-linux-2.32.tar.gz | tar -zxvf;</span><br><span class="line">cd util-linux-2.32;</span><br><span class="line"></span><br><span class="line">$ ./configure --without-ncurses</span><br><span class="line"></span><br><span class="line">$ make nsenter &amp;&amp; cp nsenter /usr/local/bin</span><br></pre></td></tr></table></figure><p>为了使用<code>nsenter</code> 连接到容器，还需要找到容器PID，可以通过下面的命令获取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//获取容器运行PID</span><br><span class="line">PID=$(docker inspect --format&quot;&#123;% raw %&#125;&#123;&#123;.State.Pid&#125;&#125;&#123;% endraw %&#125;&quot; &lt;container&gt;)</span><br><span class="line"></span><br><span class="line">//通过PID，连接到容器：</span><br><span class="line">`nsenter --target $PID --mount --uts --ipc --net --pid`</span><br></pre></td></tr></table></figure><p>下面使用完整的命令执行该操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up 4 minutes                            thirsty_lewin</span><br><span class="line"></span><br><span class="line">//查看运行容器进程PID</span><br><span class="line">[root@xxx ~]# docker inspect --format &quot;&#123;% raw %&#125;&#123;&#123;.State.Pid&#125;&#125;&#123;% endraw %&#125;&quot; thirsty_lewin</span><br><span class="line">18637</span><br><span class="line"></span><br><span class="line">//进入容器</span><br><span class="line">[root@xxx ~]# nsenter --target 18637 --mount --uts --ipc --net --pid</span><br><span class="line">mesg: ttyname failed: No such file or directory</span><br><span class="line"></span><br><span class="line">//查看用户</span><br><span class="line">root@5d4cfe5b4b61:~# w</span><br><span class="line"> 15:22:55 up 15:59,  0 users,  load average: 0.03, 0.04, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br></pre></td></tr></table></figure><h2 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h2><p>可以使用docker rm命令来删除处于终止或退出状态的容器。</p><p>命令格式：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -f, --force     强制终止并删除一个运行中的容器</span><br><span class="line">  -l, --link      删除容器的连接但保留容器</span><br><span class="line">  -v, --volumes   删除容器挂载的数据卷</span><br><span class="line"></span><br><span class="line">//查看运行中的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up 14 minutes                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//删除运行状态的容器</span><br><span class="line">[root@xxx ~]# docker rm 5d4c</span><br><span class="line">Error response from daemon: You cannot remove a running container 5d4cfe5b4b6109fd8df8717fcd87790e7692f70d7e8e8d7590ba4c269f6dd717. Stop the container before attempting removal or force remove</span><br><span class="line"></span><br><span class="line">//强制删除运行状态的容器</span><br><span class="line">[root@xxx ~]# docker rm -f 5d4c</span><br><span class="line">5d4c</span><br></pre></td></tr></table></figure><h2 id="导入和导出容器"><a href="#导入和导出容器" class="headerlink" title="导入和导出容器"></a>导入和导出容器</h2><p>某些时候，需要将容器从一个系统迁移到另外一个系统，此时可以使用docker的导入和导出功能。</p><h3 id="1、导出容器"><a href="#1、导出容器" class="headerlink" title="1、导出容器"></a>1、导出容器</h3><p>导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态。<br>命令格式：<code>docker export [OPTIONS] CONTAINER</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -o, --output string  指定导出的tar归档文件，也可直接通过重定向来实现。</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">//显示所有容器</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                    PORTS               NAMES</span><br><span class="line">684d1d0dc403        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   19 seconds ago      Up 18 seconds                                 vigorous_brahmagupta</span><br><span class="line">3fa47db4c105        ubuntu:latest       &quot;/bin/echo &apos;Hello Wo…&quot;   11 hours ago        Exited (0) 11 hours ago                       elated_goldwasser</span><br><span class="line"></span><br><span class="line">//将运行中的容器导出tar文件</span><br><span class="line">[root@xx ~]# docker export -o test_for_run.tar 684d</span><br><span class="line"></span><br><span class="line">//将已经退出的容器导出tar文件</span><br><span class="line">[root@xxx ~]# docker export 3fa4 &gt; test_for_stop.tar</span><br></pre></td></tr></table></figure><p>之后，可将导出的tar文件传输到其他机器上，然后再通过导入命令导入到系统中，从而实现容器的迁移。</p><h3 id="2、导入容器"><a href="#2、导入容器" class="headerlink" title="2、导入容器"></a>2、导入容器</h3><p>导出的文件又可以使用<code>docker import</code>命令导入变成镜像。<br>命令格式：<code>docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -c, --change list      在导入的同时执行对容器进行修改的Dockerfile指令</span><br><span class="line">  -m, --message string   Set commit message for imported image</span><br><span class="line"></span><br><span class="line">//将tar文件导入系统中</span><br><span class="line">[root@xxx ~]# docker import test_for_run.tar xym/ubuntu:1.0</span><br><span class="line">sha256:f916030e78e9046defa752bfc32a99b96460e098d3ee1cab1a5048150255d27e</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xym/ubuntu                                        1.0                 f916030e78e9        2 seconds ago       85.8MB</span><br><span class="line">centos-7                                          import              be5e039acd03        19 hours ago        435MB</span><br></pre></td></tr></table></figure><p>之前镜像章节中介绍过使用<code>docker load</code>命令来导入一个镜像文件，与<code>docker import</code>命令十分类似。</p><p>实际上，既可以使用<code>docker load</code>命令来导入镜像存储文件到本地镜像库，也可以使用<code>docker import</code>命令来导入一个容器快照到本地镜像库。</p><p>这二者的区别在于容器快照文件将丢弃所有历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。此外，从容器快照文件导入时可以重新指定标签。</p>]]></content>
    
    <summary type="html">
    
      Docker入门指南，容器各种操作命令。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="rm命令" scheme="http://xym-loveit.github.io/tags/rm%E5%91%BD%E4%BB%A4/"/>
    
      <category term="import命令" scheme="http://xym-loveit.github.io/tags/import%E5%91%BD%E4%BB%A4/"/>
    
      <category term="docker容器" scheme="http://xym-loveit.github.io/tags/docker%E5%AE%B9%E5%99%A8/"/>
    
      <category term="create命令" scheme="http://xym-loveit.github.io/tags/create%E5%91%BD%E4%BB%A4/"/>
    
      <category term="start命令" scheme="http://xym-loveit.github.io/tags/start%E5%91%BD%E4%BB%A4/"/>
    
      <category term="run命令" scheme="http://xym-loveit.github.io/tags/run%E5%91%BD%E4%BB%A4/"/>
    
      <category term="stop命令" scheme="http://xym-loveit.github.io/tags/stop%E5%91%BD%E4%BB%A4/"/>
    
      <category term="restart命令" scheme="http://xym-loveit.github.io/tags/restart%E5%91%BD%E4%BB%A4/"/>
    
      <category term="attach命令" scheme="http://xym-loveit.github.io/tags/attach%E5%91%BD%E4%BB%A4/"/>
    
      <category term="exec命令" scheme="http://xym-loveit.github.io/tags/exec%E5%91%BD%E4%BB%A4/"/>
    
      <category term="export命令" scheme="http://xym-loveit.github.io/tags/export%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Docker 基本操作之镜像</title>
    <link href="http://xym-loveit.github.io/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E9%95%9C%E5%83%8F/"/>
    <id>http://xym-loveit.github.io/2018/04/13/Docker-基本操作之镜像/</id>
    <published>2018-04-13T01:24:54.000Z</published>
    <updated>2018-04-14T16:55:47.390Z</updated>
    
    <content type="html"><![CDATA[<h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><p>命令格式：<code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --all-tags               是否获取仓库中所有镜像，默认为否</span><br><span class="line">      --disable-content-trust  是否跳过镜像校验，默认为是</span><br></pre></td></tr></table></figure></p><ul><li>如果不显示指定TAG，默认拉取latest</li><li>镜像文件是由若干层（layer）组成，层的唯一标识是以一个256比特的64个十六进程字符构成。使用docker pull下载时会获取各层的信息。当不同的镜像包括相同的层时，本地仅会存储层的一份内容，减小了需要的存储空间。</li><li>当仓库地址（registry，注册服务器）省略不写时，默认使用<code>docker hub</code>服务器，如果从非官方仓库下载，则需要在仓库名称前指定完整的镜像注册服务器地址（e.g. hub.c.163.com/library/）。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//去网易蜂巢拉取镜像仓库  </span><br><span class="line">[root@xxx ~]# docker pull hub.c.163.com/library/memcached:latest </span><br><span class="line">latest: Pulling from library/memcached</span><br><span class="line">810fd2d89f8f: Pull complete </span><br><span class="line">0f1e2d8abe76: Pull complete </span><br><span class="line">b9608bffd4d0: Pull complete </span><br><span class="line">a6554c2d9f43: Pull complete </span><br><span class="line">40661d641679: Pull complete </span><br><span class="line">Digest: sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Status: Downloaded newer image for hub.c.163.com/library/memcached:latest</span><br></pre></td></tr></table></figure><h2 id="列出镜像"><a href="#列出镜像" class="headerlink" title="列出镜像"></a>列出镜像</h2><p>命令格式：<code>docker images [OPTIONS] [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --all             显示所有镜像（包括临时文件），默认为否</span><br><span class="line">      --digests         列出镜像的数字摘要值，默认为否</span><br><span class="line">  -f, --filter filter   过滤列出的镜像</span><br><span class="line">      --format string   控制输出格式</span><br><span class="line">      --no-trunc        对输出结果中太长部分是否进行截断，如镜像ID信息，默认为是</span><br><span class="line">  -q, --quiet           仅输出ID信息，默认为否</span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------------------------------</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        About an hour ago   435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        About an hour ago   222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        32 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><ul><li>REPOSITORY:来源于哪个仓库，比如Ubuntu仓库用来保存Ubuntu系列的基础镜像。</li><li>TAG：镜像标签信息，用来标注不同的版本信息。如：14.04、latest等。</li><li>IMAGE ID：镜像的ID（唯一标识镜像），如hub.c.163.com/public/ubuntu：14.04和163ubuntu：14.04镜像的ID都是2fe5c4bba1f9，说明目前他们指向同一个镜像</li><li>CREATED：说明镜像的更新时间</li><li>镜像大小，优秀的镜像往往体积都较小</li></ul><p>其中镜像的ID信息十分重要，它唯一标识了镜像。在使用镜像ID的时候，一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID。</p><p>TAG信息用来标识来自同一个仓库的不同镜像。例如ubuntu仓库中有多个镜像，通过TAG信息来区分发行版本，包括10.04、12.04、12.10、14.04等标签。</p><p>镜像大小信息只是表示该镜像的逻辑体积大小，实际上由于相同的镜像本地只会存储一份，物理占用的存储空间会小于各镜像的逻辑体积之和。</p><p>更多子命令选项还可以通过<code>man docker-images</code>帮助命令来查看。</p><h2 id="使用tag命令添加镜像标签"><a href="#使用tag命令添加镜像标签" class="headerlink" title="使用tag命令添加镜像标签"></a>使用tag命令添加镜像标签</h2><p>命令格式：<code>docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker tag hub.c.163.com/public/ubuntu:14.04 163ubuntu:14.04 </span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        About an hour ago   435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        2 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        32 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">[root@xxx ~]#</span><br></pre></td></tr></table></figure><p>为了方便后续工作中使用特定镜像，还可以使用docker tag命令来为本地镜像任意添加新的标签。例如添加一个新的<code>163ubuntu:14.04</code>镜像标签。之后用户就可以直接使用<code>163ubuntu:14.04</code>来表示这个镜像了。观察<code>163ubuntu:14.04</code>的ID跟源镜像<code>hub.c.163.com/public/ubuntu:14.04</code>完全一致。他们实际上指向同一个镜像文件，只是别名不同而已。<code>docker tag</code>命令添加的标签实际上起到了类似连接的作用。</p><h2 id="使用inspect命令查看详细信息"><a href="#使用inspect命令查看详细信息" class="headerlink" title="使用inspect命令查看详细信息"></a>使用inspect命令查看详细信息</h2><p>命令格式：<code>docker inspect [OPTIONS] NAME|ID [NAME|ID...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --format string   使用指定的模板，格式化输出</span><br><span class="line">  -s, --size            如果是容器类型，表示其总大小</span><br><span class="line">      --type string     返回指定类型的json格式</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker inspect 163ubuntu:14.04 </span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;sha256:2fe5c4bba1f935f179e83cd5354403d1231ffc9df9c1621967194410eaf8d942&quot;,</span><br><span class="line">        &quot;RepoTags&quot;: [</span><br><span class="line">            &quot;163ubuntu:14.04&quot;,</span><br><span class="line">            &quot;hub.c.163.com/public/ubuntu:14.04&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;hub.c.163.com/public/ubuntu@sha256:ffc2fc66f8e0bfa4b417b817054d3ebec130c8db44342b8fa394e25779633257&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;Parent&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Comment&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2016-03-16T03:29:48.276492132Z&quot;,</span><br><span class="line">        &quot;Container&quot;: &quot;f807d2c2c41cc21db9201605a962047278719a09cb945d0a3d5a2a587d978769&quot;,</span><br><span class="line">        &quot;ContainerConfig&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;f807d2c2c41c&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;#(nop) ENTRYPOINT &amp;&#123;[\&quot;/bin/sh\&quot; \&quot;-c\&quot; \&quot;/usr/sbin/sshd -D\&quot;]&#125;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Image&quot;: &quot;7c5c7629089e80dea49161f10c36678cc8934601a730f8f8eb2a58d2e14c6610&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;/usr/sbin/sshd -D&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;DockerVersion&quot;: &quot;1.9.1&quot;,</span><br><span class="line">        &quot;Author&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;f807d2c2c41c&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [],</span><br><span class="line">            &quot;Cmd&quot;: null,</span><br><span class="line">            &quot;Image&quot;: &quot;7c5c7629089e80dea49161f10c36678cc8934601a730f8f8eb2a58d2e14c6610&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;/usr/sbin/sshd -D&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">        &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">        &quot;Size&quot;: 237059566,</span><br><span class="line">        &quot;VirtualSize&quot;: 237059566,</span><br><span class="line">        &quot;GraphDriver&quot;: &#123;</span><br><span class="line">            &quot;Data&quot;: &#123;</span><br><span class="line">                &quot;DeviceId&quot;: &quot;27&quot;,</span><br><span class="line">                &quot;DeviceName&quot;: &quot;docker-253:0-102127602-c30e1cbfce6f98d947b8df2100734cddf113980a3ccdb356a1b84f27825a3dbe&quot;,</span><br><span class="line">                &quot;DeviceSize&quot;: &quot;10737418240&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Name&quot;: &quot;devicemapper&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;RootFS&quot;: &#123;</span><br><span class="line">            &quot;Type&quot;: &quot;layers&quot;,</span><br><span class="line">            &quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:89688d062a0607fb50d0955de8964659e66f1bb41164b2d2b473d1edd7d8af90&quot;,</span><br><span class="line">                &quot;sha256:704e51eef17861bc3a2a7355709a7ce0b11ab720cc1b0e00235f984b33494b0e&quot;,</span><br><span class="line">                &quot;sha256:98b4fca781e7eab1cfb4d6427b60c4490b4c7d71a0bca622c7dd03cecb657a6d&quot;,</span><br><span class="line">                &quot;sha256:a695e8d298aaf8ee68638151e6068518475130eccdd224ba0591981f212e5ea2&quot;,</span><br><span class="line">                &quot;sha256:836a329bec9925c8fc76232885344a0053d19534ae108e5cbc111490481b5778&quot;,</span><br><span class="line">                &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Metadata&quot;: &#123;</span><br><span class="line">            &quot;LastTagTime&quot;: &quot;2018-04-13T10:03:07.660866339+08:00&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>更多用法请使用<code>man docker-inspect</code>帮助命令。</p><h2 id="使用history命令查看镜像历史"><a href="#使用history命令查看镜像历史" class="headerlink" title="使用history命令查看镜像历史"></a>使用history命令查看镜像历史</h2><p>命令格式：<code>docker history [OPTIONS] IMAGE</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --format string   指定格式化模板输出</span><br><span class="line">  -H, --human           Print sizes and dates in human readable format (default true)</span><br><span class="line">      --no-trunc        Don&apos;t truncate output</span><br><span class="line">  -q, --quiet           Only show numeric IDs</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker history 163ubuntu:14.04 </span><br><span class="line">IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class="line">2fe5c4bba1f9        2 years ago         /bin/sh -c #(nop) ENTRYPOINT &amp;&#123;[&quot;/bin/sh&quot; &quot;-…   0B                  </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i &apos;s/#PasswordAuthentication…   2.54kB              </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c mkdir /var/run/sshd                  0B                  </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c apt-get update &amp;&amp; apt-get install…   69.3MB              </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop) ADD file:b7283a2724cc73e4c…   872B                </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop) ADD file:9f6d0ad171ede3597…   168MB</span><br></pre></td></tr></table></figure><h2 id="镜像搜寻"><a href="#镜像搜寻" class="headerlink" title="镜像搜寻"></a>镜像搜寻</h2><p>命令格式：<code>docker search [OPTIONS] TERM</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --filter filter   Filter output based on conditions provided</span><br><span class="line">      --format string   Pretty-print search using a Go template</span><br><span class="line">      --limit int       Max number of search results (default 25)</span><br><span class="line">      --no-trunc        Don&apos;t truncate output</span><br><span class="line">      </span><br><span class="line">      Filter</span><br><span class="line">             Filter output based on these conditions:</span><br><span class="line">                - stars=&lt;numberOfStar&gt; 指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像</span><br><span class="line">                - is-automated=(true|false) 仅显示自动创建的镜像，默认为否</span><br><span class="line">                - is-official=(true|false) 仅显示官方的镜像，默认为否</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//搜索所有自动创建且评价为20+的带nginx关键字的镜像</span><br><span class="line">[root@xxx ~]# docker search --filter=is-automated=true --filter=stars=20 nginx</span><br><span class="line">NAME                                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">jwilder/nginx-proxy                                    Automated Nginx reverse proxy for docker con…   1315                                    [OK]</span><br><span class="line">richarvey/nginx-php-fpm                                Container running Nginx + PHP-FPM capable of…   544                                     [OK]</span><br><span class="line">jrcs/letsencrypt-nginx-proxy-companion                 LetsEncrypt container to use with nginx as p…   348                                     [OK]</span><br><span class="line">webdevops/php-nginx                                    Nginx with PHP-FPM                              99                                      [OK]</span><br><span class="line">zabbix/zabbix-web-nginx-mysql                          Zabbix frontend based on Nginx web-server wi…   49                                      [OK]</span><br><span class="line">bitnami/nginx                                          Bitnami nginx Docker Image                      48                                      [OK]</span><br><span class="line">1and1internet/ubuntu-16-nginx-php-phpmyadmin-mysql-5   ubuntu-16-nginx-php-phpmyadmin-mysql-5          33                                      [OK]</span><br></pre></td></tr></table></figure><ul><li>NAME：镜像名字</li><li>DESCRIPTION：描述</li><li>STARS：星级（表示该镜像受欢迎程度）</li><li>OFFICIAL：是否官方创建</li><li>AUTOMATED：是否自动创建</li></ul><p>默认结果按照星级评价进行排序。</p><h2 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h2><p>命令格式：<code>docker rmi [OPTIONS] IMAGE [IMAGE...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --force      强制删除</span><br><span class="line">      --no-prune   Do not delete untagged parents</span><br></pre></td></tr></table></figure></p><h3 id="使用标签删除镜像"><a href="#使用标签删除镜像" class="headerlink" title="使用标签删除镜像"></a>使用标签删除镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">//删除前查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        2 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">//删除镜像操作</span><br><span class="line">[root@xxx ~]# docker rmi 163ubuntu:14.04 </span><br><span class="line">Untagged: 163ubuntu:14.04</span><br><span class="line">//删除后查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        2 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：当同一个镜像拥有多个标签的时候，docker rmi命令只是删除该镜像多个标签中的指定标签而已，并不影响镜像文件。因此上述操作相当于只是删除了镜像<code>2fe5c4bba1f9</code>的一个标签而已。但当镜像只剩下一个标签的时候就要小心了,此时再使用<code>docker rmi</code>命令会彻底删除镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker rmi hub.c.163.com/library/memcached:latest </span><br><span class="line">Untagged: hub.c.163.com/library/memcached:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached@sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Deleted: sha256:8b057b9de580ce01fdce47c7ca1632ce03b925f9464afc0d91821b066f32204d</span><br><span class="line">Deleted: sha256:0382f79fb93ba9f862822a9c594019a32a39f5d46321e242a388c2e455d369e6</span><br><span class="line">Deleted: sha256:7f7bc5c738d847e3e2e647b467d3bb363bbbc99f53649cba7df71c2326fc183d</span><br><span class="line">Deleted: sha256:1c3bf91649b76e0956ab416404cb81bb30f1be5377316af42ecf680cb50c2d34</span><br><span class="line">Deleted: sha256:bbebfa4c46fd5f64fc0e0d71fc5c94448fa04fa0b20b74dc97ad0ec07cd8ff45</span><br><span class="line">Deleted: sha256:eb78099fbf7fdc70c65f286f4edc6659fcda510b3d1cfe1caa6452cc671427bf</span><br></pre></td></tr></table></figure><p>例如删除标签为<code>hub.c.163.com/library/memcached:latest</code>的镜像，由于该镜像没有额外的标签指向它，执行<code>docker rmi</code>命令，可以看出它会删除这个镜像文件的所有层。</p><h3 id="使用镜像ID删除镜像"><a href="#使用镜像ID删除镜像" class="headerlink" title="使用镜像ID删除镜像"></a>使用镜像ID删除镜像</h3><p>当使用docker rmi命令，并且后面跟上镜像的ID（也可能是能进行区分的部分ID串前缀）时，先会尝试删除所有指向该镜像的标签，然后删除该镜像本身。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">//删除前查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        3 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163mem                            latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line"></span><br><span class="line">//通过镜像ID删除镜像，提示多个镜像引用此镜像ID，必须使用-f 参数强制删除</span><br><span class="line">[root@xxx ~]# docker rmi 8b057b9de580</span><br><span class="line">Error response from daemon: conflict: unable to delete 8b057b9de580 (must be forced) - image is referenced in multiple repositories</span><br><span class="line">[root@xxx ~]# docker rmi -f 8b057b9de580</span><br><span class="line">Untagged: 163mem:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached@sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Deleted: sha256:8b057b9de580ce01fdce47c7ca1632ce03b925f9464afc0d91821b066f32204d</span><br><span class="line">Deleted: sha256:0382f79fb93ba9f862822a9c594019a32a39f5d46321e242a388c2e455d369e6</span><br><span class="line">Deleted: sha256:7f7bc5c738d847e3e2e647b467d3bb363bbbc99f53649cba7df71c2326fc183d</span><br><span class="line">Deleted: sha256:1c3bf91649b76e0956ab416404cb81bb30f1be5377316af42ecf680cb50c2d34</span><br><span class="line">Deleted: sha256:bbebfa4c46fd5f64fc0e0d71fc5c94448fa04fa0b20b74dc97ad0ec07cd8ff45</span><br><span class="line">Deleted: sha256:eb78099fbf7fdc70c65f286f4edc6659fcda510b3d1cfe1caa6452cc671427bf</span><br><span class="line"></span><br><span class="line">//删除后查看镜像列表，发现与此ID关联的镜像都已删除成功</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                        7                   0b99289e40ee        3 hours ago         435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                   latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                        14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/public/ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure></p><p><strong>注意</strong>：当有该镜像创建的容器存在时，镜像文件是无法被删除的，如要删除该镜像请先删除该容器，然后再删除镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//使用镜像运行容器</span><br><span class="line">[root@xxx ~]# docker run ubuntu:14.04 echo &quot;Hello&quot;</span><br><span class="line">Hello</span><br><span class="line">//查看所有状态容器</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">8bdb6f330ec9        ubuntu:14.04                        &quot;echo Hello&quot;             7 seconds ago       Exited (0) 6 seconds ago                       determined_varahamihira</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">//使用标签删除镜像，提示被容器引用</span><br><span class="line">[root@xxx ~]# docker rmi ubuntu:14.04 </span><br><span class="line">Error response from daemon: conflict: unable to remove repository reference &quot;ubuntu:14.04&quot; (must force) - container 8bdb6f330ec9 is using its referenced image a35e70164dfb</span><br><span class="line"></span><br><span class="line">//无法强制删除</span><br><span class="line">[root@xxx ~]# docker rmi -f a35e70164dfb</span><br><span class="line">Error response from daemon: conflict: unable to delete a35e70164dfb (cannot be forced) - image has dependent child images</span><br><span class="line"></span><br><span class="line">//删除容器</span><br><span class="line">[root@xxx ~]# docker rm 8bdb6</span><br><span class="line">8bdb6</span><br><span class="line"></span><br><span class="line">//成功删除镜像</span><br><span class="line">[root@xxx ~]# docker rmi ubuntu:14.04 </span><br><span class="line">Untagged: ubuntu:14.04</span><br><span class="line">Untagged: ubuntu@sha256:ed49036f63459d6e5ed6c0f238f5e94c3a0c70d24727c793c48fded60f70aa96</span><br></pre></td></tr></table></figure><h2 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h2><p>创建镜像的方法有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。<br>先介绍前二种创建方式</p><h3 id="基于已有镜像的容器创建"><a href="#基于已有镜像的容器创建" class="headerlink" title="基于已有镜像的容器创建"></a>基于已有镜像的容器创建</h3><p>命令格式：<code>docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --author string    作者信息</span><br><span class="line">  -c, --change list      提交的时候指定Dockerfile指令，包括CMD/ENTRYPOINT/ENV/EXPOSE/LABEL/ONBUILD/USER/VOLUME/WORKDIR等</span><br><span class="line">  -m, --message string   提交信息</span><br><span class="line">  -p, --pause            提交时暂停容器运行</span><br></pre></td></tr></table></figure><p>下面将演示如何使用该命令创建一个新镜像。首先，启动一个镜像，并在其中进行修改操作，例如创建一个test文件，之后推出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker run -it ubuntu:latest /bin/bash</span><br><span class="line">root@72ed7e58bc28:/# touch test</span><br><span class="line">root@72ed7e58bc28:/# exit</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p><p>记住此时的容器ID为：<code>72ed7e58bc28</code>,此时容器跟原<code>ubuntu:latest</code>镜像相比，已经发生了变化，可以使用docker commit命令来提交为一个新的镜像。提交的时候可以使用ID或名称来指定容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker commit -m &quot;提交一个新镜像&quot; -a &quot;xym&quot; 72ed7e58bc28 xymtest:0.1</span><br><span class="line">sha256:8a758d16a99b414b738bee50b485c3d99f6093c0c4002efd9dd5dd740efd2ee9</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xymtest                       0.1                 8a758d16a99b        26 seconds ago      113MB</span><br><span class="line">centos                        7                   0b99289e40ee        4 hours ago         435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        4 hours ago         222MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h3 id="基于本地模板导入"><a href="#基于本地模板导入" class="headerlink" title="基于本地模板导入"></a>基于本地模板导入</h3><p>用户也可以直接从一个操作系统模板文件导入一个镜像。</p><p>命令格式：<code>docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -c, --change list      导入时候指定Dockerfile指令，包括CMD/ENTRYPOINT/ENV/EXPOSE/LABEL/ONBUILD/USER/VOLUME/WORKDIR等</span><br><span class="line">  -m, --message string   提交信息</span><br></pre></td></tr></table></figure></p><p>要直接导入一个镜像，可以使用OpenVZ提供的模板来创建，或者用其他已导出的镜像模板来创建。OpenVZ模板的下载地址为：<a href="https://openvz.org/Download/template/precreated" target="_blank" rel="noopener">https://openvz.org/Download/template/precreated</a></p><p>例如：下载了<code>centos-7-x86_64-minimal.tar.gz</code>模板压缩包，之后使用以下命令导入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# cat centos-7-x86_64-minimal.tar.gz | docker import - centos-7:import</span><br><span class="line">sha256:be5e039acd03e1c3489841f6edd244954a4c1eb534de7fff605d807136b7e735</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED              SIZE</span><br><span class="line">centos-7                      import              be5e039acd03        About a minute ago   435MB</span><br><span class="line">xymtest                       0.1                 8a758d16a99b        18 minutes ago       113MB</span><br><span class="line">centos                        7                   0b99289e40ee        4 hours ago          435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        4 hours ago          222MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h2 id="存出和载入镜像"><a href="#存出和载入镜像" class="headerlink" title="存出和载入镜像"></a>存出和载入镜像</h2><p>可以使用<code>docker save</code> 和<code>docker load</code>命令来存出和载入镜像。</p><h3 id="存出镜像"><a href="#存出镜像" class="headerlink" title="存出镜像"></a>存出镜像</h3><p>命令格式：<code>docker save [OPTIONS] IMAGE [IMAGE...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -o, --output string   写出目标文件</span><br></pre></td></tr></table></figure></p><p>如果要导出镜像到本地文件，可以使用<code>docker save</code>命令。例如，导出本地的<code>163ubuntu:14.04</code>镜像为文件<code>163ubuntu_14.04.tar</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker save -o 163ubuntu_14.04.tar 163ubuntu:14.04 </span><br><span class="line">[root@xxx ~]# ls -t</span><br><span class="line">163ubuntu_14.04.tar ...</span><br></pre></td></tr></table></figure></p><p>之后，用户就可以通过复制该文件（163ubuntu_14.04.tar）将镜像分享给其他人。</p><h3 id="载入镜像"><a href="#载入镜像" class="headerlink" title="载入镜像"></a>载入镜像</h3><p>命令格式：<code>docker load [OPTIONS]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -i, --input string   指定要导入的tar归档镜像文件</span><br><span class="line">  -q, --quiet          Suppress the load output</span><br></pre></td></tr></table></figure></p><p>可以通过<code>docker load</code> 将导出的tar文件再导入到本地镜像库，例如从文件<code>163ubuntu_14.04.tar</code>导入镜像到本地镜像列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker load --input 163ubuntu_14.04.tar </span><br><span class="line">Loaded image: 163ubuntu:14.04</span><br><span class="line"></span><br><span class="line">或者可以使用</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker load &lt; 163ubuntu_14.04.tar </span><br><span class="line">Loaded image: 163ubuntu:14.04</span><br></pre></td></tr></table></figure><p>这将导入镜像及其相关元数据信息（包括标签等）。</p><h2 id="上传镜像"><a href="#上传镜像" class="headerlink" title="上传镜像"></a>上传镜像</h2><p>命令格式：<code>docker push [OPTIONS] NAME[:TAG]|[REGISTRY_HOST[:REGISTRY_PORT]/]NAME[:TAG]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --disable-content-trust   Skip image signing (default true)</span><br></pre></td></tr></table></figure></p><p>可以使用<code>docker push</code>命令上传镜像到仓库，默认上传到<code>Docker Hub</code>官方仓库（需要登录）。<br>用户在<code>Docker Hub网站</code>注册后可以上传自制镜像。<strong>例如用户user上传本地的test:latest镜像，可以先添加新的标签user/test:latest,然后用docker push命令上传镜像</strong>：</p><h4 id="上传镜像到网易蜂巢docker"><a href="#上传镜像到网易蜂巢docker" class="headerlink" title="上传镜像到网易蜂巢docker"></a>上传镜像到网易蜂巢docker</h4><p>参见官网操作文档：<a href="https://www.163yun.com/help/documents/15587826830438400" target="_blank" rel="noopener">https://www.163yun.com/help/documents/15587826830438400</a></p><p>1、登录网易云镜像仓库<br>docker login -u {你的网易云邮箱账号或手机号码} -p {你的网易云密码} hub.c.163.com</p><p>返回「Login Succeded」即为登录成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker login hub.c.163.com</span><br><span class="line">Username: xxx@126.com（你的账号）        </span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><ul><li>2、标记本地镜像<br>docker tag {镜像名或ID} hub.c.163.com/{你的用户名}/{标签名}</li></ul><p>你的网易云镜像仓库推送地址为 hub.c.163.com/{你的用户名}/{标签名}</p><p>Attention: 此处为你的用户名，不是你的邮箱帐号或者手机号码 登录网易云控制台，页面右上角头像右侧即为「用户名」</p><p>推送至不存在的镜像仓库时，自动创建镜像仓库并保存新推送的镜像版本；<br>推送至已存在的镜像仓库时，在该镜像仓库中保存新推送的版本，当版本号相同时覆盖原有镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker tag hub.c.163.com/public/ubuntu:14.04 hub.c.163.com/xxx/163ubuntu:14.04</span><br><span class="line">[root@xxx /]# docker images</span><br><span class="line">REPOSITORY                          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">163ubuntu                           14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/xxx/163ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><ul><li><ol start="3"><li>推送至网易云镜像仓库<br>docker push hub.c.163.com/{你的用户名}/{标签名}</li></ol></li></ul><p>默认为私有镜像仓库，推送成功后即可在控制台的「镜像仓库」查看。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker push hub.c.163.com/xxx/163ubuntu:14.04 </span><br><span class="line">The push refers to repository [hub.c.163.com/xxx/163ubuntu]</span><br><span class="line">5f70bf18a086: Pushed </span><br><span class="line">836a329bec99: Pushed </span><br><span class="line">a695e8d298aa: Pushed </span><br><span class="line">98b4fca781e7: Pushed </span><br><span class="line">704e51eef178: Pushed </span><br><span class="line">89688d062a06: Pushed </span><br><span class="line">14.04: digest: sha256:c6740481ffab5f07e8785e6f07d5e2bec8ba9436d67f6e686d0fe1bf65c651be size: 4031</span><br></pre></td></tr></table></figure><h4 id="上传镜像到阿里云"><a href="#上传镜像到阿里云" class="headerlink" title="上传镜像到阿里云"></a>上传镜像到阿里云</h4><blockquote><p>Docker的镜像存储中心通常被称为Registry。<br>当您需要获取Docker镜像的时候，首先需要登录Registry，然后拉取镜像。在您修改过镜像之后，您可以再次将镜像推送到Registry中去。</p><p>Docker的镜像地址是什么？我们来看一个完整的例子。（以容器服务的公共镜像为例）<br>registry.cn-hangzhou.aliyuncs.com/acs/agent:0.8</p><p>registry.cn-hangzhou.aliyuncs.com 叫做 “Registry域名”。<br>acs 叫做 “命名空间”。<br>agent 叫做 “仓库名称”。<br>0.8 叫做 “Tag”、”镜像标签”（非必须，默认latest）。<br>将这个几个完全独立的概念组合一下，还有几个术语。<br>registry.cn-hangzhou.aliyuncs.com/acs/agent 称为 “仓库坐标”。<br>acs/agent 称为 “仓库全名”（通常在API中使用）。</p></blockquote><p>参见文档：<a href="https://yq.aliyun.com/articles/70756" target="_blank" rel="noopener">https://yq.aliyun.com/articles/70756</a></p><p>了解相关说明后发现，阿里云有一个”命名空间”的概念，所以<strong>要想上传自己的镜像，请先去个人中心创建命名空间</strong>。</p><p>比如：当前创建的命名空间为<code>xym</code>,则通过以下命令即可将自己的镜像上传到命名空间</p><ul><li>1、docker login 以阿里云杭州公网Registry为例：登陆时必须指明登陆的 “Registry域名”</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker login registry.cn-hangzhou.aliyuncs.com</span><br><span class="line">Username: xxx</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><ul><li><p>2、标记本地镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//注意这里的xym为：命名空间</span><br><span class="line">[root@xxx /]# docker tag hub.c.163.com/public/ubuntu:14.04 registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04</span><br><span class="line">[root@xxx /]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                                            7                   0b99289e40ee        6 hours ago         435MB</span><br><span class="line">ubuntu                                            latest              c9d990395902        12 hours ago        113MB</span><br><span class="line">hub.c.163.com/public/ubuntu                       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure></li><li><ol start="3"><li>推送至阿里云<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker push registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu</span><br><span class="line">The push refers to repository [registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu]</span><br><span class="line">5f70bf18a086: Pushed </span><br><span class="line">836a329bec99: Pushed </span><br><span class="line">a695e8d298aa: Pushed </span><br><span class="line">98b4fca781e7: Pushed </span><br><span class="line">704e51eef178: Pushed </span><br><span class="line">89688d062a06: Pushed </span><br><span class="line">14.04: digest: sha256:ef619091bc47f4b82ce4e984668ee96a2447f244bbd73fbaffe103605c454c28 size: 1569</span><br></pre></td></tr></table></figure></li></ol></li></ul><p>登录控制台查看推送结果。</p><h2 id="镜像加速"><a href="#镜像加速" class="headerlink" title="镜像加速"></a>镜像加速</h2><p>参见阿里控制台，CentOS 镜像加速器帮助说明:</p><blockquote><p>针对Docker客户端版本大于1.10.0的用户</p></blockquote><blockquote><p>您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器：<br>sudo mkdir -p /etc/docker<br>sudo tee /etc/docker/daemon.json &lt;&lt;-‘EOF’<br>{<br>  “registry-mirrors”: [“<a href="https://4vehewku.mirror.aliyuncs.com&quot;]" target="_blank" rel="noopener">https://4vehewku.mirror.aliyuncs.com&quot;]</a><br>}<br>EOF<br>sudo systemctl daemon-reload<br>sudo systemctl restart docker</p></blockquote><p>其他情况请自行 <a href="https://www.google.com" target="_blank" rel="noopener">google</a></p>]]></content>
    
    <summary type="html">
    
      Docker入门指南，各镜像操作命令，上传镜像到镜像服务器（阿里云、网易蜂巢等云平台）详细步骤。
    
    </summary>
    
      <category term="Docker系列" scheme="http://xym-loveit.github.io/categories/Docker%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="docker镜像" scheme="http://xym-loveit.github.io/tags/docker%E9%95%9C%E5%83%8F/"/>
    
      <category term="pull命令" scheme="http://xym-loveit.github.io/tags/pull%E5%91%BD%E4%BB%A4/"/>
    
      <category term="images命令" scheme="http://xym-loveit.github.io/tags/images%E5%91%BD%E4%BB%A4/"/>
    
      <category term="tag命令" scheme="http://xym-loveit.github.io/tags/tag%E5%91%BD%E4%BB%A4/"/>
    
      <category term="inspect命令" scheme="http://xym-loveit.github.io/tags/inspect%E5%91%BD%E4%BB%A4/"/>
    
      <category term="history命令" scheme="http://xym-loveit.github.io/tags/history%E5%91%BD%E4%BB%A4/"/>
    
      <category term="search命令" scheme="http://xym-loveit.github.io/tags/search%E5%91%BD%E4%BB%A4/"/>
    
      <category term="rmi命令" scheme="http://xym-loveit.github.io/tags/rmi%E5%91%BD%E4%BB%A4/"/>
    
      <category term="rm命令" scheme="http://xym-loveit.github.io/tags/rm%E5%91%BD%E4%BB%A4/"/>
    
      <category term="commit命令" scheme="http://xym-loveit.github.io/tags/commit%E5%91%BD%E4%BB%A4/"/>
    
      <category term="import命令" scheme="http://xym-loveit.github.io/tags/import%E5%91%BD%E4%BB%A4/"/>
    
      <category term="save命令" scheme="http://xym-loveit.github.io/tags/save%E5%91%BD%E4%BB%A4/"/>
    
      <category term="load命令" scheme="http://xym-loveit.github.io/tags/load%E5%91%BD%E4%BB%A4/"/>
    
      <category term="push命令" scheme="http://xym-loveit.github.io/tags/push%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud常见问题总结</title>
    <link href="http://xym-loveit.github.io/2018/04/11/Spring-Cloud%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>http://xym-loveit.github.io/2018/04/11/Spring-Cloud常见问题总结/</id>
    <published>2018-04-11T13:01:13.000Z</published>
    <updated>2018-04-11T16:08:27.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Eureka常见问题"><a href="#Eureka常见问题" class="headerlink" title="Eureka常见问题"></a>Eureka常见问题</h2><h3 id="Eureka注册服务慢"><a href="#Eureka注册服务慢" class="headerlink" title="Eureka注册服务慢"></a>Eureka注册服务慢</h3><p>默认情况下，服务注册到Eureka Server的过程慢。在开发或测试时，常常希望能够加速这一过程，从而提升工作效率。Spring Cloud官方详细描述了该问题的原因并提供了解决方案：  </p><blockquote><p>简单翻译：服务注册涉及到周期性心跳，默认30秒一次（通过客户端配置ServiceUrl）。只有当实例、服务端和客户端的本地缓存中的元数据都相同时，服务才能被其他客户端发现（所以可能需要3次心跳）。可以使用参数<code>eureka.instance.leaseRenewalntervalInSeconds</code>修改时间间隔，从而加快客户端连接到其他服务的过程。在生产环境中最好坚持使用默认值，因为在服务器内部有一些计算，他们会对续约作出假设。</p></blockquote><p>综上，要想解决服务注册慢的问题，只须将<code>eureka.instance.leaseRenewalIntervalInSeconds</code>设定一个更小的值。该配置用于设置Eureka Client向Eureka Server发送心跳的时间间隔，默认30秒。在生产环境中，建议坚持使用默认值。</p><blockquote><p>原文来自：<a href="https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html#_why_is_it_so_slow_to_register_a_service" target="_blank" rel="noopener">https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html#_why_is_it_so_slow_to_register_a_service</a></p></blockquote><h3 id="已停止的微服务节点注销慢或不注销"><a href="#已停止的微服务节点注销慢或不注销" class="headerlink" title="已停止的微服务节点注销慢或不注销"></a>已停止的微服务节点注销慢或不注销</h3><p>在开发环境下，常常希望Eureka Server能迅速有效地注销已停止的微服务实例，然而，由于Eureka Server清理无效节点周期长（默认90秒），以及自我保护模式等原因，可能会遇到微服务注销慢甚至不注销的问题。解决方案如下：  </p><ul><li><p>Eureka Server 端：<br>配置关闭自我保护，并按需配置Eureka Server清理无效节点的时间间隔。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eureka.server.enable-self-preservation</span><br><span class="line">#设为false，关闭自我保护，从而保证会注销微服务</span><br><span class="line">eureka.server.eviction-interval-timer-in-ms</span><br><span class="line">#清理间隔（单位毫秒，默认为60*1000）</span><br></pre></td></tr></table></figure></li><li><p>Eureka Client 端<br>配置开启健康检查，并按需配置续约更新时间和到期时间。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eureka.client.healthcheck.enabled</span><br><span class="line">#设置为true,开启健康检查（需要spring-boot-starter-actuator依赖）</span><br><span class="line">eureka.instance.lease-renewal-interval-in-seconds</span><br><span class="line">#续约更新时间间隔（默认30秒）</span><br><span class="line">eureka.instance.lease-expiration-duration-in-seconds</span><br><span class="line">#续约到期时间（默认90秒）</span><br></pre></td></tr></table></figure></li></ul><p>值得注意的是，这些配置仅建议在开发或测试时使用，生产环境建议坚持使用默认值。</p><p><strong>示例</strong></p><ul><li><p>Eureka Server配置：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  server:</span><br><span class="line">    enable-self-preservation: false</span><br><span class="line">    eviction-interval-timer-in-ms: 4000</span><br></pre></td></tr></table></figure></li><li><p>Eureka Client配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  client:</span><br><span class="line">    healthcheck:</span><br><span class="line">      enabled: true</span><br><span class="line">  instance:</span><br><span class="line">    lease-expiration-duration-in-seconds: 30</span><br><span class="line">    lease-renewal-interval-in-seconds: 10</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>修改Eureka的续约频率可能会打破Eureka的自我保护特性，详见：<a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/373" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix/issues/373</a>。这意味着在生产环境中，如果想要使用Eureka的自我保护特性，应该坚持使用默认配置。</p></blockquote><h3 id="如何自定义微服务的Instance-ID。"><a href="#如何自定义微服务的Instance-ID。" class="headerlink" title="如何自定义微服务的Instance ID。"></a>如何自定义微服务的Instance ID。</h3><p>Instance ID用于唯一标识注册到Eureka Server上的微服务实例。在Eureka Server首页可以直观地看到各个微服务的Instance ID。如下图： </p><p><img src="" alt=""></p><p>在Spring Cloud中，服务的Instance ID的默认值是<code>${spring.cloud.client.hostname}:${spring.application.name}:${server.port}</code>。如果想要自定义这部分内容，只须在微服务中配置<code>eureka.instance.instance-id</code>属性即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: microservice-provider-user</span><br><span class="line">eureka:</span><br><span class="line">  instance:</span><br><span class="line">    #将Instance ID设置成 IP:端口的形式 </span><br><span class="line">    instance-id: $&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125;</span><br></pre></td></tr></table></figure><p>这样，就可将微服务<code>microservice-provider-user</code>的Instance ID设为IP:端口的形式。这样设置后，效果下图所示：  </p><p><img src="" alt=""></p><blockquote><p>Spring Cloud初始化Instance ID的相关代码：<br>org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration<br>org.springframework.cloud.commons.util.IdUtils.getDefaultInstanceId(PropertyResolver resolver);<br>org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean.getInstanceId()</p></blockquote><h3 id="Eureka的UNKNOWN问题总结"><a href="#Eureka的UNKNOWN问题总结" class="headerlink" title="Eureka的UNKNOWN问题总结"></a>Eureka的UNKNOWN问题总结</h3><p>注册信息unknown，是新手常会遇到的问题。如下图，有二种UNKNOWN的情况，一种是应用名称UNKNOWN,另一种是应用状态UNKNOWN。下面分别说明这二种情况。</p><p><img src="" alt=""></p><p><strong>应用名称UNKNOWN</strong></p><p>应用名称UNKNOWN显然不合适，首先微服务的名称不够语义化，无法直接观看出这是哪个服务；更重要的是，我们常常使用应用名称消费对应微服务接口。<br>一般来说，有二种情况会导致该问题的发生：  </p><ul><li>未配置<code>spring.application.name</code>或者<code>eureka.instance.appname</code>属性。如果这两个属性均不配置，就会导致应用名称UNKNOWN的问题。</li><li>某些版本的SpringFox会导致该问题，例如SpringFox2.6.0。建议使用SpringFox2.6.1或更新版本</li></ul><p><strong>微服务实例状态UNKNOWN</strong></p><p>微服务实例的状态UNKNOWN同样很麻烦。一般来讲，只会请求状态是UP的微服务。该问题一般由健康检查导致。<code>eureka.client.healthcheck.enabled=true</code>必须设置在<code>application.yml</code>中，而不能设置在<code>bootstrap.yml</code>中，否则一些场景下会导致应用状态UNKNOWN的问题。</p><blockquote><p>SpringFox是一款基于Spring和Swagger的开源的API文档框架，前身是swagger-springmvc。官网：<a href="http://springfox.github.io/springfox/" target="_blank" rel="noopener">http://springfox.github.io/springfox/</a>。</p></blockquote><h2 id="Hystrix-Feign整合Hystrix后首次请求失败"><a href="#Hystrix-Feign整合Hystrix后首次请求失败" class="headerlink" title="Hystrix/Feign整合Hystrix后首次请求失败"></a>Hystrix/Feign整合Hystrix后首次请求失败</h2><p>某些场景下，Feign或Ribbon整合Hystrix后，会出现首次调用失败的问题。</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>Hystrix默认的超时时间是1秒，如果在1秒内得不到响应，就会进入<code>fallback</code>逻辑。由于Spring的懒加载机制，首次请求往往会比较慢，因此在某些机器（特别是低端的机器）上，首次请求需要的时间可能就会大于1秒。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>方法一：延长Hystrix的超时时间，示例：<br><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000</code>该配置让Hystrix的超时时间改为5秒 </li><li>方法二：禁用Hystrix的超时，示例：<br><code>hystrix.command.default.execution.timeout.enabled: false</code></li><li>方法三：对于Feign，还可为Feign禁用Hystrix，示例：<br><code>feign.hystrix.enabled: false</code><br>这样即可为Feign全局禁用Hystrix支持，该方式比较极端，一般不建议使用。</li></ul><h2 id="Turbine集合数据不完整"><a href="#Turbine集合数据不完整" class="headerlink" title="Turbine集合数据不完整"></a>Turbine集合数据不完整</h2><p>在某些版本的Spring Cloud（例如Brixton SR5）中，Turbine会发生该问题。该问题直观体现是：使用Turbine聚合了多个微服务，但在Hystrix Dashboard上只能看到部分微服务的监控数据。</p><p>例如Turbine配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">turbine:</span><br><span class="line">  app-config: microservice-consumer-movie,microservice-consumer-movie-feign-hystrix-fallback-stream</span><br><span class="line">  cluster-name-expression: &quot;&apos;default&apos;&quot;</span><br></pre></td></tr></table></figure></p><p>Turbine理应聚合<code>microservice-consumer-movie</code>和<code>microservice-consumer-movie-feign-hystrix-fallback-stream</code>这两个微服务的监控数据，然而打开Hystrix Dashboard时，会发现Hystrix Dashboard只显示部分微服务的监控数据。</p><h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p>当Turbine集合的微服务部署在同一台主机时，就会出现该问题。</p><ul><li><p>方法一：为各个微服务配置不同的<code>hostname</code>。并将<code>preferIpAddress</code>设为false或者不设置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  client:</span><br><span class="line">    service-url:</span><br><span class="line">      defaultZone: http://discovery:8761/eureka/</span><br><span class="line">  instance:</span><br><span class="line">    hostname: ribbon #配置hostname</span><br></pre></td></tr></table></figure></li><li><p>方法二：设置<code>turbine.combine-host-port=true</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">turbine:</span><br><span class="line">  app-config: microservice-consumer-movie,microservice-consumer-movie-feign-hystrix-fallback-stream</span><br><span class="line">  cluster-name-expression: &quot;&apos;default&apos;&quot;</span><br><span class="line">  combine-host-port: true</span><br></pre></td></tr></table></figure></li><li><p>方法三：升级Spring Cloud到Camden或更新版本。当然，也可单独升级Spring Cloud Netflix到1.2或更新版本（一般不建议单独升级Spring Cloud Netflix，因为可能会跟Spring Cloud其他组件冲突）。这是因为老版本中的<code>combine-host-port</code>默认值是false。Spring Cloud已经意识到该问题，所以在新的版本中将该属性的默认值修改为true。该方案和方法二本质上是一致的。</p></li></ul><p>相关代码:  </p><blockquote><p>org.springframework.cloud.netflix.turbine.TurbineProperties.combineHostPort<br>org.springframework.cloud.netflix.turbine.CommonsInstanceDiscovery.getInstance(String hostname, String port, String cluster, Boolean status)<br>相关issue：<a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/1087" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix/issues/1087</a></p></blockquote><h2 id="Spring-Cloud各组件配置属性"><a href="#Spring-Cloud各组件配置属性" class="headerlink" title="Spring Cloud各组件配置属性"></a>Spring Cloud各组件配置属性</h2><p>Spring Cloud中的大部门问题都可以使用配置属性的方式来解决。下面将配置的地址罗列出来，方便查阅。</p><h3 id="Spring-Cloud的配置"><a href="#Spring-Cloud的配置" class="headerlink" title="Spring Cloud的配置"></a>Spring Cloud的配置</h3><p>Spring Cloud的所有组件配置都在其官方文档的附录，地址如下：  </p><p><a href="http://cloud.spring.io/spring-cloud-static/Camden.SR7/#_appendix_compendium_of_configuration_properties" target="_blank" rel="noopener">http://cloud.spring.io/spring-cloud-static/Camden.SR7/#_appendix_compendium_of_configuration_properties</a></p><h3 id="原生配置"><a href="#原生配置" class="headerlink" title="原生配置"></a>原生配置</h3><p>Spring Cloud 整合了很多类库，例如：<code>Eureka</code>、<code>Ribbon</code>、<code>Feign</code>等。这些组件自身也有一些配置属性，如下：  </p><ul><li>Eureka的配置：<a href="https://github.com/Netflix/eureka/wiki/Configuring-Eureka" target="_blank" rel="noopener">https://github.com/Netflix/eureka/wiki/Configuring-Eureka</a></li><li>Ribbon的配置：<a href="https://github.com/Netflix/ribbon/wiki/Programmers-Guide" target="_blank" rel="noopener">https://github.com/Netflix/ribbon/wiki/Programmers-Guide</a></li><li>Hystrix的配置：<a href="https://github.com/Netflix/Hystrix/wiki/Configuration" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/wiki/Configuration</a></li><li>Turbine的配置：<a href="https://github.com/Netflix/Turbine/wiki/Configuration-(1.x" target="_blank" rel="noopener">https://github.com/Netflix/Turbine/wiki/Configuration-(1.x)</a>)</li></ul><h2 id="Spring-Cloud定位问题的思路"><a href="#Spring-Cloud定位问题的思路" class="headerlink" title="Spring Cloud定位问题的思路"></a>Spring Cloud定位问题的思路</h2><h3 id="1、排查配置问题"><a href="#1、排查配置问题" class="headerlink" title="1、排查配置问题"></a>1、排查配置问题</h3><p>排查配置有无问题，举几个例说明。</p><ul><li>YAML缩进是否正确<ul><li>项目启动报错，错误指向yml文件</li></ul></li><li>配置属性是否正确<ul><li>可以借助IDE提示功能来排查，当IDE不提示或给出警告时，应格外注意。  </li></ul></li><li><p>配置属性的位置是否正确</p><ul><li>应当配置在<code>Eureka Client</code>项目上的属性，配置在了<code>Eureka Server</code>项目上</li><li>应当写在<code>bootstrap.yml</code>中的属性，写在了<code>application.yml</code>中，如：<code>spring.cloud.config.uri=http://localhost:8080</code>     </li><li>应当写在<code>application.yml</code>的属性，写在了<code>bootstrap.yml</code>中，如：<code>eureka.client.healthcheck.enabled-true</code><h3 id="2、排查环境问题"><a href="#2、排查环境问题" class="headerlink" title="2、排查环境问题"></a>2、排查环境问题</h3>如确认配置无误，即可考虑运行环境是否存在问题。</li></ul></li><li><p>环境变量</p><ul><li>当前使用的<code>spring boot maven</code>插件版本需要jdk8支持,在jdk7下报错，需要指定插件版本号，添加<code>&lt;version&gt;</code>配置</li></ul></li><li>依赖下载是否完整<ul><li>启动前使用<code>mvn clean package</code>,确认依赖完整性。</li></ul></li><li>网络问题<ul><li>微服务之间通过网络保持通信，因此，网络常常是排查问题的关键。当问题发生时候，可优先排查网络问题。</li></ul></li></ul><h3 id="3、排查代码问题"><a href="#3、排查代码问题" class="headerlink" title="3、排查代码问题"></a>3、排查代码问题</h3><p>经过以上步骤，依然没有定位到问题，那么可能是编写代码出了问题。很多时候，常常因为少了某个注解，或是依赖缺失，而导致了各种异常。许多场景下，设置合理的日志级别，会对问题的定位有奇效。</p><h3 id="4、排查Spring-Cloud自身问题"><a href="#4、排查Spring-Cloud自身问题" class="headerlink" title="4、排查Spring Cloud自身问题"></a>4、排查Spring Cloud自身问题</h3><p>如果确定不是自身问题，就可以debug一下Spring Cloud的代码。同时，可在github等平台给项目提交issue，然后参考官方回复，尝试规避相应问题。</p><p><strong>可参考资源：</strong></p><blockquote><p>各项自身的github，例如：Eureka的Github：<a href="https://github.com/netflix/eureka" target="_blank" rel="noopener">https://github.com/netflix/eureka</a><br>Spring Cloud对应的项目Github，例如Eureka项目在 Spring Cloud Netflix中：<a href="https://github.com/spring-cloud/spring-cloud-netflix" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix</a></p></blockquote><blockquote><p>Spring Cloud的StackOverflow：<a href="https://stackoverflow.com/questions/tagged/spring-cloud" target="_blank" rel="noopener">https://stackoverflow.com/questions/tagged/spring-cloud</a><br>Spring Cloud的 Gitter<a href="https://gitter.im/spring-cloud/spring-cloud" target="_blank" rel="noopener">https://gitter.im/spring-cloud/spring-cloud</a><br>Spring Cloud中国社区 <a href="http://www.spring4all.com" target="_blank" rel="noopener">http://www.spring4all.com</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      在使用SpringCloud的过程中，可能会遇到一些问题。本文对常见问题做一些总结。
    
    </summary>
    
      <category term="Spring-Cloud系列" scheme="http://xym-loveit.github.io/categories/Spring-Cloud%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Spring-Cloud" scheme="http://xym-loveit.github.io/tags/Spring-Cloud/"/>
    
      <category term="SpringCloud常见问题" scheme="http://xym-loveit.github.io/tags/SpringCloud%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    
      <category term="Eureka 配置" scheme="http://xym-loveit.github.io/tags/Eureka-%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Ribbon 配置" scheme="http://xym-loveit.github.io/tags/Ribbon-%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Hystrix 配置" scheme="http://xym-loveit.github.io/tags/Hystrix-%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Turbine 配置" scheme="http://xym-loveit.github.io/tags/Turbine-%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Spring Cloud 配置手册" scheme="http://xym-loveit.github.io/tags/Spring-Cloud-%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>Eureka配置参数</title>
    <link href="http://xym-loveit.github.io/2018/04/08/Eureka%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
    <id>http://xym-loveit.github.io/2018/04/08/Eureka配置参数/</id>
    <published>2018-04-08T02:16:09.000Z</published>
    <updated>2018-04-08T07:10:53.562Z</updated>
    
    <content type="html"><![CDATA[<h3 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h3><ul><li><code>eureka.client.register-with-eureka</code>: 是否支持注册功能，默认为true</li><li><code>eureka.server.enable-self-preservation</code>: 服务注册中心自我保护机制，默认为true（服务注册中心红色警告）</li><li><code>eureka.client.region</code>: 设置微服务应用的Region，默认为default</li><li><code>eureka.client.availability-zones</code>: 设置微服务应用的zone，多个可以采用“，”分割，默认为defaultZone，和region是一对多的关系，即一个region下有多个zone</li><li><code>http://&lt;username&gt;:&lt;password&gt;@localhost:1111/eureka/</code>,配置安全的注册中心地址，其中<username>为安全校验信息的用户名，<passoword>为该用户的密码。</passoword></username></li></ul><h3 id="服务续约"><a href="#服务续约" class="headerlink" title="服务续约"></a>服务续约</h3><ul><li><code>eureka.instance.lease-renewal-interval-in-seconds</code>: 定义服务续约任务的调用间隔时间，默认30秒</li><li><code>eureka.instance.lease-expiration-duration-in-seconds</code>: 定义服务失效的时间，默认90秒</li></ul><h3 id="获取服务"><a href="#获取服务" class="headerlink" title="获取服务"></a>获取服务</h3><ul><li><code>eureka.client.fetch-registry</code>: 提供获取服务功能，默认为true</li><li><code>eureka.client.registry-fetch-interval-seconds</code>: 服务注册中心，服务清单缓存更新时间间隔（更新频率），默认30秒</li></ul><p>下面整理了<code>org.springframework.cloud.netflix.eureka.EurekaClientConfigBean</code>中定义的常用配置参数以及对应的说明和默认值,这些参数均以<code>eureka.client</code>为前缀。</p><table><thead><tr><th>参数名</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>enabled</td><td>启用eureka客户端</td><td>true</td></tr><tr><td>registryFetchIntervalSeconds</td><td>从eureka服务端获取注册信息的间隔时间，单位为秒</td><td>30</td></tr><tr><td>instanceInfoReplicationIntervalSeconds</td><td>更新实例信息的变化到Eureka服务端的间隔时间，单位为秒</td><td>30</td></tr><tr><td>initialInstanceInfoReplicationIntervalSeconds</td><td>初始化实例信息到Eureka服务端的间隔时间，单位为秒</td><td>40</td></tr><tr><td>eurekaServiceUrlPollIntervalSeconds</td><td>轮询Eureka服务端地址更改的间隔时间，单位为秒。当我们与<code>Spring Cloud Config</code>配合，动态刷新<code>Eureka</code>的<code>ServiceURL</code>地址时需要关注该参数</td><td>5*60=300(5分钟)</td></tr><tr><td>eurekaServerReadTimeoutSeconds</td><td>读取Eureka Server信息的超时时间，单位为秒</td><td>8</td></tr><tr><td>eurekaServerConnectTimeoutSeconds</td><td>连接Eureka Server的超时时间，单位为秒</td><td>5</td></tr><tr><td>eurekaServerTotalConnections</td><td>从Eureka客户端到所有Eureka服务端的连接总数</td><td>200</td></tr><tr><td>eurekaServerTotalConnectionsPerHost</td><td>从Eureka客户端到每个Eureka服务端主机的连接总数</td><td>50</td></tr><tr><td>eurekaConnectionIdleTimeoutSeconds</td><td>Eureka服务端连接的空闲关闭时间，单位为秒</td><td>30</td></tr><tr><td>heartbeatExecutorThreadPoolSize</td><td>心跳连接池的初始化线程数</td><td>2</td></tr><tr><td>heartbeatExecutorExponentialBackOffBound</td><td>心跳超时重试延迟时间的最大乘数值</td><td>10</td></tr><tr><td>cacheRefreshExecutorThreadPoolSize</td><td>缓存刷新线程池的初始化线程数</td><td>2</td></tr><tr><td>cacheRefreshExecutorExponentialBackOffBound</td><td>缓存刷新重试延迟时间的最大乘数值</td><td>10</td></tr><tr><td>useDnsForFetchingServiceUrls</td><td>使用DNS来获取Eureka服务端的serviceURL</td><td>false</td></tr><tr><td>registerWithEureka</td><td>是否要将自身的实例信息注册到Eureka服务端</td><td>true</td></tr><tr><td>preferSameZoneEureka</td><td>是否偏好使用处于相同Zone的Eureka服务端</td><td>true</td></tr><tr><td>filterOnlyUpInstances</td><td>获取实例时是否过滤，仅保留UP状态的实例</td><td>true</td></tr><tr><td>fetchRegistry</td><td>是否从Eureka服务端获取注册信息</td><td>true</td></tr></tbody></table><p>下面整理了一些<code>org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean</code>中定义的配置参数以及对应的说明和默认值，这些参数均以<code>eureka.instance</code>为前缀。</p><table><thead><tr><th>参数名</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>preferIpAddress</td><td>是否优先使用IP地址作为主机名的标识</td><td>false</td></tr><tr><td>leaseRenewalIntervalInSeconds</td><td>Eureka客户端向服务端发送心跳的时间间隔，单位为秒</td><td>30</td></tr><tr><td>leaseExpirationDurationInSeconds</td><td>Eureka服务端在收到最后一次心跳之后等待的时间上限，单位为秒。超过该时间之后服务端会将该服务实例从服务清单中剔除，从而禁止服务调用请求被发送到该实例上</td><td>90</td></tr><tr><td>nonSecurePort</td><td>非安全的通信端口号</td><td>80</td></tr><tr><td>securePort</td><td>安全的通信端口号</td><td>443</td></tr><tr><td>nonSecurePortEnabled</td><td>是否启用非安全的通信端口号</td><td>true</td></tr><tr><td>securePortEnabled</td><td>是否启用安全的端口号</td><td>false</td></tr><tr><td>appname</td><td>服务名，默认取spring.application.name的配置值，如果没有则为unknow</td><td></td></tr><tr><td>hostname</td><td>主机名，不配置的时候将根据操作系统的主机名来获取</td><td></td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      eureka配置
    
    </summary>
    
      <category term="eureka配置" scheme="http://xym-loveit.github.io/categories/eureka%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="eureka配置" scheme="http://xym-loveit.github.io/tags/eureka%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>常用工具</title>
    <link href="http://xym-loveit.github.io/2018/03/29/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    <id>http://xym-loveit.github.io/2018/03/29/常用工具/</id>
    <published>2018-03-29T01:43:38.000Z</published>
    <updated>2018-03-29T03:09:43.791Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、Grepcode"><a href="#1、Grepcode" class="headerlink" title="1、Grepcode"></a>1、<a href="http://grepcode.com/" target="_blank" rel="noopener">Grepcode</a></h3><p>这是一个面向于java开发人员的网站，在这里你可以通过java的projects、classes等各种关键字在线查看它对应的源码，知道对应的project、classes等信息</p><h3 id="2、SearchCode"><a href="#2、SearchCode" class="headerlink" title="2、SearchCode"></a>2、<a href="https://searchcode.com/" target="_blank" rel="noopener">SearchCode</a></h3><p>SearchCode 是一个源码搜索引擎，目前支持从 Github、Bitbucket、Google Code、CodePlex、SourceForge 和 Fedora Project 平台搜索公开的源码。</p><h3 id="3、ProcessOn"><a href="#3、ProcessOn" class="headerlink" title="3、ProcessOn"></a>3、<a href="https://www.processon.com/" target="_blank" rel="noopener">ProcessOn</a></h3><p>ProcessOn是一个在线作图工具的聚合平台，它可以在线画流程图、思维导图、UI原型图、UML、网络拓扑图、组织结构图等等。</p><h3 id="4、json-cn"><a href="#4、json-cn" class="headerlink" title="4、json.cn"></a>4、<a href="https://www.json.cn/" target="_blank" rel="noopener">json.cn</a></h3><p>json在线解析及格式化</p><h3 id="5、bejson"><a href="#5、bejson" class="headerlink" title="5、bejson"></a>5、<a href="http://www.bejson.com/jsonviewernew/" target="_blank" rel="noopener">bejson</a></h3><p>json在线解析及格式化</p><h3 id="6、MaHua-、马克飞象-、Cmd"><a href="#6、MaHua-、马克飞象-、Cmd" class="headerlink" title="6、MaHua 、马克飞象 、Cmd"></a>6、<a href="http://mahua.jser.me/" target="_blank" rel="noopener">MaHua 、马克飞象 、Cmd</a></h3><p>一个在线编辑markdown文档的编辑器</p><h3 id="7、mvnrepository"><a href="#7、mvnrepository" class="headerlink" title="7、mvnrepository"></a>7、<a href="http://mvnrepository.com/" target="_blank" rel="noopener">mvnrepository</a></h3><p>maven依赖地址库</p><h3 id="8、代码在线运行"><a href="#8、代码在线运行" class="headerlink" title="8、代码在线运行"></a>8、<a href="https://tool.lu/coderunner/" target="_blank" rel="noopener">代码在线运行</a></h3><h3 id="9、Google翻译-百度翻译-有道翻译-爱词霸翻译"><a href="#9、Google翻译-百度翻译-有道翻译-爱词霸翻译" class="headerlink" title="9、Google翻译 百度翻译 有道翻译 爱词霸翻译"></a>9、<a href="https://translate.google.cn/" target="_blank" rel="noopener">Google翻译</a> <a href="http://fanyi.baidu.com/" target="_blank" rel="noopener">百度翻译</a> <a href="http://fanyi.youdao.com/" target="_blank" rel="noopener">有道翻译</a> <a href="http://fy.iciba.com/" target="_blank" rel="noopener">爱词霸翻译</a></h3><h3 id="10、AutoJCode"><a href="#10、AutoJCode" class="headerlink" title="10、AutoJCode"></a>10、<a href="http://www.autojcode.com/code/sql2class.jsp" target="_blank" rel="noopener">AutoJCode</a></h3><p>SQL和Java代码互相生成</p><h3 id="11、sql在线美化，格式化，压缩"><a href="#11、sql在线美化，格式化，压缩" class="headerlink" title="11、sql在线美化，格式化，压缩"></a>11、<a href="https://tool.lu/sql/" target="_blank" rel="noopener">sql在线美化，格式化，压缩</a></h3><h3 id="12、编码转换"><a href="#12、编码转换" class="headerlink" title="12、编码转换"></a>12、<a href="http://tool.chinaz.com/tools/unicode.aspx" target="_blank" rel="noopener">编码转换</a></h3><h3 id="13、Cron-常用Cron生成"><a href="#13、Cron-常用Cron生成" class="headerlink" title="13、Cron 常用Cron生成"></a>13、<a href="https://zh.wikipedia.org/zh-sg/Cron" target="_blank" rel="noopener">Cron</a> <a href="http://www.pppet.net/" target="_blank" rel="noopener">常用Cron生成</a></h3><h3 id="14、正则验证"><a href="#14、正则验证" class="headerlink" title="14、正则验证"></a>14、<a href="http://tool.chinaz.com/regex" target="_blank" rel="noopener">正则验证</a></h3><h3 id="15、正在代码生成"><a href="#15、正在代码生成" class="headerlink" title="15、正在代码生成"></a>15、<a href="http://tool.chinaz.com/tools/regexgenerate" target="_blank" rel="noopener">正在代码生成</a></h3><h3 id="16、时间戳转换"><a href="#16、时间戳转换" class="headerlink" title="16、时间戳转换"></a>16、<a href="http://tool.chinaz.com/Tools/unixtime.aspx" target="_blank" rel="noopener">时间戳转换</a></h3><h3 id="17、北美东部时间与北京时间换算"><a href="#17、北美东部时间与北京时间换算" class="headerlink" title="17、北美东部时间与北京时间换算"></a>17、<a href="http://tool.chinaz.com/Tools/unixtime.aspx" target="_blank" rel="noopener">北美东部时间与北京时间换算</a></h3><h3 id="18、加密解密"><a href="#18、加密解密" class="headerlink" title="18、加密解密"></a>18、<a href="http://tool.chinaz.com/tools/textencrypt.aspx" target="_blank" rel="noopener">加密解密</a></h3><h3 id="19、查看网页源代码"><a href="#19、查看网页源代码" class="headerlink" title="19、查看网页源代码"></a>19、<a href="http://s.tool.chinaz.com/tools/pagecode.aspx" target="_blank" rel="noopener">查看网页源代码</a></h3><h3 id="20、单位转换"><a href="#20、单位转换" class="headerlink" title="20、单位转换"></a>20、<a href="https://www.convertworld.com/zh-hans/" target="_blank" rel="noopener">单位转换</a></h3><h3 id="21、在线调色板"><a href="#21、在线调色板" class="headerlink" title="21、在线调色板"></a>21、<a href="http://tool.chinaz.com/Tools/OnlineColor.aspx" target="_blank" rel="noopener">在线调色板</a></h3><h3 id="22、ASCII码对照表"><a href="#22、ASCII码对照表" class="headerlink" title="22、ASCII码对照表"></a>22、<a href="http://tool.oschina.net/commons?type=4" target="_blank" rel="noopener">ASCII码对照表</a></h3><h3 id="24、HTTP状态码"><a href="#24、HTTP状态码" class="headerlink" title="24、HTTP状态码"></a>24、<a href="http://tool.oschina.net/commons?type=5" target="_blank" rel="noopener">HTTP状态码</a></h3><h3 id="25、HTTP-Content-type"><a href="#25、HTTP-Content-type" class="headerlink" title="25、HTTP Content-type"></a>25、<a href="http://tool.oschina.net/commons" target="_blank" rel="noopener">HTTP Content-type</a></h3><h3 id="26、TCP-UDP常见端口参考"><a href="#26、TCP-UDP常见端口参考" class="headerlink" title="26、TCP/UDP常见端口参考"></a>26、<a href="http://tool.oschina.net/commons?type=7" target="_blank" rel="noopener">TCP/UDP常见端口参考</a></h3><h3 id="27、HTML转义字符"><a href="#27、HTML转义字符" class="headerlink" title="27、HTML转义字符"></a>27、<a href="http://tool.oschina.net/commons?type=2" target="_blank" rel="noopener">HTML转义字符</a></h3><h3 id="28、RGB颜色对照表"><a href="#28、RGB颜色对照表" class="headerlink" title="28、RGB颜色对照表"></a>28、<a href="http://tool.oschina.net/commons?type=3" target="_blank" rel="noopener">RGB颜色对照表</a></h3><h3 id="29、对称非对称加解密算法"><a href="#29、对称非对称加解密算法" class="headerlink" title="29、对称非对称加解密算法"></a>29、<a href="http://web.chacuo.net/netrsakeypair" target="_blank" rel="noopener">对称非对称加解密算法</a></h3><h3 id="30、银行联行号查询"><a href="#30、银行联行号查询" class="headerlink" title="30、银行联行号查询"></a>30、<a href="http://lianhanghao.com/index.php" target="_blank" rel="noopener">银行联行号查询</a></h3><h3 id="31、字符生成1-字符生成2-字符生成3"><a href="#31、字符生成1-字符生成2-字符生成3" class="headerlink" title="31、字符生成1  字符生成2  字符生成3"></a>31、<a href="http://patorjk.com/software/taag" target="_blank" rel="noopener">字符生成1</a>  <a href="http://www.network-science.de/ascii/" target="_blank" rel="noopener">字符生成2</a>  <a href="http://www.degraeve.com/img2txt.w" target="_blank" rel="noopener">字符生成3</a></h3><h3 id="32、jdk1-8-api文档"><a href="#32、jdk1-8-api文档" class="headerlink" title="32、jdk1.8 api文档"></a>32、<a href="https://docs.oracle.com/javase/8/docs/api/" target="_blank" rel="noopener">jdk1.8 api文档</a></h3><h3 id="33、a6"><a href="#33、a6" class="headerlink" title="33、a6"></a>33、<a href="http://www.a6a6.org/" target="_blank" rel="noopener">a6</a></h3><h3 id="34、身份证号码生成器"><a href="#34、身份证号码生成器" class="headerlink" title="34、身份证号码生成器"></a>34、<a href="http://www.welefen.com/lab/identify" target="_blank" rel="noopener">身份证号码生成器</a></h3><h3 id="35、NIO入门，讲的超级好"><a href="#35、NIO入门，讲的超级好" class="headerlink" title="35、NIO入门，讲的超级好"></a>35、<a href="https://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html" target="_blank" rel="noopener">NIO入门，讲的超级好</a></h3><h3 id="36、不死鸟-分享为王"><a href="#36、不死鸟-分享为王" class="headerlink" title="36、不死鸟,分享为王"></a>36、<a href="https://lai.yuweining.cn/" target="_blank" rel="noopener">不死鸟,分享为王</a></h3><h3 id="37、分享-GitHub-上有趣、入门级的开源项目"><a href="#37、分享-GitHub-上有趣、入门级的开源项目" class="headerlink" title="37、分享 GitHub 上有趣、入门级的开源项目"></a>37、<a href="https://hellogithub.com/" target="_blank" rel="noopener">分享 GitHub 上有趣、入门级的开源项目</a></h3><h3 id="38、斗图网"><a href="#38、斗图网" class="headerlink" title="38、斗图网"></a>38、<a href="https://www.doutula.com/" target="_blank" rel="noopener">斗图网</a></h3><h3 id="39、在线电子书柜"><a href="#39、在线电子书柜" class="headerlink" title="39、在线电子书柜"></a>39、<a href="https://love2.io/" target="_blank" rel="noopener">在线电子书柜</a></h3><h3 id="40、mybatis-3中文文档"><a href="#40、mybatis-3中文文档" class="headerlink" title="40、mybatis-3中文文档"></a>40、<a href="http://www.mybatis.org/mybatis-3/zh/java-api.html" target="_blank" rel="noopener">mybatis-3中文文档</a></h3><h3 id="41、Hexo文档"><a href="#41、Hexo文档" class="headerlink" title="41、Hexo文档"></a>41、<a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">Hexo文档</a></h3>]]></content>
    
    <summary type="html">
    
      常用工具地址存档，方便使用
    
    </summary>
    
      <category term="常用工具" scheme="http://xym-loveit.github.io/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="常用工具" scheme="http://xym-loveit.github.io/tags/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之管理</title>
    <link href="http://xym-loveit.github.io/2017/06/09/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E7%AE%A1%E7%90%86/"/>
    <id>http://xym-loveit.github.io/2017/06/09/redis入门指南之管理/</id>
    <published>2017-06-09T09:22:22.000Z</published>
    <updated>2018-03-29T01:27:48.646Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★"><a href="#重要星级-★★★" class="headerlink" title="重要星级 ★★★"></a>重要星级 ★★★</h6><hr><h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><p>Redis的作者Salvatore Sanfilippo曾经发表过Redis宣言，其中提到了Redis以简洁为美。同样在安全层面Redis也没有做太多的工作。  </p><h3 id="1、可信的环境"><a href="#1、可信的环境" class="headerlink" title="1、可信的环境"></a>1、可信的环境</h3><p>Redis的安全设计是在“Redis运行在可信环境”这个前提下做出的。在生产环境运行时不能允许外界直接连接到Redis服务器上，而应该通过应用程序进行中转，运行在可信的环境中是保证Redis安全的最重要方法。<br>Redis的默认配置会接受来自任何地址发送来的请求，即在任何一个拥有公网IP的服务器上启动Redis服务器，都可以被外界直接访问到。要更改这一设置，在配置文件中修改bind参数，如只允许本机应用连接Redis，可以将bind参数改成：  </p><pre><code>bind 127.0.0.1</code></pre><p>如果想要绑定多个地址，中间采用空格隔开，配置多个即可。  </p><pre><code>bind 127.0.0.1 192.168.100.238</code></pre><h3 id="2、数据库密码"><a href="#2、数据库密码" class="headerlink" title="2、数据库密码"></a>2、数据库密码</h3><p>除此之外，还可以通过配置文件中的<code>requirepass</code>参数为Redis设置一个密码。例如：  </p><pre><code>requirepass 12345678</code></pre><p>客户端每次连接到Redis时都需要发送密码，否则Redis会拒绝执行客户端发来的命令。<br>例如：  </p><pre><code>127.0.0.1:6379&gt; info defaultNOAUTH Authentication required.127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required.</code></pre><p>发送密码需要使用AUTH命令，就像这样：  </p><pre><code>127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; client listid=145 addr=127.0.0.1:55057 fd=5 name= age=9 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client</code></pre><p>由于Redis的性能极高，并且输入错误密码后Redis并不会进行主动延迟（考虑到Redis的单线程模型），所以攻击者可以通过穷举法破解Redis的密码，因此设置密码时一定要选择复杂的密码。<br><strong>提示：配置Redis复制的时候如果主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置主数据库的密码，以使从数据库连接主数据库时自动使用AUTH命令认证。</strong>  </p><h3 id="3、重命名命令"><a href="#3、重命名命令" class="headerlink" title="3、重命名命令"></a>3、重命名命令</h3><p>Redis支持在配置文件中将命令重命名，比如将FLUSHALL 命令重命名成一个比较复杂的名字，以保证只有自己的应用可以使用该命令。就像下面这样：  </p><pre><code>rename-command FLUSHALL QKSYSJK</code></pre><p>如果希望直接禁用某个命令可以将命令重命名成空字符串：  </p><pre><code>rename-command FLUSHALL &quot;&quot;</code></pre><p>无论设置密码还是重命名命令，都需要保证配置文件的安全性，否则就没有任何意义了。  </p><h2 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h2><p>Redis通信协议是Redis客户端与Redis之间交流的语言，通信协议规定了命令和返回值的格式。了解Redis通信协议后不仅可以理解AOF文件的格式和主从复制时主数据库向从数据库发送的内容等，还可以开发自己的客户端。<br>Redis支持两种通信协议，一种是二进制安全的统一请求协议（unified request protocol），另一种是比较直观的便于在telnet程序中输入的简单协议。这两种协议只是命令格式有区别，命令返回值的格式是一样的。  </p><h3 id="1、简单协议"><a href="#1、简单协议" class="headerlink" title="1、简单协议"></a>1、简单协议</h3><p>简单协议适合在telnet程序中和Redis通信。简单协议的命令格式就是将命令和各个参数使用空格分隔开，如“EXISTS foo ”、“SET foo bar”等。由于Redis解析简单协议时只是简单地以空格分隔参数，所以无法输入二进制字符。我们可以通过telnet程序测试：  </p><pre><code>[admin@KFCS2 redis-stable]$ telnet  127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.set foo bar-NOAUTH Authentication required.auth 123456+OKset foo bar +OKget foo$3barlpush plist 1 2 3          :3lrange plist 0 -1*3$13$12$11errorcommand-ERR unknown command &apos;errorcommand&apos;</code></pre><p>我们在telnet程序中输入的5条命令恰好展示了Redis5种返回类型的格式，上面章节介绍了这5种返回值类型在redis-cli中的展现形式，这些展现形式是经过了redis-cli封装的，而上面的内容才是Redis真正返回的格式。下面分别介绍。<br>1、错误回复<br>错误回复（error reply）以-开头，并在后面跟上错误信息，最后以\r\n结尾：<br>-ERR unknown command ‘errorcommand’\r\n</p><p>2、状态回复<br>状态回复（status reply）以+开头，并在后面跟上状态信息，最后以\r\n结尾：<br>+OK\r\n</p><p>3、整数回复<br>整数回复（integer reply）以：开头，并在后面跟上数字，最后以\r\n结尾：<br>:3\r\n</p><p>4、字符串回复<br>字符串回复（bulk reply）以$开头，并在后面跟上字符串的长度，并以以\r\n分隔，接着是字符串的内容和\r\n：<br>$3\r\nbar\r\n<br>如果返回值是空结果nil，则会返回$-1以和空字符串相区别。</p><p>5、多行字符串回复<br>多行字符串回复（multi-bulk reply）以<em>开头，并在后面跟上字符串回复的组数，并以\r\n分隔。接着后面跟的就是字符串回复的具体内容了：  </em>3\r\n$1\r\n3\r\n$1\r\n2\r\n$1\r\n1\r\n</p><h3 id="2、统一请求协议"><a href="#2、统一请求协议" class="headerlink" title="2、统一请求协议"></a>2、统一请求协议</h3><p>统一请求协议是从Redis1.2开始加入的，其命令格式和多行字符串回复的格式很类似，如 SET foo bar 的统一请求协议写法是*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$3\r\nbar\r\n。还是使用telnet进行演示：  </p><pre><code>[admin@KFCS2 redis-stable]$ telnet  127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.*3$3  SET$3    foo$3bar-NOAUTH Authentication required.auth 123456+OK</code></pre><p>同样发送命令时指定了后面字符串的长度，所以命令的每个参数都可以包含二进制的字符。统一请求协议的返回值格式和简单协议一样。<br>Redis的AOF文件和主从复制时主数据库向从数据库发送的内容都是用了统一请求协议。如果要开发一个和Redis直接通信的客户端，推荐使用此协议。如果只是想通过telnet向Redis服务器发送命令则使用简单协议就可以了。  </p><h2 id="管理工具"><a href="#管理工具" class="headerlink" title="管理工具"></a>管理工具</h2><p>工欲善其事必先利其器。在使用Redis的时候如果能够有效利用Redis的各种管理工具，将会大大方便开发和管理。  </p><h3 id="1、redis-cli"><a href="#1、redis-cli" class="headerlink" title="1、redis-cli"></a>1、redis-cli</h3><p>作为Redis自带的命令行客户端，你可以从任何安装有Redis的服务器中找到它，所以对于管理Redis而言redis-cli是最简单实用的工具。<br>redis-cli可以执行大部分的Redis命令，包括查看数据库信息的INFO命令，更改数据库设置的CONFIG命令和强制进行RDB快照的SAVE命令等。下面介绍几个管理Redis时非常有用的命令。<br>1、耗时命令日志<br>当一条命令执行时间超时限制时，Redis会将该命令的执行时间等信息加入耗时命令日志（slow log）以供开发者查看。可以通过配置文件<code>slowlog-log-slower-than</code> 参数设置这一限制，要注意单位是微妙（1000 000微妙相当于1秒），默认值是10 000。耗时命令日志存储在内存中，可以通过配置文件的<code>slowlog-max-len</code>参数来限制记录的条数。为了产生一些耗时命令日志作为演示，这里将<code>slowlog-log-slower-than</code>参数值设置为0，即记录所有命令。如果设置为负数则会关闭耗时命令日志。如：  </p><pre><code>127.0.0.1:6379&gt; slowlog get 1) 1) (integer) 16    2) (integer) 1497011605    3) (integer) 52    4) 1) &quot;set&quot;       2) &quot;foo&quot;       3) &quot;bar&quot; 2) 1) (integer) 15    2) (integer) 1497011599    3) (integer) 6    4) 1) &quot;get&quot;       2) &quot;foo&quot;</code></pre><p>每条日志都由以下4个部分组成：<br>（1）改日志唯一ID<br>（2）改命令执行的UNIX时间<br>（3）改命令的耗时时间，单位是微妙<br>（4）命令及其参数  </p><p>2、命令监控<br>Redis提供了MONITOR命令来监控Redis执行的所有命令，redis-cli同样支持这个命令，如在redis-cli中执行MONITOR： </p><pre><code>127.0.0.1:6379&gt; monitorOK</code></pre><p>这时Redis执行的任何命令都会在redis-cli中打印出来，如我们打开另一个redis-cli执行SET foo bar命令，在之前的redis-cli中会输出如下内容：  </p><pre><code>1497012041.878429 [0 127.0.0.1:55062] &quot;auth&quot; &quot;123456&quot;1497012053.311366 [0 127.0.0.1:55062] &quot;set&quot; &quot;foo&quot; &quot;bar&quot;</code></pre><p>MONITOR命令非常影响Redis的性能，一个客户端使用MONITOR命令会降低Redis将近一半的负载能力。所以MONITOR命令只适合用来调试和纠错。</p><h3 id="2、采用phpRedisAdmin"><a href="#2、采用phpRedisAdmin" class="headerlink" title="2、采用phpRedisAdmin"></a>2、采用phpRedisAdmin</h3><p>Redis有一款使用PHP开发的网页管理工具phpRedisAdmin。phpRedisAdmin支持以树结构查看键列表，编辑键值，导入/导出数据库数据，查看数据库信息和查看键信息等功能。  </p><h3 id="3、Rdbtools"><a href="#3、Rdbtools" class="headerlink" title="3、Rdbtools"></a>3、Rdbtools</h3><p>Rdbtools是一个Redis快照文件解析器，它可以根据快照文件导出JSON数据文件、分析Redis中每个键的占用空间情况等。</p>]]></content>
    
    <summary type="html">
    
      Redis管理知识，包括协议和安全等内容，及其第三方管理工具。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis安全" scheme="http://xym-loveit.github.io/tags/redis%E5%AE%89%E5%85%A8/"/>
    
      <category term="redis数据库密码" scheme="http://xym-loveit.github.io/tags/redis%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%86%E7%A0%81/"/>
    
      <category term="redis命令重命名" scheme="http://xym-loveit.github.io/tags/redis%E5%91%BD%E4%BB%A4%E9%87%8D%E5%91%BD%E5%90%8D/"/>
    
      <category term="redis通信协议" scheme="http://xym-loveit.github.io/tags/redis%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="redis管理工具" scheme="http://xym-loveit.github.io/tags/redis%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之集群</title>
    <link href="http://xym-loveit.github.io/2017/06/05/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E9%9B%86%E7%BE%A4/"/>
    <id>http://xym-loveit.github.io/2017/06/05/redis入门指南之集群/</id>
    <published>2017-06-05T13:05:02.000Z</published>
    <updated>2018-03-29T01:27:48.647Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>即使使用哨兵，此时的Redis集群的每个数据库依然存有集群中的所有数据，从而导致集群的总数据存储量受限于可用存储内存最小的数据库节点，形成木桶效应。由于Redis中的所有数据都是基于内存存储，这一问题就尤为突出了，尤其是当使用Redis做了持久化存储服务使用时。<br>对Redis进行水平扩容，在旧版Redis中通常使用客户端分片来解决这个问题，即启动多个Redis数据库节点，由客户端决定每个键交由哪个数据库节点存储，下次客户端读取该键值时直接到该节点读取。这样可以实现将整个数据分布存储在N个数据库节点中，每个节点只存放总数据量的1/N。但对于需要扩容的场景来说，在客户端分片后，如果想增加更多的节点，就需要对数据进行手工迁移，同时在迁移的过程中为了保证数据的一致性，还需要将集群暂时下线，相对比较复杂。<br>考虑到Redis实例非常轻量的特点，可以采用预分片技术（presharding）来在一定程度上避免此问题，具体来说是在节点部署初期，就提前考虑日后的存储规模，建立足够多的实例（如128个节点），初期数据很少，所以每个节点存储的数据也非常少，但由于节点轻量的特性，数据之外的内存开销并不大，这使得只需要很少的服务器即可运行这些实例。日后存储规模扩大后，所要做的不过是将某些实例迁移到其他服务器上，而不需要对所有数据进行重新分片并进行集群下线和数据迁移了。<br>无论如何，客户端分片终归是有非常多的缺点，比如维护成本高，增加、移除节点较繁琐等。Redis3.0版的一大特性就是支持集群（Cluster，注意与本章标题–广义的“集群”相区别）功能。集群的特点在于拥有和单机实例同样的性能，同时在网络分区后能够提供一定的可访问性以及对主数据库故障恢复的支持。另外集群支持几乎所有的单机实例支持的命令，对于涉及多键的命令（如MGET），如果每个键都位于同一个节点中，则可以正常支持，否则会提示错误。除此之外集群还有一个限制是只能使用默认的0号数据库，如果执行SELECT切换数据库则会提示错误。<br>哨兵与集群是两个独立的功能，但从特性来看哨兵可以视为集群的子集，当不需要数据分片或者已经在客户端进行分片的场景下哨兵就足够使用了，但如果需要进行水平扩容，则集群是一个非常好的选择。  </p><h3 id="1、配置集群"><a href="#1、配置集群" class="headerlink" title="1、配置集群"></a>1、配置集群</h3><p>使用集群，只需要将每个数据库节点的cluster-enabled配置选项打开即可。每个集群中至少需要3个主数据库才能正常运行。<br>为了演示集群的应用场景以及故障恢复等操作，这里以配置一个3主3从的集群系统为例。首先建立启动6个Redis实例，需要注意的是配置文件应该打开cluster-enabled。一个示例配置为：  </p><pre><code>port 6380cluster-enabled yes  </code></pre><p>其中port参数修改成实际的端口即可。这里假设6个实例的端口分别是6380、6381、6382、6383、6384和6385。集群会将当前节点记录的集群状态持久化地存储在指定文件中，这个文件默认为当前工作目录下的nodes.conf文件。每个节点对应的文件必须不同，否则会造成启动失败，所以启动节点时要注意最后为每个节点使用不同的工作目录，或者是通过cluster-config-file选项修改持久化文件的名称：  </p><pre><code>cluster-config-file nodes.conf  </code></pre><p>启动后，可以使用Redis命令行客户端连接任意一个节点使用INFO命令来判断集群是否正常启用了：  </p><pre><code>192.168.100.238:6381&gt; info cluster# Clustercluster_enabled:1</code></pre><p>其中cluster_enabled为1表示集群正常启用了。现在每个节点都是完全独立的，要将它们加入同一个集群中还需要几个步骤。Redis源代码中提供了一个辅助工具redis-trib.rb可以非常方便地完成这一任务。因为redis-trib.rb使用Ruby语言编写的，所以运行前需要在服务器上安装Ruby程序，具体安装方法请查阅相关文档。redis-trib.rb依赖于gem包redis，可执行gem install redis来安装。使用redis-trib.rb来初始化集群，只需要执行：  </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-trib.rb create --replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385</code></pre><p>其中create参数表示要初始化集群，–replicas 1表示每个主数据库拥有的从数据库个数为1，所以集群共有3（6/2）个主数据库以及3个从数据库。执行完成后，redis-trib.rb会输出如下内容：  </p><pre><code>--未执行集群时&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:6380127.0.0.1:6381127.0.0.1:6382Adding replica 127.0.0.1:6383 to 127.0.0.1:6380Adding replica 127.0.0.1:6384 to 127.0.0.1:6381Adding replica 127.0.0.1:6385 to 127.0.0.1:6382M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) masterM: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) masterM: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) masterS: 50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383   replicates bec0f2a8743b6636cf53cd5611137dd9a5ee72f3S: 6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384   replicates a24810378b2ee15efbbef8bbf285872198ef6902S: 4c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385   replicates e18b9946f5c4db8b170b395a6de8204ab56237f9Can I set the above configuration? (type &apos;yes&apos; to accept): yes--已执行过集群后[admin@KFCS3 redis-stable]$ ./src/redis-trib.rb create --replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385&gt;&gt;&gt; Creating cluster[ERR] Node 127.0.0.1:6382 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.</code></pre><p>上实例2表示节点已分配插槽。上例1输出内容包括集群具体的分配方案，如果觉得没问题则输入yes来开始创建。下面根据上面的输出详细讲解集群创建的过程。<br>首先redis-trib.rb会以客户端的形式尝试连接所有节点，并发送PING命令以确定节点能够正常服务。如果有任何节点无法连接，则创建失败。同时发送INFO命令获取每个节点的运行ID以及是否开启了集群功能（即cluster_enabled为1）。<br>准备就绪后集群会向每个节点发送CLUSTER MEET 命令，格式为CLUSTER MEET ip port，这个命令用来告诉当前节点指定ip和port上在运行的节点也是集群的的一部分，从而使得6个节点最终可以纳入一个集群。<br>然后redis-trib.rb会分配主从数据库节点，分配的原则是尽量保证每个主数据库运行在不同的IP地址上，同时每个从数据库和主数据库均不运行在同一个IP地址上，以保证系统的容灾能力。分配结果如下：  </p><pre><code>Using 3 masters:127.0.0.1:6380127.0.0.1:6381127.0.0.1:6382Adding replica 127.0.0.1:6383 to 127.0.0.1:6380Adding replica 127.0.0.1:6384 to 127.0.0.1:6381Adding replica 127.0.0.1:6385 to 127.0.0.1:6382</code></pre><p>其中主数据库是6380、6381和6382端口上的节点（以下使用端口来指代节点），6383是6380的从数据库，6384是6381的从数据库，6385是6382的从数据库。分配完成后，会为每个主数据库分配插槽，分配插槽的过程其实就是分配哪些键归哪些节点负责。之后对每个要成为子数据库的节点发送CLUSTER REPLICATE 主数据库的运行ID 来讲当前节点转换成从数据库并复制指定运行ID的节点（主数据库）。<br>此时整个集群的过程即创建完毕，使用Redis命令行客户端连接任意一个节点执行CLUSTER NODES 可以获得集群中的所有节点信息，如在6380执行：  </p><pre><code>127.0.0.1:6380&gt; cluster nodes50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383 slave bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 0 1496677290597 4 connectede18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382 master - 0 1496677293602 3 connected 10923-163836054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384 slave a24810378b2ee15efbbef8bbf285872198ef6902 0 1496677294603 5 connectedbec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380 myself,master - 0 0 1 connected 0-54604c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385 slave e18b9946f5c4db8b170b395a6de8204ab56237f9 0 1496677292600 6 connecteda24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381 master - 0 1496677295605 2 connected 5461-10922</code></pre><p>从上面的输出中可以看到所有节点的运行ID、地址和端口、角色、状态以及负责的插槽等信息，后文会进行解读。redis-trib.rb是一个非常好用的辅助工具，其本质是通过执行Redis命令来实现集群管理的任务。如果有兴趣可以尝试不借助redis-trib.rb，手动建立一次集群。      </p><h3 id="2、节点的增加"><a href="#2、节点的增加" class="headerlink" title="2、节点的增加"></a>2、节点的增加</h3><p> 前面介绍过redis-trib.rb是使用CLUSTER MEET 命令来使每个节点认识集群中的其他节点的，可想而知如果要向集群中加入新节点，也需要使用CLUSTER MEET 命令实现。加入新节点非常简单，只需要向新节点（以下记着A）发送如下命令:  </p><pre><code>CLUSTER MEET ip port  </code></pre><p>ip和port是集群中任意一个节点的地址和端口号，A接受到客户端发来的命令后，会与该地址和端口号的节点B进行握手，使B将A认作当前集群中的一员。当B与A握手成功后，B会使用Gossip协议将节点A的信息通知给集群中的每一个节点。通过这一方式，即使集群中有多个节点，也只需要选择MEET 其中任意一个节点，即可使新节点最终加入整个集群。  </p><h3 id="3、插槽的分配"><a href="#3、插槽的分配" class="headerlink" title="3、插槽的分配"></a>3、插槽的分配</h3><p>新的节点加入集群后有两种选择，要么使用CLUSTER REPLICATE 命令复制每个数据库来以从数据库的形式运行，要么向集群申请分配插槽（solt）来以主数据库的形式运行。在一个集群中，所有的键会被分配给16384个插槽，而每个主数据库会负责处理其中的一部分插槽。现在回头来看上面创建集群时的输出：  </p><pre><code>M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) masterM: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) masterM: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) master</code></pre><p>上面的每一行表示一个主数据库的信息，其中可以看到6380负责处理0~5460折5461个插槽，6381负责处理5461~10922这5462个插槽，6382负责处理10923~16383这5461个插槽。虽然redis-trib.rb初始化集群分配给每个节点的插槽都是连续的，但是实际上Redis并没有限制，可以将任意的几个插槽分配给任意的节点负责。<br>在介绍如何将插槽分配给指定的节点前，先来介绍键和插槽的对应关系。Redis将每个键的键名的有效部分使用CRC16算法计算出散列值，然后取对16384的余数。这样使得每个键都可以分配到16384个插槽中，进而分配的指定的一个节点中处理。这里键名的有效部分是指：<br>（1）如果键名包含{符号，且在{符合后面存在}符号，并且{和}之间有至少一个字符，则有效部分是指{和}之间的内容。<br>（2）如果不满足上一条规则，那么整个键名为有效部分。<br>例如，键hello.world的有效部分为“hello.world”，键{user102}:last.name的有效部分为“user102”。如本节引言所说，如果命令涉及多个键（如MGET），只有当所有键都位于同一个节点时Redis才能正常支持。利用键的分配规则，可以将所有相关的键的有效部分设置成相同的值使得相关键都能分配到同一个节点以支持多键操作。比如，{user102}:first.name和{user102}:last.name会被分配到同一个节点，所以可以使用MGET {user102}:first.name {user102}:last.name 来同时获取两个键的值。介绍完键与插槽的对应关系后，接下来再来介绍如何将插槽分配给指定节点。插槽的分配分为如下几种情况。<br>（1）插槽之前没有被分配过，现在想分配给指定节点。<br>（2）插槽之前被分配过，现在想移动到指定节点。<br>其中第一种情况使用CLUSTER ADDSLOTS命令来实现，redis-trib.rb也是通过该命令在创建集群时为新节点分配插槽的。<strong>CLUSTER ADDSLOTS</strong>命令的用法为：  </p><pre><code>CLUSTER ADDSLOTS  slot1 [slot2] ... [slotN]</code></pre><p>如想将100和101两个插槽分配给某个节点，只需要在该节点执行：CLUSTER ADDSLOTS 100 101即可。如果指定插槽已经分配过了，则会提示：  </p><pre><code>127.0.0.1:6380&gt; cluster addslots 100 101(error) ERR Slot 100 is already busy  </code></pre><p>可以通过命令 <strong>CLUSTER SLOTS</strong> 来查看插槽分配情况，如：  </p><pre><code>127.0.0.1:6380&gt; cluster slots1) 1) (integer) 10923   2) (integer) 16383   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6382      3) &quot;e18b9946f5c4db8b170b395a6de8204ab56237f9&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6385      3) &quot;4c9ec5e346ac451d6d44df4d817112fdac3f6da6&quot;2) 1) (integer) 0   2) (integer) 5460   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6380      3) &quot;bec0f2a8743b6636cf53cd5611137dd9a5ee72f3&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6383      3) &quot;50c78a069f7d4a052d0f3e4c83083e6279b49acb&quot;3) 1) (integer) 5461   2) (integer) 10922   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;  </code></pre><p>其中返回结果的格式很容易理解，一共3条记录，每条记录的前两个表示插槽的开始号码和结束号码，后面的值则为负责该插槽的节点，包括主数据库和所有的从数据库，主数据库始终在第一位。<br>对于情况2，处理起来就相对复杂一些，不过redis-trib.rb提供了比较方便的方式来对插槽进行迁移。我们首先使用redis-trib.rb将一个插槽从6380迁移到6381，然后再介绍如何不使用redis-trib.rb来完成迁移。首先执行如下命令：  </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-trib.rb reshard 127.0.0.1:6380</code></pre><p>其中reshard表示告诉redis-trib.rb要重新分片，127.0.0.1:6380是集群中任意一个节点的地址和端口，redis-trib.rb会自动获取集群信息。接下来redis-trib.rb将会询问具体如何进行重新分片，首先会询问想要迁移多少个插槽：  </p><pre><code>How many slots do you want to move (from 1 to 16384)?</code></pre><p>我们只需要迁移一个，所以输入1后回车。接下来redis-trib.rb会询问要把插槽迁移到哪个节点： </p><pre><code>How many slots do you want to move (from 1 to 16384)? 1What is the receiving node ID? </code></pre><p>可以通过<strong>CLUSTER NODES</strong>命令获取6381的运行ID,这里是a24810378b2ee15efbbef8bbf285872198ef6902，输入并回车。接着最后异步是询问从那个节点移除插槽：  </p><pre><code>What is the receiving node ID? a24810378b2ee15efbbef8bbf285872198ef6902Please enter all the source node IDs.  Type &apos;all&apos; to use all the nodes as source nodes for the hash slots.  Type &apos;done&apos; once you entered all the source nodes IDs.Source node #1:all</code></pre><p>我们输入6380对应的ID按回车后输入done再按回车确认即可。接下来输入yes来确认重新分片方案，重新分片即告成功。</p><pre><code>Ready to move 1 slots.  Source nodes:    M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) master   1 additional replica(s)    M: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) master   1 additional replica(s)  Destination node:    M: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) master   1 additional replica(s)  Resharding plan:    Moving slot 0 from bec0f2a8743b6636cf53cd5611137dd9a5ee72f3Do you want to proceed with the proposed reshard plan (yes/no)? yesMoving slot 0 from 127.0.0.1:6380 to 127.0.0.1:6381:</code></pre><p>使用<strong>CLUSTER SLOTS</strong>命令获取当前插槽的分配情况如下：  </p><pre><code>127.0.0.1:6380&gt; cluster slots1) 1) (integer) 10923   2) (integer) 16383   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6382      3) &quot;e18b9946f5c4db8b170b395a6de8204ab56237f9&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6385      3) &quot;4c9ec5e346ac451d6d44df4d817112fdac3f6da6&quot;2) 1) (integer) 1   2) (integer) 5460   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6380      3) &quot;bec0f2a8743b6636cf53cd5611137dd9a5ee72f3&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6383      3) &quot;50c78a069f7d4a052d0f3e4c83083e6279b49acb&quot;3) 1) (integer) 0--多出来的第0号插槽   2) (integer) 0   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;4) 1) (integer) 5461   2) (integer) 10922   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;</code></pre><p>可以看到现在比之前多了一条记录，第0号插槽已经有6381负责，此时重新分片成功。那么redis-trib.rb实现重新分片的原理是什么呢？我们不妨不借助redis-trib.rb手工进行重新分片，使用如下命令即可：  </p><pre><code>CLUSTER SETSLOTS 插槽号 NODE 新节点的运行ID</code></pre><p>如想要把0号插槽迁移回6380：  </p><pre><code>127.0.0.1:6380&gt; cluster nodes50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383 slave bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 0 1496714712675 4 connectede18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382 master - 0 1496714710672 3 connected 10923-163836054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384 slave a24810378b2ee15efbbef8bbf285872198ef6902 0 1496714711674 7 connectedbec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380 myself,master - 0 0 1 connected 1-54604c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385 slave e18b9946f5c4db8b170b395a6de8204ab56237f9 0 1496714710172 6 connecteda24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381 master - 0 1496714706668 7 connected 0 5461-10922127.0.0.1:6380&gt; cluster setslot 0 node bec0f2a8743b6636cf53cd5611137dd9a5ee72f3OK</code></pre><p>此时重新使用CLUSTER SLOTS 查看插槽的分配情况，可以看到已经恢复如初了。然而这样迁移插槽的前提是插槽中并没有任何键，因为使用CLUSTER SETSLOT 命令迁移插槽时并不会连同相应的键一起迁移，这就造成了客户端在指定节点无法找到未迁移的键，造成这些键对客户端来说“丢失了”，为此需要手工获取插槽中存储在哪些键，然后将每个键迁移到新的节点中才行。手工获取某个插槽存在哪些键的方法是：  </p><pre><code>CLUSTER GETKEYSINSLOT 插槽号 要返回的键的数量</code></pre><p>之后对每个键，使用MIGRATE命令将其迁移到目标节点：  </p><pre><code>MIGRATE 目标节点地址 目标节点端口 键名 数据库号码 超时时间 [COPY] [REPLACE]</code></pre><p>其中COPY选项表示不将键从当前数据库中删除，而是复制一份副本。REPLACE表示如果目标节点存在同名键，则覆盖。因为集群模式只能使用0号数据库，所以数据库号码始终未0。如要把键abc从当前节点（如6381）迁移到6380：  </p><pre><code>MIGRATE 127.0.0.1 127.0.0.1 6380 abc 0 15999 REPLACE</code></pre><p>至此，我们已经知道如果将插槽委派给其他节点，并同时将当前节点中的插槽下所有的键迁移到目标节点中。然而还有最后一个是如果要迁移的数据量比较大，整个过程会话费较长时间，那么究竟在什么时候执行 CLUSTER SETSLOT 命令来完成插槽的交接呢？如果在键迁移未完成时执行，那么客户端就会尝试在新的节点读取键值，此时还没迁移完成，自然有可能读取不到键值，从而造成相关键的临时“丢失”。相反，如果在键迁移完成后在执行，那么在迁移时客户端会在旧的节点读取键值，然后有些键已经迁移到新节点上了，同样也会造成键的临时“丢失”。那么redis-trib.rb工具是如何解决这个问题的呢？Redis提供了如下两个命令用来实现在集群不下线的情况下迁移数据：  </p><pre><code>CLUSTER SETSLOT 插槽号 MIGRATING 新节点的运行IDCLUSTER SETSLOT 插槽号 IMPORTING 原节点的运行ID</code></pre><p>进行迁移时，假设要把0号插槽从A迁移到B，此时redis-trib.rb会依次执行如下操作。<br>（1）在B执行CLUSTER SETSLOT 0 IMPORTING A。<br>（2）在A执行CLUSTER SETSLOT 0 MIGRATING B。<br>（3）执行CLUSTER GETKEYSINSLOT 0 获取0号插槽的键列表。<br>（4）对第3步获取的每个键执行MIGRATE命令，将其从A迁移到B。<br>（5）执行CLUSTER SETSLOT 0 NODE B 来完成迁移。<br>从上面的步骤来看redis-trib.rb多了1和2两个步骤，这两个步骤就是为了解决迁移过程中键的临时“丢失”问题。首先执行完前两步后，当客户端向A请求插槽0中的键时，如果键存在（即尚未被迁移），则正常处理，如果不存在，则返回一个ASK跳转请求，告诉客户端这个键在B里，如下图所示，客户端接受到ASK跳转请求后，首先向B发送ASKING命令，然后再重新发送之前的命令。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/askA.png" alt="客户端请求A节点，服务器返回ASK情况">  </p><p>相反，当客户端向B请求插槽0中的键，如果前面执行了ASKING命令，则返回键值内容，否则返回MOVED跳转请求，如下图所示，这样一来客户端只有能够处理ASK跳转，则可以在数据库迁移时自动从正确的节点获取到相应的键值，避免了键在迁移过程中临时“丢失”的问题。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/askB.png" alt="客户端请求B节点，根据是否前面执行过ASKING，则返回不同"> </p><h3 id="4、获取与插槽对应的节点"><a href="#4、获取与插槽对应的节点" class="headerlink" title="4、获取与插槽对应的节点"></a>4、获取与插槽对应的节点</h3><p>对于指定的键，可以根据前面讲述的算法来计算其属于哪个插槽，但是如何获取某一个键有哪一个节点负责呢？<br>实际上，当客户端向集群中的任意一个节点发送命令后，该节点会判断相应的键是否在当前节点中，如果键在该节点中，则会像单机实例一样正确处理该命令；如果键不在该节点中，就会返回一个MOVE重定向请求，告诉客户端这个键目前由哪个节点负责，然后客户端再将同样的请求项目表节点重新发送一次以获取结果。<br>一些语言的redis库支持代理MOVE请求，所以对于开发者而言命令重定向的过程是透明的，使用集群与使用单机实例并没有什么不同。然而也有些语言库并不支持集群，这时就需要在客户端编码处理了。<br>还是以上面的集群配置为例，键foo实际应该由6382节点负责，如果尝试在6380节点执行与键foo相关的命令，就会有如下输出：  </p><pre><code>127.0.0.1:6380&gt; set foo bar(error) MOVED 12182 127.0.0.1:6382</code></pre><p>返回的是一个MOVE重定向请求，12182表示foo所属的插槽号，127.0.0.1:6382则是负责该插槽的节点地址和端口，客户端收到重定向请求后，应该将命令重新向6382节点发送一次：  </p><pre><code>127.0.0.1:6382&gt; set foo barOK</code></pre><p>Redis命令行客户端提供了集群模式来支持自动重定向，使用-c参数来启用： </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-cli -p 6380127.0.0.1:6380&gt; get foo(error) MOVED 12182 127.0.0.1:6382--加了c参数之后[admin@KFCS3 redis-stable_01]$ ./src/redis-cli -c -p 6380127.0.0.1:6380&gt; get foo-&gt; Redirected to slot [12182] located at 127.0.0.1:6382&quot;bar&quot;</code></pre><p>可见加入了-c参数后，如果当前节点并不负责要处理的键，Redis命令行客户端会进行自动命令重定向。而这一过程正是每个支持集群的客户端应该实现的。<br>然而相比单机实例，集群的命令重定向也增加了命令的请求次数，原先只需要执行一次的命令现在有可能需要依次发向两个节点，算上往返时延，可以说请求重定向对性能还是有些影响的。<br>为了解决这一问题，当发现新的重定向请求时，客户端应该在重新向正确节点发送命令的同时，缓存插槽的路由信息，即记录下当前插槽时由哪个节点负责的。这样每次发起命令时，客户端首先计算相关键是属于哪个插槽的，然后根据缓存的路由判断插槽有哪个节点负责。考虑到插槽总数相对少（16384个），缓存所有插槽的路由信息后，每次命令将均只发向正确的节点，从而达到和单机实例同样的性能。  </p><h3 id="5、故障恢复"><a href="#5、故障恢复" class="headerlink" title="5、故障恢复"></a>5、故障恢复</h3><p>在一个集群中，每个节点都会定期向其他节点发送PING命令，并通过有没有收到回复来判断目标节点是否已经下线了。具体来说，集群中的每个节点每隔1秒钟就会随机选择5个节点，然后选择其中最久没有响应的节点发送PING命令。<br>如果一定时间内目标节点没有响应回复，则发送PING命令的节点会认为目标节点疑似下线（PFALL）。疑似下线可以与哨兵的主观下线类比，两者都表示某一节点从自身的角度认为目标节点时下线状态。需要一定数量的节点都认为该节点疑似下线才可以，这一过程具体为：<br>（1）一旦节点A认为节点B是疑似下线状态，就会在集群中传播该消息，所有其他节点收到消息后都会记录下这一信息；<br>（2）当集群中的某一节点C收集到半数以上的节点认为B是疑似下线的状态时，就会将B标记为下线（FALL），并且向集群中的其他节点传播该消息，从而使得B在整个集群中下线。<br>在集群中，当一个数据库下线时，就会出现一部分插槽无法写入的问题。这时如果该主数据库拥有至少一个从数据库，集群就进行故障恢复操作来将其中一个从数据库转变成主数据库来保证集群的完整。选择哪个从数据库来作为主数据库的过程与哨兵中选择领头哨兵的过程一样，都是基于Raft算法，过程如下：<br>（1）发现其复制的主数据下线的从数据库（下面称作A）向每个集群中的节点发送请求，要求对方选自己成为主数据库。<br>（2）如果收到请求的节点没有选过其他人，则会同意将A设置成主数据库。<br>（3）如果A发现有超过集群中节点总数一半的节点同意选自己成为主数据库，则A则成为主数据库。<br>（4）当有多个从数据库节点同时参选主数据库，则会出现没有任何节点当选的可能。此时每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。<br>当某个从数据库当选为主数据库后，会通过命令SLAVEOF NO ONE 将自己转换成主数据库，并将旧的主数据库的插槽转换给自己负责。<br>如果一个至少负责一个插槽的主数据库下线且没有相应的从数据库可以进行故障恢复，则整个集群默认会进入下线状态无法继续工作。如果想在这种情况下使集群仍然能正常工作，可以修改配置cluster-require-full-coverage为no（默认为yes）：  </p><pre><code>cluster-require-full-converage no</code></pre>]]></content>
    
    <summary type="html">
    
      Redis集群的配置，集群工作原理；节点（nodes）、插槽（slots）、键值的对应关系；使用redis-trib.rb的辅助工具。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis集群" scheme="http://xym-loveit.github.io/tags/redis%E9%9B%86%E7%BE%A4/"/>
    
      <category term="redis-trib.rb集群辅助工具" scheme="http://xym-loveit.github.io/tags/redis-trib-rb%E9%9B%86%E7%BE%A4%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"/>
    
      <category term="集群（cluster）插槽slot" scheme="http://xym-loveit.github.io/tags/%E9%9B%86%E7%BE%A4%EF%BC%88cluster%EF%BC%89%E6%8F%92%E6%A7%BDslot/"/>
    
      <category term="节点（node）的插槽（slot）分配" scheme="http://xym-loveit.github.io/tags/%E8%8A%82%E7%82%B9%EF%BC%88node%EF%BC%89%E7%9A%84%E6%8F%92%E6%A7%BD%EF%BC%88slot%EF%BC%89%E5%88%86%E9%85%8D/"/>
    
      <category term="键归属的插槽" scheme="http://xym-loveit.github.io/tags/%E9%94%AE%E5%BD%92%E5%B1%9E%E7%9A%84%E6%8F%92%E6%A7%BD/"/>
    
      <category term="集群故障恢复" scheme="http://xym-loveit.github.io/tags/%E9%9B%86%E7%BE%A4%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之哨兵</title>
    <link href="http://xym-loveit.github.io/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%93%A8%E5%85%B5/"/>
    <id>http://xym-loveit.github.io/2017/06/02/redis入门指南之哨兵/</id>
    <published>2017-06-02T08:25:25.000Z</published>
    <updated>2018-03-29T01:27:48.640Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h2><p>Redis中的复制的原理和使用方式，在一个典型的一主多从的Redis系统中，从数据库在整个系统中起到了数据冗余备份和读写分离的作用。当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然后整个过程相对麻烦且需要人工介入，难以实现自动化。为此，Redis2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。  </p><h3 id="1、什么是哨兵"><a href="#1、什么是哨兵" class="headerlink" title="1、什么是哨兵"></a>1、什么是哨兵</h3><p>顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包含以下两个。<br>（1）监控主数据库和从数据库是否正常运行。<br>（2）主数据库出现故障时自动将从数据库转换为主数据库。<br>哨兵是一个独立的进程，使用哨兵的一个典型架构如下图:  </p><p><img src="http://op7wplti1.bkt.clouddn.com/sentinelMonitor.png" alt="哨兵监控">  </p><p>在一个一主多从的Redis系统中，可以使用多个哨兵进行监控任务以保证系统足够稳健，如下图所示。注意，此时不仅哨兵会同时监控主数据库和从数据库，哨兵之间也会相互监控。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/multiSentinel.png" alt="一主多从Redis集群多哨兵监控">  </p><h3 id="2、实例讲解"><a href="#2、实例讲解" class="headerlink" title="2、实例讲解"></a>2、实例讲解</h3><p>在理解哨兵的原理前，我们首先实际使用一下哨兵，来了解哨兵是如何工作的。为了简单起见，我们将建立三个Redis的集群（一主两从）。我们使用Redis命令行客户端来获取复制状态，以保证复制配置正确。<br>首先是主数据库：  </p><pre><code>--236服务器127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.100.237,port=6379,state=online,offset=151945,lag=1slave1:ip=192.168.100.238,port=6379,state=online,offset=152104,lag=0master_repl_offset:152104repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:152103  </code></pre><p>可见其连接了两个从数据库，配置正确。然后用相同的方法查看两个从数据库的配置：  </p><pre><code>--237服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:159045slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  --238服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:1master_sync_in_progress:0slave_repl_offset:160972slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  </code></pre><p>当出现的信息如上时，即证明一主二从的配置已经成功了。接下来配置哨兵。建立一个配置文件，如sentinel.conf，内容为：  </p><pre><code>sentinel monitor mymaster 192.168.100.236 6379 1  </code></pre><p>其中mymaster表示要监控的主数据库的名字，可以自己定义一个。这个名字必须仅有大小写字母、数字和“.-_”这三种字符组成。后面2个参数表示主数据库的地址和端口号，这里我们要监控的是主数据库236。最后一个1表示最低通过票数。接下来启动sentinel进程，并将上述配置的路径传递给哨兵：  </p><pre><code>[root@KFCS1 src]# ./redis-sentinel ../sentinel.conf  </code></pre><p>需要注意的是，配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库。启动哨兵后，哨兵输出内容如下：  </p><pre><code>Sentinel ID is 5f9becd72d6c4e8d7e5c0a06836b1b79a8ad055014246:X 02 Jun 17:39:46.909 # +monitor master mymaster 192.168.100.236 6379 quorum 114246:X 02 Jun 17:39:46.911 * +slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:39:46.938 * +slave slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 6379</code></pre><p>其中+slave表示新发现了从数据库，可见哨兵成功地发现了两个从数据库。现在哨兵已经在监控这3个Redis实例了，这时我们将主数据库关闭（杀死进程或使用SHUTDOWN命令），等待指定时间后（可以配置，默认为30秒），哨兵会输出如下内容：  </p><pre><code>14246:X 02 Jun 17:40:34.699 # +sdown master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.700 # +odown master mymaster 192.168.100.236 6379 #quorum 1/1  </code></pre><p>其中+sdown表示哨兵主观认为主数据库停止服务了，而+odown则表示哨兵客观认为主数据库停止服务了，关于主观和客观的区别后文会详细介绍。此时哨兵开始执行故障恢复，即挑选一个从数据库，将其升格为主数据库，输出如下：  </p><pre><code>14246:X 02 Jun 17:40:34.700 # +try-failover master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.714 # +vote-for-leader 5f9becd72d6c4e8d7e5c0a06836b1b79a8ad0550 214246:X 02 Jun 17:40:34.714 # +elected-leader master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.714 # +failover-state-select-slave master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.815 # +selected-slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.815 * +failover-state-send-slaveof-noone slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.891 * +failover-state-wait-promotion slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.072 # +promoted-slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.072 # +failover-state-reconf-slaves master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.134 * +slave-reconf-sent slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.104 * +slave-reconf-inprog slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.104 * +slave-reconf-done slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.186 # +failover-end master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.186 # +switch-master mymaster 192.168.100.236 6379 192.168.100.238 637914246:X 02 Jun 17:40:36.186 * +slave slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.238 637914246:X 02 Jun 17:40:36.187 * +slave slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 6379  </code></pre><p>+try-failover表示哨兵开始进行故障恢复，+failover-end表示哨兵完成故障恢复，期间涉及的内容比较复杂，包括领头哨兵的选举、备选从数据库的选择等，放到后面介绍，此处只需要关注最后3条输出。+switch-master表示主数据库从236转换到了238，即238服务器升格为主数据库，同时两个+slave则列出了新的主数据库的2个从数据库。其中236就是之前停止服务的主数据库，可见哨兵并没有彻底清除停止服务的实例信息，这是因为停止服务的实例有可能会在之后的某个时间恢复服务，这时哨兵会让其重新加入进来，所以当实例停止服务后，哨兵会更新该实例的信息，使得当其重新加入后可以按照当前信息继续对外提供服务。此例中236主数据库实例停止服务了，而238服务器的从数据库已经升格为主数据库，当236实例恢复服务后，会转变为238实例的从数据库来运行，所以哨兵将236服务器实例的信息修改成了238实例的从数据库。<br>故障恢复完成后，可以使用Redis命令行客户端重新检查237/238两台服务器上的实例信息：  </p><pre><code>--237服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.238master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:308379slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0--238服务器127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.100.237,port=6379,state=online,offset=311494,lag=1master_repl_offset:311494repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:311493  </code></pre><p>可以看到238服务器上实例已经确实升格为主数据库了，同时237服务器上的实例是其从数据库。整个故障恢复过程就此完成。那么我们重新启动236服务器上的Redis实例，监控到的日志输出如下:  </p><pre><code>14246:X 02 Jun 17:42:27.637 # -sdown slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 637914246:X 02 Jun 17:42:37.643 * +convert-to-slave slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 6379</code></pre><p>-sdown表示实例236已经恢复服务了（与+sdown相反）同时+convert-to-slave表示将236服务器的实例设置为238服务器实例的从数据库。这时使用Redis命令行客户端查看236实例的复制信息为：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.238master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:333678slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  </code></pre><p>同时238端口的复制信息为:  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.100.237,port=6379,state=online,offset=311494,lag=1slave1:ip=192.168.100.236,port=6379,state=online,offset=311494,lag=0master_repl_offset:311494repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:311493</code></pre><p>正如预期一样，238实例的从数据库变为了2个，236成功恢复服务。</p><h3 id="3、实现原理"><a href="#3、实现原理" class="headerlink" title="3、实现原理"></a>3、实现原理</h3><p>一个哨兵进程启动时会读取配置文件的内容，通过如下的配置找出需要监控的主数据库：  </p><pre><code>sentinel monitor master-name ip redis-port quorum</code></pre><p>其中master-name是一个由大小写字母、数字和“.-_”组成的主数据库的名字，因为考虑到故障恢复后当前监控的系统的主数据库的地址和端口号会产生变化，所以哨兵提供了命令可以通过主数据库的名字获取当前系统的主数据库的地址和端口号。<br>ip 表示当前系统中主数据库的地址，而redis-port则表示端口号。<br>quorum用来表示执行故障恢复操作前至少需要几个哨兵节点同意。一个哨兵节点可以同时监控多个Redis主从系统，只需要提供多个sentinel monitor 配置即可，例如：  </p><pre><code>sentinel monitor mymaster 127.0.0.1 6379 2sentinel monitor othermaster 192.168.100.238 6379 1</code></pre><p>同时多个哨兵节点也可以同时监控同一个Redis主从系统，从而形成网状结构。具体实践时如何协调哨兵与主从系统的数量关系将在后文介绍。<br>配置文件中还可以定义其他监控相关的参数，每个配置选项都包含主数据的名字使得监控不同主数据库时可以使用不同的配置参数。如：  </p><pre><code>sentinel down-after-milliseconds mymaster 60000sentinel down-after-milliseconds othermaster 10000</code></pre><p>上面的两行配置分别配置了mymaster和othermaster的sentinel down-after-milliseconds选项分别为60000和10000。<br>哨兵启动后，会与要监控的主数据库建立两条连接，这两条连接的建立方式与普通的Redis客户端无异。其中一条连接用来订阅该主数据库的__sentinel__:hello频道以获取其他同样监控该数据库的哨兵节点的信息，另外哨兵也需要定期向主数据库发送INFO等命令来获取主数据库本身的信息，因为之前介绍过当客户端的连接进入订阅模式时就不能再执行其他命令了，所以这时哨兵会使用另外一条连接来发送这些命令。和主数据库的连接建立完成后，哨兵会定时执行下面3个操作。<br>（1）每10秒哨兵会向主数据库和从数据库发送INFO命令。<br>（2）每2秒哨兵会向主数据库和从数据库的__sentinel__:hello频道发送自己的信息。<br>（3）每1秒哨兵会向主数据库、从数据库和其他哨兵节点发送PING命令。<br>这3个操作贯穿哨兵进程的整个生命周期中，非常重要，可以说了解了这3个操作的意义就能够了解哨兵工作原理的一半内容了。<br>首先，发送INFO命令使得哨兵可以获得当前数据库的相关信息（包括运行ID、复制信息等）从而实现新节点的自动发现。前面说配置哨兵监控Redis主从系统时只需要指定主数据库的信息即可，因为哨兵正是借助INFO命令来获取所有复制该主数据库的从数据库信息的。启动后，哨兵向主数据库发送INFO命令，通过解析返回结果来得知从数据库列表，而后对每个从数据库同样建立2个连接，2个连接的作用和前面介绍的与主数据库建立的2个连接完全一致。在此之后哨兵会每10秒定时向已知的所有主从数据库发送INFO命令来获取信息更新并进行相应操作，比如对新增的从数据库建立连接并加入监控列表，对主从数据库的角色变化（由故障恢复操作引起）进行信息更新等。<br>接下来哨兵向主从数据库的__sentinel__:hello频道发送信息来与同样监控该数据库的哨兵分享自己的信息。发送的消息内容为：  </p><blockquote><p>&lt;哨兵的地址&gt;,&lt;哨兵的端口&gt;,&lt;哨兵的运行ID&gt;,&lt;哨兵的配置版本&gt;,&lt;主数据的名字&gt;,&lt;主数据库的地址&gt;,&lt;主数据库的端口&gt;,&lt;主数据库的配置版本&gt;  </p></blockquote><p>可以看到消息包括的哨兵的基本信息，以及其监控的数据库的信息。前文介绍过，哨兵会订阅每个其监控的数据库的__sentinel__:hello频道，所以当其他哨兵收到消息后，会判断发送消息的哨兵是不是新发现的哨兵。如果是则将其加入已发现的哨兵列表中并创建一个到其的连接（与数据库不同，哨兵与哨兵之间只会创建一条连接用来发送PING命令，而不需要创建另外一条连接来订阅频道，因为哨兵只需要订阅数据库的频道即可实现自动发现其他哨兵）。同时哨兵会判断信息中主数据的配置版本，如果该版本比当前记录的主数据库的版本高，则更新主数据库的数据。配置版本的作用将在后面介绍。<br>实现了自动发现从数据库和其他哨兵节点后，哨兵要做的就是定时监控这些数据库和节点有没有停止服务。这是通过每隔一定时间向这些节点发送PING命令实现的。时间间隔与down-after-milliseconds选项有关，当down-after-milliseconds的值小于1秒时，哨兵会每隔down-after-milliseconds指定的时间发送一次PING命令，当down-after-milliseconds的值大于1秒时，哨兵会每隔1秒发送一次PING命令。如：  </p><pre><code>--每隔1秒发送一次PING命令sentinel down-after-milliseconds mymaster 60000--每隔600毫秒发送一次PING命令sentinel down-after-milliseconds mymaster 600</code></pre><p>当超过down-after-milliseconds选项指定时间后，如果被PING的数据库或节点仍然未进行回复，则哨兵认为其主观下线(subjectively down)。主观下线表示从当前的哨兵进程看来，该节点已经下线。如果该节点是主数据库，则哨兵会进一步判断是否需要对其进行故障恢复：哨兵发送SENTINEL is-master-down-by-addr命令询问其他哨兵节点以了解他们是否也认为该主数据库主观下线，如果达到指定数量时，哨兵会认为其客观下线（objectively down），并选举领头的哨兵节点对主从系统发起故障恢复。这个指定数量即为前文介绍的quorum参数。如下配置：  </p><pre><code>sentinel monitor mymaster 127.0.0.1 6379 2</code></pre><p>该配置表示只有当至少2个sentinel节点（包括当前节点）认为该主数据库主观下线时，当前哨兵节点才会认为该主数据库客观下线。进行接下来的选举领头哨兵步骤。<br>虽然当前哨兵节点发现了主数据库客观下线，需要故障恢复，但是故障恢复需要有领头的哨兵来完成，这样可以保证同一时间只有一个哨兵节点来执行故障恢复。选举领头哨兵的过程使用后了Raft算法，具体如下：<br>（1）发现主数据库客观下线的哨兵节点（下面称作A）向每个哨兵节点发送命令，要求对方选自己成为领头哨兵。<br>（2）如果目标哨兵节点没有选过其他人，则会同意将A设置成领头哨兵。<br>（3）如果A发现有超过半数且超过quorum参数值的哨兵节点同意选自己成为领头哨兵，则A成功成为领头哨兵。<br>（4）当有多个哨兵节点同时参选领头哨兵，则会出现没有任何节点当选的可能。此时每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。<br>具体过程可以参考Raft算法的过程<a href="http://www.cnblogs.com/mindwind/p/5231986.html" target="_blank" rel="noopener">http://www.cnblogs.com/mindwind/p/5231986.html</a>。因为要成为领头哨兵必须有超过半数的哨兵节点支持，所以每次选举最多只会选出一个领头哨兵。<br>选出领头哨兵后，领头哨兵将会开始对主数据库进行故障恢复。故障恢复的过程相对简单，具体如下：<br>首先领头哨兵将从停止服务的主数据库的从数据库中挑选一个充当新的主数据库。挑选的依据如下：<br>（1）所有在线的从数据库中，选择优先级最高的从数据库。优先级可以通过slave-priority选项来设置。<br>（2）如果有多个最高优先级的从数据库，则复制的命令偏移量越大（即复制越完整）越优先。<br>（3）如果以上条件都一样，则选择运行ID较小的从数据库。<br>选出一个从数据库后，领头哨兵将向从数据库发送SLAVEOF NO ONE 命令使其升格为主数据库。而后领头哨兵向其他从数据库发送SLAVEOF命令来使其成为新主数据库的从数据库。最后一步则是更新内部的记录，将已经停止服务的旧的主数据库更新成为新的主数据库的从数据库，使得当其恢复服务时自动以从数据库的身份继续服务。  </p><h3 id="4、哨兵的部署"><a href="#4、哨兵的部署" class="headerlink" title="4、哨兵的部署"></a>4、哨兵的部署</h3><p>哨兵以独立进程的方式对一个主从系统进行监控，监控的效果好坏与否取决于哨兵的视角是否有代表性。如果一个主从系统中配置的哨兵较少，哨兵对整个系统的判断的可靠性就会降低。极端情况下，当只有一个哨兵时，哨兵本身就可能会发生单点故障。整体来讲，相对稳妥的哨兵部署方案是使得哨兵的视角尽可能地与每个节点的视角一致，即：<br>（1）为每个节点（无论是主数据库还是从数据库）部署一个哨兵。<br>（2）使每个哨兵与其对应的节点网络环境相同或相近。<br>这样的部署方案可以保证哨兵的视角拥有较高的代表性和可靠性。举例：当网络分区后，如果哨兵认为某个分区是主要分区，即意味着从每个节点观察，该分区均为主分区。同时设置quorum的值为N/2+1（其中N为哨兵节点数量），这样使得只有当大部分哨兵节点同意后才会进行故障恢复。<br>当系统中的节点较多时，考虑到每个哨兵都会和系统中的所有节点建立连接，为每个节点分配一个哨兵会产生较多连接，尤其是当进行客户端分片时使用多个哨兵节点监控多个主数据库会因为Redis不支持连接复用而产生大量冗余连接，同时如果Redis节点负载较高，会在一定程度上影响其对哨兵的回复以及与其节点的通信。所以配置哨兵时还需要根据实际的生产环境情况进行选择。</p>]]></content>
    
    <summary type="html">
    
      通过使用redis主从模式提升redis负载能力，减小单点故障的可能，阅读本章使用哨兵（sentinel）可以配置出更强劲的Redis集群，重中之重。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis哨兵监控" scheme="http://xym-loveit.github.io/tags/redis%E5%93%A8%E5%85%B5%E7%9B%91%E6%8E%A7/"/>
    
      <category term="哨兵（sentinel）的实现原理" scheme="http://xym-loveit.github.io/tags/%E5%93%A8%E5%85%B5%EF%BC%88sentinel%EF%BC%89%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    
      <category term="哨兵的配置" scheme="http://xym-loveit.github.io/tags/%E5%93%A8%E5%85%B5%E7%9A%84%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之复制</title>
    <link href="http://xym-loveit.github.io/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%A4%8D%E5%88%B6/"/>
    <id>http://xym-loveit.github.io/2017/06/02/redis入门指南之复制/</id>
    <published>2017-06-02T00:59:46.000Z</published>
    <updated>2018-03-29T01:27:48.641Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此，Redis提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。  </p><h3 id="1、配置"><a href="#1、配置" class="headerlink" title="1、配置"></a>1、配置</h3><p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库（slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/masterSlave.png" alt="Redis一主多从数据库示意图">  </p><p>在Redis中使用复制功能非常容易，只需要在从数据库的配置文件中加入“slaveof 主数据库地址 主数据库端口”即可，主数据库无需进行任何配置。为了能够更直观地展示复制的流程，下面将实现一个最简化的复制系统。我们在1台服务器上启动2个Redis实例，监听不同端口，其中一个作为主数据库，另一个作为从数据库。首先我们不加任何参数来启动一个Redis实例作为主数据库： </p><pre><code>redis-server redis.conf</code></pre><p>该实例默认监听6379端口。然后加上slaveof参数启动另一个Redis实例作为从数据库，并让其监听6380端口：  </p><pre><code>redis-server --port 6380 --slaveof 127.0.0.1 6379</code></pre><p>此时在主数据库中的任何数据变化都会自动同步到从数据库中。我们打开redis-cli实例A并连接到主数据库： </p><pre><code>redis-cli -p 6379</code></pre><p>再打开redis-cli实例B并连接到从数据库：  </p><pre><code>redis-cli -p 6380</code></pre><p>这是我们使用INFO命令来分别在实例A和实例B中获取Replication节点的相关信息：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.100.237,port=6379,state=online,offset=1346,lag=1master_repl_offset:1346repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:1345</code></pre><p>可以看到，实例A的角色（上面输出中的role）是master，即主数据库，同时已连接的从数据库（上面输出中的connected_slaves）的个数为1。同样在实例B中获取相应的信息为：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:4master_sync_in_progress:0slave_repl_offset:1714slave_priority:100slave_read_only:0connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0</code></pre><p>这里可以看到，实例B的role是slave，即从数据库，同时其主数据的地址为127.0.0.1，端口为6379。在实例A中使用SET命令设置一个键的值： </p><pre><code>127.0.0.1:6379&gt; set foo barOK</code></pre><p>此时在实例B中就可以获得该值了：  </p><pre><code>127.0.0.1:6379&gt; get foo&quot;bar&quot;</code></pre><p>默认情况下，从数据库是只读的，如果直接修改从数据库的数据库会出现错误： </p><pre><code>127.0.0.1:6379&gt; set foo bar(error) READONLY You can&apos;t write against a read only slave.</code></pre><p>可以通过设置从数据库的slave-read-only为no以使从数据库可写，但是因为对从数据库的任何更改都不会同步给任何其他数据库，并且一旦主数据库中更新了对应的数据就会覆盖从数据库中的改动，所以通常的场景下不应该设置从数据库可写，以免导致易被忽略的潜在应用逻辑错误。<br>配置多台从数据库的方法也一样，在所有的从数据库的配置文件中都加上slaveof 参数指向同一个主数据库即可。除了通过配置文件或命令行参数设置slaveof 参数，还可以在运行时使用slaveof命令修改：  </p><pre><code>slaveof 127.0.0.1 6379</code></pre><p>如果该数据库已经是其他主数据库的从数据库了，SLAVEOF命令会停止和原来数据库的同步转而和新数据库同步。此外对于从数据库来说，还可以使用SLAVEOF NO ONE 命令来使当前数据库停止接受其他数据库的同步并转换成为主数据库。  </p><h3 id="2、原理"><a href="#2、原理" class="headerlink" title="2、原理"></a>2、原理</h3><p>了解Redis复制的原理对日后运维有很大帮助，包括如何规划节点，如何处理节点故障等。下面将详细介绍Redis实现复制的过程。<br>当一个从数据库启动后，会向主数据库发送SYNC命令。同时主数据库接收到SYNC命令后会开始在后台保存快照（即RDB持久化的过程），并将保存快照期间接收到的命令缓存起来。当快照完成后，Redis会将快照文件和所有缓存的命令发送给从数据库。从数据库收到后，会载入快照文件并执行收到的缓存的命令。以上过程称为复制初始化。复制初始化结束后，主数据库每当收到写命令时就会将命令同步给从数据库，从而保证主从数据库数据一致。<br>当主从数据库之间的连接断开重连后，Redis2.6以及之前的版本会重新进行复制初始化（即主数据库保存快照并传送给从数据库），即使从数据库可能仅有几条命令没有收到，主数据库也必须要将数据库里的所有数据重新传送给从数据库。这使得主从数据库断线重连后的数据恢复过程效率很低下，在网络环境不好的时候这一问题尤其明显。Redis2.8版的一个重要改进就是断线重连能够支持有条件的增量数据传输，当从数据库重新连接上主数据库后，主数据库只需要将断线期间执行的命令传送给从数据库，从而大大提高Redis复制的实用性。<br>下面将从具体协议角度详细介绍复制初始化的过程。由于Redis服务器使用TCP协议通信，所以我们可以使用telnet工具伪装成一个从数据库来与主数据库通信。首先在命令行中连接主数据库（默认端口为6379，假设目前没有任何从数据库连接）：  </p><pre><code>[admin@KFCS2 ~]$ telnet 192.168.100.236 6379Trying 192.168.100.236...Connected to 192.168.100.236.Escape character is &apos;^]&apos;.</code></pre><p>然后作为从数据库，我们先要发送PING命令确认主数据库是否可以连接： </p><pre><code>ping+PONG</code></pre><p>主数据库会回复+PONG。如果没有收到主数据库的回复，则向用户提示错误。如果主数据库需要密码才能连接，我们还要发送AUTH命令进行验证。而后向主数据库发送REPLCONF命令说明自己的端口号：  </p><pre><code>replconf listening-port 6379 +OK</code></pre><p>这时就可以开通同步的过程了：向主数据库发送SYNC命令开始同步，此时主数据库发送回快照文件和缓存命令。目前主数据库中只有一个foo键，所以收到的内容如下：  </p><pre><code>sync$90REDIS0007    redis-ver3.2.5  </code></pre><p>从数据库会将收到的内容写入到硬盘上的临时文件中，当写入完成后从数据库会用该临时文件替换RDB快照文件（RDB快照文件的位置就是持久化时配置的位置，由dir和dbfilename两个参数确定），之后的操作就和RDB持久化时启动恢复的过程一样了。需要注意的是在同步过程中从数据库并不会阻塞，而是可以继续处理客户端发来的命令。默认情况下，从数据库会用同步前的数据对命令进行响应。可以配置slave-serve-stale-data 参数为no来使从数据库在同步完成前对所有命令（除了INFO和SLAVEOF）都回复错误:”SYNC with master in progress.”<br>复制初始化阶段结束后，主数据库执行的任何会导致数据变化的命令都会异步地传送给从数据库，这一过程为复制同步阶段。同步的内容和Redis通信协议一样，比如我们在主数据库中执行了SET foo bar，通过telnet我们收到了： </p><pre><code>set$3foo$3bar*1$4</code></pre><p>复制同步阶段会贯穿整个主从同步过程的始终，直到主从关系终止为止。<br>在复制的过程中，快照无论在主数据库还是从数据库中都起了很大的作用，只要执行复制就会进行快照，即使我们关闭了RDB方式的持久化（通过删除所有save参数）。Redis2.8.18之后支持了无硬盘复制。<br>（1）乐观复制<br>Redis采用了乐观复制（optimistic replication）的复制策略，容忍在一定时间内主从数据库的内容是不同的，但是两者的数据会最终同步。具体来说，Redis在主从数据库之间复制数据的过程本身是异步的，这意味着，主数据库执行完客户端请求的命令后会立即将命令在主数据库的执行结果返回给客户端，并异步地将命令同步给从数据库，而不会等待从数据库接收到改该命令后再返回给客户端。这一特性保证了启用复制后主数据库的性能不会受到影响，但另一方面也会产生一个主从数据库数据不一致的时间窗口，当主数据库执行一条写命令后，主数据库的数据已经发生的变动，然而在主数据库将该命令传送给从数据库之前，如果两个数据库之前的网络连接断开了，此时二者之间数据就会是不一致的。从这个角度来看，主数据库是无法得知某个命令最终同步给了多少个从数据库的，不过Redis提供了两个配置选项来限制只有当数据至少同步给指定数量的从数据库时，主数据库才是可写的：  </p><pre><code>min-slaves-to-write 3min-slaves-max-lag 10</code></pre><p>上面的配置中，min-slaves-to-write表示只有当3个或3个以上的从数据库连接到主数据库时，主数据库才是可写的，否则会返回错误，例如：  </p><pre><code>set foo bar(error) NOREPLICAS Not enough good slaves to write</code></pre><p>min-slaves-max-lag表示允许从数据库最长失去连接的时间，如果从数据库最后与主数据库联系（即发送REPLCONF ACK命令）的时间小于这个值，则认为从数据还在保持与主数据库的连接。举个例子，按上面的配置，主数据库假设与3个从数据库相连，其中一个从数据库上一次与主数据库联系是9秒前，这时主数据库可以正常接受写入，一旦1秒过后这台从数据库依旧没有活动，则主数据库认为目前连接的从数据库只有2个，从而拒绝写入。这一特性默认是关闭的，在分布式系统中，打开并合理配置该选项后可以降低主从架构中因为网络分区导致的数据不一致的问题。  </p><h3 id="3、图结构"><a href="#3、图结构" class="headerlink" title="3、图结构"></a>3、图结构</h3><p>从数据库不仅可以接受主数据库的同步数据，自己也可以同时作为主数据库存在，形成类似图的结构，如下图，数据库A的数据会同步到B和C中，而B中的数据会同步到D和E中。向B中写入数据不会同步到A或C中，只会同步到D和E中。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/slaveWithSlave.png" alt="slave也可再拥有slave">  </p><h3 id="4、读写分离与一致性"><a href="#4、读写分离与一致性" class="headerlink" title="4、读写分离与一致性"></a>4、读写分离与一致性</h3><p>通过复制可以实现读写分离，以提高服务器的负载能力。在常见的场景中（如电子商务网站），读的频率大于写，当单机的Redis无法应付大量的读请求时（尤其是较耗资源的请求，如SORT命令等）可以通过复制功能建立多个从数据库节点，主数据库只进行写操作，而从数据库负责读操作。这种一主多从的结果很适合读多写少的场景，而当单个的主数据库不能满足需求时，就需要使用Redis3.0推出的集群功能。  </p><h3 id="5、从数据库持久化"><a href="#5、从数据库持久化" class="headerlink" title="5、从数据库持久化"></a>5、从数据库持久化</h3><p>另一个相对耗时的操作是持久化，为了提高性能，可以通过复制功能建立一个（或多个）从数据库，并在从数据库中启用持久化，同时在主数据库中禁用持久化。当从数据库奔溃重启后主数据库会自动将数据同步过来，所以无需担心数据丢失。然后当主数据库奔溃时，情况就稍显复杂了。手工通过从数据库数据恢复主数据库数据时，需要严格按照以下两部进行。<br>（1）在从数据中使用SLAVEOF NO ONE 命令将从数据库提升成主数据库继续服务。<br>（2）启动之前奔溃的主数据库，然后使用SLAVEOF命令将其设置成新的主数据库的从数据库，即可将数据同步回来。  </p><p><strong>注意：当开启复制且主数据关闭持久化功能时，一定不要使用Supervisor以及类似的进程管理工具令主数据库奔溃后自动重启。同样当主数据所在的服务器因故关闭时，也要避免直接重新启动。这是因为当数据库重新启动后，因为没有开启持久化功能，所以数据库中的所有数据都被清空，这时从数据库依然会从主数据库中接受收据，使得所有从数据库也被清空，导致从数据库的持久化失去意义。</strong>  </p><p>无论哪种情况，手工维护从数据库或主数据库的重启以及数据恢复都相对麻烦，好在Redis提供了一种自动化方案哨兵来实现这一过程，避免了手工维护的麻烦和容易出错的问题。 </p><h3 id="6、无硬盘复制"><a href="#6、无硬盘复制" class="headerlink" title="6、无硬盘复制"></a>6、无硬盘复制</h3><p>Redis复制的工作原理时介绍了复制是基于RDB方式的持久化实现的，即主数据库端在后台保存RDB快照，从数据库端则接受并载入快照文件。这样的实现有点是可以显著地简化逻辑，复用已有代码，但是缺点也很明显。<br>（1）当数据库禁用RDB快照时（即删除了所有的配置文件中的save语句）。如果执行了复制初始化操作，Redis依然会生成RDB快照，所以下次启动后主数据库会以该快照恢复数据。因为复制发生的时间不确定，这使得恢复的数据可能是任何时间点的。<br>（2）因为复制初始化时需要在硬盘中创建RDB快照文件，所以如果硬盘性能很慢（如网络硬盘）时这一过程会对性能产生影响。举例来说，当使用Redis作缓存系统时，因为不需要持久化，所以服务器的硬盘读写速度可能较差。但是当该缓存系统使用一主多从的集群架构时，每次和从数据同步，Redis都会执行一次快照，同时对硬盘进行读写，导致性能降低。因此从2.8.18版本开始，Redis引入了无硬盘复制选项，开启该选项时，Redis在与从数据库进行复制初始化时将不会将快照内容存储到硬盘上，而是直接通过网络发送给从数据库，避免了硬盘的性能瓶颈。<br>目前无硬盘复制的功能还在试验阶段，可以在配置文件中使用如下配置来开启该功能：  </p><pre><code>repl-diskless-sync yes</code></pre><h3 id="7、增量复制"><a href="#7、增量复制" class="headerlink" title="7、增量复制"></a>7、增量复制</h3><p>在介绍复制的原理时提到当主从数据库连接断开后，从数据库会发送SYNC命令来重新进行一次完成的复制操作。这样即使断开期间数据库的变化很小（甚至没有），也需要将数据库中的所有数据重新快照并传送一次。在正常的网络应用环境中，这种实现方式显然不太理想。Redis2.8版相对2.6版的重要更新之一就是实现了主从断线重连的情况下的增量复制。增量复制是基于如下三点实现：<br>（1）从数据库会存储主数据库的运行ID（run id）。每个Redis运行实例均会拥有一个唯一的运行ID，每当实例重启后，就会自动生成一个新的运行ID。<br>（2）在复制同步阶段，主数据库每将一个命令传送给从数据库时，都会同时把该命令存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围。<br>（3）同时，从数据库接收到主数据库传来的命令时，会记录下该命令的偏移量。<br>这三点是实现增量复制的基础。回到之前介绍主从通信流程，可以看到，当主从连接准备就绪后，从数据库会发送一条SYNC命令来告诉主数据库可以开始把所有数据同步过来了。而2.8版以后，不再发送SYNC命令，取而代之的是发送PSYNC，格式为“PSYNC 主数据库的运行id 断开前最新的命令偏移量”。主数据库收到PSYNC命令后，会执行以下判断来决定此次重连是否可以执行增量复制。<br>（1）首先主数据库会判断从数据库传送的运行ID是否和自己的运行ID相同。这一步骤的意义在于确保从数据库之前确实是和自己同步的，以免从数据库拿到错误的数据（比如主数据库在断线重启过，会造成数据的不一致）。<br>（2）然后判断从数据库最后同步成功的命令偏移量是否在积压队列中，如果在则可以执行增量复制，并将积压队列中的相应的命令发送给从数据库。如果此次重连不满足增量复制的条件，主数据库会进行一次全部同步（即与Redis2.6的过程相同）。大部分情况下，增量复制的过程对开发者来说是完全透明的，开发者不需要关心增量复制的具体细节。2.8版本的主数据库也可以正常地和旧版本的从数据库同步（通过接受SYNC命令），同样2.8版本的从数据库也可以与旧版本的主数据库同步（通过发送SYNC命令）。唯一需要开发者设置的就是积压队列的大小了。<br>积压队列的本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件的repl-backlog-size选项来调整。很容易理解的是，积压队列越大，其允许的主从数据库断线的时间就越长。根据主从数据库之间的网络状态，设置一个合理的积压队列很重要。因为积压队列存储的内容是命令本身，如SET foo bar，所以估算积压队列的大小只需要估计主从数据库断线的时间中主数据库可能执行的命令的大小即可。与积压队列相关的另一个配置是repl-backlog-ttl，即当所有从数据库与主数据库断开连接后，经过多久时间可以释放积压队列的内存空间。默认时间是1小时。</p>]]></content>
    
    <summary type="html">
    
      通过使用redis主从模式提升redis负载能力，减小单点故障的可能，阅读本章可以配置出更强劲的Redis集群。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis主从模式" scheme="http://xym-loveit.github.io/tags/redis%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="redis复制" scheme="http://xym-loveit.github.io/tags/redis%E5%A4%8D%E5%88%B6/"/>
    
      <category term="redis一主多从模式" scheme="http://xym-loveit.github.io/tags/redis%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="redis复制原理" scheme="http://xym-loveit.github.io/tags/redis%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    
      <category term="redis复制初始化" scheme="http://xym-loveit.github.io/tags/redis%E5%A4%8D%E5%88%B6%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    
      <category term="redis增量复制" scheme="http://xym-loveit.github.io/tags/redis%E5%A2%9E%E9%87%8F%E5%A4%8D%E5%88%B6/"/>
    
      <category term="redis积压队列" scheme="http://xym-loveit.github.io/tags/redis%E7%A7%AF%E5%8E%8B%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之持久化</title>
    <link href="http://xym-loveit.github.io/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>http://xym-loveit.github.io/2017/06/01/redis入门指南之持久化/</id>
    <published>2017-06-01T02:29:27.000Z</published>
    <updated>2018-03-29T01:27:48.642Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><p>Redis的强劲性能很大程度上市由于将其所有数据都存储在了内存中，然而当Redis重启后，所有存储在内存中的数据就会丢失。在一些情况下，我们希望在重启后能保证数据不丢失，例如：<br>（1）将Redis作为数据库使用时。<br>（2）将Redis作为缓存服务器，但缓存被穿透后会对性能造成较大影响，所有缓存同时失效会导致缓存雪崩，从而使服务无法响应。<br>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘中，使得重启后可以根据硬盘中的记录恢复数据。这一过程就是持久化。Redis支持两种方式的持久化，一种是RDB方式，另一种是AOF方式。前者会根据指定的规则“定时”将内存中的数据存储在硬盘上，而后者在每次执行命令后将命令本身记录下来。两种持久化方式可以单独使用其中一种，但更多情况下是将二者结合使用。  </p><h2 id="RDB方式"><a href="#RDB方式" class="headerlink" title="RDB方式"></a>RDB方式</h2><p>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据生成一份副本存储在硬盘上，这个过程即为“快照”。Redis会在以下几种情况下对数据进行快照：  </p><ol><li>根据配置规则进行自动快照  </li><li>用户执行SAVE或GBSAVE命令手动快照  </li><li>执行FLUSHALL命令  </li><li>执行复制（replication）时。  </li></ol><h3 id="1、根据配置规则自动快照"><a href="#1、根据配置规则自动快照" class="headerlink" title="1、根据配置规则自动快照"></a>1、根据配置规则自动快照</h3><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间窗口M和改动的键的个数N。每当时间M内被更改的键的个数大于N时，即符合自动快照条件。例如Redis安装目录中包含的样例配置文件中预置的3个条件：  </p><pre><code>save 900 1save 300 10save 60 10000</code></pre><p>每条快照条件占一行，并且以save参数开头。同时可以存在多个条件，条件之间是“或”的关系。就这个例子而言，save 900 1的意思是在15分钟（900秒）内有一个或一个以上的键被更改则进行快照。同理save 300 10表示在300秒内至少有10个键被修改则进行快照。  </p><h3 id="2、用户执行SAVE或BGSAVE命令手动快照"><a href="#2、用户执行SAVE或BGSAVE命令手动快照" class="headerlink" title="2、用户执行SAVE或BGSAVE命令手动快照"></a>2、用户执行SAVE或BGSAVE命令手动快照</h3><p>除了让Redis自动进行快照外，当服务重启、手动迁移以及备份时我们也会需要手动执行快照操作。Redis提供了2个命令来完成这一任务。  </p><h4 id="1、SAVE命令"><a href="#1、SAVE命令" class="headerlink" title="1、SAVE命令"></a>1、SAVE命令</h4><p>当执行SAVE命令时，Redis同步地进行快照操作，在快照执行的过程中会阻塞所有来自客户端的请求。当数据库中的数据比较多时，这一过程会导致Redis较长时间不相应，所以要尽量避免在生产环境使用这一命令。  </p><h4 id="2、BGSAVE命令"><a href="#2、BGSAVE命令" class="headerlink" title="2、BGSAVE命令"></a>2、BGSAVE命令</h4><p>需要手动执行快照时推荐使用BGSAVE命令。BGSAVE命令可以在后台异步地进行数据快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后Redis会立即返回OK表示开始执行快照操作，如果想知道快照是否完成，可以通过LASTSAVE命令获取最近一次成功执行快照的时间，返回结果是一个Unix时间戳，如：  </p><pre><code>127.0.0.1:6379&gt; lastsave(integer) 1496286152  </code></pre><p>执行自动快照时，Redis采用的策略即是异步快照。  </p><h3 id="3、执行FLUSHALL命令"><a href="#3、执行FLUSHALL命令" class="headerlink" title="3、执行FLUSHALL命令"></a>3、执行FLUSHALL命令</h3><p>当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是，不论清空数据库的过程是否触发了自动快照条件，只要自动快照条件不为空，Redis就会执行一次快照操作。例如，当定义的快照条件为当一秒内修改10000个键时进行自动快照，而当数据库里只有一个键时，执行FLUSHALL命令也会触发快照，即使这一过程实际上只有一个键被修改了。当没有定义自动快照条件时，执行FLUSHALL则不会进行快照。  </p><h3 id="4、执行复制时"><a href="#4、执行复制时" class="headerlink" title="4、执行复制时"></a>4、执行复制时</h3><p>当设置了主从模式时，Redis会在复制初始化时进行自动快照。当使用复制操作时，即使没有自定义自动快照条件，并且也没有手动执行过快照操作，也会生成RDB快照文件。  </p><h3 id="快照原理"><a href="#快照原理" class="headerlink" title="快照原理"></a>快照原理</h3><p>理清Redis实现快照的过程对我们了解快照文件的特性有很大帮助。Redis默认会将快照文件存储在Redis当前进程的工作目录中的dump.rdb文件中，可以通过配置<strong>dir</strong>和<strong>dofilename</strong>两个参数分别指定快照文件的存储路径和文件名。快照过程如下：<br>（1）Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；<br>（2）父进程继续接受并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；<br>（3）当子进程写入完所有数据后会用临时文件替换掉旧的RDB文件，至此一次快照操作完成。  </p><p><strong>提示：在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。写时复制策略也保证了在fork的时刻虽然看上去生成了两份内存副本，但实际上内存的占用量并不会增加一倍。这就意味着当系统内存只有2GB，而Redis数据库的内存有1.5GB时，执行fork后内存使用量不会增加到3GB（超出物理内存）。为此需要确保Linux系统允许应用程序申请超过可用内存（物理内存和交换分区）的空间，方法是在/etc/sysctl.conf文件中加入vm.overcommit_memory=1，然后重启系统或者执行sysctl vm.overcommit_memory=1确保设置生效。另外需要注意的是，当进行快照的过程中，如果写入操作较多，造成fork前后数据差异较大，是会使得内存占用量显著超过实际数据大小的，因为内存中不仅保存了当前的数据库数据，而且保存着fork时刻的内存数据。进行内存用量估算时很容易忽略这一问题，造成内存用量超限。 </strong> </p><p>通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。<br>Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录1000万个字符串类型建、大小为1GB的快照文件载入到内存中需要花费20~30秒。<br>通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能否接受的范围。例如，使用Redis存储缓存数据时，丢失最近几秒的数据或者丢失最近更新的几十个键并不会有很大的影响。如果数据相对重要，希望将损失降到最小，则可以使用AOF方式进行持久化。  </p><h2 id="AOF方式"><a href="#AOF方式" class="headerlink" title="AOF方式"></a>AOF方式</h2><p>当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程终止导致的数据丢失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这一过程显然会降低Redis性能，但是大部分情况下这个影响是可以接受的，另外使用较快的硬盘可以提高AOF的性能。  </p><h3 id="1、开启AOF"><a href="#1、开启AOF" class="headerlink" title="1、开启AOF"></a>1、开启AOF</h3><p>默认情况下Redis没有开始AOF（append only file）方式的持久化，可以通过appendonly参数启用：</p><pre><code>appendonly yes  </code></pre><p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：  </p><pre><code>appendfilename appendonly.aof  </code></pre><h3 id="2、AOF实现"><a href="#2、AOF实现" class="headerlink" title="2、AOF实现"></a>2、AOF实现</h3><p>AOF文件以纯文本的形式记录了Redis执行的写命令，例如在开启AOF持久化的情况下执行了如下4个命令:  </p><pre><code>SET foo 1SET foo 2SET foo 3GET foo  </code></pre><p>Redis会将前3条命令写入AOF文件中。AOF文件内容为Redis客户端向Redis发送的原始通信协议的内容，从中可见Redis确实只记录了前3条命令。然而这时有一个问题是前2条命令其实都是冗余的，因为这2执行结果会第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，即使内存中实际的数据可能并没有多少。很自然地，我们希望Redis可以自动优化AOF文件，就上例而言，就是将前两条无用的记录删除，只保留第三条。实际上Redis也正是这样做的，每当达到一定条件时Redis就会自动重写AOF文件，这个条件可以在配置文件中设置：  </p><pre><code>auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb  </code></pre><p>auto-aof-rewrite-percentage参数的意义是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据。auto-aof-rewrite-min-size参数限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。除了让Redis自动执行重写外，我们还可以主动使用BGREWRITEAOF命令手动执行AOF重写。重写的过程只和内存中的数据有关，和之前的AOF文件无关，这与RDB很相似，只不过二者的文件格式完全不同。在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对RDB会慢一些。  </p><h3 id="3、同步硬盘数据"><a href="#3、同步硬盘数据" class="headerlink" title="3、同步硬盘数据"></a>3、同步硬盘数据</h3><p>虽然每次执行更改数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正的写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒回执行一次同步操作，以便将硬盘缓存中的内容真正地写入硬盘，在这30秒的过程中如果系统异常退出则会导致缓存中的数据丢失。一般来讲启用AOF持久化的应用都无法容忍这样的损失，这就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在Redis中我们可以通过appendfsync参数设置同步机制：  </p><pre><code>#appendfsync alwaysappendfsync everysec#appendfsync no   </code></pre><p>默认情况下Redis采用everysec规则，即每秒执行一次同步操作。always表示每次执行写入都会执行同步，这是最安全也是最慢的方式。no表示不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），这是最快但最不安全的方式。一般情况下使用默认值everysec就足够了，即兼顾了性能又保证了安全。<br>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。  </p>]]></content>
    
    <summary type="html">
    
      通过redis的RDB和AOF两种持久化选择适当场景下的安全处理方式
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis持久化" scheme="http://xym-loveit.github.io/tags/redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    
      <category term="redis的AOF持久化" scheme="http://xym-loveit.github.io/tags/redis%E7%9A%84AOF%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    
      <category term="redis的RDB持久化" scheme="http://xym-loveit.github.io/tags/redis%E7%9A%84RDB%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之Lua脚本</title>
    <link href="http://xym-loveit.github.io/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8BLua%E8%84%9A%E6%9C%AC/"/>
    <id>http://xym-loveit.github.io/2017/06/01/redis入门指南之Lua脚本/</id>
    <published>2017-06-01T02:29:19.000Z</published>
    <updated>2018-03-29T01:27:48.639Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><p>在进阶章节讲到实现访问频率限制功能，用来限制一个IP地址1分钟最多只能访问100次：  </p><pre><code>$isKeyExists=EXISTS rate.limiting:$IPif $isKeyExists is 1    $times=INCR rate.limiting:$IP    if $times&gt;100        print 访问频率超过限制，请稍后再试        exitelse    MULTI    INCR rate.limiting:$IP    EXPIRE $keyName,60    EXEC  </code></pre><p>当时提到上面的代码会出现竞态条件，解决方法是用WATCH命令检测rate.limiting:$IP键的变动，但是这样做比较麻烦，而且还需要判断事务是否因为键被改动而没有执行。除此之外这段代码在不适用管道的情况下最多要向Redis请求5条命令，在网络传输上会浪费很多时间。<br>我们这时最希望就是Redis直接提供一个“RATELIMITING”命令用来实现访问频率限制功能，这个命令只需要我们提供键名、时间限制和在时间限制内最多访问的次数三个参数就可以直接返回访问频率是否超限。就像下面这样：  </p><pre><code>if RATELIMITING rate.limiting:$IP,60 100    print 访问频率超过限制，请稍后再试else     #没有超限，其他业务处理  </code></pre><p>这种方式不仅代码简单、没有竞态条件（Redis的命令都是原子的），而且减少了通过网络发送和接收命令的传输开销。然而可惜的是Redis并没有提供这个命令，不过我们可以使用Redis脚本功能自己定义新的命令。  </p><h3 id="1、脚本介绍"><a href="#1、脚本介绍" class="headerlink" title="1、脚本介绍"></a>1、脚本介绍</h3><p>Redis在2.6版推出了脚本功能，允许开发者用Lua语言编写脚本传到Redis中执行。在Lua脚本中可以调用大部分的Redis命令，也就是说可以写一段Lua脚本发送给Redis执行。使用脚本的好处：<br>（1）减少网络开销。复合操作需要向Redis发送多次请求，如上例，而是用脚本功能完成同样的操作只需要发送一个请求即可，减少了网络往返时延。<br>（2）原子操作。Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。换句话说在编写脚本的过程中无需担心会出现竞态条件，也就无需使用事务。事务可以完成的所有功能都可以用脚本来实现。<br>（3）复用。客户端发送的脚本会永久存储在Redis中，这就意味着其他客户端（可以是其他语言开发的项目）可以复用这一脚本而不需要使用代码完成同样的逻辑。  </p><h3 id="2、实例：访问频率限制"><a href="#2、实例：访问频率限制" class="headerlink" title="2、实例：访问频率限制"></a>2、实例：访问频率限制</h3><p>因为无需考虑事务，使用Redis脚本实现访问频率限制非常简单。Lua代码如下：  </p><pre><code>local time=redis.call(&apos;incr&apos;,KEYS[1])if times==1 then --KEYS[1]键刚创建，所以为其设置生存时间    redis.call(&apos;expire&apos;,KEYS[1],ARGV[1])endif times &gt;tonumber(ARGV[2]) then    return 0endreturn 1  </code></pre><p>这段代码实现的功能与我们之前所做的类似，不过简洁了很多，即使不了解Lua语言也能猜出来大概意思。那么，该如何测试这个脚本呢？首先我们把这段代码存为ratelimiting.lua然后在命令行输入：<br>redis-cli –eval /path/to/ratelimiting.lua rate.limiting:127.0.0.1 , 10 3，其中–eval参数是告诉redis-cli读取并运行后面的Lua脚本，/path/to/ratelimiting.lua是ratelimiting.lua文件的位置，后面跟着的是传给Lua脚本的参数。其中“，”前的rate.limiting:127.0.0.1是要操作的键，可以在脚本中使用KEYS[1]获取，“，”后面的10和3是参数，在脚本中能够使用ARGV[1]/ARGV[2]获得。结合脚本的内容可知这行命令的作用是将访问频率限制为每10秒最多3次，所以在终端中不断地运行此命令会发现当访问频率在10秒内小于或等于3次时返回1，否则返回0。<br><strong>注意：上面命令中的“，”两边的空格不能省略，否则会出错。</strong>  </p><h2 id="Lua-语法学习"><a href="#Lua-语法学习" class="headerlink" title="Lua 语法学习"></a>Lua 语法学习</h2><p>请参见一些网络学习地址或学习书籍，本人收集地址如下：</p><blockquote><p><a href="http://book.luaer.cn/" target="_blank" rel="noopener">Lua程序设计</a><br><a href="http://manual.luaer.cn/" target="_blank" rel="noopener">Lua在线手册</a><br><a href="http://lua-users.org/wiki/" target="_blank" rel="noopener">Lua WIKI</a><br><a href="https://github.com/wenquan0hf/lua/blob/master/TOC.md" target="_blank" rel="noopener">GitHub Lua教程</a><br><a href="http://www.runoob.com/lua/lua-tutorial.html" target="_blank" rel="noopener">Lua菜鸟教程</a>  </p></blockquote><h2 id="Redis与Lua"><a href="#Redis与Lua" class="headerlink" title="Redis与Lua"></a>Redis与Lua</h2><p>编写Redis脚本的目的就是读写Redis的数据，本章主要介绍Redis与Lua交互的方法。  </p><h3 id="1、在脚本中调用Redis命令"><a href="#1、在脚本中调用Redis命令" class="headerlink" title="1、在脚本中调用Redis命令"></a>1、在脚本中调用Redis命令</h3><p>在脚本中可以使用redis.call函数调用Redis命令。就像这样：  </p><pre><code>redis.call(&apos;set&apos;,&apos;foo&apos;,&apos;bar&apos;)local value=redis.call(&apos;get&apos;,&apos;foo&apos;) --value的值为bar</code></pre><p>redis.call函数的返回值就是Redis命令的执行结果。Redis命令的返回值有5种类型，redis.call函数会将这5种类型的回复转换成对应的Lua的数据类型，具体的对应规则如下表（空结果比较特殊，其对应为Lua的false）。 </p><table><thead><tr><th>Redis返回值类型</th><th>Lua数据类型</th></tr></thead><tbody><tr><td>整数回复</td><td>数字类型</td></tr><tr><td>字符串回复</td><td>字符串类型</td></tr><tr><td>多行字符串回复</td><td>表类型（数组形式）</td></tr><tr><td>状态回复</td><td>表类型（只有一个ok字段存储状态信息）</td></tr><tr><td>错误回复</td><td>表类型（只有一个err字段存储错误信息）  </td></tr></tbody></table><p>Redis还提供了了redis.pcall函数，功能与redis.call相同，唯一区别是当命令执行出错时redis.pcall会记录错误并继续执行，而redis.call会直接返回错误，不会继续执行。  </p><h3 id="2、从脚本中返回值"><a href="#2、从脚本中返回值" class="headerlink" title="2、从脚本中返回值"></a>2、从脚本中返回值</h3><p>在很多情况下都需要脚本返回值，比如前面的访问频率限制脚本会返回频率是否超限。在脚本中可以使用return语句将值返回给客户端，如果没有执行return语句则会默认返回nil。因为我们可以向调用其他Redis内置命令一样调用我们自己写的脚本，所以同样Redis会自动将脚本返回值的Lua数据类型转换成Redis的返回值类型。具体的转换规则见下表（其中Lua的false比较特殊，会被转换成空结果）。  </p><table><thead><tr><th>Lua数据类型</th><th>Redis返回值类型</th></tr></thead><tbody><tr><td>数字类型</td><td>整数回复（Lua的数字类型会被自动转换成整数）</td></tr><tr><td>字符串类型</td><td>字符串回复</td></tr><tr><td>表类型（数组形式）</td><td>多行字符串回复</td></tr><tr><td>表类型（只有一个ok字段存储状态信息）</td><td>状态回复</td></tr><tr><td>表类型（只有一个err字段存储错误信息）</td><td>错误回复  </td></tr></tbody></table><h3 id="3、脚本相关命令"><a href="#3、脚本相关命令" class="headerlink" title="3、脚本相关命令"></a>3、脚本相关命令</h3><h4 id="1-EVAL命令"><a href="#1-EVAL命令" class="headerlink" title="1.EVAL命令"></a>1.EVAL命令</h4><p>编写完脚本后最重要的就是在程序中执行脚本。Redis提供了EVAL命令可以使开发者像调用其他Redis内指命令一样调用脚本。EVAL命令的格式是：EVAL 脚本内容 key参数的数量 [key…] [arg …]。可以通过key和arg这两类参数向脚本传递数据，他们的值可以在脚本中分别使用KEYS和ARGV两个类型的全局变量访问。比如希望用脚本功能实现一个SET命令,脚本内容是这样：  </p><pre><code>return redis.call(&apos;SET&apos;,KEYS[1],ARGV[1])  </code></pre><p>现在打开redis-cli执行此脚本</p><pre><code>127.0.0.1:6379&gt; eval &quot;return redis.call(&apos;SET&apos;,KEYS[1],ARGV[1])&quot; 1 foo barOK127.0.0.1:6379&gt; get foo&quot;bar&quot;  </code></pre><p>其中要读写的键名应该作为key参数，其他的数据都作为arg参数。<br><strong>注意：EVAL命令依据第二个参数将后面的所有参数分别存入脚本中的KEYS和ARGV两个表类型的全局变量中。当脚本不需要任务参数时也不能省略这个参数（设为0）</strong>。  </p><h4 id="2-EVALSHA命令"><a href="#2-EVALSHA命令" class="headerlink" title="2.EVALSHA命令"></a>2.EVALSHA命令</h4><p>考虑到在脚本比较长的情况下，如果每次调用脚本都需要将这个脚本传给Redis会占用较多的带宽。为了解决这个问题，Redis提供了EVALSHA命令允许开发者通过脚本内容的SHA1摘要来执行脚本，改命令的用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要。<br>Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中，执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了则执行脚本，否则会返回错误：“NOSCRIPT No matching script.Please use EVAL.”,在程序中使用EVALSHA命令的一般流程：<br>（1）先计算脚本的SHA1摘要，并使用EVALSHA命令执行脚本。<br>（2）获得返回值，如果返回“NOSCRIPT”错误则使用EVAL命令重新执行脚本。<br>虽然这一流程略显麻烦，但值得庆幸的是很多编程语言的Redis客户端都会代替开发者完成这一流程。比如使用node_redis客户端执行EVAL命令时，node_redis会先尝试执行EVALSHA命令，如果失败才会执行EVAL命令。  </p><h2 id="深入脚本"><a href="#深入脚本" class="headerlink" title="深入脚本"></a>深入脚本</h2><h3 id="1、KEYS与ARGV"><a href="#1、KEYS与ARGV" class="headerlink" title="1、KEYS与ARGV"></a>1、KEYS与ARGV</h3><p>前面提到过向脚本传递参数分为KEYS和ARGV两类，前者表示要操作的键名，后者表示非键名参数。但事实上这一要求并不是强制的，比如 EVAL “return redis.call(‘get’,KEYS[1])” 1 user:Bob可以获得user:Bob的键值，同样还可以使用EVAL “return redis.call(‘get’,’user:’ .. ARGV[1])” 0 Bob完成同样的功能，此时我们虽然并未按照Redis的规则使用KEYS参数传递键名，但还是获得了正确的结果。<br>虽然规则不是强制的，但不遵守规则依然有一定代价。Redis3.0版带有集群的功能，集群的作用是将数据库中的键分散到不同的节点上。这意味着在脚本执行前就需要知道脚本会操作哪些键以便于找到对应的节点，所以如果脚本中的键名没有使用KEYS参数传递则无法兼容集群。  </p><h3 id="2、沙盒与随机数"><a href="#2、沙盒与随机数" class="headerlink" title="2、沙盒与随机数"></a>2、沙盒与随机数</h3><p>Redis脚本禁止使用Lua标准库中与文件或系统调用相关函数，在脚本中只允许对Redis的数据进行处理。并且Redis还通过禁用脚本的全局变量的方式保证每个脚本都要是相对隔离的，不会相互干扰。<br>使用沙盒不仅是为了保证服务器的安全性，而且还确保了脚本的执行结果只和脚本本身和执行时传递的参数有关，不依赖外界条件（如 系统时间、系统中某个文件内容、其他脚本执行结果等。）这是因为在执行复制和AOF持久化操作时记录的是脚本的内容而不是脚本调用命令，所以必须保证在脚本内容和参数一样的前提下的执行结果是一样的。  </p><h3 id="3、其他脚本相关命令"><a href="#3、其他脚本相关命令" class="headerlink" title="3、其他脚本相关命令"></a>3、其他脚本相关命令</h3><p>除了EVAL和EVALSHA外，Redis还提供了了其他4个脚本相关的命令，一般都会被客户端封装起来，开发者很少能使用到。<br>（1）、将脚本加入缓存：SCRIPT LOAD<br>每次执行EVAL命令时Redis都会将脚本的SHA1摘要加入到脚本缓存中，以便下次客户端可以使用EVALSHA命令调用该脚本。如果只是希望将脚本加入脚本缓存而不执行则可以使用SCRIPT LOAD命令，返回值是脚本的SHA1摘要。如：  </p><pre><code>127.0.0.1:6379&gt; script load &quot;return 1&quot;&quot;e0e1f9fabfc9d4800c877a703b823ac0578ff8db&quot;  </code></pre><p>（2）、判断脚本是否已经被缓存：SCRIPT EXISTS<br>SCRIPT EXISTS 命令可以同时查找1个或多个脚本的SHA1摘要是否被缓存，如：  </p><pre><code>127.0.0.1:6379&gt; script exists e0e1f9fabfc9d4800c877a703b823ac0578ff8db1) (integer) 1  </code></pre><p>（3）、清空脚本缓存：SCRIPT FLUSH<br>Redis将脚本的SHA1摘要加入到脚本缓存后会永久保留，不会删除，但可以手动使用SCRIPT FLUSH命令清空脚本缓存：  </p><pre><code>127.0.0.1:6379&gt; script flushOK  </code></pre><p>（4）、强制终止当前脚本的执行：SCRIPT KILL<br>如果想终止当前正在执行的脚本可以使用SCRIPT KILL命令。  </p><h3 id="4、原子性和执行时间"><a href="#4、原子性和执行时间" class="headerlink" title="4、原子性和执行时间"></a>4、原子性和执行时间</h3><p>Redis的脚本执行时原子的，即脚本执行期间Redis不会执行其他命令。所有的命令都必须等待脚本执行完成后才能执行。为了防止某个脚本执行时间过长导致Redis无法提供服务（比如陷入死循环），Redis提供了<strong>lua-time-limit</strong>参数限制脚本的最长运行时间，默认为5秒钟。当脚本运行时间超过这一限制后，Redis将开始接受其他命令但不会执行（以确保脚本的原子性，因为此时脚本并没有被终止），而是会返回“BUSY”错误。限制我们可以打开2个redis-cli实例A和B来测试一下。首先A中执行一个死循环脚本：  </p><pre><code>127.0.0.1:6379&gt; eval &quot;while true do end&quot; 0  --死循环  </code></pre><p>然后在另一个B客户端执行一条命令:  </p><pre><code>127.0.0.1:6379&gt; get foo(error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE.  </code></pre><p>这时实例B中命令并没有马上返回结果，因为、Redis已经被实例A发送的死循环脚本阻塞了，无法执行其他命令。且等待5秒钟之后实例B收到了“BUSY”错误，此时Redis虽然可以接受任何命令，但实际会执行的只有两个命令：SCRIPT KILL 和SHUTDOWN NOSAVE。在实例B中执行SCRIPT KILL命令可以终止当前脚本的运行，并且此时实例A中会返回错误:  </p><pre><code>--实例A127.0.0.1:6379&gt; script killOK  --实例B127.0.0.1:6379&gt; eval &quot;while true do end&quot; 0(error) ERR Error running script (call to f_694a5fe1ddb97a4c6a1bf299d9537c7d3d0f84e7): @user_script:1: Script killed by user with SCRIPT KILL... (343.29s)</code></pre><p>需要注意的是如果当前执行的脚本对Redis的数据进行了修改（如调用SET、LPUSH或DEL等命令）则SCRIPT KILL 命令不会终止脚本的运行以防止脚本只执行了一部分。因为如果脚本只执行了一部分就被终止，会违背脚本的原子性要求，即脚本中的所有命令都要么执行，要么都不执行。比如在实例A中执行：  </p><pre><code>127.0.0.1:6379&gt; eval &quot;redis.call(&apos;SET&apos;,&apos;foo&apos;,&apos;bar&apos;) while true do end&quot; 0--死循环卡住  </code></pre><p>5秒钟后尝试在B中终止该脚本：  </p><pre><code>127.0.0.1:6379&gt; script kill(error) UNKILLABLE Sorry the script already executed write commands against the dataset. You can either wait the script termination or kill the server in a hard way using the SHUTDOWN NOSAVE command.  </code></pre><p>这是只能通过SHUTDOWN NOSAVE命令强制终止Redis。SHUTDOWN NOSAVE命令与SHUTDOWN命令的区别在于前者将不会进行持久化操作，这意味着所有发生在上一次快照后的数据库修改都会丢失。由于Redis脚本非常高效，所以在大部分情况下都不用担心脚本的性能。但同时由于脚本的强大功能，很多原本在程序中执行的逻辑都可以放到脚本中执行，这时就需要开发者根据具体的应用权衡到底哪些任务适合交给脚本。通常来说不应该在脚本中进行大量耗时的运算，因为毕竟Redis是单进程单线程执行脚本，而程序却能够多进程多线程运行。  </p>]]></content>
    
    <summary type="html">
    
      使用Redis的Lua编程脚本，实现复杂的复合操作，实现原子操作避免竞态条件。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="redis使用Lua脚本" scheme="http://xym-loveit.github.io/tags/redis%E4%BD%BF%E7%94%A8Lua%E8%84%9A%E6%9C%AC/"/>
    
      <category term="Lua脚本" scheme="http://xym-loveit.github.io/tags/Lua%E8%84%9A%E6%9C%AC/"/>
    
      <category term="EVAL及EVALSHA" scheme="http://xym-loveit.github.io/tags/EVAL%E5%8F%8AEVALSHA/"/>
    
      <category term="KEYS与ARGV" scheme="http://xym-loveit.github.io/tags/KEYS%E4%B8%8EARGV/"/>
    
  </entry>
  
  <entry>
    <title>redis入门指南之提高篇III</title>
    <link href="http://xym-loveit.github.io/2017/05/26/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87III/"/>
    <id>http://xym-loveit.github.io/2017/05/26/redis入门指南之提高篇III/</id>
    <published>2017-05-26T10:21:49.000Z</published>
    <updated>2018-03-29T01:27:48.644Z</updated>
    
    <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="消息通知"><a href="#消息通知" class="headerlink" title="消息通知"></a>消息通知</h2><p>任务队列顾名思义，就是“传递任务的队列”。与任务队列进行交互的尸体有两类，一类是生产者（producer），一类是消费者（consumer）。生产者会将需要处理的任务放入队列中，而消费者则不断地从队列中读入任务信息并执行。<br>使用任务队列有如下好处：<br>（1）松耦合。生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产者和消费者可以由不同的团队使用不同的编程语言编写。<br>（2）易于扩展消费者可以有多个，而且可以分布在不同的服务器中，借此可以轻易地降低单台服务器的负载。</p><p><img src="http://op7wplti1.bkt.clouddn.com/producerandConsumer.png" alt="多个消费者消费生产者放入队列的任务"></p><h3 id="1、Redis实现任务队列"><a href="#1、Redis实现任务队列" class="headerlink" title="1、Redis实现任务队列"></a>1、Redis实现任务队列</h3><p>说到任务队列自然想到之前介绍的LPUSH和RPOP命令实现队列的概念。如果要实现队列，只需要让生产者将任务使用LPUSH命令加入某个键中，另一边让消费者不断地使用RPOP命令从该键中取出任务即可。消费者伪代码如下：  </p><pre><code>loop //无限循环读取任务队列中的内容    $task=RPOP queue    if $task        //如果任务队列中有任务执行它        execute($task)    else        //如果没有则等待1秒以免过于频繁请求数据        wait 1 second</code></pre><p>到此一个使用Redis实现的简单任务队列就写好了。不好还有一点不完美的地方:当任务队列中没有任务时消费者每秒都会调用一次RPOP命令查看是否有新任务。如果可以实现一旦有新任务队列就通知消费者就好了。其实借助BRPOP命令就可以实现这一的需求。<br>BRPOP命令和RPOP命令相似，唯一的区别是当列表中没有元素时BRPOP命令会一直阻塞住连接，知道有新元素加入。如上代码可改为： </p><pre><code>loop    //如果任务队列中没有新任务，BRPOP命令会一直阻塞，不会执行execute()。    $task=BRPOP queue,0    //返回值是数组，数组第二个元素时我们需要的任务。    execute($task[1])</code></pre><p>BRPOP命令接受2个参数，第一个是键名，第二个是超时时间，单位是秒。当超过了此时间仍然没有获得新元素就会返回nil。上例中超时时间为“0”，表示不限制等待的时间，即如果没有新元素加入列表就会永远组塞下去。<br>当获得一个元素后BPOP命令返回二个值，分别是键名和元素值。为了测试BPOP命令，我们可以打开2个redis-cli实例，在实例A中：  </p><pre><code>127.0.0.1:6379&gt; brpop queue 0</code></pre><p>键入回车后实例1会处于阻塞状态，这时在实例B中向queue中加入一个元素： </p><pre><code>127.0.0.1:6379&gt; lpush queue task(integer) 1</code></pre><p>在LPUSH命令执行后实例A马上就返回了结果： </p><pre><code>127.0.0.1:6379&gt; brpop queue 01) &quot;queue&quot;2) &quot;task&quot;(73.70s)</code></pre><p>同时会发现queue中的元素已经被取走： </p><pre><code>127.0.0.1:6379&gt; llen queue(integer) 0</code></pre><p>除了BRPOP命令外，Redis还提供了BLPOP，和BRPOP的区别在于从队列取元素时BLPOP会从左边取。  </p><h3 id="2、优先级队列"><a href="#2、优先级队列" class="headerlink" title="2、优先级队列"></a>2、优先级队列</h3><p>BRPOP命令可以同时接受多个键，其完整的命令格式为BRPOP key [key …] timeout，如BRPOP queue:1 queue:2 0。意义是同时检测多个键，如果所有键都没有元素则阻塞，如果其中有一个键有元素则会从该键中弹出元素。例如，打开两个redis-cli实例，在实例A中:  </p><pre><code>127.0.0.1:6379&gt; BLPOP queue:1 queue:2 queue:3 0</code></pre><p>在实例B中：  </p><pre><code>127.0.0.1:6379&gt; lpush queue:2 task(integer) 1</code></pre><p>则实例A中返回： </p><pre><code>1) &quot;queue:2&quot;2) &quot;task&quot;(15.54s)</code></pre><p>如果多个键都有元素则按照从左到右的顺序取第一个的一个元素。我们现在queue:2和queue:3中各加入一个元素： </p><pre><code>127.0.0.1:6379&gt; lpush queue:2 task2(integer) 1127.0.0.1:6379&gt; lpush queue:3 task3(integer) 1</code></pre><p>然后执行BRPOP命令：  </p><pre><code>127.0.0.1:6379&gt; BRPOP queue:1 queue:2 queue:3 01) &quot;queue:2&quot;2) &quot;task2&quot;</code></pre><p>借此特性可以实现区分优先级的任务队列。我们分别使用queue:confirm.email和queue：notification.email两个键存储发送确认邮件（注册网站需要发送确认邮箱正确性邮件）和发送通知邮件（一旦有新博客文章就发送邮件信息提醒）两种任务，然后将消费者的代码改为： </p><pre><code>loop    $task=BRPOP queue:confirm.email,queue:notification.email,0    execute($task[1])</code></pre><p>这时一旦发送确认邮件的任务被加入到queue:confirm.email队列中，无论queue:notification.email还有多少任务，消费者都会优先完成发送确认邮件的任务。  </p><h3 id="3、发布-订阅模式"><a href="#3、发布-订阅模式" class="headerlink" title="3、发布/订阅模式"></a>3、发布/订阅模式</h3><p>除了实现任务队列外，Redis还提供了一组命令可以让开发者实现“发布/订阅”（publish/subscribe）模式。“发布/订阅”模式同样可以实现进程间的消息传递，其原理是这样的：<br>“发布/订阅”模式中包含两种角色，分别是发布者和订阅者。订阅者可以订阅一个或若干个频道（channel），而发布者可以向指定的频道发送消息，所有订阅此频道的订阅者都会收到此消息。发布者发布消息的命令是publish，用法是publish channel message，如向channel1.1发送“hello”： </p><pre><code>127.0.0.1:6379&gt; publish channel1.1 hello(integer) 0</code></pre><p>这样消息就发出去了。PUBLISH命令的返回值表示接收到这条消息的订阅者数量。因为此时没有客户端订阅channel1.1，所以返回0。发出去的消息不会被持久化，也就是说当有客户端订阅channel1.1后只能收到后续发布到该频道的消息，之前发送的就收不到了。订阅频道的命令时SUBSCRIBE，可以同时订阅多个频道，用法是SUBSCRIBE channel [channel …]。现在新开一个redis-cli实例A，用它来订阅channel1.1： </p><pre><code>127.0.0.1:6379&gt; subscribe channel1.1Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;channel1.1&quot;3) (integer) 1</code></pre><p>执行SUBSCRIBE命令后客户端会进入订阅状态，处于此状态下的客户端不能使用除SUBSCRIBE/UNSUBSCRIBE/PSUBSCRIBE/PUNSUBSCRIBE这4个属于“发布/订阅”模式的命令之外的其他命令，否则会报错。<br>进入订阅状态后客户端可能收到三种类型的回复。每种类型的回复都包含3个值，第一个值是消息的类型，根据消息类型的不同，第二、第三个值的含义也不同。消息类型可能取值有：<br>（1）Subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个值是当前客户端订阅的频道数量。<br>（2）message。这个类型的回复使我们最关心的，它表示接受到的消息。第二个值表示产生消息的频道名称，第三个是消息的内容。<br>（3）unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值是当前客户端订阅频道的数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他非“发布/订阅”模式的命令了。<br>上例中当实例A订阅了channel1.1进入订阅状态后收到了一条subscribe类型的回复，这时我们打开另一个redis-cli实例B，并向channel1.1发送一条消息：  </p><pre><code>127.0.0.1:6379&gt; publish channel1.1 hello(integer) 1</code></pre><p>返回值为1表示有一个客户端订阅了channel1.1，此时实例A收到了类型为message的回复：<br>127.0.0.1:6379&gt; subscribe channel1.1</p><pre><code>Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;channel1.1&quot;3) (integer) 11) &quot;message&quot;2) &quot;channel1.1&quot;3) &quot;hello&quot;</code></pre><p>使用UNSUBSCRIBE命令可以取消订阅指定的频道，用法为UNSUBSCRIBE [channel [channel…]]，如果不指定频道则会取消订阅所有频道。  </p><h3 id="4、按照规则订阅"><a href="#4、按照规则订阅" class="headerlink" title="4、按照规则订阅"></a>4、按照规则订阅</h3><p>除了可以使用SUBSCRIBE命令订阅指定名称的频道外，还可以使用PSUBSCRIBE命令订阅指定的规则。规则支持glob风格通配符格式，如：  </p><pre><code>127.0.0.1:6379&gt; psubscribe channel.?*Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;channel.?*&quot;3) (integer) 1</code></pre><p>规则channel.?*可以匹配channel.1和channel.10但不会匹配channel.。这时在实例B中发送消息：  </p><pre><code>127.0.0.1:6379&gt; publish channel.1 hello(integer) 2</code></pre><p>返回结果是2因为2个实例客户端都订阅了channel.1频道。实例psubscribe channel.?*收到的回复是：  </p><pre><code>1) &quot;pmessage&quot;2) &quot;channel.?*&quot;3) &quot;channel.1&quot;4) &quot;hello&quot;</code></pre><p>第一个值表示这条消息是通过PSUBSCRIBE命令订阅频道而收到的======，第二个值表示订阅时用的通配符，第三个值表示实际收到的消息的频道，第四个值则是消息内容。 </p><p>提示：使用PSUBSCRIBE命令可以重复订阅一个频道，如某客户端执行了PSUBSCRIBE channel.? channel.?*，这时向channel.2发布消息后该客户端会收到2条消息，而同时PUBLISH命令返回的值也是2而不是1。同样的，如果有另一个客户端执行了SUBSCRIBE channel.10和PSUBSCRIBE channel.?*的话，向channel.10发送命令该客户端也会收到两条消息（但是是两种类型，message和pmessage），同时publish命令会返回2。<br>PUNSUBSCRIBE命令可以推定指定的规则，用法是PUNSUBSCRIBE [pattern [pattern …]]，如果没有参数则会退订所有规则。  </p><p><strong>注意：使用PUNSUBSCRIBE命令只能退订通过PSUBSCRIBE命令订阅的规则，不会影响直接通过SUBSCRIBE命令订阅的频道；同样UNSUBSCRIBE命令也不会影响通过PSUBSCRIBE命令订阅的规则。另外容易出错的是使用PUNSUBSCRIBE命令退订某个规则时不会将其中的通配符展开，而是进行严格的字符串匹配，所以PUNSUBSCRIBE * 无法退订channel.* 规则，而是必须使用PUNSUBSCRIBE channel.*才能退订。</strong>  </p><h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>客户端和Redis使用TCP协议连接。不论是客户端向Redis发送命令还是Redis向客户端返回命令的执行结果，都需要经过网络传输，这两个部分的总耗时称为往返时延。根据网络性能不同，往返时延也不同，大致来说到本地回环地址（loop back address）的往返时延在数量级上相当于Redis处理一条简单命令（如LPUSH list 1 2 3）的时间。如果执行较多的命令，每个命令的往返时延累加起来对性能还是有一定影响的。<br>在执行多个命令时每条命令都需要等待上一条命令执行完（即收到Redis的返回结果）才能执行，即使命令不需要上一条命令的执行结果。如要获得post:1、post:2和post:3这3个键中的title字段，需要执行三条命令，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/executeCommand.png" alt="不使用管道时多条命令执行示意图">  </p><p>Redis的底层通信协议对管道（pipelining）提供了支持。通过管道可以一次性发动多条命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出。管道通过减少客户端与Redis的通信次数来实现降低往返时延累计值的目的，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/pipeExecute.png" alt="管道执行多条命令示意图">  </p><h2 id="节省空间"><a href="#节省空间" class="headerlink" title="节省空间"></a>节省空间</h2><p>相比于硬盘而言，内存在今天仍然显得比较昂贵。而Redis是一个基于内存的数据库，所有的数据都存储在内存中，所以如何优化存储，减少内存空间占用对成本控制来说是一个非常重要的话题。  </p><h3 id="1、精简键名和键值"><a href="#1、精简键名和键值" class="headerlink" title="1、精简键名和键值"></a>1、精简键名和键值</h3><p>精简键名和键值是最直观的减少内存占用的方式，如将键名very.important.person:20改成VIP:20。当然精简键名一定要把握尺度，不能单纯为了节约空间而使用不易理解的键名（比如将VIP:20修改为V:20，这样既不易维护，还容易造成命名冲突）。又比如一个存储用户性别的字符串类型键的取值是male和female，我们可以将其修改成m和f来为每条记录节约几个字节空间（更好的办法是使用0和1来表示性别）。  </p><h3 id="2、内部编码优化"><a href="#2、内部编码优化" class="headerlink" title="2、内部编码优化"></a>2、内部编码优化</h3><p>有时候仅凭精简键名和键值所减少的空间并不足以满足需求，这时就需要根据Redis内部的编码规则来节省更多的空间。Redis为每种数据类型都提供了两种内部编码方式，以散列类型为例，散列类型是通过散列表实现，这样就可以实现O（1）时间复杂度的查找、赋值操作，然而当键中元素很少的时候，O（1）的操作并不会比O（n）有明显的性能提高，所以这种情况下Redis会采用一种更为紧凑但性能稍差（获取元素的时间复杂度为O（n））的内部编码方式。内部编码方式的选择对于开发者来说是透明的，Redis会根据实际情况自动调整。当键中元素变多时Redis会自动将该键的内部编码方式转换成散列表。如果想查看一个键的内部编码方式可以使用OBJECT ENCODING 命令，如：  </p><pre><code>127.0.0.1:6379&gt; type score:2string127.0.0.1:6379&gt; get score:2&quot;100&quot;127.0.0.1:6379&gt; object encoding score:2&quot;int&quot;127.0.0.1:6379&gt; type post:5hash127.0.0.1:6379&gt; object encoding post:5&quot;ziplist&quot;</code></pre><p>Redis的每个键值都是使用一个redisObject结构体保存的，redisObject的定义如下：  </p><pre><code>typedef struct redisObject{    unsigned type:4;    unsigned notused:2;    unsigned encoding:4;    unsigned lru:22; /* lru time(relative to server.lruclock) */    int refcount;    void *ptr;} robj;</code></pre><p>其中type字段表示的是键值的数据类型，取值可以是如下内容：  </p><pre><code>#define REDIS_STRING 0#define REDIS_LIST 1#define REDIS_SET 2#define REDIS_ZSET 3#define REDIS_HASH 4</code></pre><p>encoding字段表示的就是Redis键值内部编码方式，取值如下：  </p><pre><code>#define REDIS_ENCODING_RAW 0 /* Raw representation */#define REDIS_ENCODING_INT 1 /* Encoded as integer */#define REDIS_ENCODING_HT 2  /* Encoded as hash table */#define REDIS_ENCODING_ZIPMAP 3 /* Encoded as zipmap */#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define REDIS_ENCODING_INTSET 6 /* Encoded as intset */#define REDIS_ENCODING_SKIPLIST 7 /* Encoded as skiplist */</code></pre><p>各个数据类型可能采用的内部编码方式及其相应的OBJECT ENCODING 命令执行结果如下：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/redisEncoding.png" alt="Redis每种数据类型都采用二种编码方式中的一种存储"></p><h4 id="1、字符串类型"><a href="#1、字符串类型" class="headerlink" title="1、字符串类型"></a>1、字符串类型</h4><p>Redis使用一个sdshdr类型的变量来存储字符串，而redisObject的ptr字段指向的是该变量的地址。sdshdr的定义如下： </p><pre><code>struct sdshdr{    int len;    int free;    char buf[];}</code></pre><p>其中len字段表示的是字符串的长度，free字段表示buf中的剩余空间，而buf字段存储的才是字符串的内容。所以当执行SET key foobar时，存储键值需要占用的空间是sizeof(redisObject)+sizeof(sdshdr)+strlen(“foobar”)=30字节，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/strstructure.png" alt="字符串键值的存储结构">  </p><p>而当键值内容可以用一个64位有符号整数表示时，Redis会将键值转换成long类型来存储。如SET key 123456，实际占用空间是sizeof(redisObject)=16字节，比存储“foobar”节省了一般的存储空间，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/strstructure2.png" alt="字符串键值的存储结构2">   </p><p>redisObject中的refcount字段存储的是该键值被引用数量，即一个键值可以被多个键引用。Redis启动后会预先建立10000个分别存储从0到9999这些数字的redisObject类型变量作为共享对象，如果要设置的字符串在这10000个数字内（如SET key1 123）则可以直接引用共享对象而不用再建立一个redisObject了，也就是说存储键值占用的空间是0字节，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/shareObject.png" alt="Redis直接引用共享对象">  </p><p>由此可见，使用字符串类型键存储对象ID这种小数字是非常节省存储空间的，Redis只需存储键名和一个对共享对象的引用即可。<br><strong>提示：当通过配置文件参数maxmemory设置了Redis可用的最大空间大小时，Redis不会使用共享对象，因为对于每个键值都需要使用一个redisObject来记录其LRU信息。</strong>  </p><h4 id="2、散列类型"><a href="#2、散列类型" class="headerlink" title="2、散列类型"></a>2、散列类型</h4><p>散列类型的内部编码方式可能是REDIS_ENCODING_HT或REDIS_ENCODING_ZIPLIST。在配置文件中可以定义使用REDIS_ENCODING_ZIPLIST方式编码散列表类型的时机：  </p><pre><code>hash-max-ziplist-entries 512hash-max-ziplist-value 64</code></pre><p>当散列类型键的字段个数少于hash-max-ziplist-entries参数值且每个字段名和字段值的长度都小于hash-max-ziplist-value 参数值（单位为字节）时，Redis就会使用REDIS_ENCODING_ZIPLIST来存储该键，否则就会使用REDIS_ENCODING_HT。转换过程是透明的，每当键值变更后Redis都会自动判断是否满足条件来完成转换。  </p><p>REDIS_ENCODING_HT编码即散列表，可以实现O（1）时间复杂度的赋值取值等操作，其字段和字段值都是使用redisObject存储的，所以前面讲到的字符串类型键值的优化方法同样适用于散列类型键的字段和字段值。  </p><p>提示 Redis的键值对存储也是通过散列表实现的，与REDIS_ENCODING_HT编码方式类似，但键名并非使用redisObject存储，所以键名“123456”并不会比“abcdef”占用更少空间。之所以不对键名进行优化是因为绝大多数情况下键名都不会是纯数字。  </p><pre><code>补充知识 Redis支持多数据库，每个数据库中的数据都是通过结构体redisDb存储。redisDb的定义如下：  typedef struct redisDb{    dict *dict; /* The keyspace for this DB */    dict *expires; /* Timeout of keys with a timeout set */    dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) */    dict *ready_keys; /* Blocked keys that received a PUSH */    dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */    int id;} redisDb;dict类型就是散列表结构，expires存储的是数据的过期时间。当Redis启动时会根据配置文件中databases参数指定的数量创建若干个redisDb类型变量存储不同数据库中的数据。</code></pre><p>REDIS_ENCODING_ZIPLIST编码类型是一种紧凑的编码格式，它牺牲了部分读取性能以换取极高的空间利用率，适合在元素较少的时使用。该编码类型同样还在列表类型和有序集合类型中使用。REDIS_ENCODING_ZIPLIST编码结构下图所示:  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_bmjg.png" alt="REDIS_ENCODING_ZIPLIST编码的内存结构"><br>其中zlbytes是uint32_t类型，表示整个结构占用的空间。zltail也是uint32_t类型，表示到最后一个元素的偏移，记录zltail是的程序可以直接定位到尾部元素而无需遍历整个结构，执行从尾部弹出（对列表类型而言）等操作时速度更快。zllen是uint16_t类型，存储的是元素的数量。zlend是一个单字节标识，标记结构的末尾，值永远是255。<br>在REDIS_ENCODING_ZIPLIST中每个元素由4个部分组成。第一个部分用来存储前一个元素的大小以实现倒序查找，当前一个元素的大小小于245字节时第一个部分占用1个字节，否则会占用5个字节。</p><p>第二、三个部分分别是元素的编码类型和元素大小，当元素的大小小于或等于63个字节时，元素的编码类型是ZIP_STR_06B（即0&lt;&lt;6），同时第三个部分用6个二进制位来记录元素的长度，所以第二、三个部分总占用空间是1字节。当元素的大小大于63且小于或等于16383字节时，第二、三个部分总占用空间是2字节。当元素的大小大于16383字节时，第二、三个部分总占用空间是5字节。<br>第四个部分是元素的实际内容，如果元素可以转换成数字的话Redis会使用相应的数字类型来存储以节省空间，并用第二、第三个部分来表示数字的类型（int16_t/int32_t等）。使用REDIS_ENCODING_ZIPLIST编码存储散列类型时元素的排列方式是：元素1存储字段1，元素2存储字段值1，以此类推，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_2.png" alt="使用REDIS_ENCODING_ZIPLIST编码存储散列类型内存结构">    </p><p>例如，当执行命令HSET hkey foo bar 命令后，hkey键值的内存结构如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_3.png" alt="使用REDIS_ENCODING_ZIPLIST编码存储散列类型内存结构2">   </p><p>下次需要执行HSET hkey foo anothervalue 时Redis需要从头开始找到值为foo的元素（查找时每次都会跳过一个元素以保证只查找字段名），找到后删除其下一个元素，并将新值anothervalue 插入。删除和插入都需要移动后面的内存数据，而且查找操作也需要遍历才能完成，可想而知当散列键中的数据多时性能将很低，所以不宜将<strong>hash-max-ziplist-entries</strong>和<strong>hash-max-ziplist-value</strong> 两个参数设置得很大。  </p><h4 id="3、列表类型"><a href="#3、列表类型" class="headerlink" title="3、列表类型"></a>3、列表类型</h4><p>列表类型的内部编码方式可能是REDIS_ENCODING_LINKEDLIST或REDIS_ENCODING_ZIPLIST。同样在配置文件中可以使用REDIS_ENCODING_ZIPLIST方式编码的时机:  </p><pre><code>list-max-ziplist-entries 512list-max-ziplist-value 64</code></pre><p>具体转换方式和散列类型一样，REDIS_ENCODING_LINKEDLIST编码方式即双向链表，链表中的每个元素是用redisObject存储的，所以此种编码方式下的元素值的优化方法与字符串的键值相同。<br>而是用REDIS_ENCODING_ZIPLIST编码方式时具体的表现和散列类型一样，由于REDIS_ENCODING_ZIPLIST编码方式同样支持倒序访问，所以采用此种编码方式时获取两端的数据依然较快。  </p><h4 id="4、集合类型"><a href="#4、集合类型" class="headerlink" title="4、集合类型"></a>4、集合类型</h4><p>集合类型的内部编码方式可能是REDIS_ENCODING_HT或REDIS_ENCODING_INTSET。当集中的所有元素都是整数且元素的个数小于配置文件中的set-max-intset-entries参数指定值（默认512）时Redis会使用REDIS_ENCODING_INTSET编码存储该集合，否则会使用REDIS_ENCODING_HT来存储。REDIS_ENCODING_INTSET编码存储结构体intset的定义如下： </p><pre><code>typedef struct intset{    uint32_t encoding;    uint32_t length;    int8_t contents[];} intset;</code></pre><p>其中contents存储的就是集合中的元素值，根据encoding的不同，每个元素占用的字节大小不同。默认encoding是INTSET_ENC_INT16（即2个字节），当新增加的整数元素无法使用2个字节表示时，Redis会将该集合的encoding升级为INTSET_ENC_INT32（即2个字节）并调整之前所有元素的位置和长度，同样集合的encoding还可升级为INTSET_ENC_INT64（即8个字节）。<br>REDIS_ENCODING_INTSET编码以有序的方式存储元素（所以使用SMEMBERS命令获得的结果是有序的），使得可以使用二分算法查找元素。然后无论是添加还是删除元素，Redis都需要调整后面元素的内存位置，所以当集合中元素太多时性能较差。当新增加的元素不是整数或集合中的元素数量超过了set-max-intset-entries参数指定值时，Redis会自动将该集合的存储结构转换成REDIS_ENCODING_HT。  </p><h4 id="5、有序集合类型"><a href="#5、有序集合类型" class="headerlink" title="5、有序集合类型"></a>5、有序集合类型</h4><p>有序集合类型的内部编码方式可能是REDIS_ENCODING_SKIPLIST或REDIS_ENCODING_ZIPLIST。同样在配置文件中可以使用REDIS_ENCODING_ZIPLIST方式编码的时机:  </p><pre><code>zset-max-ziplist-entries 128zset-max-ziplist-value 64</code></pre><p>具体规则和散列表一样。当编码方式是REDIS_ENCODING_SKIPLIST时，Redis使用散列表和跳跃列表（skip list）两种数据结构来存储有序集合类型键值，其中散列表用来存储元素值与元素分数的映射关系以实现O（1）时间复杂度的ZSCORE等命令。跳跃列表用来存储元素的分数及其到元素值的映射以实现排序的功能。Redis对跳跃表的实现进行了几点修改，其中包括允许跳跃列表中的元素（即分数）相同，还有为跳跃链表每个节点增加了指向前一个元素的指针以实现倒序查找。采用此种编码方式时，元素值是使用redisObject存储的，所以可以使用字符串类型键值的优化方式优化元素值，而元素的分数是使用double类型存储的。<br>使用REDIS_ENCODING_ZIPLIST编码时有序集合存储的方式按照“元素1的值，元素1的分数，元素2的值，元素2的分数”的顺序排列，并且分数是有序的。</p>]]></content>
    
    <summary type="html">
    
      Redis中的任务队列（消费者/生产者模式）、发布订阅的使用、从Redis节省空间到详解Redis存储数据结构（节约内存必读）。
    
    </summary>
    
      <category term="redis系列" scheme="http://xym-loveit.github.io/categories/redis%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Redis任务队列" scheme="http://xym-loveit.github.io/tags/Redis%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97/"/>
    
      <category term="Redis优先级队列" scheme="http://xym-loveit.github.io/tags/Redis%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/"/>
    
      <category term="Redis发布订阅" scheme="http://xym-loveit.github.io/tags/Redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/"/>
    
      <category term="Redis管道概念" scheme="http://xym-loveit.github.io/tags/Redis%E7%AE%A1%E9%81%93%E6%A6%82%E5%BF%B5/"/>
    
      <category term="Redis键值存储详解" scheme="http://xym-loveit.github.io/tags/Redis%E9%94%AE%E5%80%BC%E5%AD%98%E5%82%A8%E8%AF%A6%E8%A7%A3/"/>
    
  </entry>
  
</feed>
