<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Docker基础-docker compose网络</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-compose%E7%BD%91%E7%BB%9C/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-compose%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<blockquote><p>注意： 本文涉及的compose只适用于compose文件格式为version 2的版本，v1(旧的)不支持网络功能</p></blockquote><p>默认<code>compose</code>会为你的app配置一个单独的网络。服务中的每个容器加入到这个默认的网络且在这个网络的容器都能互相通信，它们也能通过与容器名称相同的主机名发现对方。</p><blockquote><p>注意： app的网络基于”项目名称”设置网络名称，这个项目名称基于项目所处的目录名。可以使用–project-name选项或COMPOSE_PROJECT_NAME环境变量来覆盖。</p></blockquote><p>例如，假设app在一个名为<code>myapp</code>的目录，<code>docker-compose.yml</code>内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    build: .</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;8000:8000&quot;</span><br><span class="line">  db:</span><br><span class="line">    image: postgres</span><br></pre></td></tr></table></figure><p>当执行<code>docker-compose up</code>时，网络部分设置如下： 1.创建了称之为myapp_default的网络 2.使用web的配置创建容器，然后这个容器加入到myapp_default网络 3.使用db的配置创建容器，这个容器加入到myapp_default网络</p><p>每个容器现在能直接查找主机名web或db来得到容器的IP地址。例如，web应用程序的代码可以连接URL postgres://db:5432并开始使用postgres数据库。 由于web明确的映射了一个端口，外部网络也就能通过在docker主机的网络接口的8000端口连接容器。</p><h2 id="容器更新"><a href="#容器更新" class="headerlink" title="容器更新"></a>容器更新</h2><p>如果更改了服务的配置并执行<code>docker-compose up</code>来更新它，将删除旧的容器并且新的容器会加入到相同的网络，分配到了不同的IP地址，不过主机名不变。运行中的容器应该能够查找主机名并连接到新的地址，不过旧的地址将失效。</p><p>如果任何一个容器与旧容器有连接，它们会被关闭掉。容器有责任检测这种情况然后重新查找旧容器的主机来重新连接。</p><h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><p>links可以为一个容器定义一个额外的别名。即使服务没有启动，它们也能进行通信。默认任何服务都可以通过该服务的名称访问其他的服务。例如：在web容器中可以通过db和database访问db容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    build: .</span><br><span class="line">    links:</span><br><span class="line">      - &quot;db:database&quot;</span><br><span class="line">  db:</span><br><span class="line">    image: postgres</span><br></pre></td></tr></table></figure><h2 id="多主机网络"><a href="#多主机网络" class="headerlink" title="多主机网络"></a>多主机网络</h2><p>当在swarm集群中部署compose app的时候，你可以使用内置的overlaydriver来启用容器之间的多主机通信，这不会更改你的compose文件和app code。</p><p>请参阅Getting started with multi-host networking<a href="https://docs.docker.com/network/overlay-standalone.swarm/" target="_blank" rel="noopener">Getting started with multi-host networking</a>来了解怎么配置swarm集群。swarm默认是使用overlay网络驱动，当然你也可以自己自定义。详情在下一段</p><h2 id="指定自定义网络"><a href="#指定自定义网络" class="headerlink" title="指定自定义网络"></a>指定自定义网络</h2><p>除了使用默认的app网络之外，还可以使用最顶层的<code>networks</code>关键字来指定自定义的网络。这让你可以创建更复杂的网络并制定自定义网络驱动及其选项。也可以使用它将服务连接到不是有compose管理的外部网络。</p><p>每个服务都能指定由networks关键字配置的网络，可以配置service级别和top级的网络。</p><p>下面的示例compose文件定义了两个自定义网络。proxy服务与db服务隔离，因为它们没有指定相同的网络。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  proxy:</span><br><span class="line">    build: ./proxy</span><br><span class="line">    networks:</span><br><span class="line">      - front</span><br><span class="line">  app:</span><br><span class="line">    build: ./app</span><br><span class="line">    networks:</span><br><span class="line">      - front</span><br><span class="line">      - back</span><br><span class="line">  db:</span><br><span class="line">    image: postgres</span><br><span class="line">    networks:</span><br><span class="line">      - back</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  front:</span><br><span class="line">    # Use a custom driver</span><br><span class="line">    driver: custom-driver-1</span><br><span class="line">  back:</span><br><span class="line">    # Use a custom driver which takes special options</span><br><span class="line">    driver: custom-driver-2</span><br><span class="line">    driver_opts:</span><br><span class="line">      foo: &quot;1&quot;</span><br><span class="line">      bar: &quot;2&quot;</span><br></pre></td></tr></table></figure><h2 id="配置默认网络"><a href="#配置默认网络" class="headerlink" title="配置默认网络"></a>配置默认网络</h2><p>除了指定你自己的网络之外，还可以通过在名为default的网络下定义一个条目来更改应用范围内的默认网络设置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    build: .</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;8000:8000&quot;</span><br><span class="line">  db:</span><br><span class="line">    image: postgres</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  default:</span><br><span class="line">    # Use a custom driver</span><br><span class="line">    driver: custom-driver-1</span><br></pre></td></tr></table></figure></p><h2 id="使用预先存在的网络"><a href="#使用预先存在的网络" class="headerlink" title="使用预先存在的网络"></a>使用预先存在的网络</h2><p>如果你希望你的容器加入一个预先存在的网络，使用external选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">networks:</span><br><span class="line">  default:</span><br><span class="line">    external:</span><br><span class="line">      name: my-pre-existing-network</span><br></pre></td></tr></table></figure><p>compose检测到有external选项后，不会创建名为[PROJECTNAME]_default的网络，而是会查找一个名为my-pre-existing-network的网络，并将应用程序连接到它。</p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> compose网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-docker 容器日志命名</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%91%BD%E5%90%8D/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E5%91%BD%E5%90%8D/</url>
      <content type="html"><![CDATA[<p>tag 选项指定你该为容器的日志如何命名。默认是容器ID的前12个字符。要覆盖默认值，可指定一个tag选项:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --log-driver=fluentd --log-opt fluentd-address=myhost.local:24224 --log-opt tag=&quot;mailer&quot;</span><br></pre></td></tr></table></figure></p><p>docker支持一些特殊的标记模板，你可以在指定的时候使用</p><table><thead><tr><th>标记</th><th>描述</th></tr></thead><tbody><tr><td>{ { .ID } }</td><td>容器ID的前12个字符</td></tr><tr><td>{ { .FullID } }</td><td>容器的全部ID</td></tr><tr><td>{ { .Name } }</td><td>容器名</td></tr><tr><td>{ { .ImageID } }</td><td>Image ID 前12个字符</td></tr><tr><td>{ { .ImageFullID } }</td><td>全部的Image ID</td></tr><tr><td>{ { .ImageName } }</td><td>Image 名</td></tr><tr><td>{ { .DaemonName } }</td><td>docker 进程的名称</td></tr></tbody></table><p>例如：指定一个 <code>--log-opt tag=&quot;{ { .ImageName } }/{ { .Name } }/{ { .ID } }&quot;</code>,让其输出到syslog，那么最终他输出的内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Aug  7 18:33:19 HOSTNAME docker/hello-world/foobar/5790672ab6a0[9103]: Hello from Docker</span><br></pre></td></tr></table></figure></p><p>在启动时，系统会在<code>tag</code>中设置<code>container_name</code> 字段和<code>{ { .name } }</code>字段，如果你使用<code>docker rename</code>重命名容器，新名称不会反映在日志消息中，这些消息会继续使用原来的容器名。</p><p>更高级的用法，可以去参考<a href="https://golang.org/pkg/text/template/" target="_blank" rel="noopener">go templates</a>和<a href="https://github.com/moby/moby/tree/master/daemon/logger" target="_blank" rel="noopener">container’s logging context</a></p><p>下面是一个syslog的例子，如果我们使用下面的内容,就会得到如下的日志内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --rm \</span><br><span class="line">    --log-driver syslog \</span><br><span class="line">    --log-opt tag=&quot;&#123; &#123;  (.ExtraAttributes nil).SOME_ENV_VAR  &#125; &#125;&quot; \</span><br><span class="line">    --log-opt env=SOME_ENV_VAR \</span><br><span class="line">    -e SOME_ENV_VAR=logtester.1234 \</span><br><span class="line">    flyinprogrammer/logtester</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Apr  1 15:22:17 ip-10-27-39-73 docker/logtester.1234[45499]: + exec app</span><br><span class="line">Apr  1 15:22:17 ip-10-27-39-73 docker/logtester.1234[45499]: 2016-04-01 15:22:17.075416751 +0000 UTC stderr msg: 1</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker容器日志 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-docker limit资源限制</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-limit%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-limit%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/</url>
      <content type="html"><![CDATA[<p>默认情况下，容器没有资源约束，可以使用与主机的内核调度程序允许的的资源一样多的资源。docker提供了在运行<code>docker run</code>指定选项来控制容器内存，cpu或IO的方法。这部分提供了有关何时应该设置这类限制以及设置这些限制可能有什么影响的详细信息。</p><h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>Docker 可以强制执行硬内存限制，其允许容器使用不超过用户或系统给定的内存大小，或者软限制，允许容器在满足条件的情况下使用所需内存，例如,当内核检测到主机上的内存不足或有争抢。下面的选项单独使用或集中使用会有不同的效果。 这些选项中大部分都是采用正整数，后面跟一个后缀b,k,m,g，表示字节，千字节，兆字节，千兆字节。</p><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>-m or –memory=</td><td>容器可以使用的最大内存大小，如果你设置了这个选项，那么内存最小也要4m</td></tr><tr><td>–memory-swarp*</td><td>容器可以交换到硬盘的内存大小，可参考<a href="https://docs.docker.com/config/containers/resource_constraints/" target="_blank" rel="noopener">–memory-swap details</a></td></tr><tr><td>–memory-swappiness</td><td>默认情况下，主机内核可以交换容器使用的匿名页面的百分比，可以在0-100之间设置<code>--memory-swappiness</code>的百分比，可参考<a href="https://docs.docker.com/config/containers/resource_constraints/#--memory-swappiness-details" target="_blank" rel="noopener">–memory-swappiness details</a></td></tr><tr><td>–memory-reservation</td><td>允许你指定一个小于–memory的软限制，当docker在主机上检测到争用或低内存时激活该限制。如果使用–memory-reservation，则必须将其设置为低于–memory，以使其优先。因为它是一个软限制，不保证容器不会超过限制。</td></tr><tr><td>–kernel-memory</td><td>容器可以使用的最大内核内存，最小值是4m。因为内核内存无法交换出来，一个缺少内核内存的容器可能会阻塞主机资源，这会对主机和其他容器产生副作用</td></tr><tr><td>–oom-kill-disable</td><td>默认情况下，如果发生内存不足(OOM)错误，内核会杀死容器中的进程。我们可以使用–oom-kill-disable选项来改变设置，如果你设置了-m/–memory选项，那么容器会一直耗尽到-m限制的内存大小。而如果你没有设定-m，主机会尽可能的耗尽内存，内核可能需要杀死主机系统的进程以释放内存。</td></tr></tbody></table><h3 id="–memory-swap-details"><a href="#–memory-swap-details" class="headerlink" title="–memory-swap details"></a>–memory-swap details</h3><ul><li>如果没有设置–memory-swap，而设置了–memory，容器能够使用–memory值的两倍的swap。例如：–memory=300m,–memory-swap没有设置，那么容器能够使用300m内存和600m swap。</li><li>如果–memory和–memory-swap都设置了，–memory-swap表示能够使用内存和swap的总数，–memory控制非swap的内存大小。例如：–memory=300m,–memory-swap=1g，那么容器能够使用300m内存和700m的swap。</li><li>如果设置为-1(默认)，表示容器可以无限使用swap</li></ul><h3 id="–memory-swappiness-details"><a href="#–memory-swappiness-details" class="headerlink" title="–memory-swappiness details"></a>–memory-swappiness details</h3><ul><li>如果值为0，关闭匿名页面交换</li><li>值100，将所有匿名页面设置为可交换</li><li>默认情况下，如果不设置<code>--memory-swappiness</code>，容器将继承主机计算机的值</li></ul><h3 id="–kernel-memory-details"><a href="#–kernel-memory-details" class="headerlink" title="–kernel-memory details"></a>–kernel-memory details</h3><p>内核内存限制以分配给容器的总内存来表示，有以下几种场景：</p><ul><li>没有限制–memory，没有限制–kernel-memory： 这是默认值</li><li>没有限制–memory，有限制–kernel-memory: 当所有的cgroups所需的内存量超过主机实际拥有的内存量时，适合设置为这样子。你可以设置内核内存不超过主机可用内存，容器需要更多内存只能等待了。</li><li>有限制–memory，没有限制–kernel-memory：总内存是限制的，不过内核内存无限制</li><li>有限制–memory，有限制–kernel-memory：用户和内核限制都限制时，对调试内存相关问题会有帮助。如果一个容器用完了这两种内存之中的一种，它不会影响到其他的容器和主机。如果内核内存限制比用户内存低，使用完内核内存后，会导致容器长生OOM错误，反之，则不会。</li></ul><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>默认情况下，所有容器获得CPU周期的比例相同，你可以通过下面的选项来对容器的CPU使用进行调整。</p><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>–cpu-shares</td><td>设置权重，修改默认的1024增大或者减小。当其他容器有空闲CPU时，其他容器可使用空闲CPU时间</td></tr><tr><td>–cpu-period</td><td>容器的一个逻辑CPU的调度周期。默认值是100000（100ms），当然我们也可以自己设置CPU周期，限制容器CPU用量，通常和<code>--cpu-quota</code>参数使用</td></tr><tr><td>–cpu-quota</td><td>在由<code>--cpu-period</code>设置的时间段内，容器可以调度的最大CPU使用量，默认是0，以为着允许容器获得1个CPU的100%的资源量。设置50000限制CPU资源的50%</td></tr><tr><td>–cpuset-cpus</td><td>定容器允许运行的CPU号(在多核心系统中)</td></tr></tbody></table><h2 id="Block-IO"><a href="#Block-IO" class="headerlink" title="Block IO"></a>Block IO</h2><p>有两个选项可用于调整容器对直连块IO设备的访问。你还可以按照每秒字节数或每秒IO操作来指定带宽限制。</p><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>blkio-weight</td><td>默认情况下，每个容器可以使用相同比例的IO带宽。默认权重是500，要提高或者降低，可以设置–blkio-weight来设置介于10-1000之间的值，此设置会平等的影响到所有块IO设备</td></tr><tr><td>blkio-weight-device</td><td>与<code>--blkio-weight</code>相同，但你可以使用<code>--blkio-weight-device=DEVICE_NAME:WEGITH</code>为每个设备设置权重。</td></tr><tr><td>–device-read-bps和–device-write-bps</td><td>根据大小限制设备读取或写入的速率，使用kb，mb或gb后缀</td></tr><tr><td>–device-read-iops和–device-write-iops</td><td>通过IO操作/秒限制设备读取或写入的速率</td></tr></tbody></table>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker资源限制 </tag>
            
            <tag> Docker limit </tag>
            
            <tag> Memory limit </tag>
            
            <tag> CPU limit </tag>
            
            <tag> IO limit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-当docker daemon停止时依然保持容器运行</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-%E5%BD%93docker-daemon%E5%81%9C%E6%AD%A2%E6%97%B6%E4%BE%9D%E7%84%B6%E4%BF%9D%E6%8C%81%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-%E5%BD%93docker-daemon%E5%81%9C%E6%AD%A2%E6%97%B6%E4%BE%9D%E7%84%B6%E4%BF%9D%E6%8C%81%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C/</url>
      <content type="html"><![CDATA[<p>默认情况下，当docker daemon停止，它会关闭所有正在运行的容器。从docker1.12起，你可以配置当docker daemon不可用时依然保持容器继续运行。<code>live restore</code>选项有助于减少由于docker daemon崩溃，中断或升级而导致的容器停机时间。</p><blockquote><p>Note: live restore不支持windows容器，但是它支持运行在windows上的linux容器。</p></blockquote><h2 id="开启live-restore选项"><a href="#开启live-restore选项" class="headerlink" title="开启live restore选项"></a>开启live restore选项</h2><p>有两种方式开启<code>live restore</code>:</p><ul><li>如果<code>docker daemon</code>正在运行并且你不想停止它，你可以添加配置到<code>docker daemon</code>的配置文件。例如：在linux系统上默认的配置文件是<code>/etc/docker/daemon.json</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;live-restore&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>你必须传递一个<code>SIGHUP</code>信号给daemon进程来重载配置。更多有关使用config.json来配置docker daemon的信息，可以参考<a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file" target="_blank" rel="noopener">daemon configuration file</a></p><ul><li>在使用dockerd启动时指定<code>--live-restore</code>选项<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dockerd --live-restore</span><br></pre></td></tr></table></figure></li></ul><h2 id="升级docker-daemon-时的Live-restore"><a href="#升级docker-daemon-时的Live-restore" class="headerlink" title="升级docker daemon 时的Live restore"></a>升级docker daemon 时的Live restore</h2><p><code>live restore</code>支持当升级<code>docker daemon</code>后，还原容器到docker</p><h2 id="重启时的live-restore"><a href="#重启时的live-restore" class="headerlink" title="重启时的live restore"></a>重启时的live restore</h2><p>live restore只支持还原到和原docker daemon一样的docker daemon。比如：如果新的docker daemon使用不同的网桥IP重新启动，则live restore不起作用。</p><h2 id="live-restore-对正在运行的容器的影响"><a href="#live-restore-对正在运行的容器的影响" class="headerlink" title="live restore 对正在运行的容器的影响"></a>live restore 对正在运行的容器的影响</h2><p>长时间缺少docker daemon可能会影响正在运行的容器。容器写入FIFO日志在daemon消耗时。如果daemon不能用于输出，缓冲区将填满并阻止对日志的进一步写入，因为阻塞该进程直到有更多的可用空间，默认缓冲区大小通常为64K。 你必须重启docker来刷新buffers 你可以修改<code>/proc/sys/fs/pipe-max-size</code>来修改内核buffer 大小</p><h2 id="live-restore-和-swarm-模式"><a href="#live-restore-和-swarm-模式" class="headerlink" title="live restore 和 swarm 模式"></a>live restore 和 swarm 模式</h2><p>live restore 和docker swarm模式不兼容。当docker 运行在swarm模式下时，是由编排功能来管理任务并使容器根据服务规范运行的。</p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> live restore配置 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-docker 环境变量在compose文件中的使用</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%9C%A8compose%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%9C%A8compose%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="在compose文件中引用环境变量"><a href="#在compose文件中引用环境变量" class="headerlink" title="在compose文件中引用环境变量"></a>在compose文件中引用环境变量</h2><p>可以在compose文件中引用运行<code>docker-compose</code>所在的shell中的环境变量，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">web:</span><br><span class="line">  image: &quot;webapp:$&#123;TAG&#125;&quot;</span><br></pre></td></tr></table></figure></p><h2 id="在容器中设置环境变量"><a href="#在容器中设置环境变量" class="headerlink" title="在容器中设置环境变量"></a>在容器中设置环境变量</h2><p>可以在compose文件中的<code>environment</code>关键字下设置容器的环境变量，就像使用<code>docker run -e VARIABLE=VALUE</code>一样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">web:</span><br><span class="line">  environment:</span><br><span class="line">    - DEBUG=1</span><br></pre></td></tr></table></figure></p><h2 id="将环境变量传递到容器"><a href="#将环境变量传递到容器" class="headerlink" title="将环境变量传递到容器"></a>将环境变量传递到容器</h2><p>可以在compose文件中的<code>environment</code>关键字下定义一个环境变量而不是直接赋值，就像是<code>docker run -e VARIABLE</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">web:</span><br><span class="line">  environment:</span><br><span class="line">    - DEBUG</span><br></pre></td></tr></table></figure></p><h2 id="env-file配置选项"><a href="#env-file配置选项" class="headerlink" title="env_file配置选项"></a>env_file配置选项</h2><p>可以使用compose文件中的<code>env_file</code>选项从一个外部文件传递多个环境变量到容器中，就像<code>docker run --env-file=FILE</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">web:</span><br><span class="line">  env_file:</span><br><span class="line">    - web-variables.env</span><br></pre></td></tr></table></figure><p>使用<code>docker-compose run</code>设置环境变量<br>就像<code>docker run -e</code>,可以使用<code>docker-compose run -e</code>为一次性容器设置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose run -e DEBUG=1 web python console.py</span><br></pre></td></tr></table></figure><p>也可以不赋值，直接从shell变量中取值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose run -e DEBUG web python console.py</span><br></pre></td></tr></table></figure></p><p>DEBUG的值是从执行compose文件所在的shell的同一个环境变量取得。</p><h2 id="env文件"><a href="#env文件" class="headerlink" title=".env文件"></a>.env文件</h2><p>可以在环境文件<code>.env</code>设置默认的环境变量，这些环境变量可以在compose文件中调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cat .env</span><br><span class="line">TAG=v1.5</span><br><span class="line"></span><br><span class="line">$ cat docker-compose.yml</span><br><span class="line">version: &apos;2.0&apos;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: &quot;webapp:$&#123;TAG&#125;&quot;</span><br></pre></td></tr></table></figure></p><p>当执行<code>docker-compose up</code>命令时，上面定义的web服务将使用<code>webapp:v1.5</code>镜像，可以使用config命令来打印出来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose config</span><br><span class="line">version: &apos;2.0&apos;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: &apos;webapp:v1.5&apos;</span><br></pre></td></tr></table></figure><p>在shell中的环境变量将比定义在<code>.env</code>文件中的环境变量优先。如果在shell中设置一个不同的TAG，镜像将优先使用shell中的定义，而不是.evn文件中的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ export TAG=v2.0</span><br><span class="line">$ docker-compose config</span><br><span class="line">version: &apos;2.0&apos;</span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: &apos;webapp:v2.0&apos;</span><br></pre></td></tr></table></figure><h2 id="使用环境变量来配置compose"><a href="#使用环境变量来配置compose" class="headerlink" title="使用环境变量来配置compose"></a>使用环境变量来配置compose</h2><p>某些环境变量可用来配置以改变<code>docker compose</code>的命令行特性，以<code>COMPOSE_</code>或<code>DOCKER_</code>开头，详细信息参考<a href="https://docs.docker.com/compose/reference/envvars/" target="_blank" rel="noopener">CLI Environment Variables</a></p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> compose的环境变量 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-docker在各个平台的基本配置</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker%E5%9C%A8%E5%90%84%E4%B8%AA%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker%E5%9C%A8%E5%90%84%E4%B8%AA%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>在安装完<code>docker</code>之后，<code>docker daemon</code>会用默认的配置来运行。</p><p>在生产环境中，系统管理员通常会根据需求来配置<code>docker</code>，在大多数例子中，系统管理员配置会配置进程管理器，如：<code>sysvinit</code>,<code>upstart</code>或<code>systemd</code>来管理<code>docker</code>的启动和停止。</p><h2 id="直接运行docker-daemon"><a href="#直接运行docker-daemon" class="headerlink" title="直接运行docker daemon"></a>直接运行docker daemon</h2><p>我们可以直接用<code>dockerd</code>命令来直接运行<code>docker daemon</code>.默认是监听在<code>unix socket unix:///var/run/docker.sock</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ dockerd</span><br><span class="line"></span><br><span class="line">INFO[0000] +job init_networkdriver()</span><br><span class="line">INFO[0000] +job serveapi(unix:///var/run/docker.sock)</span><br><span class="line">INFO[0000] Listening for HTTP on unix (/var/run/docker.sock)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="直接配置docker-daemon"><a href="#直接配置docker-daemon" class="headerlink" title="直接配置docker daemon"></a>直接配置docker daemon</h2><p>如果你是直接运行<code>dockerd</code>命令，而非使用进程管理器(<code>systemctl start docker</code>)，你可以直接将配置选项附加到<code>docker run</code>命令。其他配置选项可传递给<code>docker daemon</code>来配置 配置选项如下：</p><p><code>| Flag | Description | | :—- | :——— | | -D,–debug=false |</code> 开启或关闭debug模式，默认是关闭的 <code>| | -H,–host=[] | Daemon socket[s]</code>连接到哪 <code>| | –tls=false |</code>开启或关闭TLS，默认是关闭的 | 这里有一个使用配置选项运行<code>docker daemon</code>的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ dockerd -D \</span><br><span class="line">--tls=true \</span><br><span class="line">--tlscert=/var/docker/server.pem \</span><br><span class="line">--tlskey=/var/docker/serverkey.pem \</span><br><span class="line">-H tcp://192.168.59.3:2376</span><br></pre></td></tr></table></figure><p>这些选项是：</p><ul><li>开启<code>debug</code>模式 -D</li><li>开启<code>tls</code>并指定证书 <code>--tlscert</code>和<code>--tlskey</code></li><li>监听连接<code>tcp://192.168.59.3:2376</code></li></ul><p>命令行可参考<a href="https://docs.docker.com/engine/reference/commandline/dockerd/" target="_blank" rel="noopener">complete list of daemon flags</a></p><h2 id="Daemon-debugging"><a href="#Daemon-debugging" class="headerlink" title="Daemon debugging"></a>Daemon debugging</h2><p>如上所诉，开启debug模式来允许管理员或操作者来获取docker daemon运行时的信息。如果面对一个没有响应的daemon，管理员可以通过向Docker daemon发送<code>SIGUSR1</code>信号来强制所有线程的完整堆栈跟踪添加到daemon的日志中。在linux上通常使用kill命令。例：<code>kill -USR1 &lt;daemon-pid&gt;</code>发送<code>SIGUSR1</code>到daemon，这会导致堆栈被添加到daemon日志中。</p><blockquote><p>Note: 日志级别至少是info及以上，默认日志界别是info</p></blockquote><p>在处理<code>SIGUSR1</code>信号并将堆栈跟踪转存到日志后，daemon将继续运行，堆栈跟踪可用于确定daemon所有线程和goroutines的状态</p><h2 id="在centos上配置docker"><a href="#在centos上配置docker" class="headerlink" title="在centos上配置docker"></a>在centos上配置docker</h2><p>在CENTOS 6.X和RHEL 6.X中，我们在<code>/etc/sysconfig/docker</code>文件中配置docker daemon，我们可以通过指定<code>other_args</code>变量来实现。短时间内，在Centos7.x 和RHEL 7.x我们使用<code>OPTIONS</code>变量值，不再推荐直接使用systemd。</p><p>1.登录到你的系统，使用<code>root</code>账户，或者使用<code>sudo</code></p><p>2.创建<code>/etc/systemd/system/docker.service.d</code>目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure><p>3.创建<code>/etc/systemd/system/docker.service.d/docker.conf</code>文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir /etc/systemd/system/docker.service.d/docker.conf</span><br></pre></td></tr></table></figure></p><p>4.打开这个docker.conf文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vi /etc/systemd/system/docker.service.d/docker.conf</span><br></pre></td></tr></table></figure></p><p>5.覆盖从<code>docker.service</code>文件复制过来的<code>ExecStart</code>，用以自定义<code>docker daemon</code>。要修改<code>ExecStart</code>配置，必须先指定一个空配置，然后再定义一个新配置，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/dockerd -H fd:// -D --tls=true --tlscert=/var/docker/server.pem --tlskey=/var/docker/serverkey.pem -H tcp://192.168.59.3:2376</span><br></pre></td></tr></table></figure><p>6.保存关闭文件 </p><p>7.重新载入改变<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure></p><p>8.重启docker daemon<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure></p><p>9.检查docker daemon是否运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps aux | grep docker | grep -v grep</span><br></pre></td></tr></table></figure></p><h2 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h2><p>docker 在centos7.x上是将日志保存在<code>/var/log/messages</code> 中的，我们也可以使用<code>journalctl -u docker</code>来查看docker的日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@xym ~]# journalctl -u docker</span><br><span class="line">-- Logs begin at Wed 2018-04-18 13:46:33 CST, end at Thu 2018-04-26 15:01:01 CST. --</span><br><span class="line">Apr 18 13:46:43 xym systemd[1]: Starting Docker Application Container Engine...</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44.353903498+08:00&quot; level=info msg=&quot;libcontainerd: started new docker-containerd process&quot; pid=1364</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=info msg=&quot;starting containerd&quot; module=containerd revision=89623f28b87a6004d4b785663257362d1658a729 version=v1.0.0</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=info msg=&quot;setting subreaper...&quot; module=containerd</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=info msg=&quot;changing OOM score to -500&quot; module=containerd</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=info msg=&quot;loading plugin &quot;io.containerd.content.v1.content&quot;...&quot; module=containerd type=io.containerd.content.v1</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=info msg=&quot;loading plugin &quot;io.containerd.snapshotter.v1.btrfs&quot;...&quot; module=containerd type=io.containerd.snapshotter.</span><br><span class="line">Apr 18 13:46:44 xym dockerd[1279]: time=&quot;2018-04-18T13:46:44+08:00&quot; level=warning msg=&quot;failed to load plugin io.containerd.snapshotter.v1.btrfs&quot; error=&quot;path /var/lib/docker/containerd/daemo</span><br><span class="line">Apr 18 1</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker daemon配置 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker基础-docker常用命令</title>
      <link href="/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2018/04/26/Docker%E5%9F%BA%E7%A1%80-docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h2 id="Docker-Command"><a href="#Docker-Command" class="headerlink" title="Docker Command"></a>Docker Command</h2><p>介绍一些docker常用的命令</p><h3 id="Docker-container-management"><a href="#Docker-container-management" class="headerlink" title="Docker container management"></a>Docker container management</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#运行容器</span><br><span class="line">docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br><span class="line">  -t 分配一个terminal窗口</span><br><span class="line">  -i 允许和容器进行交互</span><br><span class="line">  -d 后台运行一个容器</span><br><span class="line">  -P 将容器内部的所有exposed的端口映射为宿主机上的随意端口</span><br><span class="line">  -p 将容器内部的端口绑定到宿主机上指定的端口</span><br><span class="line">     后面跟&lt;port&gt; ：表示将容器内部的这个端口隐射到宿主机上的随意端口</span><br><span class="line">     后面跟&lt;port1&gt;:&lt;port2&gt; ：表示将&lt;port2容器内部端口&gt;隐射到&lt;port1宿主机端口&gt;</span><br><span class="line">  --name 为容器命名</span><br><span class="line">  --net 为容器指定网络</span><br><span class="line">  -v 为容器挂载卷组</span><br><span class="line">  --volume-driver 指定容器卷组的驱动</span><br><span class="line"></span><br><span class="line">$ docker run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py</span><br><span class="line">$ docker run -d -P --name web training/webapp python app.py</span><br><span class="line">$ docker run -d -p 80:5000 trainning/webapp python app.py</span><br><span class="line">$ docker run ubuntu /bin/echo &quot;Hello world&quot;</span><br><span class="line">$ docker run -ti ubuntu /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#启动容器，可同时启动多个容器</span><br><span class="line">docker start [OPTIONS] CONTAINER [CONTAINER...]</span><br><span class="line"></span><br><span class="line">$ docker start 215b04f73370</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#停止容器运行，可同时停止多个容器</span><br><span class="line">docker stop [OPTIONS] CONTAINER [CONTAINER...]</span><br><span class="line"></span><br><span class="line">$ docker stop 215b04f73370</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#重启重启，可同时重启多个容器</span><br><span class="line">docker restart [OPTIONS] CONTAINER [CONTAINER...]</span><br><span class="line"></span><br><span class="line">$ docker restart 215b04f73370</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#删除容器</span><br><span class="line">docker rm [OPTIONS] CONTAINER [CONTAINER...]</span><br><span class="line">  -f 强制删除一个正在运行的容器(实际上是先停止容器，然后再删除容器)</span><br><span class="line">  -v 删除和容器关联的卷</span><br><span class="line"></span><br><span class="line">$ docker rm -f 215b04f73370</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#列出容器清单</span><br><span class="line">docker ps [OPTIONS]</span><br><span class="line">  -a 列出所有容器,包括已经停止的容器</span><br><span class="line">  -q 值显示容器ID</span><br><span class="line">  -l 列出最近创建的容器</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#连接到一个正在运行的容器</span><br><span class="line">docker attach [OPTIONS] [CONTAINER]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#在一个已经运行的容器里运行命令</span><br><span class="line">docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br><span class="line"></span><br><span class="line">$ docker exec -ti db1 /bin/bash</span><br></pre></td></tr></table></figure><h3 id="Docker-container-state-management"><a href="#Docker-container-state-management" class="headerlink" title="Docker container state management"></a>Docker container state management</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#查看容器内部日志</span><br><span class="line">docker logs [OPTIONS] CONTAINER</span><br><span class="line">  -f 容器日志追踪</span><br><span class="line"></span><br><span class="line">$ docker logs grave_roentgen</span><br><span class="line">$ docker logs 20348fdf82e4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#查看容器内部运行的进程</span><br><span class="line">docker top CONTAINER</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#获取容器、images、task的配置信息和状态信息</span><br><span class="line">docker inspect [OPTIONS] CONTAINER|IMAGE|TASK [CONTAINER|IMAGE|TASK...]</span><br><span class="line">  -f 按照给定的模板来输出结果</span><br><span class="line"></span><br><span class="line">$ docker inspect -f &apos;&#123; &#123; range .NetworkSettings.Networks &#125; &#125;&#123; &#123; .IPAddress &#125; &#125;&#123; &#123; end &#125; &#125;&apos; romantic_mahavira</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看容器内公开端口隐射在宿主机上的端口</span><br><span class="line">docker port CONTAINER [PRIVATE_PORT[/PROTO]]</span><br><span class="line"></span><br><span class="line">$ docker port 215b04f73370</span><br></pre></td></tr></table></figure><h3 id="Docker-images-management"><a href="#Docker-images-management" class="headerlink" title="Docker images management"></a>Docker images management</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#列出image清单</span><br><span class="line">docker images [OPTIONS] [REPOSITORY[:TAG]]</span><br><span class="line">  -a 显示所有image</span><br><span class="line">  -q 只显示image ID</span><br><span class="line">  --digests 显示摘要信息</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#拉取image镜像</span><br><span class="line">docker pull [OPTIONS] IMAGENAME[:TAG|@DIGEST]</span><br><span class="line">  -a 将所有tag image下载下来</span><br><span class="line">  --disable-content-trust=true 取消检查image</span><br><span class="line"></span><br><span class="line">$ docker pull chinakevinguo/docker-whale:latest</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查找images</span><br><span class="line">docker search [OPTIONS] image</span><br><span class="line"></span><br><span class="line">$ docker search sinatra</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#登录到docke服务器</span><br><span class="line">docker login [OPTIONS] [SERVER]</span><br><span class="line">  -u 用户名</span><br><span class="line">  -p 密码</span><br><span class="line"></span><br><span class="line">$ docker login</span><br><span class="line">Username: chinakevinguo</span><br><span class="line">Password:</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#将经过修改的容器构建成新的镜像，一般不推荐这种用法</span><br><span class="line">docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</span><br><span class="line">  -a 作者</span><br><span class="line">  -m 描述</span><br><span class="line"></span><br><span class="line">$ docker commit -m &quot;Added json gem&quot; -a &quot;Kevin Guo&quot; goofy_bohr chinakevinguo/sinatra:v2</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#通过dockerfile构建镜像</span><br><span class="line">docker build [OPTIONS] PATH | URL</span><br><span class="line">  -t 指定image的REPOSITORY，可以指定多个REPOSITORY</span><br><span class="line">  -f 指定你的dockerfile的名称路径（默认是$PATH/Dockerfile）</span><br><span class="line"></span><br><span class="line">$ docker build -t chinakevinguo/sinatra:v3  ~/sinatra</span><br><span class="line">$ docker build -t chinakevinguo/sinatra:v3 -f ~/sinatra/mydockerfile .</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#为image打tag，也可以算是为images重命名</span><br><span class="line">docker tag IMAGE[:TAG] IMAGE[:TAG]</span><br><span class="line"></span><br><span class="line">$ docker tag chinakevinguo/sinatrasdfa:v3 chinakevinguo/sinatra:v5</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#上传image到dockerHub上</span><br><span class="line">docker push [OPTIONS] NAME[:TAG]</span><br><span class="line"></span><br><span class="line">$ docker push chinakevinguo/docker-whale:latest</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#删除镜像</span><br><span class="line">docker rmi [OPTIONS] IMAGE [IMAGE...]</span><br><span class="line">  -f 强制删除镜像(实际上是先删除了基于该镜像创建的容器之后再删除的该镜像)</span><br><span class="line">$ docker rmi -f web1</span><br></pre></td></tr></table></figure><h3 id="Docker-network-management"><a href="#Docker-network-management" class="headerlink" title="Docker network management"></a>Docker network management</h3><ul><li>host模式：容器和宿主机共享network namespace</li><li>container模式：容器和另外一个容器共享network namespace。kubernetes中的pod就是多容器共享一个network namespace</li><li>none模式：容器有独立的network namespace，但没有对其进行任何的网络配置</li><li>bridge模式：docker默认模式，容器通过一个网桥获取ip，以NAT的方式和外界通信 </li></ul><p><img src="/assets/img/docker-bridge-module.png" alt="docker网络模型"></p><p>总结一下bridge网络就是：docker会在机器上自己维护一个网络，并通过<code>docker0</code>这个虚拟交换机和主机本身的网络连接在一起</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#docker网络管理</span><br><span class="line">docker network COMMAND</span><br><span class="line"></span><br><span class="line">COMMANDS:</span><br><span class="line">  create       创建一个网络</span><br><span class="line">  connect      链接容器到网络</span><br><span class="line">  disconnect   将容器从网络断开</span><br><span class="line">  inspect      显示网络的详细信息</span><br><span class="line">  ls           列出网络</span><br><span class="line">  rm           删除一个或者更多网络</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#创建一个网络</span><br><span class="line">docker network create [OPTIONS] YOURNETWORK</span><br><span class="line">  -d 指定docker使用哪种模式的网络</span><br><span class="line"></span><br><span class="line">$ docker network create -d bridge my-bridge-network</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#将容器从网络断开</span><br><span class="line">docker network disconnect [OPTIONS] NETWORK CONTAINER</span><br><span class="line"></span><br><span class="line">$ docker network disconnect bridge web1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#将容器链接到网络</span><br><span class="line">docker network connect [OPTIONS] NETWORK CONTAINER</span><br><span class="line">  --ip   指定ip地址</span><br><span class="line">  --link 添加连接到其他容器</span><br><span class="line"></span><br><span class="line">$ docker network connect my-bridge-network web1</span><br></pre></td></tr></table></figure><h3 id="Docker-container-volume-management"><a href="#Docker-container-volume-management" class="headerlink" title="Docker container volume management"></a>Docker container volume management</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#docker volume 管理</span><br><span class="line">docker volume COMMAND</span><br><span class="line">  COMMANDS：</span><br><span class="line">    create    创建卷组</span><br><span class="line">    inspect   显示卷组详细信息</span><br><span class="line">    ls        列出卷组</span><br><span class="line">    rm        删除卷组</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#为容器挂载卷组</span><br><span class="line">$ docker run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py</span><br></pre></td></tr></table></figure><p>这个命令是将宿主机上的/src/webapp挂载到容器的/webapp，如果/webapp存在，则/src/webapp会覆盖挂载，但是不会删除以前的内容，取消此次挂载后，以前的内容又可以访问了。 容器内部的目录必须指定绝对路径，而宿主机上的目录即可以是绝对路径，也可以仅仅是一个名字或者什么都不写，如果只是一个名字$NAME，则会默认挂载到<code>/var/lib/docker/volumes/$NAME/_data</code>，如果什么都不写，则会挂载到<code>/var/lib/docker/volumes/</code>下的一个随机生成的字符串下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#不指定名字，默认挂载</span><br><span class="line">$ docker run -d -P --name web -v /webapp training/webapp python app.py</span><br><span class="line"></span><br><span class="line">$ docker inspect web</span><br><span class="line">&quot;Name&quot;: &quot;fac362...80535&quot;,</span><br><span class="line">&quot;Source&quot;: &quot;/var/lib/docker/volumes/fac362...80535/_data&quot;,</span><br><span class="line">&quot;Destination&quot;: &quot;/webapp&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#仅仅指定名字</span><br><span class="line">$ docker run -d -P --name web -v webapp:/webapp training/webapp python app.py</span><br><span class="line"></span><br><span class="line">$ docker inspect web</span><br><span class="line">&quot;Name&quot;: &quot;webapp&quot;,</span><br><span class="line">&quot;Source&quot;: &quot;/var/lib/docker/volumes/webapp/_data&quot;,</span><br><span class="line">&quot;Destination&quot;: &quot;/webapp&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#指定绝对路径</span><br><span class="line">$ docker run -d -P --name web -v /src/webapp:/webapp training/webapp python app.py</span><br><span class="line"></span><br><span class="line">$ docker inspect web</span><br><span class="line">&quot;Source&quot;: &quot;/src/webapp&quot;,</span><br><span class="line">&quot;Destination&quot;: &quot;/webapp&quot;,</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#挂载共享卷组作为数据卷</span><br><span class="line">$ docker run -d -P --volume-driver=flocker -v my-named-volume:/webapp --name web training/webapp python app.py</span><br><span class="line"></span><br><span class="line">#先创建共享卷组，然后再进行挂载</span><br><span class="line">$ docker volume create -d flocker -o size-20GB my-named-volume</span><br><span class="line">$ docker run -d -P -v my-named-volume:/webapp --name web training/webapp python app.py</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#将容器作为卷组挂载进容器</span><br><span class="line"></span><br><span class="line">#创建一个卷组容器</span><br><span class="line">$ docker create -v /dbdata --name dbstore training/postgres /bin/true</span><br><span class="line"></span><br><span class="line">#使用--volumes-from 将dbdata挂载进其他容器</span><br><span class="line">$ docker run -d --volumes-from dbstore --name db1 training/postgres</span><br><span class="line">$ docker run -d --volumes-from dbstore --name db2 training/postgres</span><br></pre></td></tr></table></figure><h3 id="Backup，restore，migrate-data-volumes"><a href="#Backup，restore，migrate-data-volumes" class="headerlink" title="Backup，restore，migrate data volumes"></a>Backup，restore，migrate data volumes</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#将卷组容器挂载到对应的容器之后，进行卷组数据备份</span><br><span class="line">$ docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#数据恢复</span><br><span class="line">$ docker run -v /dbdata --name dbstore2 ubuntu /bin/bash</span><br><span class="line">$ docker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c &quot;cd /dbdata &amp;&amp; tar xvf /backup/backup.tar --strip 1&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#在使用--rm的时候，会删除匿名卷组，而不会删除定义好的命名卷组</span><br><span class="line">$ docker run --rm -v /foo -v awesome:/bar busybox top</span><br></pre></td></tr></table></figure><p><strong>所谓匿名卷组：即那些指定了路径和那些没有指定命名的挂载项目</strong></p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker容器管理 </tag>
            
            <tag> docker容器状态 </tag>
            
            <tag> docker镜像管理 </tag>
            
            <tag> docker网络管理 </tag>
            
            <tag> docker容器卷管理 </tag>
            
            <tag> docker数据备份及恢复 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用 Docker 安装 Jenkins</title>
      <link href="/2018/04/25/%E4%BD%BF%E7%94%A8-Docker-%E5%AE%89%E8%A3%85-Jenkins/"/>
      <url>/2018/04/25/%E4%BD%BF%E7%94%A8-Docker-%E5%AE%89%E8%A3%85-Jenkins/</url>
      <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>jenkins是一个用Java编写的开源自动化服务器,它是Hudson的一个分支project ; 它是一个持续集成软件(continuous integration),它以节点为单位,连接整个工作流, 通过各种类型插件支持构成具有个性化要求的项目持续集成, 通过各种各样的插件(plugin)来实现各个节点的功能, 它们共同完成持续集成(自动部署)/自动测试或者持续交付等工作.</p></blockquote><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>1、直接从 DockerHub 上pull 镜像：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull jenkins</span><br></pre></td></tr></table></figure></p><p>2、由于 Jenkins 容器运行后，会自动在宿主计算机中挂在一个数据卷 <code>var/jenkins_home</code>，我们在主机中可以新建一个数据卷的文件夹，这里注意的是，有权限问题，不然会启动失败，有点坑这里，卡了半天，给宿主的这个挂载卷目录中加上下面的权限的就好了，改成为uid 1000的用户，具体参考阿里云<a href="https://yq.aliyun.com/articles/53990" target="_blank" rel="noopener">谈谈 Docker Volume 之权限管理（一）</a>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R 1000 /var/jenkins_home</span><br></pre></td></tr></table></figure></p><p>3、启动容器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 7322:8080 -p 50000:50000 -v /var/jenkins_home/:/var/jenkins_home/  --name my_jenkins -d jenkins</span><br></pre></td></tr></table></figure></p><ul><li>8080 端口是访问 jenkins 网页的端口，如果你想在 80 端口访问，就改成 -p 80:8080</li><li>50000 端口与 slave 有关，主要作为master的jenkins用来连接slave的。</li></ul><p>可以更改挂载卷的目录，不过记得也要设置目录权限的问题。</p><p>使用 <code>docker ps</code> 查看运行的容器。</p><h2 id="配置和使用"><a href="#配置和使用" class="headerlink" title="配置和使用"></a>配置和使用</h2><p>1、使用 host + port 访问 jenkins，会进入第一个页面：</p><p><img src="http://op7wplti1.bkt.clouddn.com/install_Jenkins.png" alt="Jenkins安装"></p><p>因为我们将目录<code>/var/jenkins_home</code>已经挂载在宿主主机，可以直接去这个目录查看密码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> cat /var/jenkins_home/secrets/initialAdminPassword</span><br><span class="line">c49d4a7883e1410685c45092a6fabeac</span><br></pre></td></tr></table></figure></p><p>2、进入后就开始安装插件的过程，然后等待安装完成。</p><p>3、然后跳出一个页面设置账号和密码，这样就安装完成，后面学习使用 jenkins 运用到工作中。</p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker安装Jenkins </tag>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>为Docker镜像添加SSH服务</title>
      <link href="/2018/04/20/%E4%B8%BADocker%E9%95%9C%E5%83%8F%E6%B7%BB%E5%8A%A0SSH%E6%9C%8D%E5%8A%A1/"/>
      <url>/2018/04/20/%E4%B8%BADocker%E9%95%9C%E5%83%8F%E6%B7%BB%E5%8A%A0SSH%E6%9C%8D%E5%8A%A1/</url>
      <content type="html"><![CDATA[<p>一些进入容器的办法，比如<code>attach</code>、<code>exec</code>等命令，都无法解决远程管理容器的问题。因此，当我们需要远程登录到容器内进行一些操作的时候，就需要<code>SSH</code>的支持了。</p><p>有两种创建带有SSH服务的镜像：基于<code>Docker commit</code>命令创建和基于<code>Dockerfile</code>创建。</p><h2 id="基于commit命令创建"><a href="#基于commit命令创建" class="headerlink" title="基于commit命令创建"></a>基于commit命令创建</h2><p>Docker提供了<code>docker commit</code>命令，支持用户提交自己对制定容器的修改，并生产新的镜像。<br>命令格式：<code>docker commit CONTAINER[REPOSITORY:[:TAG]]</code></p><h3 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h3><p>首先，使用<code>ubuntu:14.04</code>镜像来创建容器：<br><code>docker run -it ubuntu:14.04 /bin/bash</code><br>更新<code>apt</code>缓存，并安装<code>openssh-server</code><br><code>apt-get update;apt-get install -y openssh-server</code></p><h3 id="2、安装和配置SSH服务"><a href="#2、安装和配置SSH服务" class="headerlink" title="2、安装和配置SSH服务"></a>2、安装和配置SSH服务</h3><p>如果需要正常启动SSH服务，则目录<code>/var/run/sshd</code>必须存在，手动创建它，并启动SSH服务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/run/sshd</span><br><span class="line">/usr/sbin/sshd -D &amp;</span><br></pre></td></tr></table></figure></p><p>此时查看容器的22端口（ssh服务默认监听端口），可见此端口已经处于监听状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">netstat -tlnp</span><br><span class="line">//修改SSH服务的安全登录配置，取消pam登录限制</span><br><span class="line">sed -ri &apos;s/session required pam_loginuid.so/#session required pam_loginuid.so/g` /etc/pam.d/sshd</span><br></pre></td></tr></table></figure></p><p>在root用户目录下创建<code>.ssh</code>目录，并复制需要登录的公钥信息（一般为本地主机目录下的<code>.ssh/id_rsa.pub</code>文件，可由<code>ssh-keygen -t rsa</code>命令生成）到<code>authorized_keys</code>文件中。</p><p>创建自动启动SSH服务的可执行文件<code>run.sh</code>。并添加可执行权限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /run.sh</span><br><span class="line">chmod +x run.sh</span><br></pre></td></tr></table></figure></p><p>其中，<code>run.sh</code>脚本内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">/usr/sbin/sshd -D</span><br></pre></td></tr></table></figure></p><p>最后，退出容器执行，<code>exit</code>命令。</p><h3 id="3、保存镜像"><a href="#3、保存镜像" class="headerlink" title="3、保存镜像"></a>3、保存镜像</h3><p><code>docker commit [OPTIONS]  CONTAINER [REPOSITORY[:TAG]]</code></p><h3 id="4、使用镜像"><a href="#4、使用镜像" class="headerlink" title="4、使用镜像"></a>4、使用镜像</h3><p>启动容器，并添加端口映射<code>10022--&gt;22</code>。其中10022是宿主主机的端口，22是容器的SSH服务端口：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//启动容器</span><br><span class="line">docker run -p 10022:22 -d sshd:ubuntu /run.sh </span><br><span class="line">//查看运行进程</span><br><span class="line">docker ps</span><br></pre></td></tr></table></figure></p><p>在宿主主机（<code>192.168.1.200</code>）或其他主机上，可以通过<code>SSH</code>访问10022端口来登录容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh 192.168.1.200 -p 10022</span><br></pre></td></tr></table></figure></p><h2 id="使用Dockerfile创建"><a href="#使用Dockerfile创建" class="headerlink" title="使用Dockerfile创建"></a>使用Dockerfile创建</h2><h3 id="1、创建工作目录"><a href="#1、创建工作目录" class="headerlink" title="1、创建工作目录"></a>1、创建工作目录</h3><p>创建一个<code>ssh_ubuntu</code>目录,<code>mkdir ssh_ubuntu</code>,并在其中创建<code>Dockerfile</code>和<code>run.sh</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch Dockerfile run.sh</span><br></pre></td></tr></table></figure></p><h3 id="2、编写run-sh脚本和authorized-keys文件"><a href="#2、编写run-sh脚本和authorized-keys文件" class="headerlink" title="2、编写run.sh脚本和authorized_keys文件"></a>2、编写<code>run.sh</code>脚本和<code>authorized_keys</code>文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">/usr/sbin/sshd -D</span><br></pre></td></tr></table></figure><p>在宿主主机上生成SSH秘钥对，并创建<code>authorized_keys</code>文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt; authorized_keys</span><br></pre></td></tr></table></figure></p><h3 id="3、编写Dockerfile"><a href="#3、编写Dockerfile" class="headerlink" title="3、编写Dockerfile"></a>3、编写Dockerfile</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#设置基础镜像</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line">#提供作者信息</span><br><span class="line">LABEL author=&quot;xym&quot; author_email=&quot;xym@126.com&quot;</span><br><span class="line">#更新命令</span><br><span class="line">RUN apt-get update</span><br><span class="line">#安装SSH服务</span><br><span class="line">RUN apt-get install -y openssh-server</span><br><span class="line">RUN mkdir -p /var/run/sshd</span><br><span class="line">RUN mkdir -p /root/.ssh</span><br><span class="line">#取消pam限制</span><br><span class="line">RUN sed -ri &apos;s/session required pam_loginuid.so/#session required pam_loginuid.so/g&apos; /etc/pam.d/sshd </span><br><span class="line">#复制配置文件到相应位置，并赋予脚本可执行权限</span><br><span class="line">ADD authorized_keys /root/.ssh/authorized_keys</span><br><span class="line">ADD run.sh /run.sh</span><br><span class="line">RUN chmod 755 run.sh</span><br><span class="line">#开放端口</span><br><span class="line">EXPOSE 22</span><br><span class="line">#设置自启动命令</span><br><span class="line">CMD [&quot;/run.sh&quot;]</span><br></pre></td></tr></table></figure><h3 id="4、创建镜像xd"><a href="#4、创建镜像xd" class="headerlink" title="4、创建镜像xd"></a>4、创建镜像xd</h3><p>在ssh_ubuntu目录下，使用<code>docker build</code>命令来创建镜像，这里注意还有一个”.”，表示使用当前目录中的<code>Dockerfile</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ssh_ubuntu</span><br><span class="line">docker build -t sshd:Dockerfile .</span><br></pre></td></tr></table></figure></p><h3 id="5、测试镜像，运行容器"><a href="#5、测试镜像，运行容器" class="headerlink" title="5、测试镜像，运行容器"></a>5、测试镜像，运行容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//启动镜像，映射容器22端口到本地的10122端口</span><br><span class="line">docker run -d -p 10122:22 sshd:Dockerfile</span><br><span class="line">//在宿主主机新打开一个终端，连接到新建的容器</span><br><span class="line">ssh 192.168.1.200 -p 10122</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dockerfile创建SSH服务 </tag>
            
            <tag> Commit容器创建SSH服务 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用Dockerfile创建镜像</title>
      <link href="/2018/04/20/%E4%BD%BF%E7%94%A8Dockerfile%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F/"/>
      <url>/2018/04/20/%E4%BD%BF%E7%94%A8Dockerfile%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F/</url>
      <content type="html"><![CDATA[<p><code>Dockerfile</code>是一个文本格式的配置文件，用户可以使用<code>Dockerfile</code>来快速创建自定义的镜像。</p><h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><p><code>Dockerfile</code>由一行行命令语句组成，并且支持以<code>#</code>开头的注释行。<br>一般而言，<code>Dockerfile</code>分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#一个nginx dockerfile例子</span><br><span class="line">#基础镜像</span><br><span class="line">FROM ubuntu</span><br><span class="line">#维护者信息</span><br><span class="line">MAINTAINER xym xym@126.com</span><br><span class="line">#镜像操作指令</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y nginx</span><br><span class="line">RUN echo &quot;daemon off;&quot; &gt; /etc/nginx/nginx.conf</span><br><span class="line">#容器启动时执行指令</span><br><span class="line">CMD /usr/sbin/nginx</span><br></pre></td></tr></table></figure></p><p>其中一开始必须指明所基于的镜像名称，接下来一般是说明维护信息。后面则是镜像操作指令，例如RUN指令，RUN指令将对镜像执行跟随的命令。每运行一条RUN指令，镜像就添加新的一层，并提交。最后是CMD指令，用来指定运行容器时的操作命令。</p><h2 id="指令说明"><a href="#指令说明" class="headerlink" title="指令说明"></a>指令说明</h2><p>指令的一般格式为<code>INSTRUCTION arguments</code>，指令包括<code>FROM</code>、<code>MAINTAINER</code>、<code>RUN</code>等。</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_8b1-i_epub.jpg" alt="http://op7wplti1.bkt.clouddn.com/1900654235_8b1-i_epub.jpg"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_8b1x-i_epub.jpg" alt="http://op7wplti1.bkt.clouddn.com/1900654235_8b1x-i_epub.jpg"></p><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p>指定所创建镜像的基础镜像，如果本地不存在，则默认会去<code>Docker Hub</code>下载指定镜像。</p><p>命令格式：<code>FROM &lt;image&gt;</code> or <code>FROM &lt;image&gt;:&lt;tag&gt;</code> or <code>FROM &lt;image&gt;@&lt;digest&gt;</code></p><p>任何<code>Dockerfile</code>中的第一条指令必须为FROM指令。并且，如果在同一个<code>Dockerfile</code>中创建多个镜像，可以使用多个FROM指令（每个镜像一次）。 </p><h3 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h3><p>指定维护者信息，格式为 <code>MAINTAINER &lt;name&gt;</code>。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAINTAINER  image_creator@docker.com</span><br></pre></td></tr></table></figure></p><p>该信息会写入生成镜像的Author属性域中，可以使用 <code>docker inspect imageName/imageId</code>查看。 </p><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p>运行指定命令，格式为：<code>RUN &lt;command&gt;</code> 或 <code>RUN [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</code>。注意，后一个指令会被解析为<code>json</code>数组，因此必须使用双引号。</p><p>前者默认将在<code>shell</code>终端中运行命令，即<code>/bin/sh-c</code>;后者则使用<code>exec</code>执行，不会启动shell环境。<br>指定使用其他终端类型可以使用第二种方式实现，例如：<code>RUN [&quot;bin/bash&quot;,&quot;-c&quot;,&quot;echo hello&quot;]</code>。</p><p>每条RUN指令将在当前镜像的基础上执行指定指令，并提交为新的镜像。当命令较长时可以使用”\”来换行。</p><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p>CMD指令用来指定启动容器时默认执行的命令。它支持三种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//使用exec执行，是推荐的使用方式</span><br><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line"></span><br><span class="line">//在/bin/sh中执行，提供给需要交互的应用</span><br><span class="line">CMD command param1 param2</span><br><span class="line"></span><br><span class="line">//提供给ENTRYPOINT的默认参数</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;]</span><br></pre></td></tr></table></figure></p><p>每个<code>Dockerfile</code>只能有一条CMD命令，如果指定了多条命令，只有最后一条会被执行。<br>如果用户启动容器时手动指定了运行的命令（作为run的参数），则会覆盖掉CMD指定的命令。</p><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p>LABEL指令用来指定生成镜像的元数据标签信息。<br>命令格式：<code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;...</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL author=&quot;xym&quot; author_email=xxx@126.com</span><br></pre></td></tr></table></figure></p><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><p>声明镜像内的服务所监听的端口。</p><p>命令格式：<code>EXPOSE &lt;port&gt;[&lt;port&gt;...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE 22 80 8443</span><br></pre></td></tr></table></figure></p><p>该命令只是起到声明作用，并不会自动完成端口映射。在启动容器时需要使用<code>-P</code>，Docker主机会自动分配一个宿主机的临时端口转发到指定的端口；使用<code>-p</code>，则可以具体指定哪个宿主机的本地端口会映射过来。</p><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p>指定环境变量，在镜像生成过程中会被后续RUN指令使用，在镜像启动的容器中也会存在。</p><p>命令格式：<code>ENV &lt;key&gt; &lt;value&gt;</code> or <code>ENV &lt;key&gt;=&lt;value&gt;</code></p><p>指令指定的环境变量在运行中可以被覆盖掉，如<code>docker run --env &lt;key&gt;=&lt;value&gt; built_image</code></p><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><p>该命令将复制指定的<code>&lt;src&gt;</code>路径下的内容到容器中的<code>&lt;dest&gt;</code>路径下。</p><p>命令格式：<code>ADD &lt;src&gt; &lt;dest&gt;</code></p><p>其中<code>&lt;src&gt;</code>可以是<code>Dockerfile</code>所在目录的一个相对路径（文件或目录），也可以是一个URL，还可以是一个tar文件（如果为<code>tar</code>文件，会自动解压到<code>&lt;dest&gt;</code>路径下）。<code>&lt;dest&gt;</code>可以是镜像内的路径，或者相对于工作目录（<code>WORKDIR</code>）的相对路径。</p><p>路径支持正则格式：<code>ADD *.c /code/</code></p><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p>格式为<code>COPY &lt;src&gt; &lt;dest&gt;</code></p><p>复制本地主机的<code>&lt;src&gt;</code>（为<code>Dockerfile</code>所在目录的相对路径、文件或者目录）下的内容到镜像中的<code>&lt;dest&gt;</code>下。目标路径不存在时，会自动创建。路径同样支持正则表达式。当使用本地目录为源目录时，推荐使用<code>COPY</code>。</p><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><p>指定镜像的默认入口命令，该入口命令会在启动容器时作为根命令执行，所有传入值作为该命令的参数。<br>支持两种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]（exec调用执行）</span><br><span class="line">ENTRYPOINT command param1 param2（shell中执行）</span><br></pre></td></tr></table></figure></p><p>此时，<code>CMD</code>指令指定值将作为根命令的参数。<br>每个Dockerfile中只能有一个<code>ENTRYPOINT</code>，当指定多个时，只有最后一个有效。在运行时，可以被<code>--entrypoint</code>参数覆盖掉，如<code>docker run --entrypoint</code></p><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p>创建一个数据卷挂载点。格式为<code>VOLUME [&quot;/data&quot;]</code>，可以从本地主机或其他容器挂载数据卷，一般用来存放数据库和需要保存的数据等。</p><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><p>指定运行容器时的用户名和UID，后续的RUN等指令也会使用指定的用户身份。<br>格式为：<code>USER daemon</code></p><p>当服务不需要管理员权限时，可以通过该命令指定运行用户，并且可以在之前创建所需要的用户。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN groupadd -r postgres &amp;&amp; useradd -r -g postgres postgres</span><br></pre></td></tr></table></figure></p><p>要临时获取管理员权限可以使用<code>gosu</code>或<code>sudo</code></p><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p>为后续的<code>RUN/CMD/ENTRYPOINT</code>指令配置工作目录。</p><p>格式为：<code>WORKDIR /path/to/workdir</code><br>可以使用多个<code>WORKDIR</code>指令，后续命令如果参数是相对路径，后续命令如果是相对路径，则会基于之前命令指定的路径。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure></p><p>则最终路径为<code>/a/b/c</code></p><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><p>指定一些镜像内使用的的参数（例如版本号信息等），这些参数在执行<code>docker build</code>命令时以<code>--build-arg&lt;varname&gt;=&lt;value&gt;</code>格式传入。格式为<code>ARG &lt;name&gt;=[&lt;default value&gt;]</code>，则可以用<code>docker build --build-arg &lt;name&gt;=&lt;value&gt; .</code>来指定参数值。</p><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><p>配置当所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作指令。格式为：<code>ONBUILD [INSTRUCTION]</code></p><p>例如：Dockerfile使用了如下的内容创建了镜像<code>image-A</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[...]</span><br><span class="line">ONBUILD ADD . /app/src</span><br><span class="line">ONBUILD RUN /usr/local/bin/python-build --dir /app/src</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>如果基于<code>image-A</code>创建新的镜像时，新的Dockerfile中使用<code>FROM image-A</code>指定基础镜像，会自动执行<code>ONBUILD</code>指令的内容，等价于在后面添加了两条指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">FROM image-A</span><br><span class="line">#自动执行onbuild指定的命令</span><br><span class="line">ADD . /app/src</span><br><span class="line">RUN /usr/local/bin/python-build --dir /app/src</span><br></pre></td></tr></table></figure><p>使用<code>ONBUILD</code>指令的镜像，推荐在标签中注明，例如：<code>ruby:1.9-onbuild</code></p><h3 id="STOPSIGNAL"><a href="#STOPSIGNAL" class="headerlink" title="STOPSIGNAL"></a>STOPSIGNAL</h3><p>指定所创建镜像启动的容器接受退出的信号值，例如：<br><code>STOPSIGNAL signal</code></p><h3 id="HEALTHCHECK"><a href="#HEALTHCHECK" class="headerlink" title="HEALTHCHECK"></a>HEALTHCHECK</h3><p>配置所启动容器如何进行健康检查（如何判断健康与否），自Docker1.12开始支持。</p><p>格式有两种：</p><p><code>HEALTHCHECK [OPTIONS] CMD command</code></p><p>根据所执行命令返回值是否为0来判断；<br><code>HEALTHCHECK NONE</code>禁止基础镜像中的健康检查。</p><p>OPTIONS支持：</p><ul><li>–interval=DURATION（默认为30s）：过多久检查一次；</li><li>–timeout=DURATION（默认为30s）：每次检查等待结果的超时；</li><li>–retries=N（默认为3）：如果失败了，重试几次才最终确定失败。</li></ul><h3 id="SHELL"><a href="#SHELL" class="headerlink" title="SHELL"></a>SHELL</h3><p>指定其他命令使用<code>shell</code>时的默认shell类型。默认值为<code>[&quot;/bin/sh&quot;,&quot;-c&quot;]</code></p><p>注意：对于<code>Windows</code>系统，建议在Dockerfile开头添加<code>#escape=</code>来指定转义信息。</p><h2 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h2><p>编写完成<code>Dockerfile</code>之后，可以通过<code>docker build</code>命令来创建镜像。基本格式为<code>docker build [选项] 内容路径</code>，该命令将读取指定路径下（包括子目录）的Dockerfile，并将该路径下的所有内容发送给Docker服务端，由服务端来创建镜像。因此除非生成镜像需要，否则一般建议放置Dockerfile的目录为空目录。有两点经验：</p><ul><li>如果使用非内容路径下的Dockerfile，可以通过-f选项来指定其路径</li><li>要指定生成镜像的标签信息，可以使用-t选项</li></ul><p>例如，指定Dockerfile所在路径为<code>/tmp/docker_builder/</code>,并且希望生成镜像标签为<code>build_repo/first_image</code>,可以使用下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t build_repo/first_image /tmp/docker_builder/</span><br></pre></td></tr></table></figure></p><h2 id="使用-dockerignore文件"><a href="#使用-dockerignore文件" class="headerlink" title="使用.dockerignore文件"></a>使用.dockerignore文件</h2><p>可以通过<code>.dockerignore</code>文件（每一行添加一条匹配模式）来让<code>Docker</code>忽略匹配模式路径下的目录和文件。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#comment</span><br><span class="line">*/temp*</span><br><span class="line">*/*/temp*</span><br><span class="line">tmp?</span><br><span class="line">~*</span><br></pre></td></tr></table></figure></p><h2 id="编写Dockerfile的指导原则"><a href="#编写Dockerfile的指导原则" class="headerlink" title="编写Dockerfile的指导原则"></a>编写Dockerfile的指导原则</h2><ul><li>精简镜像用途：尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂，多功能的镜像；</li><li>选用合适的基础镜像：过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的<code>debian</code>镜像；</li><li>提供足够清晰的命令注释和维护者信息：Dockerfile也是一种代码，需要考虑方便后续扩展和他人使用；</li><li>正确使用版本：使用明确的版本号信息，如：1.0，2.0而非latest，将避免内容不一致可能引发的惨案；</li><li>减少镜像层数：如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；</li><li>及时删除临时文件和缓存文件：特别是在执行apt-get指令后，/var/cache/apt/下面会缓存一些安装包；</li><li>提高生成速度：如合理使用缓存，减少内容目录下的文件，或使用<code>.dockerignore</code>文件指定等。</li><li>调整合理的指令顺序：在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用</li><li>减少外部源的干扰：如果确实要从外部引入数据，需要指定持久地址，并带有版本信息，让他人可以重复而不出错</li></ul><h2 id="优良的镜像"><a href="#优良的镜像" class="headerlink" title="优良的镜像"></a>优良的镜像</h2><h3 id="BUSYBOX"><a href="#BUSYBOX" class="headerlink" title="BUSYBOX"></a>BUSYBOX</h3><p>BusyBox是一个集成了100多个最常见的<code>Liunx</code>命令和工具（如：cat/echo/grep/mount/telnet等）的精简工具箱。它只有几MB的大小，很方便进行各种快速验证，被誉为“Linux系统的瑞士军刀”。BusyBox可以运行于多款POSIX环境的操作系统中，如Liunx（包括Andrid）、Hurd、FreeBSD等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//查询busybox镜像</span><br><span class="line">docker search busybox</span><br><span class="line"></span><br><span class="line">//下载busybox镜像</span><br><span class="line">docker pull busybox</span><br><span class="line"></span><br><span class="line">//使用busybox创建容器</span><br><span class="line">docker run -it --name my_busybox busybox</span><br></pre></td></tr></table></figure><h3 id="Alpine"><a href="#Alpine" class="headerlink" title="Alpine"></a>Alpine</h3><p>Alpine操作系统是一个面向安全的轻型Linux发行版。Alpine是由非商业组织维护的支持广泛场景的Linux发行版，它特别为资深/重度Liunx用户而优化，关注安全、性能和资源效能。Alpine镜像适用于更多常用场景，并且是一个优秀的可以适用于生产的基础环境。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//查询busybox镜像</span><br><span class="line">docker search alpine</span><br><span class="line"></span><br><span class="line">//下载busybox镜像</span><br><span class="line">docker pull alpine</span><br><span class="line"></span><br><span class="line">//使用busybox创建容器</span><br><span class="line">docker run -it --name my_alpine alpine</span><br></pre></td></tr></table></figure><h3 id="Debian-Ubuntu"><a href="#Debian-Ubuntu" class="headerlink" title="Debian/Ubuntu"></a>Debian/Ubuntu</h3><h3 id="CentOS-Fedora"><a href="#CentOS-Fedora" class="headerlink" title="CentOS/Fedora"></a>CentOS/Fedora</h3>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dockerfile命令 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker镜像构建文件Dockerfile及相关命令介绍</title>
      <link href="/2018/04/19/Docker%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E6%96%87%E4%BB%B6Dockerfile%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D/"/>
      <url>/2018/04/19/Docker%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E6%96%87%E4%BB%B6Dockerfile%E5%8F%8A%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p>使用<code>docker build</code>命令或使用<code>Docker Hub</code>的自动构建功能构建Docker镜像时，都需要一个<code>Dockerfile</code>文件。<code>Dockerfile</code>文件是一个由一系列构建指令组成的文本文件，<code>docker build</code>命令会根据这些构建指令完成<code>Docker</code>镜像的构建。本文将会介绍<code>Dockerfile</code>文件，及其中使用的构建指令。</p><h2 id="Dockerfile文件使用"><a href="#Dockerfile文件使用" class="headerlink" title="Dockerfile文件使用"></a>Dockerfile文件使用</h2><p><code>docker build</code>命令会根据<code>Dockerfile</code>文件及上下文构建新<code>Docker镜像</code>。构建上下文是指Dockerfile所在的本地路径或一个URL（Git仓库地址）。构建上下文环境会被递归处理，所以，构建所指定的路径还包括了子目录，而URL还包括了其中指定的子模块。</p><h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p>将当前目录做为构建上下文时，可以像下面这样使用docker build命令构建镜像：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker build .</span><br><span class="line">Sending build context to Docker daemon  6.51 MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>说明：构建会在Docker后台守护进程（daemon）中执行，而不是<code>CLI</code>中。构建前，构建进程会将全部内容（递归）发送到守护进程。大多情况下，应该将一个空目录作为构建上下文环境，并将<code>Dockerfile</code>文件放在该目录下。</p><p>在构建上下文中使用的<code>Dockerfile</code>文件，是一个构建指令文件。为了提高构建性能，可以通过<code>.dockerignore</code>文件排除上下文目录下，不需要的文件和目录。</p><p><code>Dockerfile</code>一般位于构建上下文的根目录下，也可以通过<code>-f</code>指定该文件的位置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -f /path/to/a/Dockerfile .</span><br></pre></td></tr></table></figure><p>构建时，还可以通过-t参数指定构建成后，镜像的仓库、标签等：</p><h3 id="镜像标签"><a href="#镜像标签" class="headerlink" title="镜像标签"></a>镜像标签</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t shykes/myapp .</span><br></pre></td></tr></table></figure><p>如果存在多个仓库下，或使用多个镜像标签，就可以使用多个<code>-t</code>参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .</span><br></pre></td></tr></table></figure><p>在Docker守护进程执行<code>Dockerfile</code>中的指令前，首先会对<code>Dockerfile</code>进行语法检查，有语法错误时会返回：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t test/myapp .</span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">Error response from daemon: Unknown instruction: RUNCMD</span><br></pre></td></tr></table></figure><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>Docker 守护进程会一条一条的执行<code>Dockerfile</code>中的指令，而且会在每一步提交并生成一个新镜像，最后会输出最终镜像的ID。生成完成后，Docker 守护进程会自动清理你发送的上下文。</p><p><code>Dockerfile</code>文件中的每条指令会被独立执行，并会创建一个新镜像，<code>RUN cd /tmp</code>等命令不会对下条指令产生影响。</p><p>Docker 会重用已生成的中间镜像，以加速<code>docker build</code>的构建速度。以下是一个使用了缓存镜像的执行过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t svendowideit/ambassador .</span><br><span class="line">Sending build context to Docker daemon 15.36 kB</span><br><span class="line">Step 1/4 : FROM alpine:3.2</span><br><span class="line"> ---&gt; 31f630c65071</span><br><span class="line">Step 2/4 : MAINTAINER SvenDowideit@home.org.au</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 2a1c91448f5f</span><br><span class="line">Step 3/4 : RUN apk update &amp;&amp;      apk add socat &amp;&amp;        rm -r /var/cache/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 21ed6e7fbb73</span><br><span class="line">Step 4/4 : CMD env | grep _TCP= | (sed &apos;s/.*_PORT_\([0-9]*\)_TCP=tcp:\/\/\(.*\):\(.*\)/socat -t 100000000 TCP4-LISTEN:\1,fork,reuseaddr TCP4:\2:\3 \&amp;/&apos; &amp;&amp; echo wait) | sh</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 7ea8aef582cc</span><br><span class="line">Successfully built 7ea8aef582cc</span><br></pre></td></tr></table></figure><p>构建缓存仅会使用本地父生成链上的镜像。如果不想使用本地缓存的镜像，也可以通过<code>--cache-from</code>指定缓存。指定后将再不使用本地生成的镜像链，而是从镜像仓库中下载。</p><h3 id="寻找缓存的逻辑"><a href="#寻找缓存的逻辑" class="headerlink" title="寻找缓存的逻辑"></a>寻找缓存的逻辑</h3><p>Docker 寻找缓存的逻辑其实就是树型结构根据 <code>Dockerfile</code> 指令遍历子节点的过程。下图可以说明这个逻辑。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> FROM base_image:version           Dockerfile:</span><br><span class="line">           +----------+                FROM base_image:version</span><br><span class="line">           |base image|                RUN cmd1  --&gt; use cache because we found base image</span><br><span class="line">           +-----X----+                RUN cmd11 --&gt; use cache because we found cmd1</span><br><span class="line">                / \</span><br><span class="line">               /   \</span><br><span class="line">       RUN cmd1     RUN cmd2           Dockerfile:</span><br><span class="line">       +------+     +------+           FROM base_image:version</span><br><span class="line">       |image1|     |image2|           RUN cmd2  --&gt; use cache because we found base image</span><br><span class="line">       +---X--+     +------+           RUN cmd21 --&gt; not use cache because there&apos;s no child node</span><br><span class="line">          / \                                        running cmd21, so we build a new image here</span><br><span class="line">         /   \</span><br><span class="line">RUN cmd11     RUN cmd12</span><br><span class="line">+-------+     +-------+</span><br><span class="line">|image11|     |image12|</span><br><span class="line">+-------+     +-------+</span><br></pre></td></tr></table></figure><p>大部分指令可以根据上述逻辑去寻找缓存，除了 <code>ADD</code> 和 <code>COPY</code> 。这两个指令会复制文件内容到镜像内，除了指令相同以外，Docker 还会检查每个文件内容校验(不包括最后修改时间和最后访问时间)，如果校验不一致，则不会使用缓存。</p><p>除了这两个命令，Docker 并不会去检查容器内的文件内容，比如 <code>RUN apt-get -y update</code>，每次执行时文件可能都不一样，但是 Docker 认为命令一致，会继续使用缓存。这样一来，以后构建时都不会再重新运行<code>apt-get -y update</code>。</p><p>如果 Docker 没有找到当前指令的缓存，则会构建一个新的镜像，并且之后的所有指令都不会再去寻找缓存。</p><h2 id="Dockerfile文件格式"><a href="#Dockerfile文件格式" class="headerlink" title="Dockerfile文件格式"></a>Dockerfile文件格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Comment</span><br><span class="line">INSTRUCTION arguments</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 注释</span><br><span class="line">指令 参数</span><br></pre></td></tr></table></figure><p><code>Dockerfile</code>文件中指令不区分大小写，但为了更易区分，约定使用<strong>大写</strong>形式。</p><p><code>Docker</code> 会依次执行<code>Dockerfile</code>中的指令，<strong>文件中的第一条指令必须是FROM，FROM指令用于指定一个基础镜像</strong>。</p><p>以#开头的行，Docker会认为是注释。但#出现在指令参数中时，则不是注释。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Comment</span><br><span class="line">RUN echo &apos;we are running some # of cool things&apos;</span><br></pre></td></tr></table></figure><h2 id="Dockerfile中使用指令"><a href="#Dockerfile中使用指令" class="headerlink" title="Dockerfile中使用指令"></a>Dockerfile中使用指令</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p><code>FROM</code>指令用于指定其后构建新镜像所使用的基础镜像。FROM指令必是<code>Dockerfile</code>文件中的首条命令，启动构建流程后，Docker将会基于该镜像构建新镜像，<code>FROM</code>后的命令也会基于这个基础镜像。</p><p><code>FROM</code>语法格式为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;</span><br></pre></td></tr></table></figure></p><p>或<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p><p>或<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;:&lt;digest&gt;</span><br></pre></td></tr></table></figure></p><p>通过<code>FROM</code>指定的镜像，可以是任何有效的基础镜像。FROM有以下限制：</p><ul><li>FROM必须是Dockerfile中第一条非注释命令</li><li>在一个Dockerfile文件中创建多个镜像时，FROM可以多次出现。只需在每个新命令FROM之前，记录提交上次的镜像ID。</li><li>tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像</li></ul><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p><code>RUN</code>用于在镜像容器中执行命令，其有以下两种命令执行方式：</p><h4 id="shell执行"><a href="#shell执行" class="headerlink" title="shell执行"></a>shell执行</h4><p>在这种方式会在<code>shell</code>中执行命令，Linux下默认使用<code>/bin/sh -c</code>，Windows下使用<code>cmd /S /C</code>。</p><p>注意：通过<code>SHELL</code>命令修改RUN所使用的默认shell<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN &lt;command&gt;</span><br></pre></td></tr></table></figure></p><h4 id="exec执行"><a href="#exec执行" class="headerlink" title="exec执行"></a>exec执行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><p><code>RUN</code>可以执行任何命令，然后在当前镜像上创建一个新层并提交。提交后的结果镜像将会用在<code>Dockerfile</code>文件的下一步。</p><p>通过<code>RUN</code>执行多条命令时，可以通过<code>\</code>换行执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN /bin/bash -c &apos;source $HOME/.bashrc; \</span><br><span class="line">echo $HOME&apos;</span><br></pre></td></tr></table></figure><p>也可以在同一行中，通过分号分隔命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN /bin/bash -c &apos;source $HOME/.bashrc; echo $HOME&apos;</span><br></pre></td></tr></table></figure></p><p><code>RUN</code>指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定<code>--no-cache</code>参数，如：<code>docker build --no-cache</code>。</p><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p><code>CMD</code>用于指定在容器启动时所要执行的命令。<code>CMD</code>有以下三种格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;]</span><br><span class="line">CMD command param1 param2</span><br></pre></td></tr></table></figure></p><p><code>CMD</code>不同于<code>RUN</code>，<code>CMD</code>用于指定在容器启动时所要执行的命令，而<code>RUN</code>用于指定镜像构建时所要执行的命令。</p><p><code>CMD</code>与<code>RUN</code>在功能实现上也有相似之处。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker run -t -i itbilu/static_web_server /bin/true</span><br></pre></td></tr></table></figure></p><p>等价于：</p><p>cmd [“/bin/true”]</p><p>CMD在Dockerfile文件中仅可指定一次，指定多次时，会覆盖前的指令。</p><p>另外，<code>docker run</code>命令也会覆盖<code>Dockerfile</code>中CMD命令。如果<code>docker run</code>运行容器时，使用了<code>Dockerfile</code>中CMD相同的命令，就会覆盖<code>Dockerfile</code>中的CMD命令。</p><p>如，我们在构建镜像的<code>Dockerfile</code>文件中使用了如下指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;/bin/bash&quot;]</span><br></pre></td></tr></table></figure></p><p>使用<code>docker build</code>构建一个新镜像，镜像名为<code>itbilu/test</code>。构建完成后，使用这个镜像运行一个新容器，运行效果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t itbilu/test</span><br><span class="line">root@e3597c81aef4:/#</span><br></pre></td></tr></table></figure><p>在使用<code>docker run</code>运行容器时，我们并没有在命令结尾指定会在容器中执行的命令，这时Docker就会执行在<code>Dockerfile</code>的CMD中指定的命令。</p><p>如果不想使用CMD中指定的命令，就可以在<code>docker run</code>命令的结尾指定所要运行的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t itbilu/test /bin/ps</span><br><span class="line">  PID TTY          TIME CMD</span><br><span class="line">    1 ?        00:00:00 ps</span><br></pre></td></tr></table></figure></p><p>这时，docker run结尾指定的<code>/bin/ps</code>命令覆盖了<code>Dockerfile</code>的CMD中指定的命令。</p><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><p><code>ENTRYPOINT</code>用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过<code>ENTRYPOINT</code>指定的程序都会被设置为默认程序。<code>ENTRYPOINT</code>有以下两种形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br><span class="line">ENTRYPOINT command param1 param2</span><br></pre></td></tr></table></figure><p><code>ENTRYPOINT</code>与<code>CMD</code>非常类似，不同的是通过<code>docker run</code>执行的命令不会覆盖<code>ENTRYPOINT</code>，而<code>docker run</code>命令中指定的任何参数，都会被当做参数再次传递给<code>ENTRYPOINT</code>。<code>Dockerfile</code>中只允许有一个<code>ENTRYPOINT</code>命令，多指定时会覆盖前面的设置，而只执行最后的<code>ENTRYPOINT</code>指令。</p><p><code>docker run</code>运行容器时指定的参数都会被传递给<code>ENTRYPOINT</code>，且会覆盖CMD命令指定的参数。如，执行<code>docker run &lt;image&gt; -d</code>时，<code>-d</code>参数将被传递给入口点。</p><p>也可以通过<code>docker run --entrypoint</code>重写<code>ENTRYPOINT</code>入口点。</p><p>如：可以像下面这样指定一个容器执行程序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;/usr/bin/nginx&quot;]</span><br></pre></td></tr></table></figure></p><p>完整构建代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Version: 0.0.3</span><br><span class="line">FROM ubuntu:16.04</span><br><span class="line">MAINTAINER 何民三 &quot;cn.liuht@gmail.com&quot;</span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN apt-get install -y nginx</span><br><span class="line">RUN echo &apos;Hello World, 我是个容器&apos; \ </span><br><span class="line">   &gt; /var/www/html/index.html</span><br><span class="line">ENTRYPOINT [&quot;/usr/sbin/nginx&quot;]</span><br><span class="line">EXPOSE 8</span><br></pre></td></tr></table></figure><p>使用<code>docker build</code>构建镜像，并将镜像指定为<code>itbilu/test</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker build -t=&quot;itbilu/test&quot; .</span><br></pre></td></tr></table></figure></p><p>构建完成后，使用<code>itbilu/test</code>启动一个容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t  itbilu/test -g &quot;daemon off;&quot;</span><br></pre></td></tr></table></figure></p><p>在运行容器时，我们使用了<code>-g &quot;daemon off;&quot;</code>，这个参数将会被传递给<code>ENTRYPOINT</code>，最终在容器中执行的命令为<code>/usr/sbin/nginx -g &quot;daemon off;&quot;</code>。</p><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p><code>LABEL</code>用于为镜像添加元数据，元数以键值对的形式指定：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</span><br></pre></td></tr></table></figure></p><p>使用<code>LABEL</code>指定元数据时，一条<code>LABEL</code>指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条<code>LABEL</code>指令指定，以免生成过多的中间镜像。</p><p>如，通过<code>LABEL</code>指定一些元数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot;</span><br></pre></td></tr></table></figure></p><p>指定后可以通过<code>docker inspect</code>查看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$sudo docker inspect itbilu/test</span><br><span class="line">&quot;Labels&quot;: &#123;</span><br><span class="line">    &quot;version&quot;: &quot;1.0&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;这是一个Web服务器&quot;,</span><br><span class="line">    &quot;by&quot;: &quot;IT笔录&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><p>注意：<code>Dockerfile</code>中还有个<code>MAINTAINER</code>命令，该命令用于指定镜像作者。但<code>MAINTAINER</code>并不推荐使用，更推荐使用<code>LABEL</code>来指定镜像作者。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL maintainer=&quot;itbilu.com&quot;</span><br></pre></td></tr></table></figure></p><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><p><code>EXPOSE</code>用于指定容器在运行时监听的端口：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;...]</span><br></pre></td></tr></table></figure></p><p><code>EXPOSE</code>并不会让容器的端口访问到主机。要使其可访问，需要在<code>docker run</code>运行容器时通过<code>-p</code>来发布这些端口，或通过<code>-P</code>参数来发布<code>EXPOSE</code>导出的所有端口。</p><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p><code>ENV</code>用于设置环境变量，其有以下两种设置形式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV &lt;key&gt; &lt;value&gt;</span><br><span class="line">ENV &lt;key&gt;=&lt;value&gt; ...</span><br></pre></td></tr></table></figure></p><p>如，通过<code>ENV</code>设置一个环境变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENV ITBILU_PATH /home/itbilu/</span><br></pre></td></tr></table></figure></p><p>设置后，这个环境变量在<code>ENV</code>命令后都可以使用。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKERDIR $ITBILU_PATH</span><br></pre></td></tr></table></figure></p><p>这些环境变量不仅可以构建镜像过程使用，使用该镜像创建的容器中也可以使用。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -i -t  itbilu/test </span><br><span class="line">root@196ca123c0c3:/# cd $ITBILU_PATH</span><br><span class="line">root@196ca123c0c3:/home/itbilu#</span><br></pre></td></tr></table></figure></p><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><p><code>ADD</code>用于复制构建环境中的文件或目录到镜像中。其有以下两种使用方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure></p><p>通过<code>ADD</code>复制文件时，需要通过<code>&lt;src&gt;</code>指定源文件位置，并通过<code>&lt;dest&gt;</code>来指定目标位置。<code>&lt;src&gt;</code>可以是一个构建上下文中的文件或目录，也可以是一个<code>URL</code>，但不能访问构建上下文之外的文件或目录。</p><p>如，通过<code>ADD</code>复制一个网络文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD http://wordpress.org/latest.zip $ITBILU_PATH</span><br></pre></td></tr></table></figure></p><p>在上例中，<code>$ITBILU_PATH</code>是我们使用<code>ENV</code>指定的一个环境变量。</p><p>另外，如果使用的是本地归档文件（<code>gzip、bzip2、xz</code>）时，Docker会自动进行解包操作，类似使用<code>tar -x</code>。</p><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p><code>COPY</code>同样用于复制构建环境中的文件或目录到镜像中。其有以下两种使用方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COPY &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure></p><p><code>COPY</code>指令非常类似于<code>ADD</code>，不同点在于<code>COPY</code>只会复制构建目录下的文件，不能使用<code>URL</code>也不会进行解压操作。</p><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p><code>VOLUME</code>用于创建挂载点，即向基于所构建镜像创始的容器添加卷：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [&quot;/data&quot;]</span><br></pre></td></tr></table></figure></p><p>一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：</p><ul><li>卷可以容器间共享和重用</li><li>容器并不一定要和其它容器共享卷</li><li>修改卷后会立即生效</li><li>对卷的修改不会对镜像产生影响</li><li>卷会一直存在，直到没有任何容器在使用它</li></ul><p><code>VOLUME</code>让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。</p><p>如，通过<code>VOLUME</code>创建一个挂载点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV ITBILU_PATH /home/itbilu/</span><br><span class="line">VOLUME [$ITBILU_PATH]</span><br></pre></td></tr></table></figure></p><p>构建的镜像，并指定镜像名为<code>itbilu/test</code>。构建镜像后，使用新构建的运行一个容器。运行容器时，需<code>-v</code>参将能本地目录绑定到容器的卷（挂载点）上，以使容器可以访问宿主机的数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t -v ~/code/itbilu:/home/itbilu/  itbilu/test </span><br><span class="line">root@31b0fac536c4:/# cd /home/itbilu/</span><br><span class="line">root@31b0fac536c4:/home/itbilu# ls</span><br><span class="line">README.md  app.js  bin  config.js  controller  db  demo  document  lib  minify.js  node_modules  package.json  public  routes  test  views</span><br></pre></td></tr></table></figure></p><p>如上所示，我们已经可以容器的<code>/home/itbilu/</code>目录下访问到宿主机<code>~/code/itbilu</code>目录下的数据了。</p><h3 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h3><p><code>USER</code>用于指定运行镜像所使用的用户：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER daemon</span><br></pre></td></tr></table></figure></p><p>使用<code>USER</code>指定用户时，可以使用用户名、UID或GID，或是两者的组合。以下都是合法的指定试：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">USER user</span><br><span class="line">USER user:group</span><br><span class="line">USER uid</span><br><span class="line">USER uid:gid</span><br><span class="line">USER user:gid</span><br><span class="line">USER uid:group</span><br></pre></td></tr></table></figure></p><p>使用<code>USER</code>指定用户后，<code>Dockerfile</code>中其后的命令<code>RUN</code>、<code>CMD</code>、<code>ENTRYPOINT</code>都将使用该用户。镜像构建完成后，通过<code>docker run</code>运行容器时，可以通过<code>-u</code>参数来覆盖所指定的用户。</p><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p><code>WORKDIR</code>用于在容器内设置一个工作目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /path/to/workdir</span><br></pre></td></tr></table></figure></p><p>通过<code>WORKDIR</code>设置工作目录后，<code>Dockerfile</code>中其后的命令<code>RUN</code>、<code>CMD</code>、<code>ENTRYPOINT</code>、<code>ADD</code>、<code>COPY</code>等命令都会在该目录下执行。</p><p>如，使用<code>WORKDIR</code>设置工作目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure></p><p>在以上示例中，<code>pwd</code>最终将会在<code>/a/b/c</code>目录中执行。</p><p>在使用<code>docker run</code>运行容器时，可以通过<code>-w</code>参数覆盖构建时所设置的工作目录。</p><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><p><code>ARG</code>用于指定传递给构建运行时的变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARG &lt;name&gt;[=&lt;default value&gt;]</span><br></pre></td></tr></table></figure></p><p>如，通过<code>ARG</code>指定两个变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ARG site</span><br><span class="line">ARG build_user=IT笔录</span><br></pre></td></tr></table></figure></p><p>以上我们指定了<code>site</code>和<code>build_user</code>两个变量，其中<code>build_user</code>指定了默认值。在使用<code>docker build</code>构建镜像时，可以通过<code>--build-arg &lt;varname&gt;=&lt;value&gt;</code>参数来指定或重设置这些变量的值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker build --build-arg site=itiblu.com -t itbilu/test .</span><br></pre></td></tr></table></figure></p><p>这样我们构建了<code>itbilu/test</code>镜像，其中<code>site</code>会被设置为<code>itbilu.com</code>，由于没有指定<code>build_user</code>，其值将是默认值IT笔录。</p><h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><p><code>ONBUILD</code>用于设置镜像触发器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONBUILD [INSTRUCTION]</span><br></pre></td></tr></table></figure></p><p>当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。</p><p>如，当镜像被使用时，可能需要做一些处理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line">ONBUILD ADD . /app/src</span><br><span class="line">ONBUILD RUN /usr/local/bin/python-build --dir /app/src</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure></p><h3 id="STOPSIGNAL"><a href="#STOPSIGNAL" class="headerlink" title="STOPSIGNAL"></a>STOPSIGNAL</h3><p><code>STOPSIGNAL</code>用于设置停止容器所要发送的系统调用信号：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">STOPSIGNAL signal</span><br></pre></td></tr></table></figure></p><p>所使用的信号必须是内核系统调用表中的合法的值，如：<code>9</code>、<code>SIGKILL</code>。</p><h3 id="SHELL"><a href="#SHELL" class="headerlink" title="SHELL"></a>SHELL</h3><p><code>SHELL</code>用于设置执行命令（<code>shell</code>式）所使用的的默认shell类型：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHELL [&quot;executable&quot;, &quot;parameters&quot;]</span><br></pre></td></tr></table></figure></p><p><code>SHELL</code>在Windows环境下比较有用，Windows下通常会有cmd和powershell两种shell，可能还会有sh。这时就可以通过SHELL来指定所使用的shell类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">FROM microsoft/windowsservercore</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C echo default</span><br><span class="line">RUN echo default</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C powershell -command Write-Host default</span><br><span class="line">RUN powershell -command Write-Host default</span><br><span class="line"></span><br><span class="line"># Executed as powershell -command Write-Host hello</span><br><span class="line">SHELL [&quot;powershell&quot;, &quot;-command&quot;]</span><br><span class="line">RUN Write-Host hello</span><br><span class="line"></span><br><span class="line"># Executed as cmd /S /C echo hello</span><br><span class="line">SHELL [&quot;cmd&quot;, &quot;/S&quot;&quot;, &quot;/C&quot;]</span><br><span class="line">RUN echo hello</span><br></pre></td></tr></table></figure><blockquote><p>原文链接：<a href="https://itbilu.com/linux/docker/VyhM5wPuz.html" target="_blank" rel="noopener">https://itbilu.com/linux/docker/VyhM5wPuz.html</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dockerfile命令 </tag>
            
            <tag> Dockerfile命令详解 </tag>
            
            <tag> FROM命令 </tag>
            
            <tag> RUN命令 </tag>
            
            <tag> CMD命令 </tag>
            
            <tag> ADD命令 </tag>
            
            <tag> COPY命令 </tag>
            
            <tag> ENTRYPOINT命令 </tag>
            
            <tag> ENV命令 </tag>
            
            <tag> ONBUILD命令 </tag>
            
            <tag> ARG命令 </tag>
            
            <tag> WORKDIR命令，LABEL命令 </tag>
            
            <tag> EXPOSE命令 </tag>
            
            <tag> VOLUME命令 </tag>
            
            <tag> USER命令 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 配置加速器</title>
      <link href="/2018/04/19/Docker-%E9%85%8D%E7%BD%AE%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
      <url>/2018/04/19/Docker-%E9%85%8D%E7%BD%AE%E5%8A%A0%E9%80%9F%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>在国内使用Docker Hub有个很大的问题就是速度太慢，pull一个image要很久，幸亏国内有个组织解决了这个问题——DaoCloud。在<a href="http://www.daocloud.io/#" target="_blank" rel="noopener">DaoCloud</a>上注册一个帐号，找到它的加速器页面，根据提示进行操作即可。</p><p>进入<a href="http://www.daocloud.io/mirror#accelerator-doc" target="_blank" rel="noopener">加速器</a>页面</p><p><img src="http://op7wplti1.bkt.clouddn.com/daocloud_%E5%8A%A0%E9%80%9F%E5%99%A8.png" alt="daocloud加速器"></p><p><img src="http://op7wplti1.bkt.clouddn.com/%E5%8A%A0%E9%80%9F%E9%85%8D%E7%BD%AE.png" alt="daocloud配置"></p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker加速器配置 </tag>
            
            <tag> daocloud加速器 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hexo在遇到特殊符号时出现解析报错</title>
      <link href="/2018/04/17/Hexo%E5%9C%A8%E9%81%87%E5%88%B0%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%E6%97%B6%E5%87%BA%E7%8E%B0%E8%A7%A3%E6%9E%90%E6%8A%A5%E9%94%99/"/>
      <url>/2018/04/17/Hexo%E5%9C%A8%E9%81%87%E5%88%B0%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%E6%97%B6%E5%87%BA%E7%8E%B0%E8%A7%A3%E6%9E%90%E6%8A%A5%E9%94%99/</url>
      <content type="html"><![CDATA[<h2 id="hexo-在遇到-““-符号时出现解析报错"><a href="#hexo-在遇到-““-符号时出现解析报错" class="headerlink" title="hexo 在遇到 ““ 符号时出现解析报错"></a>hexo 在遇到 “{{“ 符号时出现解析报错</h2><p>最近在更新一篇文章后，无论是 hexo g 生成，还是 hexo s 预览都会报解析错误， 大致如下，后面还有很长的信息，就不贴了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html</span><br><span class="line">Template render error: unexpected token: .</span><br><span class="line">    at Object._prettifyError (D:\workspace\IdeaProjects\myHexo\node_modules\nunjucks\src\lib.js:35:11)</span><br><span class="line">    at Template.render (D:\workspace\IdeaProjects\myHexo\node_modules\nunjucks\src\environment.js:526:21)</span><br></pre></td></tr></table></figure><p>而把那篇文章移除后一切又是正常的。从错误上来看基本可以判断是模板解析错误，从 unexpected token: . 又看不出来具体是哪里出错，一直找不到原因。</p><p>今天查找资料发现有人遇到和我类似的问题，但报的是 <code>unexpected token: }}</code> 的错误。搜索一下我那篇文章，果然有好几处带有 <code>}}</code> 符号。尝试着把几处符号删除，果然正常了。看来问题真的出在 }} 上面。</p><p>直接说解决方案吧，参考别人的解决方法是在 }} 中间加一个空格，但因为我的是有部分教程含义的文章，所以并不想这样误导人。于是去 github 上找解决方案。</p><p>github 上给出的方法是在需要显示 }} 符号的地方加上 <code>{% raw %}{% endraw %}</code> 标签，标记这部分不需要解析。例如文章中可能会出现 <code></code> 的片段，写成 <code>{% raw %}{{ something }}{% endraw %}</code> 就可以了。</p><p>虽然有点麻烦，但也算临时解决了这个问题，这是个已知 bug ，希望后续的版本能修复吧，毕竟使用太多 hexo 专属的标签对博客以后的迁移、改版什么的来说还是很麻烦的。</p><p>本文链接: <a href="https://icewing.cc/post/hexo-bug-of-quot.html" target="_blank" rel="noopener">https://icewing.cc/post/hexo-bug-of-quot.html</a></p>]]></content>
      
      <categories>
          
          <category> hexo笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo小技巧 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 端口映射与容器互联</title>
      <link href="/2018/04/16/Docker-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/"/>
      <url>/2018/04/16/Docker-%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94/</url>
      <content type="html"><![CDATA[<p>在实践中会经常碰到需要多个服务组件容器共同协作的情况，这往往需要多个容器之间能够互相访问到对方的服务。除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。</p><h2 id="端口映射实现访问容器"><a href="#端口映射实现访问容器" class="headerlink" title="端口映射实现访问容器"></a>端口映射实现访问容器</h2><h3 id="1、从外部访问容器应用"><a href="#1、从外部访问容器应用" class="headerlink" title="1、从外部访问容器应用"></a>1、从外部访问容器应用</h3><p>在启动容器的时候，如果不指定对应的参数，在容器外部是无法通过网络来访问容器内的网络应用和服务的。当容器中运行一些网络应用，要让外部访问这些应用时，可以通过<code>-p</code>或<code>-P</code>参数来指定端口映射。当使用<code>-P</code>（大写的）标记时，Docker会随机映射一个端口到内部容器开放的网络端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -d -P training/webapp python app.py</span><br><span class="line">f2c1a06b94b49de281b403fa339d5975be5dd6fae662c664b300540c851c3565</span><br><span class="line"></span><br><span class="line">//ps命令后发现本地主机的32783被映射到了容器的5000端口。访问宿主主机的32783端口即可访问容器内的web应用</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                          PORTS                     NAMES</span><br><span class="line">f2c1a06b94b4        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 2 seconds                    0.0.0.0:32783-&gt;5000/tcp   inspiring_hawking</span><br><span class="line"></span><br><span class="line">//同样使用docker logs命令来查看应用信息</span><br><span class="line">[root@xxx ~]# docker logs -f  f2c</span><br><span class="line">Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</span><br><span class="line">172.17.0.1 - - [14/Apr/2018 16:13:50] &quot;GET / HTTP/1.1&quot; 200 -</span><br></pre></td></tr></table></figure><p><code>-p</code>（小写的）可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IP:HostPort:ContainerPort|IP::ContainerPort|HostPort:ContainerPort</span><br></pre></td></tr></table></figure><h3 id="2、映射所有接口地址"><a href="#2、映射所有接口地址" class="headerlink" title="2、映射所有接口地址"></a>2、映射所有接口地址</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">//使用HostPort:ContainerPort格式将本地的5000端口映射到容器的5000端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 training/webapp python app.py</span><br><span class="line">22c0bc271d46033c16f9ebdbc60ebf78938a1a0710bcede98afd15f887a92968</span><br><span class="line"></span><br><span class="line">//查看容器，注意端口映射栏</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                    NAMES</span><br><span class="line">22c0bc271d46        training/webapp     &quot;python app.py&quot;          8 seconds ago       Up 7 seconds                0.0.0.0:5000-&gt;5000/tcp   confident_saha</span><br><span class="line"></span><br><span class="line">//多次使用-p标记可以绑定多个端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 -p 8080:80  training/webapp python app.py</span><br><span class="line">c18177c0e1ec3a40c175cec0b7c165d8e0ff9576087c1734293e890357152919</span><br><span class="line"></span><br><span class="line">//查看容器，注意端口映射栏</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                                          NAMES</span><br><span class="line">c18177c0e1ec        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 2 seconds                0.0.0.0:5000-&gt;5000/tcp, 0.0.0.0:8080-&gt;80/tcp   suspicious_swartz</span><br></pre></td></tr></table></figure><h3 id="3、映射到指定地址的指定端口"><a href="#3、映射到指定地址的指定端口" class="headerlink" title="3、映射到指定地址的指定端口"></a>3、映射到指定地址的指定端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//只有自己访问自己</span><br><span class="line">[root@xxx ~]# docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py </span><br><span class="line">4da1f3ed9ee27026b9929e2b96ebd422e2bf6ab212b07ab8fbb8339c322fef70</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                      NAMES</span><br><span class="line">4da1f3ed9ee2        training/webapp     &quot;python app.py&quot;          4 seconds ago       Up 4 seconds                127.0.0.1:5000-&gt;5000/tcp   affectionate_elion</span><br></pre></td></tr></table></figure><h3 id="4、映射到指定地址的任意端口"><a href="#4、映射到指定地址的任意端口" class="headerlink" title="4、映射到指定地址的任意端口"></a>4、映射到指定地址的任意端口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">//使用IP::ContainerPort绑定localhost的任意端口到容器的5000端口，本地主机会自动分配一个端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 127.0.0.1::5000 training/webapp python app.py</span><br><span class="line">ed9497ef017e2e90fac7e783c92ccde2f59c14f62d429190cb24c0dfa43eeefb</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                         PORTS                       NAMES</span><br><span class="line">ed9497ef017e        training/webapp     &quot;python app.py&quot;          5 seconds ago       Up 4 seconds                   127.0.0.1:32768-&gt;5000/tcp   wonderful_yonath</span><br><span class="line"></span><br><span class="line">//还可以使用udp标记来指定udp端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000/udp training/webapp python app.py</span><br><span class="line">4880a7d119f226591ad1b99ad0324d55d8e2caa98a399c9f426e6757fc7491c5</span><br><span class="line">[root@xym ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                         PORTS                              NAMES</span><br><span class="line">4880a7d119f2        training/webapp     &quot;python app.py&quot;          3 seconds ago       Up 3 seconds                   5000/tcp, 0.0.0.0:5000-&gt;5000/udp   gracious_williams</span><br><span class="line">b5257d2e</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">### 5、查看映射端口配置</span><br><span class="line"></span><br><span class="line">使用`docker port`命令来查看当前映射的端口配置，也可以查看到绑定的地址：</span><br></pre></td></tr></table></figure><p>[root@xxx ~]# docker port priceless_franklin 5000<br>0.0.0.0:5000</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 互联机制实现便捷互访</span><br><span class="line"></span><br><span class="line">容器的互联（linking）是一种让多个容器中应用进行快速交互的方式。它会在源和接受容器之间创建连接关系，接受容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址。</span><br><span class="line"></span><br><span class="line">### 1、自定义容器命名</span><br><span class="line"></span><br><span class="line">连接系统依据容器名称来执行。因此，首先需要定义好一个好记的容器名字。虽然当创建容器的时候，系统默认会分配一个名字，但自定义容器名字有两个好处：</span><br><span class="line"></span><br><span class="line">* 自定义的名字比较好记，比如一个web应用容器，我们可以给它起个名字叫web ，一目了然。</span><br><span class="line">* 当要连接其他容器时，即便重启，也可以使用容器名而不用改变，比如连接web容器到db容器。</span><br></pre></td></tr></table></figure><p>//使用–name参数自定义容器名称<br>[root@xxx ~]# docker run -d -p 5000:5000 –name web training/webapp python app.py<br>757d2ee95be01e2c509426c52bf5b4176ff7199eb654b5854ddf0e9b8412c044</p><p>//查看运行容器，注意NAMES栏<br>[root@xxx ~]# docker ps -l<br>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES<br>757d2ee95be0        training/webapp     “python app.py”     5 seconds ago       Up 4 seconds        0.0.0.0:5000-&gt;5000/tcp   web</p><p>//还可使用inspect –format “{{.Name}}“获取容器名字<br>[root@xxx ~]# docker inspect –format “{{.Name}}“ 757d2ee95be<br>/web</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在执行`docker run`的时候如果添加了`--rm`标记，则容器在终止后会立即删除。注意`--rm`和`-d`参数不能同时使用。</span><br><span class="line"></span><br><span class="line">### 2、容器互联</span><br><span class="line"></span><br><span class="line">使用`--link`参数可以让容器之间安全地进行交互。</span><br></pre></td></tr></table></figure><p>//创建一个db容器<br>[root@xxx ~]# docker run -d –name db training/postgres<br>Unable to find image ‘training/postgres:latest’ locally<br>latest: Pulling from training/postgres<br>a3ed95caeb02: Pull complete<br>6e71c809542e: Pull complete<br>2978d9af87ba: Pull complete<br>e1bca35b062f: Pull complete<br>500b6decf741: Pull complete<br>74b14ef2151f: Pull complete<br>7afd5ed3826e: Pull complete<br>3c69bb244f5e: Pull complete<br>d86f9ec5aedf: Pull complete<br>010fabf20157: Pull complete<br>Digest: sha256:a945dc6dcfbc8d009c3d972931608344b76c2870ce796da00a827bd50791907e<br>Status: Downloaded newer image for training/postgres:latest<br>3b48a3a82a86a52244527112a4a03e98e951c8edcdaedb3b63bc1a0775ac0315</p><p>//删除原来的web容器<br>[root@xxx ~]# docker rm -f web<br>web</p><p>//重建web容器，并让它连接到db容器,–link参数的格式为–link name:alias，其中name是要连接的容器名称，alias是这个连接的别名<br>[root@xxx ~]# docker run -d -P –name web –link db:db training/webapp python app.py<br>ca82ea2a2e5ad9b407d5c80fcfd6cd01f7e03be46864e5058b539075e858c626</p><p>//查看运行容器<br>[root@xxx ~]# docker ps<br>CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                     NAMES<br>ca82ea2a2e5a        training/webapp     “python app.py”          22 seconds ago       Up 21 seconds       0.0.0.0:32784-&gt;5000/tcp   web<br>3b48a3a82a86        training/postgres   “su postgres -c ‘/us…”   About a minute ago   Up About a minute   5432/tcp                  db</p><p>//查看接受容器(web)连接信息<br>[root@xxx ~]# docaker inspect –format “{{.HostConfig.Links}}“ web<br>[/db:/web/db]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Docker相当于在两个互联的容器之间创建了一个虚机通道，而且不用映射他们的端口在宿主主机上。在启动db容器的时候并没有使用`-p`和`-P`标记，从而避免了暴露数据库服务端口到外部网路上。</span><br><span class="line"></span><br><span class="line">Docker通过两种方式为容器公开连接信息：</span><br><span class="line"></span><br><span class="line">* 更新环境变量</span><br><span class="line">* 更新`/etc/hosts`文件</span><br><span class="line"></span><br><span class="line">使用env命令来查看web容器的环境变量：</span><br></pre></td></tr></table></figure><p>[root@xxx ~]# docker run –rm –name web2 –link db:db training/webapp env<br>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin<br>HOSTNAME=6f8232ea8d36<br>DB_PORT=tcp://172.17.0.3:5432<br>DB_PORT_5432_TCP=tcp://172.17.0.3:5432<br>DB_PORT_5432_TCP_ADDR=172.17.0.3<br>DB_PORT_5432_TCP_PORT=5432<br>DB_PORT_5432_TCP_PROTO=tcp<br>DB_NAME=/web2/db<br>DB_ENV_PG_VERSION=9.3<br>HOME=/root</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">其中`DB_`开头的环境变量时提供web容器连接db容器使用的，前缀采用大写的连接别名。除了环境变量之外，Docker还添加host信息到子容器的`/etc/hosts`文件，下面是子容器web的hosts文件：</span><br></pre></td></tr></table></figure><p>//创建容器，并进入bash<br>[root@xxx ~]# docker run -it –rm –link db:db training/webapp /bin/bash</p><p>//查看hosts配置<br>root@d64fd0fa99f0:/opt/webapp# cat /etc/hosts<br>172.17.0.3    db 3b48a3a82a86<br>172.17.0.4    d64fd0fa99f0</p><p>//查看db容器，发现其将容器id作为主机名<br>root@3b48a3a82a86:/# cat /etc/hosts<br>127.0.0.1    localhost<br>172.17.0.3    3b48a3a82a86</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这里有两个hosts信息，第一个是db容器的IP、主机名和容器id，第二个是web容器，web容器使用自己的id作为默认主机名。</span><br></pre></td></tr></table></figure><p>//安装ping命令<br>root@d64fd0fa99f0:/opt/webapp# apt-get install inetutils-ping<br>Unpacking inetutils-ping (2:1.9.2-1) …<br>Setting up inetutils-ping (2:1.9.2-1) …</p><p>//执行ping命令，测试与db容器的连通性<br>root@d64fd0fa99f0:/opt/webapp# ping db<br>PING db (172.17.0.3): 56 data bytes<br>64 bytes from 172.17.0.3: icmp_seq=0 ttl=64 time=0.267 ms<br>64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.314 ms<br>64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.260 ms<br>64 bytes from 172.17.0.3: icmp_seq=3 ttl=64 time=0.131 ms</p><p><code>`</code></p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker容器端口映射 </tag>
            
            <tag> Pp命 </tag>
            
            <tag> link选项 </tag>
            
            <tag> 容器互联原理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hexo 跳过指定文件的渲染</title>
      <link href="/2018/04/16/Hexo-%E8%B7%B3%E8%BF%87%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9A%84%E6%B8%B2%E6%9F%93/"/>
      <url>/2018/04/16/Hexo-%E8%B7%B3%E8%BF%87%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9A%84%E6%B8%B2%E6%9F%93/</url>
      <content type="html"><![CDATA[<p>关于hexo的<code>_config.yml</code>配置，官方文档中：</p><blockquote><p>skip_render：跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。</p></blockquote><p>但并没有说明具体该怎么配置，一番折腾后得以解决：</p><p>如果要跳过source文件夹下的<code>test.html</code>，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test.html</span><br></pre></td></tr></table></figure></p><p>注意，千万不要手贱加上个<code>/</code>写成<code>/test.html</code>，这里只能填相对于source文件夹的相对路径。</p><p>如果要忽略source下的test文件夹下所有文件，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test/*</span><br></pre></td></tr></table></figure></p><p>如果要忽略source下的test文件夹下<code>.html</code>文件，可以这样配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">skip_render: test/*.html</span><br></pre></td></tr></table></figure></p><p>如果要忽略source下的test文件夹下所有文件和目录，可以这样配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">skip_render: test/**</span><br></pre></td></tr></table></figure><p>如果要忽略多个路径的文件或目录，可以这样配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">skip_render:</span><br><span class="line">    - test.html</span><br><span class="line">    - test/*</span><br></pre></td></tr></table></figure><p><strong>Tips:</strong></p><p><a href="https://github.com/hexojs/hexo/issues/1146" target="_blank" rel="noopener">如何不处理source目录下某个子目录的所有文件，仅仅是将其copy到public目录中对应目录？</a></p>]]></content>
      
      <categories>
          
          <category> hexo笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo小技巧 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 数据管理</title>
      <link href="/2018/04/15/Docker-%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"/>
      <url>/2018/04/15/Docker-%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>在生产环境中使用Docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及到容器的数据管理操作。</p><p>容器中管理数据主要有两种方式：</p><p>数据卷（Data volumes）：容器内数据直接映射到本地主机环境；<br>数据卷容器（Data Volume Containers）：使用特定容器维护数据卷；</p><p>本文首先介绍如果在容器内创建数据卷，并且把本地的目录或文件挂载到容器内的数据卷中。接下来，会介绍如何使用数据卷容器，在容器和主机、容器和容器之间共享数据，并实现数据的备份和恢复。</p><h2 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h2><p>数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于linux中的mount操作。</p><p>数据卷可以提供很多有用的特性：  </p><ul><li>数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便</li><li>对数据卷内数据的修改会立马生效，无论是容器内操作还是本机操作</li><li>对数据卷的更新不会影响镜像，解耦了应用和数据</li><li>卷会一直存在，直到没有容器使用，可以安全的卸载它</li></ul><h3 id="1、在容器内创建一个数据卷"><a href="#1、在容器内创建一个数据卷" class="headerlink" title="1、在容器内创建一个数据卷"></a>1、在容器内创建一个数据卷</h3><p>在用<code>docker run</code>命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//使用training/webapp镜像创建一个web（name参数指定容器名称）容器，并创建一个数据卷挂载到容器的/webapp目录（-v 指定创建的数据卷）</span><br><span class="line">// -P参数是将容器服务暴露的端口自动映射到本地主机的临时端口上，python app.py(为执行的命令COMMAND和其对应的参数ARG)</span><br><span class="line">[root@xxx ~]# docker run -d -P --name web -v /webapp training/webapp python app.py</span><br><span class="line">Unable to find image &apos;training/webapp:latest&apos; locally</span><br><span class="line">latest: Pulling from training/webapp</span><br><span class="line">e190868d63f8: Pull complete </span><br><span class="line">909cd34c6fd7: Pull complete </span><br><span class="line">0b9bfabab7c1: Pull complete </span><br><span class="line">a3ed95caeb02: Pull complete </span><br><span class="line">10bbbc0fc0ff: Pull complete </span><br><span class="line">fca59b508e9f: Pull complete </span><br><span class="line">e7ae2541b15b: Pull complete </span><br><span class="line">9dd97ef58ce9: Pull complete </span><br><span class="line">a4c1b0cb7af7: Pull complete </span><br><span class="line">Digest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d</span><br><span class="line">Status: Downloaded newer image for training/webapp:latest</span><br><span class="line">e7816725b3d075b56410c9d64543a4febfe965e9a5d7cc1c8ea82c92c966f030</span><br><span class="line"></span><br><span class="line">//查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hub.c.163.com/public/ubuntu                       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">training/webapp                                   latest              6fae60ef3446        2 years ago         349MB  </span><br><span class="line"></span><br><span class="line">//查看运行态的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">e7816725b3d0        training/webapp     &quot;python app.py&quot;     21 seconds ago      Up 20 seconds       0.0.0.0:32768-&gt;5000/tcp   web</span><br></pre></td></tr></table></figure><h3 id="2、挂载一个主机目录作为数据卷"><a href="#2、挂载一个主机目录作为数据卷" class="headerlink" title="2、挂载一个主机目录作为数据卷"></a>2、挂载一个主机目录作为数据卷</h3><p>使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷（推荐方式）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//使用-v /src/webapp:/opt/webapp 加载主机/src/webapp目录到容器的/opt/webapp目录，python为command命令，app.py为运行参数</span><br><span class="line">[root@xxx webapp]# docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py</span><br><span class="line">1e0d2372472f8697a65c7da879a8807cf048bc4601b7136e354e4b0c87a7126f</span><br><span class="line"></span><br><span class="line">//查看运行的容器</span><br><span class="line">[root@xxx webapp]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">1e0d2372472f        training/webapp     &quot;python app.py&quot;     4 seconds ago       Up 3 seconds        0.0.0.0:32781-&gt;5000/tcp   web</span><br></pre></td></tr></table></figure><p>这个功能在进行测试的时候非常方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器中运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在,Docker会自动创建</p><p>Docker挂载数据卷的默认权限是读写（rw），用户也可以通过<code>ro</code>指定为只读。加了<code>ro</code>之后，容器内对所挂载数据卷内的数据就无法修改了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</span><br><span class="line">f5d7d04aa46c50db6696efa8554a9d344bbd3f13eb077be3c680a1ac89d509a0</span><br></pre></td></tr></table></figure><h3 id="3、挂载一个本地主机文件作为数据卷"><a href="#3、挂载一个本地主机文件作为数据卷" class="headerlink" title="3、挂载一个本地主机文件作为数据卷"></a>3、挂载一个本地主机文件作为数据卷</h3><p><code>-v</code>参数，也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//使用-v ~/.bash_history:/.bash_history，这样就可以记录在容器中输入过的命令历史了</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash</span><br><span class="line">root@43e50ea02e35:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">root@43e50ea02e35:/# history </span><br><span class="line">    1  ls</span><br><span class="line">    2  history</span><br></pre></td></tr></table></figure><p>挂载文件引起的问题：使用文件编辑工具，包括<code>vi</code>或者<code>sed --in-place</code>的时候，可能会造成文件<code>inode</code>的改变，从Docker1.1.0起，这会导致报错误信息。所以推荐的方式是直接挂载文件所在目录。</p><h2 id="数据卷容器"><a href="#数据卷容器" class="headerlink" title="数据卷容器"></a>数据卷容器</h2><p>如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。</p><p>首先创建一个数据卷容器<code>dbdata</code>,并在其中创建一个数据卷挂载到<code>/dbdata</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//创建一个数据卷容器</span><br><span class="line">[root@xxx ~]# docker run -it -v /dbdata --name dbdata ubuntu</span><br><span class="line"></span><br><span class="line">//查看目录</span><br><span class="line">root@d4bb57243d45:/# ls</span><br><span class="line">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p><p>然后，可以在其他容器中使用<code>--volumes-from</code>来挂载<code>dbdata</code>容器中的数据卷，例如创建<code>db1</code>和<code>db2</code>两个容器，并从<code>dbdata</code>容器挂载数据卷：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 创建2个容器挂载dbdata容器中的数据卷</span><br><span class="line">[root@xxx ~]# docker run -it --volumes-from dbdata --name db1 ubuntu</span><br><span class="line">[root@xxx ~]# docker run -it --volumes-from dbdata --name db2 ubuntu</span><br></pre></td></tr></table></figure><p>此时，容器db1和容器db2都挂载同一个数据卷到相同的<code>dbdata</code>目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。例如，在<code>dbdata</code>容器中创建一个<code>test</code>文件,在<code>db1</code>容器中可能查看到它：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在dbdata容器的数据卷中创建文件a</span><br><span class="line">root@9e90f695bcb8:/dbdata# touch a</span><br><span class="line">root@9e90f695bcb8:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root   14 Apr 14 10:02 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:01 ../</span><br><span class="line">-rw-r--r--.  1 root root    0 Apr 14 10:02 a</span><br><span class="line"></span><br><span class="line">//在db1容器中查看数据卷目录dbdata，也发现了文件a</span><br><span class="line">root@ab4426a23cb4:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root    6 Apr 14 10:01 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:02 ../</span><br><span class="line">root@ab4426a23cb4:/dbdata# ls     </span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">//db2结果和db1一样</span><br><span class="line">root@b4bea0f56613:/# cd dbdata/</span><br><span class="line">root@b4bea0f56613:/dbdata# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x.  2 root root   14 Apr 14 10:02 ./</span><br><span class="line">drwxr-xr-x. 22 root root 4096 Apr 14 10:03 ../</span><br><span class="line">-rw-r--r--.  1 root root    0 Apr 14 10:02 a</span><br></pre></td></tr></table></figure><p>可以多次使用<code>--volumes-from</code>参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。  </p><p>使用<code>--volumes-from</code>参数所挂载数据卷的容器自身并不需要保持在运行状态。如果删除了挂载容器（包括dbdata、db1和bd2），数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显示使用<code>docker rm -v</code>命令来指定同时删除关联的数据卷。</p><h2 id="利用数据卷容器迁移数据"><a href="#利用数据卷容器迁移数据" class="headerlink" title="利用数据卷容器迁移数据"></a>利用数据卷容器迁移数据</h2><p>可以使用数据卷容器对其中的数据卷进行备份、恢复、以实现数据的迁移。</p><h3 id="1、备份"><a href="#1、备份" class="headerlink" title="1、备份"></a>1、备份</h3><p>使用如下命令来备份<code>dbdata</code>数据卷容器内的数据卷：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@xxx ~]# docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar -zcvf /backup/backup.tar /dbdata</span><br><span class="line">tar: Removing leading `/&apos; from member names</span><br><span class="line">/dbdata/</span><br><span class="line">/dbdata/a</span><br><span class="line"></span><br><span class="line">[root@xxx ~]#</span><br></pre></td></tr></table></figure><p>分析命令：  </p><ul><li>利用ubuntu镜像创建一个容器worker。对应命令参数：<code>docker run --name worker ubuntu</code></li><li>使用<code>--volumes-from dbdata</code>参数来让<code>worker</code>容器挂载<code>dbdata</code>容器的数据卷(即dbdata)。对应命令参数：<code>--volumes-from dbdata</code></li><li>使用 <code>-v $(pwd):/backup</code>参数来挂载本地的当前目录到<code>woker</code>容器的<code>/backup</code>目录。对应命令参数：<code>-v $(pwd):/backup</code></li><li><code>worker</code>容器启动后，使用<code>tar -zcvf /backup/backup.tar /dbdata</code>命令来将<code>/dbdata</code>下内容备份为容器内的<code>/backup/backup.tar</code>,即宿主主机当前目录下的<code>backup.tar</code>。</li></ul><h3 id="2、恢复"><a href="#2、恢复" class="headerlink" title="2、恢复"></a>2、恢复</h3><p>如果要将数据恢复到一个容器，可以按照下面步骤操作。首先创建一个带有数据卷的容器<code>dbdata2</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v /dbdata --name dbdata2 ubuntu /bin/bash</span><br></pre></td></tr></table></figure><p>然后创建另一个新的容器，挂载<code>dbdata2</code>的容器，并使用<code>untar</code>解压备份文件到所挂载的容器中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker run --volumes-from dbdata2 -v $(pwd):/backup busybox untar /backup/backup.tar</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker数据管理 </tag>
            
            <tag> -v选项 </tag>
            
            <tag> --volumes-from选项 </tag>
            
            <tag> 数据卷备份 </tag>
            
            <tag> 数据卷恢复 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 基本操作之仓库</title>
      <link href="/2018/04/15/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E4%BB%93%E5%BA%93/"/>
      <url>/2018/04/15/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E4%BB%93%E5%BA%93/</url>
      <content type="html"><![CDATA[<p>仓库（Repository）是集中存放镜像的地方，分为公共仓库和私有仓库。一个容易与之混淆的概念是注册服务器（Registry）。实际上注册服务器是存放仓库的具体服务器，一个注册服务器上可以有多个仓库，而每个仓库下面可以有多个镜像。从这方面来说，可将仓库看做一个具体的项目或目录。例如对于仓库地址<code>private-docker.com/ubuntu</code>来说,<code>private-docker.com</code>是注册服务器地址，<code>ubuntu</code>是仓库名。</p><h2 id="Docker-Hub公共镜像"><a href="#Docker-Hub公共镜像" class="headerlink" title="Docker Hub公共镜像"></a>Docker Hub公共镜像</h2><p>访问地址：<a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a></p><h3 id="1、登录仓库"><a href="#1、登录仓库" class="headerlink" title="1、登录仓库"></a>1、登录仓库</h3><p>命令格式：<code>docker login [OPTIONS] [SERVER]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --password string   Password</span><br><span class="line">      --password-stdin    Take the password from stdin</span><br><span class="line">  -u, --username string   Username</span><br><span class="line">  </span><br><span class="line">//通过存储的登录信息，直接确认登录  </span><br><span class="line">[root@xxx ~]# docker login</span><br><span class="line">Authenticating with existing credentials...</span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><h3 id="2、基本操作"><a href="#2、基本操作" class="headerlink" title="2、基本操作"></a>2、基本操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查找官方仓库中的镜像，搜索关键词centos</span><br><span class="line">[root@xxx ~]# docker search centos</span><br><span class="line">NAME                               DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">centos                             The official build of CentOS.                   4188                [OK]                </span><br><span class="line">ansible/centos7-ansible            Ansible on Centos7                              108                                     [OK]</span><br><span class="line">jdeathe/centos-ssh                 CentOS-6 6.9 x86_64 / CentOS-7 7.4.1708 x86_…   94                                      [OK]</span><br><span class="line">consol/centos-xfce-vnc             Centos container with &quot;headless&quot; VNC session…   52                                      [OK]</span><br><span class="line">imagine10255/centos6-lnmp-php56    centos6-lnmp-php56                              40                                      [OK]</span><br><span class="line">tutum/centos                       Simple CentOS docker image with SSH access      38                                      </span><br><span class="line">gluster/gluster-centos             Official GlusterFS Image [ CentOS-7 +  Glust…   26                                      [OK]</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">//下载centos镜像</span><br><span class="line">[root@xxx ~]# docker pull centos</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">469cfcc7a4b3: Pull complete </span><br><span class="line">Digest: sha256:989b936d56b1ace20ddf855a301741e52abca38286382cba7f44443210e96d16</span><br><span class="line">Status: Downloaded newer image for centos:latest</span><br></pre></td></tr></table></figure><p>根据search结果，可将镜像资源分为两类。一种是类似centos这样的镜像，称为基础或根镜像。这些镜像是由docker公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。还有一种类型，比如<code>ansible/centos7-ansible</code>镜像，它是由docker用户ansible创建并维护的，带有用户名称前缀，表明是某用户下的某仓库。可以通过用户名称前缀<code>user_name/镜像名</code>来指定使用某个用户提供的镜像。另外，在查找的时候通过-s N参数可以指定仅显示评价为N星级以上的镜像。</p><h3 id="3、自动创建"><a href="#3、自动创建" class="headerlink" title="3、自动创建"></a>3、自动创建</h3><p>自动创建（Automated Builds）功能对于需要经常升级镜像内程序来说，十分方便。有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。而自动创建允许用户通过Docker Hub指定跟踪一个目标网站（目前支持Github或Bitbucket）上的项目，一旦项目发生新的提交，则自动执行创建。</p><p>要配置自动创建，包括如下步骤：</p><ul><li>1)创建并登陆Docker Hub，以及目标网站；在目标网站中连接账户到Docker Hub。</li><li>2)在Docker Hub中配置一个“自定创建”</li><li>3)选取一个目标网站中的项目（需要含Dockerfile）和分支；</li><li>4)指定Dockerfile位置，并提交创建</li></ul><p>之后，可以在Docker Hub的“自动创建”页面中跟踪每次创建的状态。</p><h2 id="国内时速云镜像"><a href="#国内时速云镜像" class="headerlink" title="国内时速云镜像"></a>国内时速云镜像</h2><p>访问地址：<a href="https://hub.tenxcloud.com/" target="_blank" rel="noopener">https://hub.tenxcloud.com/</a></p><h3 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//下载镜像</span><br><span class="line">[root@xxx ~]# docker pull index.tenxcloud.com/tenxcloud/centos</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from tenxcloud/centos</span><br><span class="line">a3ed95caeb02: Pull complete </span><br><span class="line">5989106db7fb: Pull complete </span><br><span class="line">c9d12ea9fc45: Pull complete </span><br><span class="line">68317fcc0aa1: Pull complete </span><br><span class="line">83ef48200e63: Pull complete </span><br><span class="line">c6eb26bf54de: Pull complete </span><br><span class="line">1bcf3170bbc2: Pull complete </span><br><span class="line">Digest: sha256:190cbd5234c4aad993b852d5f118ecfba5499adc6f752026938bce0eca754b0c</span><br><span class="line">Status: Downloaded newer image for index.tenxcloud.com/tenxcloud/centos:latest</span><br><span class="line"></span><br><span class="line">//查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xymtest                                           0.1                 8a758d16a99b        22 hours ago        113MB</span><br><span class="line">ubuntu                                            latest              c9d990395902        32 hours ago        113MB</span><br><span class="line">centos                                            latest              e934aafc2206        7 days ago          199MB</span><br><span class="line">registry                                          latest              d1fd7d86a825        3 months ago        33.3MB</span><br><span class="line">index.tenxcloud.com/tenxcloud/centos              latest              6e7516266d96        23 months ago       310MB</span><br></pre></td></tr></table></figure><h2 id="搭建本地私有仓库"><a href="#搭建本地私有仓库" class="headerlink" title="搭建本地私有仓库"></a>搭建本地私有仓库</h2><h3 id="1、使用registry镜像创建私有仓库"><a href="#1、使用registry镜像创建私有仓库" class="headerlink" title="1、使用registry镜像创建私有仓库"></a>1、使用registry镜像创建私有仓库</h3><p>安装Docker后，可以通过官方提供的<code>registry</code>镜像来简单搭建一套本地私有仓库环境：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在本地启动registry镜像，作为私有服务器，监听5000端口</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 registry</span><br><span class="line">Unable to find image &apos;registry:latest&apos; locally</span><br><span class="line">latest: Pulling from library/registry</span><br><span class="line">81033e7c1d6a: Pull complete </span><br><span class="line">b235084c2315: Pull complete </span><br><span class="line">c692f3a6894b: Pull complete </span><br><span class="line">ba2177f3a70e: Pull complete </span><br><span class="line">a8d793620947: Pull complete </span><br><span class="line">Digest: sha256:672d519d7fd7bbc7a448d17956ebeefe225d5eb27509d8dc5ce67ecb4a0bce54</span><br><span class="line">Status: Downloaded newer image for registry:latest</span><br><span class="line">67083c200be2f6a043377a9b4d69af24d0ba9c58a140b753634f5be4ede67464</span><br></pre></td></tr></table></figure><p>这将自动下载并启动一个<code>registry</code>容器，创建本地的私有仓库服务。默认情况下，会将仓库创建在容器的<code>/tmp/registry</code>目录下。可以通过-v参数来将镜像文件存放在本地的指定路径。例如以下实例将上传的镜像放到<code>/opt/data/registry</code>目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//在本地启动registry镜像，作为私有服务器，监听5000端口,并指定本地目录数据卷/opt/data/registry，映射容器内/tmp/registry目录</span><br><span class="line">[root@xxx ~]# docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry</span><br><span class="line">5b9a1ad53352c4e3a6f5bf7d70ef9a6d573cb4da064fb24f8f406444d125555c</span><br></pre></td></tr></table></figure><h3 id="2、管理私有仓库"><a href="#2、管理私有仓库" class="headerlink" title="2、管理私有仓库"></a>2、管理私有仓库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//标记镜像</span><br><span class="line">[root@xxx ~]# docker tag xymtest:0.1 192.168.206.128:5000/test</span><br><span class="line"></span><br><span class="line">//上传镜像</span><br><span class="line">[root@xxx ~]# docker push 192.168.206.128:5000/test</span><br><span class="line">The push refers to repository [192.168.206.128:5000/test]</span><br><span class="line">Get https://192.168.206.128:5000/v2/: http: server gave HTTP response to HTTPS client</span><br><span class="line"></span><br><span class="line">//编辑daemon.json,配置，&quot;insecure-registries&quot;:[&quot;192.168.206.128:5000&quot;]，表示信任这个私有仓库，不进行安全证书检查</span><br><span class="line">[root@xxx docker]# pwd</span><br><span class="line">/etc/docker</span><br><span class="line">[root@xxx docker]# cat daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  //表示信任这个私有仓库，不进行安全证书检查</span><br><span class="line">  &quot;insecure-registries&quot;:[&quot;192.168.206.128:5000&quot;],</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://4vehewku.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//重启docker 服务</span><br><span class="line">[root@xxx docker]# systemctl restart docker</span><br><span class="line"></span><br><span class="line">//推送本地镜像到私有仓库</span><br><span class="line">[root@xxx docker]# docker push 192.168.206.128:5000/test</span><br><span class="line">The push refers to repository [192.168.206.128:5000/test]</span><br><span class="line">6d7697f5e458: Pushed </span><br><span class="line">a8de0e025d94: Pushed </span><br><span class="line">a5e66470b281: Pushed </span><br><span class="line">ac7299292f8b: Pushed </span><br><span class="line">e1a9a6284d0d: Pushed </span><br><span class="line">fccbfa2912f0: Pushed </span><br><span class="line">latest: digest: sha256:46d25028e0eb194348b8b1256b1375238b44116a018de67f3318a1bb9954ee9d size: 1564</span><br><span class="line"></span><br><span class="line">//下载刚刚上传的，私有仓库镜像</span><br><span class="line">[root@xxx docker]# docker pull 192.168.206.128:5000/test</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from test</span><br><span class="line">Digest: sha256:46d25028e0eb194348b8b1256b1375238b44116a018de67f3318a1bb9954ee9d</span><br><span class="line">Status: Downloaded newer image for 192.168.206.128:5000/test:latest</span><br></pre></td></tr></table></figure><p>如果要使用安全证书，我们也可以从较知名的CA服务商（如<code>verisign</code>）申请公开的<code>SSL/TLS</code>证书，或者使用<code>openssl</code>等软件自行生成。</p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker仓库 </tag>
            
            <tag> login命令 </tag>
            
            <tag> search命令 </tag>
            
            <tag> pull命令 </tag>
            
            <tag> 本地搭建私有仓库配置 </tag>
            
            <tag> 时速云镜像仓库 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 基本操作之容器</title>
      <link href="/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E5%AE%B9%E5%99%A8/"/>
      <url>/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E5%AE%B9%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>容器是Docker的另一个核心概念。简单来说，容器时镜像的一个运行实例。所不同的是，镜像是静态只读文件，而容器带有运行时需要的可写文件层。如果认为虚拟机是模拟运行的一整套操作系统（包括内核、应用运行环境和其他系统环境）和跑在上面的应用，那么Docker容器就是独立运行的一个（或一组）应用，以及它们必须的运行环境。</p><h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><h3 id="1、新建容器"><a href="#1、新建容器" class="headerlink" title="1、新建容器"></a>1、新建容器</h3><p>命令格式：<code>docker create [OPTIONS] IMAGE [COMMAND] [ARG...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --add-host list                  Add a custom host-to-IP mapping (host:ip)</span><br><span class="line">  -a, --attach list                    Attach to STDIN, STDOUT or STDERR</span><br><span class="line">      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)</span><br><span class="line">      --blkio-weight-device list       Block IO weight (relative device weight) (default [])</span><br><span class="line">      --cap-add list                   Add Linux capabilities</span><br><span class="line">      ...</span><br></pre></td></tr></table></figure><p>Create命令和后续的run命令支持的选项都十分复杂，主要包括如下几大类：与容器运行模式相关、与容器和环境配置相关、与容器资源限制和安全保护相关。</p><p>Create命令与容器运行模式相关的选项见下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b1-i_epub.jpg" alt="Create命令与容器运行模式相关的选项"></p><p>Create命令与容器环境和配置相关选项如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b2-i_epub.jpg" alt="Create命令与容器环境和配置相关选项1"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b2x-i_epub.jpg" alt="Create命令与容器环境和配置相关选项2"></p><p>Create命令与容器资源限制和安全保护相关选项如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b3-i_epub.jpg" alt="Create命令与容器资源限制和安全保护相关选项1"></p><p><img src="http://op7wplti1.bkt.clouddn.com/1900654235_4b3x-i_epub.jpg" alt="Create命令与容器资源限制和安全保护相关选项2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//根据镜像创建一个容器</span><br><span class="line">[root@xxx /]# docker create -it registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04 </span><br><span class="line">d26cbeecf22d92fdff515a9bb8146521c8e4c6ea76cf7baab5abebb4b31dfc52</span><br><span class="line"></span><br><span class="line">//查看docker本地所有容器,注意状态为Created</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   8 seconds ago       Created                                 practical_wright</span><br><span class="line"></span><br><span class="line">//使用start启动docker容器</span><br><span class="line">[root@xxx /]# docker start d26</span><br><span class="line">d26</span><br><span class="line"></span><br><span class="line">//查看docker本地所有容器,注意状态为Up</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   41 seconds ago      Up 2 seconds                            practical_wright</span><br></pre></td></tr></table></figure><p>其他比较重要的选项还包括：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-l，--label=[]：以键值对方式指定容器的标签信息;</span><br><span class="line"></span><br><span class="line">--label-file=[]：从文件读取标签信息。</span><br></pre></td></tr></table></figure><h3 id="2、启动容器"><a href="#2、启动容器" class="headerlink" title="2、启动容器"></a>2、启动容器</h3><p>命令格式：<code>docker start [OPTIONS] CONTAINER [CONTAINER...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Exited</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS                       PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   14 minutes ago      Exited (137) 5 seconds ago                       practical_wright</span><br><span class="line"></span><br><span class="line">//使用start启动容器</span><br><span class="line">[root@xxx /]# docker start d26cb</span><br><span class="line">d26cb</span><br><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Up</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d26cbeecf22d        registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04   &quot;/bin/sh -c &apos;/usr/sb…&quot;   14 minutes ago      Up 2 seconds</span><br></pre></td></tr></table></figure><h3 id="3、新建并启动容器"><a href="#3、新建并启动容器" class="headerlink" title="3、新建并启动容器"></a>3、新建并启动容器</h3><p>除了创建容器后通过start命令来启动，也可以直接新建并启动容器。所需要的命令主要为<code>docker run</code>,等价于先执行<code>docker create</code>命令，再执行<code>docker start</code>命令。<br>例如，下面的命令输出一个“Hello World”，之后容器自动终止：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//创建容器并执行一个输出命令</span><br><span class="line">[root@xxx /]# docker run ubuntu:latest /bin/echo &quot;Hello World&quot;</span><br><span class="line">Hello World</span><br><span class="line"></span><br><span class="line">//查看本地所有Docker容器，注意状态为Exited</span><br><span class="line">[root@xxx /]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">3fa47db4c105        ubuntu:latest       &quot;/bin/echo &apos;Hello Wo…&quot;   8 seconds ago       Exited (0) 7 seconds ago                       elated_goldwasser</span><br></pre></td></tr></table></figure><p>这跟在本地直接执行<code>/bin/echo &quot;Hello World&quot;</code>几乎感觉不出任何区别。当利用<code>docker run</code>来创建并启动容器时，Docker在后台运行的标准操作：  </p><ul><li>检查本地是否存在指定的镜像，不存在就从共有仓库下载；</li><li>利用镜像创建容器，并启动该容器；</li><li>分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层；</li><li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中；</li><li>从网桥的地址池配置一个IP地址给容器；</li><li>执行用户指定的应用程序</li><li>执行完毕后容器被自动终止</li></ul><p>启动一个终端，并允许用户进行交互：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//其中-t选项当Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上，-i则让容器的标准输入保持打开。</span><br><span class="line">[root@xxx /]# docker run -it ubuntu:latest /bin/bash</span><br><span class="line">root@21536661367e:/# pwd</span><br><span class="line">/</span><br><span class="line"></span><br><span class="line">//用户可以在交互模式下输入系统命令进行操作</span><br><span class="line">root@21536661367e:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line"></span><br><span class="line">//用户可以在交互模式下输入系统命令进行操作，使用ps可以看到系统只运行了bash应用，并没有运行其他无关的进程</span><br><span class="line">root@21536661367e:/# ps</span><br><span class="line">   PID TTY          TIME CMD</span><br><span class="line">     1 pts/0    00:00:00 bash</span><br><span class="line">    10 pts/0    00:00:00 ps</span><br><span class="line">    </span><br><span class="line">//用户可以输入exit或ctrl+d来退出容器</span><br><span class="line">root@21536661367e:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@xxx /]#</span><br></pre></td></tr></table></figure><p>对于所创建的bash容器，当使用exit命令退出之后，容器就自动处于退出（Exited）状态了。这是因为对Docker容器来说，当运行的应用退出后，容器也就没有必要继续运行了。<br>某些时候，执行<code>docker run</code>会出错，因为命令无法正常执行容器会直接退出，此时可以查看退出的错误代码。  </p><ul><li>125：Docker daemon执行出错，例如指定了不支持的Docker命令参数；</li><li>126：所指定的命令无法执行，例如权限出错。</li><li>127：容器内命令无法找到；</li></ul><p>命令执行出错后，会默认返回错误码。</p><h3 id="4、守护态运行"><a href="#4、守护态运行" class="headerlink" title="4、守护态运行"></a>4、守护态运行</h3><p>更多的时候，需要让Docker容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加-d参数来实现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//-d参数以后台模式启动Docker，返回容器id</span><br><span class="line">[root@xxx ~]# docker run -d ubuntu:latest /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;</span><br><span class="line">5d4cfe5b4b6109fd8df8717fcd87790e7692f70d7e8e8d7590ba4c269f6dd717</span><br><span class="line"></span><br><span class="line">//通过docker ps查看运行的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   13 seconds ago      Up 12 seconds                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//使用docker logs命令获取容器输出信息</span><br><span class="line">[root@xxx ~]# docker logs 5d4c</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br></pre></td></tr></table></figure><h2 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h2><p>命令格式：<code>docker stop [OPTIONS] CONTAINER [CONTAINER...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -t, --time int   Seconds to wait for stop before killing it (default 10)</span><br></pre></td></tr></table></figure></p><p>原理：首先向容器发送SIGTERM信号,等待一段超时时间（默认10秒）后，再发送SIGKILL信号来终止容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//终止前</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   16 minutes ago      Up 16 minutes                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//发送终止命令</span><br><span class="line">[root@xxx ~]# docker stop 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//终止后状态为Exited</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                        PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   18 minutes ago      Exited (137) 56 seconds ago                       thirsty_lewin</span><br></pre></td></tr></table></figure></p><ul><li>使用<code>docker kill</code>命令会直接发送SIGKILL信号来强行终止容器。</li><li>当容器中指定的应用终结时，容器也会自动终止。</li><li>使用<code>docker start</code>可以重新启动处于终止状态的容器。</li><li>使用<code>docker restart</code>命令会将一个运行态的容器先终止，然后再重新启动</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//重新启动已终止的容器</span><br><span class="line">[root@xxx ~]# docker start 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   25 minutes ago      Up 6 seconds                            thirsty_lewin</span><br><span class="line"></span><br><span class="line">//发送SIGKILL信号来强行终止容器</span><br><span class="line">[root@xxx ~]# docker kill 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line"></span><br><span class="line">//重启容器</span><br><span class="line">[root@xxx ~]# docker restart 5d4c</span><br><span class="line">5d4c</span><br><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   25 minutes ago      Up 1 second                             thirsty_lewin</span><br></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><p>在使用-d参数时，容器启动后会进入后台，用户无法看到容器中的信息，也无法操作。这个时候如果要进入容器进行操作，有三种方法：</p><h3 id="1、使用attach命令"><a href="#1、使用attach命令" class="headerlink" title="1、使用attach命令"></a>1、使用attach命令</h3><p>命令格式：<code>docker attach [OPTIONS] CONTAINER</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --detach-keys string   指定退出attach模式的快捷键序列，默认是ctrl+q ctrl+p;</span><br><span class="line">      --no-stdin             是否关闭标准输入，默认是保持打开</span><br><span class="line">      --sig-proxy            是否代理收到的系统信号给应用进程，默认为true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker run -itd ubuntu /bin/bash</span><br><span class="line">3535fd6c5ccab3c4d4737c1385ac18c36bd190c129c70c664fbf8c62a1707e67</span><br><span class="line">[root@xxx ~]# docker attach 3535</span><br><span class="line">root@3535fd6c5cca:/# </span><br><span class="line">root@3535fd6c5cca:/# ls</span><br><span class="line">bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p><p>attach命令缺点：当多个窗口同时用attach命令连到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时，其他窗口也无法执行操作了。</p><h3 id="2、使用exec命令（exec命令用于从外部运行容器内部的命令）"><a href="#2、使用exec命令（exec命令用于从外部运行容器内部的命令）" class="headerlink" title="2、使用exec命令（exec命令用于从外部运行容器内部的命令）"></a>2、使用exec命令（exec命令用于从外部运行容器内部的命令）</h3><p>命令格式：<code>docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -d, --detach               以后台模式运行命令</span><br><span class="line">      --detach-keys string   Override the key sequence for detaching a container</span><br><span class="line">  -e, --env list             设置环境变量</span><br><span class="line">  -i, --interactive          打开标准输入接受用户输入命令，默认为false</span><br><span class="line">      --privileged           Give extended privileges to the command</span><br><span class="line">  -t, --tty                  分配一个伪终端，默认为false</span><br><span class="line">  -u, --user string          执行命令的用户名或ID</span><br><span class="line">  -w, --workdir string       Working directory inside the container</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up About a minute                       thirsty_lewin</span><br><span class="line"></span><br><span class="line">//使用exec进入后台运行的镜像中</span><br><span class="line">[root@xxx ~]# docker exec -it thirsty_lewin /bin/bash</span><br><span class="line">root@5d4cfe5b4b61:/#</span><br></pre></td></tr></table></figure></p><p>通过以上可以看出，一个bash终端被打开了，在不影响容器内其他应用的前提下，用户可以很容易与容器进行交互。</p><p>注意：通过指定<code>-it</code>参数来保持标准输入打开，并且分配一个伪终端。通过<code>exec</code>命令对容器执行操作是最为推荐的方式。</p><h3 id="3、使用第三方nsenter工具"><a href="#3、使用第三方nsenter工具" class="headerlink" title="3、使用第三方nsenter工具"></a>3、使用第三方<code>nsenter</code>工具</h3><p>在<code>util-linux</code>软件包版本2.23+中包含<code>nsenter</code>工具，如果系统中的<code>util-linux</code>包没有该命令，可以按照下面方式从源码安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ cd /emp;curl https://mirrors.edge.kernel.org/pub/linux/utils/util-linux/v2.32/util-linux-2.32.tar.gz | tar -zxvf;</span><br><span class="line">cd util-linux-2.32;</span><br><span class="line"></span><br><span class="line">$ ./configure --without-ncurses</span><br><span class="line"></span><br><span class="line">$ make nsenter &amp;&amp; cp nsenter /usr/local/bin</span><br></pre></td></tr></table></figure><p>为了使用<code>nsenter</code> 连接到容器，还需要找到容器PID，可以通过下面的命令获取：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//获取容器运行PID</span><br><span class="line">PID=$(docker inspect --format&quot;&#123;% raw %&#125;&#123;&#123;.State.Pid&#125;&#125;&#123;% endraw %&#125;&quot; &lt;container&gt;)</span><br><span class="line"></span><br><span class="line">//通过PID，连接到容器：</span><br><span class="line">`nsenter --target $PID --mount --uts --ipc --net --pid`</span><br></pre></td></tr></table></figure><p>下面使用完整的命令执行该操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">//查看运行容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up 4 minutes                            thirsty_lewin</span><br><span class="line"></span><br><span class="line">//查看运行容器进程PID</span><br><span class="line">[root@xxx ~]# docker inspect --format &quot;&#123;% raw %&#125;&#123;&#123;.State.Pid&#125;&#125;&#123;% endraw %&#125;&quot; thirsty_lewin</span><br><span class="line">18637</span><br><span class="line"></span><br><span class="line">//进入容器</span><br><span class="line">[root@xxx ~]# nsenter --target 18637 --mount --uts --ipc --net --pid</span><br><span class="line">mesg: ttyname failed: No such file or directory</span><br><span class="line"></span><br><span class="line">//查看用户</span><br><span class="line">root@5d4cfe5b4b61:~# w</span><br><span class="line"> 15:22:55 up 15:59,  0 users,  load average: 0.03, 0.04, 0.05</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br></pre></td></tr></table></figure><h2 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h2><p>可以使用docker rm命令来删除处于终止或退出状态的容器。</p><p>命令格式：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -f, --force     强制终止并删除一个运行中的容器</span><br><span class="line">  -l, --link      删除容器的连接但保留容器</span><br><span class="line">  -v, --volumes   删除容器挂载的数据卷</span><br><span class="line"></span><br><span class="line">//查看运行中的容器</span><br><span class="line">[root@xxx ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">5d4cfe5b4b61        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   About an hour ago   Up 14 minutes                           thirsty_lewin</span><br><span class="line"></span><br><span class="line">//删除运行状态的容器</span><br><span class="line">[root@xxx ~]# docker rm 5d4c</span><br><span class="line">Error response from daemon: You cannot remove a running container 5d4cfe5b4b6109fd8df8717fcd87790e7692f70d7e8e8d7590ba4c269f6dd717. Stop the container before attempting removal or force remove</span><br><span class="line"></span><br><span class="line">//强制删除运行状态的容器</span><br><span class="line">[root@xxx ~]# docker rm -f 5d4c</span><br><span class="line">5d4c</span><br></pre></td></tr></table></figure><h2 id="导入和导出容器"><a href="#导入和导出容器" class="headerlink" title="导入和导出容器"></a>导入和导出容器</h2><p>某些时候，需要将容器从一个系统迁移到另外一个系统，此时可以使用docker的导入和导出功能。</p><h3 id="1、导出容器"><a href="#1、导出容器" class="headerlink" title="1、导出容器"></a>1、导出容器</h3><p>导出容器是指导出一个已经创建的容器到一个文件，不管此时这个容器是否处于运行状态。<br>命令格式：<code>docker export [OPTIONS] CONTAINER</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -o, --output string  指定导出的tar归档文件，也可直接通过重定向来实现。</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">//显示所有容器</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                    PORTS               NAMES</span><br><span class="line">684d1d0dc403        ubuntu:latest       &quot;/bin/sh -c &apos;while t…&quot;   19 seconds ago      Up 18 seconds                                 vigorous_brahmagupta</span><br><span class="line">3fa47db4c105        ubuntu:latest       &quot;/bin/echo &apos;Hello Wo…&quot;   11 hours ago        Exited (0) 11 hours ago                       elated_goldwasser</span><br><span class="line"></span><br><span class="line">//将运行中的容器导出tar文件</span><br><span class="line">[root@xx ~]# docker export -o test_for_run.tar 684d</span><br><span class="line"></span><br><span class="line">//将已经退出的容器导出tar文件</span><br><span class="line">[root@xxx ~]# docker export 3fa4 &gt; test_for_stop.tar</span><br></pre></td></tr></table></figure><p>之后，可将导出的tar文件传输到其他机器上，然后再通过导入命令导入到系统中，从而实现容器的迁移。</p><h3 id="2、导入容器"><a href="#2、导入容器" class="headerlink" title="2、导入容器"></a>2、导入容器</h3><p>导出的文件又可以使用<code>docker import</code>命令导入变成镜像。<br>命令格式：<code>docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -c, --change list      在导入的同时执行对容器进行修改的Dockerfile指令</span><br><span class="line">  -m, --message string   Set commit message for imported image</span><br><span class="line"></span><br><span class="line">//将tar文件导入系统中</span><br><span class="line">[root@xxx ~]# docker import test_for_run.tar xym/ubuntu:1.0</span><br><span class="line">sha256:f916030e78e9046defa752bfc32a99b96460e098d3ee1cab1a5048150255d27e</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xym/ubuntu                                        1.0                 f916030e78e9        2 seconds ago       85.8MB</span><br><span class="line">centos-7                                          import              be5e039acd03        19 hours ago        435MB</span><br></pre></td></tr></table></figure><p>之前镜像章节中介绍过使用<code>docker load</code>命令来导入一个镜像文件，与<code>docker import</code>命令十分类似。</p><p>实际上，既可以使用<code>docker load</code>命令来导入镜像存储文件到本地镜像库，也可以使用<code>docker import</code>命令来导入一个容器快照到本地镜像库。</p><p>这二者的区别在于容器快照文件将丢弃所有历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。此外，从容器快照文件导入时可以重新指定标签。</p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker容器 </tag>
            
            <tag> create命令 </tag>
            
            <tag> start命令 </tag>
            
            <tag> run命令 </tag>
            
            <tag> stop命令 </tag>
            
            <tag> restart命令 </tag>
            
            <tag> attach命令 </tag>
            
            <tag> exec命令 </tag>
            
            <tag> rm命令 </tag>
            
            <tag> export命令 </tag>
            
            <tag> import命令 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker 基本操作之镜像</title>
      <link href="/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E9%95%9C%E5%83%8F/"/>
      <url>/2018/04/13/Docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%B9%8B%E9%95%9C%E5%83%8F/</url>
      <content type="html"><![CDATA[<h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><p>命令格式：<code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --all-tags               是否获取仓库中所有镜像，默认为否</span><br><span class="line">      --disable-content-trust  是否跳过镜像校验，默认为是</span><br></pre></td></tr></table></figure></p><ul><li>如果不显示指定TAG，默认拉取latest</li><li>镜像文件是由若干层（layer）组成，层的唯一标识是以一个256比特的64个十六进程字符构成。使用docker pull下载时会获取各层的信息。当不同的镜像包括相同的层时，本地仅会存储层的一份内容，减小了需要的存储空间。</li><li>当仓库地址（registry，注册服务器）省略不写时，默认使用<code>docker hub</code>服务器，如果从非官方仓库下载，则需要在仓库名称前指定完整的镜像注册服务器地址（e.g. hub.c.163.com/library/）。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//去网易蜂巢拉取镜像仓库  </span><br><span class="line">[root@xxx ~]# docker pull hub.c.163.com/library/memcached:latest </span><br><span class="line">latest: Pulling from library/memcached</span><br><span class="line">810fd2d89f8f: Pull complete </span><br><span class="line">0f1e2d8abe76: Pull complete </span><br><span class="line">b9608bffd4d0: Pull complete </span><br><span class="line">a6554c2d9f43: Pull complete </span><br><span class="line">40661d641679: Pull complete </span><br><span class="line">Digest: sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Status: Downloaded newer image for hub.c.163.com/library/memcached:latest</span><br></pre></td></tr></table></figure><h2 id="列出镜像"><a href="#列出镜像" class="headerlink" title="列出镜像"></a>列出镜像</h2><p>命令格式：<code>docker images [OPTIONS] [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --all             显示所有镜像（包括临时文件），默认为否</span><br><span class="line">      --digests         列出镜像的数字摘要值，默认为否</span><br><span class="line">  -f, --filter filter   过滤列出的镜像</span><br><span class="line">      --format string   控制输出格式</span><br><span class="line">      --no-trunc        对输出结果中太长部分是否进行截断，如镜像ID信息，默认为是</span><br><span class="line">  -q, --quiet           仅输出ID信息，默认为否</span><br><span class="line"></span><br><span class="line">---------------------------------------------------------------------------------------------------</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        About an hour ago   435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        About an hour ago   222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        32 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><ul><li>REPOSITORY:来源于哪个仓库，比如Ubuntu仓库用来保存Ubuntu系列的基础镜像。</li><li>TAG：镜像标签信息，用来标注不同的版本信息。如：14.04、latest等。</li><li>IMAGE ID：镜像的ID（唯一标识镜像），如hub.c.163.com/public/ubuntu：14.04和163ubuntu：14.04镜像的ID都是2fe5c4bba1f9，说明目前他们指向同一个镜像</li><li>CREATED：说明镜像的更新时间</li><li>镜像大小，优秀的镜像往往体积都较小</li></ul><p>其中镜像的ID信息十分重要，它唯一标识了镜像。在使用镜像ID的时候，一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID。</p><p>TAG信息用来标识来自同一个仓库的不同镜像。例如ubuntu仓库中有多个镜像，通过TAG信息来区分发行版本，包括10.04、12.04、12.10、14.04等标签。</p><p>镜像大小信息只是表示该镜像的逻辑体积大小，实际上由于相同的镜像本地只会存储一份，物理占用的存储空间会小于各镜像的逻辑体积之和。</p><p>更多子命令选项还可以通过<code>man docker-images</code>帮助命令来查看。</p><h2 id="使用tag命令添加镜像标签"><a href="#使用tag命令添加镜像标签" class="headerlink" title="使用tag命令添加镜像标签"></a>使用tag命令添加镜像标签</h2><p>命令格式：<code>docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker tag hub.c.163.com/public/ubuntu:14.04 163ubuntu:14.04 </span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        About an hour ago   435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        2 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        32 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">[root@xxx ~]#</span><br></pre></td></tr></table></figure><p>为了方便后续工作中使用特定镜像，还可以使用docker tag命令来为本地镜像任意添加新的标签。例如添加一个新的<code>163ubuntu:14.04</code>镜像标签。之后用户就可以直接使用<code>163ubuntu:14.04</code>来表示这个镜像了。观察<code>163ubuntu:14.04</code>的ID跟源镜像<code>hub.c.163.com/public/ubuntu:14.04</code>完全一致。他们实际上指向同一个镜像文件，只是别名不同而已。<code>docker tag</code>命令添加的标签实际上起到了类似连接的作用。</p><h2 id="使用inspect命令查看详细信息"><a href="#使用inspect命令查看详细信息" class="headerlink" title="使用inspect命令查看详细信息"></a>使用inspect命令查看详细信息</h2><p>命令格式：<code>docker inspect [OPTIONS] NAME|ID [NAME|ID...]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --format string   使用指定的模板，格式化输出</span><br><span class="line">  -s, --size            如果是容器类型，表示其总大小</span><br><span class="line">      --type string     返回指定类型的json格式</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker inspect 163ubuntu:14.04 </span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Id&quot;: &quot;sha256:2fe5c4bba1f935f179e83cd5354403d1231ffc9df9c1621967194410eaf8d942&quot;,</span><br><span class="line">        &quot;RepoTags&quot;: [</span><br><span class="line">            &quot;163ubuntu:14.04&quot;,</span><br><span class="line">            &quot;hub.c.163.com/public/ubuntu:14.04&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;hub.c.163.com/public/ubuntu@sha256:ffc2fc66f8e0bfa4b417b817054d3ebec130c8db44342b8fa394e25779633257&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;Parent&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Comment&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2016-03-16T03:29:48.276492132Z&quot;,</span><br><span class="line">        &quot;Container&quot;: &quot;f807d2c2c41cc21db9201605a962047278719a09cb945d0a3d5a2a587d978769&quot;,</span><br><span class="line">        &quot;ContainerConfig&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;f807d2c2c41c&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [],</span><br><span class="line">            &quot;Cmd&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;#(nop) ENTRYPOINT &amp;&#123;[\&quot;/bin/sh\&quot; \&quot;-c\&quot; \&quot;/usr/sbin/sshd -D\&quot;]&#125;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;Image&quot;: &quot;7c5c7629089e80dea49161f10c36678cc8934601a730f8f8eb2a58d2e14c6610&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;/usr/sbin/sshd -D&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;DockerVersion&quot;: &quot;1.9.1&quot;,</span><br><span class="line">        &quot;Author&quot;: &quot;&quot;,</span><br><span class="line">        &quot;Config&quot;: &#123;</span><br><span class="line">            &quot;Hostname&quot;: &quot;f807d2c2c41c&quot;,</span><br><span class="line">            &quot;Domainname&quot;: &quot;&quot;,</span><br><span class="line">            &quot;User&quot;: &quot;&quot;,</span><br><span class="line">            &quot;AttachStdin&quot;: false,</span><br><span class="line">            &quot;AttachStdout&quot;: false,</span><br><span class="line">            &quot;AttachStderr&quot;: false,</span><br><span class="line">            &quot;Tty&quot;: false,</span><br><span class="line">            &quot;OpenStdin&quot;: false,</span><br><span class="line">            &quot;StdinOnce&quot;: false,</span><br><span class="line">            &quot;Env&quot;: [],</span><br><span class="line">            &quot;Cmd&quot;: null,</span><br><span class="line">            &quot;Image&quot;: &quot;7c5c7629089e80dea49161f10c36678cc8934601a730f8f8eb2a58d2e14c6610&quot;,</span><br><span class="line">            &quot;Volumes&quot;: null,</span><br><span class="line">            &quot;WorkingDir&quot;: &quot;&quot;,</span><br><span class="line">            &quot;Entrypoint&quot;: [</span><br><span class="line">                &quot;/bin/sh&quot;,</span><br><span class="line">                &quot;-c&quot;,</span><br><span class="line">                &quot;/usr/sbin/sshd -D&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;OnBuild&quot;: null,</span><br><span class="line">            &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Architecture&quot;: &quot;amd64&quot;,</span><br><span class="line">        &quot;Os&quot;: &quot;linux&quot;,</span><br><span class="line">        &quot;Size&quot;: 237059566,</span><br><span class="line">        &quot;VirtualSize&quot;: 237059566,</span><br><span class="line">        &quot;GraphDriver&quot;: &#123;</span><br><span class="line">            &quot;Data&quot;: &#123;</span><br><span class="line">                &quot;DeviceId&quot;: &quot;27&quot;,</span><br><span class="line">                &quot;DeviceName&quot;: &quot;docker-253:0-102127602-c30e1cbfce6f98d947b8df2100734cddf113980a3ccdb356a1b84f27825a3dbe&quot;,</span><br><span class="line">                &quot;DeviceSize&quot;: &quot;10737418240&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;Name&quot;: &quot;devicemapper&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;RootFS&quot;: &#123;</span><br><span class="line">            &quot;Type&quot;: &quot;layers&quot;,</span><br><span class="line">            &quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:89688d062a0607fb50d0955de8964659e66f1bb41164b2d2b473d1edd7d8af90&quot;,</span><br><span class="line">                &quot;sha256:704e51eef17861bc3a2a7355709a7ce0b11ab720cc1b0e00235f984b33494b0e&quot;,</span><br><span class="line">                &quot;sha256:98b4fca781e7eab1cfb4d6427b60c4490b4c7d71a0bca622c7dd03cecb657a6d&quot;,</span><br><span class="line">                &quot;sha256:a695e8d298aaf8ee68638151e6068518475130eccdd224ba0591981f212e5ea2&quot;,</span><br><span class="line">                &quot;sha256:836a329bec9925c8fc76232885344a0053d19534ae108e5cbc111490481b5778&quot;,</span><br><span class="line">                &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Metadata&quot;: &#123;</span><br><span class="line">            &quot;LastTagTime&quot;: &quot;2018-04-13T10:03:07.660866339+08:00&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>更多用法请使用<code>man docker-inspect</code>帮助命令。</p><h2 id="使用history命令查看镜像历史"><a href="#使用history命令查看镜像历史" class="headerlink" title="使用history命令查看镜像历史"></a>使用history命令查看镜像历史</h2><p>命令格式：<code>docker history [OPTIONS] IMAGE</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --format string   指定格式化模板输出</span><br><span class="line">  -H, --human           Print sizes and dates in human readable format (default true)</span><br><span class="line">      --no-trunc        Don&apos;t truncate output</span><br><span class="line">  -q, --quiet           Only show numeric IDs</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker history 163ubuntu:14.04 </span><br><span class="line">IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class="line">2fe5c4bba1f9        2 years ago         /bin/sh -c #(nop) ENTRYPOINT &amp;&#123;[&quot;/bin/sh&quot; &quot;-…   0B                  </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i &apos;s/#PasswordAuthentication…   2.54kB              </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c mkdir /var/run/sshd                  0B                  </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c apt-get update &amp;&amp; apt-get install…   69.3MB              </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop) ADD file:b7283a2724cc73e4c…   872B                </span><br><span class="line">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop) ADD file:9f6d0ad171ede3597…   168MB</span><br></pre></td></tr></table></figure><h2 id="镜像搜寻"><a href="#镜像搜寻" class="headerlink" title="镜像搜寻"></a>镜像搜寻</h2><p>命令格式：<code>docker search [OPTIONS] TERM</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --filter filter   Filter output based on conditions provided</span><br><span class="line">      --format string   Pretty-print search using a Go template</span><br><span class="line">      --limit int       Max number of search results (default 25)</span><br><span class="line">      --no-trunc        Don&apos;t truncate output</span><br><span class="line">      </span><br><span class="line">      Filter</span><br><span class="line">             Filter output based on these conditions:</span><br><span class="line">                - stars=&lt;numberOfStar&gt; 指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像</span><br><span class="line">                - is-automated=(true|false) 仅显示自动创建的镜像，默认为否</span><br><span class="line">                - is-official=(true|false) 仅显示官方的镜像，默认为否</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">//搜索所有自动创建且评价为20+的带nginx关键字的镜像</span><br><span class="line">[root@xxx ~]# docker search --filter=is-automated=true --filter=stars=20 nginx</span><br><span class="line">NAME                                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">jwilder/nginx-proxy                                    Automated Nginx reverse proxy for docker con…   1315                                    [OK]</span><br><span class="line">richarvey/nginx-php-fpm                                Container running Nginx + PHP-FPM capable of…   544                                     [OK]</span><br><span class="line">jrcs/letsencrypt-nginx-proxy-companion                 LetsEncrypt container to use with nginx as p…   348                                     [OK]</span><br><span class="line">webdevops/php-nginx                                    Nginx with PHP-FPM                              99                                      [OK]</span><br><span class="line">zabbix/zabbix-web-nginx-mysql                          Zabbix frontend based on Nginx web-server wi…   49                                      [OK]</span><br><span class="line">bitnami/nginx                                          Bitnami nginx Docker Image                      48                                      [OK]</span><br><span class="line">1and1internet/ubuntu-16-nginx-php-phpmyadmin-mysql-5   ubuntu-16-nginx-php-phpmyadmin-mysql-5          33                                      [OK]</span><br></pre></td></tr></table></figure><ul><li>NAME：镜像名字</li><li>DESCRIPTION：描述</li><li>STARS：星级（表示该镜像受欢迎程度）</li><li>OFFICIAL：是否官方创建</li><li>AUTOMATED：是否自动创建</li></ul><p>默认结果按照星级评价进行排序。</p><h2 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h2><p>命令格式：<code>docker rmi [OPTIONS] IMAGE [IMAGE...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -f, --force      强制删除</span><br><span class="line">      --no-prune   Do not delete untagged parents</span><br></pre></td></tr></table></figure></p><h3 id="使用标签删除镜像"><a href="#使用标签删除镜像" class="headerlink" title="使用标签删除镜像"></a>使用标签删除镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">//删除前查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        2 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163ubuntu                         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">//删除镜像操作</span><br><span class="line">[root@xxx ~]# docker rmi 163ubuntu:14.04 </span><br><span class="line">Untagged: 163ubuntu:14.04</span><br><span class="line">//删除后查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        2 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：当同一个镜像拥有多个标签的时候，docker rmi命令只是删除该镜像多个标签中的指定标签而已，并不影响镜像文件。因此上述操作相当于只是删除了镜像<code>2fe5c4bba1f9</code>的一个标签而已。但当镜像只剩下一个标签的时候就要小心了,此时再使用<code>docker rmi</code>命令会彻底删除镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker rmi hub.c.163.com/library/memcached:latest </span><br><span class="line">Untagged: hub.c.163.com/library/memcached:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached@sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Deleted: sha256:8b057b9de580ce01fdce47c7ca1632ce03b925f9464afc0d91821b066f32204d</span><br><span class="line">Deleted: sha256:0382f79fb93ba9f862822a9c594019a32a39f5d46321e242a388c2e455d369e6</span><br><span class="line">Deleted: sha256:7f7bc5c738d847e3e2e647b467d3bb363bbbc99f53649cba7df71c2326fc183d</span><br><span class="line">Deleted: sha256:1c3bf91649b76e0956ab416404cb81bb30f1be5377316af42ecf680cb50c2d34</span><br><span class="line">Deleted: sha256:bbebfa4c46fd5f64fc0e0d71fc5c94448fa04fa0b20b74dc97ad0ec07cd8ff45</span><br><span class="line">Deleted: sha256:eb78099fbf7fdc70c65f286f4edc6659fcda510b3d1cfe1caa6452cc671427bf</span><br></pre></td></tr></table></figure><p>例如删除标签为<code>hub.c.163.com/library/memcached:latest</code>的镜像，由于该镜像没有额外的标签指向它，执行<code>docker rmi</code>命令，可以看出它会删除这个镜像文件的所有层。</p><h3 id="使用镜像ID删除镜像"><a href="#使用镜像ID删除镜像" class="headerlink" title="使用镜像ID删除镜像"></a>使用镜像ID删除镜像</h3><p>当使用docker rmi命令，并且后面跟上镜像的ID（也可能是能进行区分的部分ID串前缀）时，先会尝试删除所有指向该镜像的标签，然后删除该镜像本身。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">//删除前查看镜像</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                            7                   0b99289e40ee        3 hours ago         435MB</span><br><span class="line">test                              0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                       latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                            14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/library/memcached   latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">163mem                            latest              8b057b9de580        7 months ago        58.6MB</span><br><span class="line">hub.c.163.com/public/ubuntu       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line"></span><br><span class="line">//通过镜像ID删除镜像，提示多个镜像引用此镜像ID，必须使用-f 参数强制删除</span><br><span class="line">[root@xxx ~]# docker rmi 8b057b9de580</span><br><span class="line">Error response from daemon: conflict: unable to delete 8b057b9de580 (must be forced) - image is referenced in multiple repositories</span><br><span class="line">[root@xxx ~]# docker rmi -f 8b057b9de580</span><br><span class="line">Untagged: 163mem:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached:latest</span><br><span class="line">Untagged: hub.c.163.com/library/memcached@sha256:537918e564521a6aa1d4da202e33af500ecfcb4ab9be78d5a6f222ef919b3ba9</span><br><span class="line">Deleted: sha256:8b057b9de580ce01fdce47c7ca1632ce03b925f9464afc0d91821b066f32204d</span><br><span class="line">Deleted: sha256:0382f79fb93ba9f862822a9c594019a32a39f5d46321e242a388c2e455d369e6</span><br><span class="line">Deleted: sha256:7f7bc5c738d847e3e2e647b467d3bb363bbbc99f53649cba7df71c2326fc183d</span><br><span class="line">Deleted: sha256:1c3bf91649b76e0956ab416404cb81bb30f1be5377316af42ecf680cb50c2d34</span><br><span class="line">Deleted: sha256:bbebfa4c46fd5f64fc0e0d71fc5c94448fa04fa0b20b74dc97ad0ec07cd8ff45</span><br><span class="line">Deleted: sha256:eb78099fbf7fdc70c65f286f4edc6659fcda510b3d1cfe1caa6452cc671427bf</span><br><span class="line"></span><br><span class="line">//删除后查看镜像列表，发现与此ID关联的镜像都已删除成功</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                        7                   0b99289e40ee        3 hours ago         435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        3 hours ago         222MB</span><br><span class="line">hello-world                   latest              e38bc07ac18e        33 hours ago        1.85kB</span><br><span class="line">ubuntu                        14.04               a35e70164dfb        5 weeks ago         222MB</span><br><span class="line">hub.c.163.com/public/ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure></p><p><strong>注意</strong>：当有该镜像创建的容器存在时，镜像文件是无法被删除的，如要删除该镜像请先删除该容器，然后再删除镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//使用镜像运行容器</span><br><span class="line">[root@xxx ~]# docker run ubuntu:14.04 echo &quot;Hello&quot;</span><br><span class="line">Hello</span><br><span class="line">//查看所有状态容器</span><br><span class="line">[root@xxx ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS                     PORTS               NAMES</span><br><span class="line">8bdb6f330ec9        ubuntu:14.04                        &quot;echo Hello&quot;             7 seconds ago       Exited (0) 6 seconds ago                       determined_varahamihira</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">//使用标签删除镜像，提示被容器引用</span><br><span class="line">[root@xxx ~]# docker rmi ubuntu:14.04 </span><br><span class="line">Error response from daemon: conflict: unable to remove repository reference &quot;ubuntu:14.04&quot; (must force) - container 8bdb6f330ec9 is using its referenced image a35e70164dfb</span><br><span class="line"></span><br><span class="line">//无法强制删除</span><br><span class="line">[root@xxx ~]# docker rmi -f a35e70164dfb</span><br><span class="line">Error response from daemon: conflict: unable to delete a35e70164dfb (cannot be forced) - image has dependent child images</span><br><span class="line"></span><br><span class="line">//删除容器</span><br><span class="line">[root@xxx ~]# docker rm 8bdb6</span><br><span class="line">8bdb6</span><br><span class="line"></span><br><span class="line">//成功删除镜像</span><br><span class="line">[root@xxx ~]# docker rmi ubuntu:14.04 </span><br><span class="line">Untagged: ubuntu:14.04</span><br><span class="line">Untagged: ubuntu@sha256:ed49036f63459d6e5ed6c0f238f5e94c3a0c70d24727c793c48fded60f70aa96</span><br></pre></td></tr></table></figure><h2 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h2><p>创建镜像的方法有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。<br>先介绍前二种创建方式</p><h3 id="基于已有镜像的容器创建"><a href="#基于已有镜像的容器创建" class="headerlink" title="基于已有镜像的容器创建"></a>基于已有镜像的容器创建</h3><p>命令格式：<code>docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -a, --author string    作者信息</span><br><span class="line">  -c, --change list      提交的时候指定Dockerfile指令，包括CMD/ENTRYPOINT/ENV/EXPOSE/LABEL/ONBUILD/USER/VOLUME/WORKDIR等</span><br><span class="line">  -m, --message string   提交信息</span><br><span class="line">  -p, --pause            提交时暂停容器运行</span><br></pre></td></tr></table></figure><p>下面将演示如何使用该命令创建一个新镜像。首先，启动一个镜像，并在其中进行修改操作，例如创建一个test文件，之后推出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker run -it ubuntu:latest /bin/bash</span><br><span class="line">root@72ed7e58bc28:/# touch test</span><br><span class="line">root@72ed7e58bc28:/# exit</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p><p>记住此时的容器ID为：<code>72ed7e58bc28</code>,此时容器跟原<code>ubuntu:latest</code>镜像相比，已经发生了变化，可以使用docker commit命令来提交为一个新的镜像。提交的时候可以使用ID或名称来指定容器：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker commit -m &quot;提交一个新镜像&quot; -a &quot;xym&quot; 72ed7e58bc28 xymtest:0.1</span><br><span class="line">sha256:8a758d16a99b414b738bee50b485c3d99f6093c0c4002efd9dd5dd740efd2ee9</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">xymtest                       0.1                 8a758d16a99b        26 seconds ago      113MB</span><br><span class="line">centos                        7                   0b99289e40ee        4 hours ago         435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        4 hours ago         222MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h3 id="基于本地模板导入"><a href="#基于本地模板导入" class="headerlink" title="基于本地模板导入"></a>基于本地模板导入</h3><p>用户也可以直接从一个操作系统模板文件导入一个镜像。</p><p>命令格式：<code>docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -c, --change list      导入时候指定Dockerfile指令，包括CMD/ENTRYPOINT/ENV/EXPOSE/LABEL/ONBUILD/USER/VOLUME/WORKDIR等</span><br><span class="line">  -m, --message string   提交信息</span><br></pre></td></tr></table></figure></p><p>要直接导入一个镜像，可以使用OpenVZ提供的模板来创建，或者用其他已导出的镜像模板来创建。OpenVZ模板的下载地址为：<a href="https://openvz.org/Download/template/precreated" target="_blank" rel="noopener">https://openvz.org/Download/template/precreated</a></p><p>例如：下载了<code>centos-7-x86_64-minimal.tar.gz</code>模板压缩包，之后使用以下命令导入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# cat centos-7-x86_64-minimal.tar.gz | docker import - centos-7:import</span><br><span class="line">sha256:be5e039acd03e1c3489841f6edd244954a4c1eb534de7fff605d807136b7e735</span><br><span class="line">[root@xxx ~]# docker images</span><br><span class="line">REPOSITORY                    TAG                 IMAGE ID            CREATED              SIZE</span><br><span class="line">centos-7                      import              be5e039acd03        About a minute ago   435MB</span><br><span class="line">xymtest                       0.1                 8a758d16a99b        18 minutes ago       113MB</span><br><span class="line">centos                        7                   0b99289e40ee        4 hours ago          435MB</span><br><span class="line">test                          0.1                 ff67a67177d8        4 hours ago          222MB</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h2 id="存出和载入镜像"><a href="#存出和载入镜像" class="headerlink" title="存出和载入镜像"></a>存出和载入镜像</h2><p>可以使用<code>docker save</code> 和<code>docker load</code>命令来存出和载入镜像。</p><h3 id="存出镜像"><a href="#存出镜像" class="headerlink" title="存出镜像"></a>存出镜像</h3><p>命令格式：<code>docker save [OPTIONS] IMAGE [IMAGE...]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -o, --output string   写出目标文件</span><br></pre></td></tr></table></figure></p><p>如果要导出镜像到本地文件，可以使用<code>docker save</code>命令。例如，导出本地的<code>163ubuntu:14.04</code>镜像为文件<code>163ubuntu_14.04.tar</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker save -o 163ubuntu_14.04.tar 163ubuntu:14.04 </span><br><span class="line">[root@xxx ~]# ls -t</span><br><span class="line">163ubuntu_14.04.tar ...</span><br></pre></td></tr></table></figure></p><p>之后，用户就可以通过复制该文件（163ubuntu_14.04.tar）将镜像分享给其他人。</p><h3 id="载入镜像"><a href="#载入镜像" class="headerlink" title="载入镜像"></a>载入镜像</h3><p>命令格式：<code>docker load [OPTIONS]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -i, --input string   指定要导入的tar归档镜像文件</span><br><span class="line">  -q, --quiet          Suppress the load output</span><br></pre></td></tr></table></figure></p><p>可以通过<code>docker load</code> 将导出的tar文件再导入到本地镜像库，例如从文件<code>163ubuntu_14.04.tar</code>导入镜像到本地镜像列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx ~]# docker load --input 163ubuntu_14.04.tar </span><br><span class="line">Loaded image: 163ubuntu:14.04</span><br><span class="line"></span><br><span class="line">或者可以使用</span><br><span class="line"></span><br><span class="line">[root@xxx ~]# docker load &lt; 163ubuntu_14.04.tar </span><br><span class="line">Loaded image: 163ubuntu:14.04</span><br></pre></td></tr></table></figure><p>这将导入镜像及其相关元数据信息（包括标签等）。</p><h2 id="上传镜像"><a href="#上传镜像" class="headerlink" title="上传镜像"></a>上传镜像</h2><p>命令格式：<code>docker push [OPTIONS] NAME[:TAG]|[REGISTRY_HOST[:REGISTRY_PORT]/]NAME[:TAG]</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">      --disable-content-trust   Skip image signing (default true)</span><br></pre></td></tr></table></figure></p><p>可以使用<code>docker push</code>命令上传镜像到仓库，默认上传到<code>Docker Hub</code>官方仓库（需要登录）。<br>用户在<code>Docker Hub网站</code>注册后可以上传自制镜像。<strong>例如用户user上传本地的test:latest镜像，可以先添加新的标签user/test:latest,然后用docker push命令上传镜像</strong>：</p><h4 id="上传镜像到网易蜂巢docker"><a href="#上传镜像到网易蜂巢docker" class="headerlink" title="上传镜像到网易蜂巢docker"></a>上传镜像到网易蜂巢docker</h4><p>参见官网操作文档：<a href="https://www.163yun.com/help/documents/15587826830438400" target="_blank" rel="noopener">https://www.163yun.com/help/documents/15587826830438400</a></p><p>1、登录网易云镜像仓库<br>docker login -u {你的网易云邮箱账号或手机号码} -p {你的网易云密码} hub.c.163.com</p><p>返回「Login Succeded」即为登录成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker login hub.c.163.com</span><br><span class="line">Username: xxx@126.com（你的账号）        </span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><ul><li>2、标记本地镜像<br>docker tag {镜像名或ID} hub.c.163.com/{你的用户名}/{标签名}</li></ul><p>你的网易云镜像仓库推送地址为 hub.c.163.com/{你的用户名}/{标签名}</p><p>Attention: 此处为你的用户名，不是你的邮箱帐号或者手机号码 登录网易云控制台，页面右上角头像右侧即为「用户名」</p><p>推送至不存在的镜像仓库时，自动创建镜像仓库并保存新推送的镜像版本；<br>推送至已存在的镜像仓库时，在该镜像仓库中保存新推送的版本，当版本号相同时覆盖原有镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker tag hub.c.163.com/public/ubuntu:14.04 hub.c.163.com/xxx/163ubuntu:14.04</span><br><span class="line">[root@xxx /]# docker images</span><br><span class="line">REPOSITORY                          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">163ubuntu                           14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/public/ubuntu         14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">hub.c.163.com/xxx/163ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure><ul><li><ol start="3"><li>推送至网易云镜像仓库<br>docker push hub.c.163.com/{你的用户名}/{标签名}</li></ol></li></ul><p>默认为私有镜像仓库，推送成功后即可在控制台的「镜像仓库」查看。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker push hub.c.163.com/xxx/163ubuntu:14.04 </span><br><span class="line">The push refers to repository [hub.c.163.com/xxx/163ubuntu]</span><br><span class="line">5f70bf18a086: Pushed </span><br><span class="line">836a329bec99: Pushed </span><br><span class="line">a695e8d298aa: Pushed </span><br><span class="line">98b4fca781e7: Pushed </span><br><span class="line">704e51eef178: Pushed </span><br><span class="line">89688d062a06: Pushed </span><br><span class="line">14.04: digest: sha256:c6740481ffab5f07e8785e6f07d5e2bec8ba9436d67f6e686d0fe1bf65c651be size: 4031</span><br></pre></td></tr></table></figure><h4 id="上传镜像到阿里云"><a href="#上传镜像到阿里云" class="headerlink" title="上传镜像到阿里云"></a>上传镜像到阿里云</h4><blockquote><p>Docker的镜像存储中心通常被称为Registry。<br>当您需要获取Docker镜像的时候，首先需要登录Registry，然后拉取镜像。在您修改过镜像之后，您可以再次将镜像推送到Registry中去。</p><p>Docker的镜像地址是什么？我们来看一个完整的例子。（以容器服务的公共镜像为例）<br>registry.cn-hangzhou.aliyuncs.com/acs/agent:0.8</p><p>registry.cn-hangzhou.aliyuncs.com 叫做 “Registry域名”。<br>acs 叫做 “命名空间”。<br>agent 叫做 “仓库名称”。<br>0.8 叫做 “Tag”、”镜像标签”（非必须，默认latest）。<br>将这个几个完全独立的概念组合一下，还有几个术语。<br>registry.cn-hangzhou.aliyuncs.com/acs/agent 称为 “仓库坐标”。<br>acs/agent 称为 “仓库全名”（通常在API中使用）。</p></blockquote><p>参见文档：<a href="https://yq.aliyun.com/articles/70756" target="_blank" rel="noopener">https://yq.aliyun.com/articles/70756</a></p><p>了解相关说明后发现，阿里云有一个”命名空间”的概念，所以<strong>要想上传自己的镜像，请先去个人中心创建命名空间</strong>。</p><p>比如：当前创建的命名空间为<code>xym</code>,则通过以下命令即可将自己的镜像上传到命名空间</p><ul><li>1、docker login 以阿里云杭州公网Registry为例：登陆时必须指明登陆的 “Registry域名”</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker login registry.cn-hangzhou.aliyuncs.com</span><br><span class="line">Username: xxx</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Are you sure you want to proceed? [y/N] y</span><br><span class="line">Login Succeeded</span><br></pre></td></tr></table></figure><ul><li><p>2、标记本地镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//注意这里的xym为：命名空间</span><br><span class="line">[root@xxx /]# docker tag hub.c.163.com/public/ubuntu:14.04 registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu:14.04</span><br><span class="line">[root@xxx /]# docker images</span><br><span class="line">REPOSITORY                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                                            7                   0b99289e40ee        6 hours ago         435MB</span><br><span class="line">ubuntu                                            latest              c9d990395902        12 hours ago        113MB</span><br><span class="line">hub.c.163.com/public/ubuntu                       14.04               2fe5c4bba1f9        2 years ago         237MB</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu   14.04               2fe5c4bba1f9        2 years ago         237MB</span><br></pre></td></tr></table></figure></li><li><ol start="3"><li>推送至阿里云<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@xxx /]# docker push registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu</span><br><span class="line">The push refers to repository [registry.cn-hangzhou.aliyuncs.com/xym/163ubuntu]</span><br><span class="line">5f70bf18a086: Pushed </span><br><span class="line">836a329bec99: Pushed </span><br><span class="line">a695e8d298aa: Pushed </span><br><span class="line">98b4fca781e7: Pushed </span><br><span class="line">704e51eef178: Pushed </span><br><span class="line">89688d062a06: Pushed </span><br><span class="line">14.04: digest: sha256:ef619091bc47f4b82ce4e984668ee96a2447f244bbd73fbaffe103605c454c28 size: 1569</span><br></pre></td></tr></table></figure></li></ol></li></ul><p>登录控制台查看推送结果。</p><h2 id="镜像加速"><a href="#镜像加速" class="headerlink" title="镜像加速"></a>镜像加速</h2><p>参见阿里控制台，CentOS 镜像加速器帮助说明:</p><blockquote><p>针对Docker客户端版本大于1.10.0的用户</p></blockquote><blockquote><p>您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器：<br>sudo mkdir -p /etc/docker<br>sudo tee /etc/docker/daemon.json &lt;&lt;-‘EOF’<br>{<br>  “registry-mirrors”: [“<a href="https://4vehewku.mirror.aliyuncs.com&quot;]" target="_blank" rel="noopener">https://4vehewku.mirror.aliyuncs.com&quot;]</a><br>}<br>EOF<br>sudo systemctl daemon-reload<br>sudo systemctl restart docker</p></blockquote><p>其他情况请自行 <a href="https://www.google.com" target="_blank" rel="noopener">google</a></p>]]></content>
      
      <categories>
          
          <category> Docker系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> search命令 </tag>
            
            <tag> pull命令 </tag>
            
            <tag> rm命令 </tag>
            
            <tag> import命令 </tag>
            
            <tag> docker镜像 </tag>
            
            <tag> images命令 </tag>
            
            <tag> tag命令 </tag>
            
            <tag> inspect命令 </tag>
            
            <tag> history命令 </tag>
            
            <tag> rmi命令 </tag>
            
            <tag> commit命令 </tag>
            
            <tag> save命令 </tag>
            
            <tag> load命令 </tag>
            
            <tag> push命令 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Cloud常见问题总结</title>
      <link href="/2018/04/11/Spring-Cloud%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/2018/04/11/Spring-Cloud%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="Eureka常见问题"><a href="#Eureka常见问题" class="headerlink" title="Eureka常见问题"></a>Eureka常见问题</h2><h3 id="Eureka注册服务慢"><a href="#Eureka注册服务慢" class="headerlink" title="Eureka注册服务慢"></a>Eureka注册服务慢</h3><p>默认情况下，服务注册到Eureka Server的过程慢。在开发或测试时，常常希望能够加速这一过程，从而提升工作效率。Spring Cloud官方详细描述了该问题的原因并提供了解决方案：  </p><blockquote><p>简单翻译：服务注册涉及到周期性心跳，默认30秒一次（通过客户端配置ServiceUrl）。只有当实例、服务端和客户端的本地缓存中的元数据都相同时，服务才能被其他客户端发现（所以可能需要3次心跳）。可以使用参数<code>eureka.instance.leaseRenewalntervalInSeconds</code>修改时间间隔，从而加快客户端连接到其他服务的过程。在生产环境中最好坚持使用默认值，因为在服务器内部有一些计算，他们会对续约作出假设。</p></blockquote><p>综上，要想解决服务注册慢的问题，只须将<code>eureka.instance.leaseRenewalIntervalInSeconds</code>设定一个更小的值。该配置用于设置Eureka Client向Eureka Server发送心跳的时间间隔，默认30秒。在生产环境中，建议坚持使用默认值。</p><blockquote><p>原文来自：<a href="https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html#_why_is_it_so_slow_to_register_a_service" target="_blank" rel="noopener">https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html#_why_is_it_so_slow_to_register_a_service</a></p></blockquote><h3 id="已停止的微服务节点注销慢或不注销"><a href="#已停止的微服务节点注销慢或不注销" class="headerlink" title="已停止的微服务节点注销慢或不注销"></a>已停止的微服务节点注销慢或不注销</h3><p>在开发环境下，常常希望Eureka Server能迅速有效地注销已停止的微服务实例，然而，由于Eureka Server清理无效节点周期长（默认90秒），以及自我保护模式等原因，可能会遇到微服务注销慢甚至不注销的问题。解决方案如下：  </p><ul><li><p>Eureka Server 端：<br>配置关闭自我保护，并按需配置Eureka Server清理无效节点的时间间隔。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eureka.server.enable-self-preservation</span><br><span class="line">#设为false，关闭自我保护，从而保证会注销微服务</span><br><span class="line">eureka.server.eviction-interval-timer-in-ms</span><br><span class="line">#清理间隔（单位毫秒，默认为60*1000）</span><br></pre></td></tr></table></figure></li><li><p>Eureka Client 端<br>配置开启健康检查，并按需配置续约更新时间和到期时间。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eureka.client.healthcheck.enabled</span><br><span class="line">#设置为true,开启健康检查（需要spring-boot-starter-actuator依赖）</span><br><span class="line">eureka.instance.lease-renewal-interval-in-seconds</span><br><span class="line">#续约更新时间间隔（默认30秒）</span><br><span class="line">eureka.instance.lease-expiration-duration-in-seconds</span><br><span class="line">#续约到期时间（默认90秒）</span><br></pre></td></tr></table></figure></li></ul><p>值得注意的是，这些配置仅建议在开发或测试时使用，生产环境建议坚持使用默认值。</p><p><strong>示例</strong></p><ul><li><p>Eureka Server配置：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  server:</span><br><span class="line">    enable-self-preservation: false</span><br><span class="line">    eviction-interval-timer-in-ms: 4000</span><br></pre></td></tr></table></figure></li><li><p>Eureka Client配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  client:</span><br><span class="line">    healthcheck:</span><br><span class="line">      enabled: true</span><br><span class="line">  instance:</span><br><span class="line">    lease-expiration-duration-in-seconds: 30</span><br><span class="line">    lease-renewal-interval-in-seconds: 10</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>修改Eureka的续约频率可能会打破Eureka的自我保护特性，详见：<a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/373" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix/issues/373</a>。这意味着在生产环境中，如果想要使用Eureka的自我保护特性，应该坚持使用默认配置。</p></blockquote><h3 id="如何自定义微服务的Instance-ID。"><a href="#如何自定义微服务的Instance-ID。" class="headerlink" title="如何自定义微服务的Instance ID。"></a>如何自定义微服务的Instance ID。</h3><p>Instance ID用于唯一标识注册到Eureka Server上的微服务实例。在Eureka Server首页可以直观地看到各个微服务的Instance ID。如下图： </p><p><img src="" alt=""></p><p>在Spring Cloud中，服务的Instance ID的默认值是<code>${spring.cloud.client.hostname}:${spring.application.name}:${server.port}</code>。如果想要自定义这部分内容，只须在微服务中配置<code>eureka.instance.instance-id</code>属性即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: microservice-provider-user</span><br><span class="line">eureka:</span><br><span class="line">  instance:</span><br><span class="line">    #将Instance ID设置成 IP:端口的形式 </span><br><span class="line">    instance-id: $&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125;</span><br></pre></td></tr></table></figure><p>这样，就可将微服务<code>microservice-provider-user</code>的Instance ID设为IP:端口的形式。这样设置后，效果下图所示：  </p><p><img src="" alt=""></p><blockquote><p>Spring Cloud初始化Instance ID的相关代码：<br>org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration<br>org.springframework.cloud.commons.util.IdUtils.getDefaultInstanceId(PropertyResolver resolver);<br>org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean.getInstanceId()</p></blockquote><h3 id="Eureka的UNKNOWN问题总结"><a href="#Eureka的UNKNOWN问题总结" class="headerlink" title="Eureka的UNKNOWN问题总结"></a>Eureka的UNKNOWN问题总结</h3><p>注册信息unknown，是新手常会遇到的问题。如下图，有二种UNKNOWN的情况，一种是应用名称UNKNOWN,另一种是应用状态UNKNOWN。下面分别说明这二种情况。</p><p><img src="" alt=""></p><p><strong>应用名称UNKNOWN</strong></p><p>应用名称UNKNOWN显然不合适，首先微服务的名称不够语义化，无法直接观看出这是哪个服务；更重要的是，我们常常使用应用名称消费对应微服务接口。<br>一般来说，有二种情况会导致该问题的发生：  </p><ul><li>未配置<code>spring.application.name</code>或者<code>eureka.instance.appname</code>属性。如果这两个属性均不配置，就会导致应用名称UNKNOWN的问题。</li><li>某些版本的SpringFox会导致该问题，例如SpringFox2.6.0。建议使用SpringFox2.6.1或更新版本</li></ul><p><strong>微服务实例状态UNKNOWN</strong></p><p>微服务实例的状态UNKNOWN同样很麻烦。一般来讲，只会请求状态是UP的微服务。该问题一般由健康检查导致。<code>eureka.client.healthcheck.enabled=true</code>必须设置在<code>application.yml</code>中，而不能设置在<code>bootstrap.yml</code>中，否则一些场景下会导致应用状态UNKNOWN的问题。</p><blockquote><p>SpringFox是一款基于Spring和Swagger的开源的API文档框架，前身是swagger-springmvc。官网：<a href="http://springfox.github.io/springfox/" target="_blank" rel="noopener">http://springfox.github.io/springfox/</a>。</p></blockquote><h2 id="Hystrix-Feign整合Hystrix后首次请求失败"><a href="#Hystrix-Feign整合Hystrix后首次请求失败" class="headerlink" title="Hystrix/Feign整合Hystrix后首次请求失败"></a>Hystrix/Feign整合Hystrix后首次请求失败</h2><p>某些场景下，Feign或Ribbon整合Hystrix后，会出现首次调用失败的问题。</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>Hystrix默认的超时时间是1秒，如果在1秒内得不到响应，就会进入<code>fallback</code>逻辑。由于Spring的懒加载机制，首次请求往往会比较慢，因此在某些机器（特别是低端的机器）上，首次请求需要的时间可能就会大于1秒。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>方法一：延长Hystrix的超时时间，示例：<br><code>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 5000</code>该配置让Hystrix的超时时间改为5秒 </li><li>方法二：禁用Hystrix的超时，示例：<br><code>hystrix.command.default.execution.timeout.enabled: false</code></li><li>方法三：对于Feign，还可为Feign禁用Hystrix，示例：<br><code>feign.hystrix.enabled: false</code><br>这样即可为Feign全局禁用Hystrix支持，该方式比较极端，一般不建议使用。</li></ul><h2 id="Turbine集合数据不完整"><a href="#Turbine集合数据不完整" class="headerlink" title="Turbine集合数据不完整"></a>Turbine集合数据不完整</h2><p>在某些版本的Spring Cloud（例如Brixton SR5）中，Turbine会发生该问题。该问题直观体现是：使用Turbine聚合了多个微服务，但在Hystrix Dashboard上只能看到部分微服务的监控数据。</p><p>例如Turbine配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">turbine:</span><br><span class="line">  app-config: microservice-consumer-movie,microservice-consumer-movie-feign-hystrix-fallback-stream</span><br><span class="line">  cluster-name-expression: &quot;&apos;default&apos;&quot;</span><br></pre></td></tr></table></figure></p><p>Turbine理应聚合<code>microservice-consumer-movie</code>和<code>microservice-consumer-movie-feign-hystrix-fallback-stream</code>这两个微服务的监控数据，然而打开Hystrix Dashboard时，会发现Hystrix Dashboard只显示部分微服务的监控数据。</p><h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p>当Turbine集合的微服务部署在同一台主机时，就会出现该问题。</p><ul><li><p>方法一：为各个微服务配置不同的<code>hostname</code>。并将<code>preferIpAddress</code>设为false或者不设置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eureka:</span><br><span class="line">  client:</span><br><span class="line">    service-url:</span><br><span class="line">      defaultZone: http://discovery:8761/eureka/</span><br><span class="line">  instance:</span><br><span class="line">    hostname: ribbon #配置hostname</span><br></pre></td></tr></table></figure></li><li><p>方法二：设置<code>turbine.combine-host-port=true</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">turbine:</span><br><span class="line">  app-config: microservice-consumer-movie,microservice-consumer-movie-feign-hystrix-fallback-stream</span><br><span class="line">  cluster-name-expression: &quot;&apos;default&apos;&quot;</span><br><span class="line">  combine-host-port: true</span><br></pre></td></tr></table></figure></li><li><p>方法三：升级Spring Cloud到Camden或更新版本。当然，也可单独升级Spring Cloud Netflix到1.2或更新版本（一般不建议单独升级Spring Cloud Netflix，因为可能会跟Spring Cloud其他组件冲突）。这是因为老版本中的<code>combine-host-port</code>默认值是false。Spring Cloud已经意识到该问题，所以在新的版本中将该属性的默认值修改为true。该方案和方法二本质上是一致的。</p></li></ul><p>相关代码:  </p><blockquote><p>org.springframework.cloud.netflix.turbine.TurbineProperties.combineHostPort<br>org.springframework.cloud.netflix.turbine.CommonsInstanceDiscovery.getInstance(String hostname, String port, String cluster, Boolean status)<br>相关issue：<a href="https://github.com/spring-cloud/spring-cloud-netflix/issues/1087" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix/issues/1087</a></p></blockquote><h2 id="Spring-Cloud各组件配置属性"><a href="#Spring-Cloud各组件配置属性" class="headerlink" title="Spring Cloud各组件配置属性"></a>Spring Cloud各组件配置属性</h2><p>Spring Cloud中的大部门问题都可以使用配置属性的方式来解决。下面将配置的地址罗列出来，方便查阅。</p><h3 id="Spring-Cloud的配置"><a href="#Spring-Cloud的配置" class="headerlink" title="Spring Cloud的配置"></a>Spring Cloud的配置</h3><p>Spring Cloud的所有组件配置都在其官方文档的附录，地址如下：  </p><p><a href="http://cloud.spring.io/spring-cloud-static/Camden.SR7/#_appendix_compendium_of_configuration_properties" target="_blank" rel="noopener">http://cloud.spring.io/spring-cloud-static/Camden.SR7/#_appendix_compendium_of_configuration_properties</a></p><h3 id="原生配置"><a href="#原生配置" class="headerlink" title="原生配置"></a>原生配置</h3><p>Spring Cloud 整合了很多类库，例如：<code>Eureka</code>、<code>Ribbon</code>、<code>Feign</code>等。这些组件自身也有一些配置属性，如下：  </p><ul><li>Eureka的配置：<a href="https://github.com/Netflix/eureka/wiki/Configuring-Eureka" target="_blank" rel="noopener">https://github.com/Netflix/eureka/wiki/Configuring-Eureka</a></li><li>Ribbon的配置：<a href="https://github.com/Netflix/ribbon/wiki/Programmers-Guide" target="_blank" rel="noopener">https://github.com/Netflix/ribbon/wiki/Programmers-Guide</a></li><li>Hystrix的配置：<a href="https://github.com/Netflix/Hystrix/wiki/Configuration" target="_blank" rel="noopener">https://github.com/Netflix/Hystrix/wiki/Configuration</a></li><li>Turbine的配置：<a href="https://github.com/Netflix/Turbine/wiki/Configuration-(1.x" target="_blank" rel="noopener">https://github.com/Netflix/Turbine/wiki/Configuration-(1.x)</a>)</li></ul><h2 id="Spring-Cloud定位问题的思路"><a href="#Spring-Cloud定位问题的思路" class="headerlink" title="Spring Cloud定位问题的思路"></a>Spring Cloud定位问题的思路</h2><h3 id="1、排查配置问题"><a href="#1、排查配置问题" class="headerlink" title="1、排查配置问题"></a>1、排查配置问题</h3><p>排查配置有无问题，举几个例说明。</p><ul><li>YAML缩进是否正确<ul><li>项目启动报错，错误指向yml文件</li></ul></li><li>配置属性是否正确<ul><li>可以借助IDE提示功能来排查，当IDE不提示或给出警告时，应格外注意。  </li></ul></li><li><p>配置属性的位置是否正确</p><ul><li>应当配置在<code>Eureka Client</code>项目上的属性，配置在了<code>Eureka Server</code>项目上</li><li>应当写在<code>bootstrap.yml</code>中的属性，写在了<code>application.yml</code>中，如：<code>spring.cloud.config.uri=http://localhost:8080</code>     </li><li>应当写在<code>application.yml</code>的属性，写在了<code>bootstrap.yml</code>中，如：<code>eureka.client.healthcheck.enabled-true</code><h3 id="2、排查环境问题"><a href="#2、排查环境问题" class="headerlink" title="2、排查环境问题"></a>2、排查环境问题</h3>如确认配置无误，即可考虑运行环境是否存在问题。</li></ul></li><li><p>环境变量</p><ul><li>当前使用的<code>spring boot maven</code>插件版本需要jdk8支持,在jdk7下报错，需要指定插件版本号，添加<code>&lt;version&gt;</code>配置</li></ul></li><li>依赖下载是否完整<ul><li>启动前使用<code>mvn clean package</code>,确认依赖完整性。</li></ul></li><li>网络问题<ul><li>微服务之间通过网络保持通信，因此，网络常常是排查问题的关键。当问题发生时候，可优先排查网络问题。</li></ul></li></ul><h3 id="3、排查代码问题"><a href="#3、排查代码问题" class="headerlink" title="3、排查代码问题"></a>3、排查代码问题</h3><p>经过以上步骤，依然没有定位到问题，那么可能是编写代码出了问题。很多时候，常常因为少了某个注解，或是依赖缺失，而导致了各种异常。许多场景下，设置合理的日志级别，会对问题的定位有奇效。</p><h3 id="4、排查Spring-Cloud自身问题"><a href="#4、排查Spring-Cloud自身问题" class="headerlink" title="4、排查Spring Cloud自身问题"></a>4、排查Spring Cloud自身问题</h3><p>如果确定不是自身问题，就可以debug一下Spring Cloud的代码。同时，可在github等平台给项目提交issue，然后参考官方回复，尝试规避相应问题。</p><p><strong>可参考资源：</strong></p><blockquote><p>各项自身的github，例如：Eureka的Github：<a href="https://github.com/netflix/eureka" target="_blank" rel="noopener">https://github.com/netflix/eureka</a><br>Spring Cloud对应的项目Github，例如Eureka项目在 Spring Cloud Netflix中：<a href="https://github.com/spring-cloud/spring-cloud-netflix" target="_blank" rel="noopener">https://github.com/spring-cloud/spring-cloud-netflix</a></p></blockquote><blockquote><p>Spring Cloud的StackOverflow：<a href="https://stackoverflow.com/questions/tagged/spring-cloud" target="_blank" rel="noopener">https://stackoverflow.com/questions/tagged/spring-cloud</a><br>Spring Cloud的 Gitter<a href="https://gitter.im/spring-cloud/spring-cloud" target="_blank" rel="noopener">https://gitter.im/spring-cloud/spring-cloud</a><br>Spring Cloud中国社区 <a href="http://www.spring4all.com" target="_blank" rel="noopener">http://www.spring4all.com</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> Spring-Cloud系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring-Cloud </tag>
            
            <tag> SpringCloud常见问题 </tag>
            
            <tag> Eureka 配置 </tag>
            
            <tag> Ribbon 配置 </tag>
            
            <tag> Hystrix 配置 </tag>
            
            <tag> Turbine 配置 </tag>
            
            <tag> Spring Cloud 配置手册 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Eureka配置参数</title>
      <link href="/2018/04/08/Eureka%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
      <url>/2018/04/08/Eureka%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</url>
      <content type="html"><![CDATA[<h3 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h3><ul><li><code>eureka.client.register-with-eureka</code>: 是否支持注册功能，默认为true</li><li><code>eureka.server.enable-self-preservation</code>: 服务注册中心自我保护机制，默认为true（服务注册中心红色警告）</li><li><code>eureka.client.region</code>: 设置微服务应用的Region，默认为default</li><li><code>eureka.client.availability-zones</code>: 设置微服务应用的zone，多个可以采用“，”分割，默认为defaultZone，和region是一对多的关系，即一个region下有多个zone</li><li><code>http://&lt;username&gt;:&lt;password&gt;@localhost:1111/eureka/</code>,配置安全的注册中心地址，其中<username>为安全校验信息的用户名，<passoword>为该用户的密码。</passoword></username></li></ul><h3 id="服务续约"><a href="#服务续约" class="headerlink" title="服务续约"></a>服务续约</h3><ul><li><code>eureka.instance.lease-renewal-interval-in-seconds</code>: 定义服务续约任务的调用间隔时间，默认30秒</li><li><code>eureka.instance.lease-expiration-duration-in-seconds</code>: 定义服务失效的时间，默认90秒</li></ul><h3 id="获取服务"><a href="#获取服务" class="headerlink" title="获取服务"></a>获取服务</h3><ul><li><code>eureka.client.fetch-registry</code>: 提供获取服务功能，默认为true</li><li><code>eureka.client.registry-fetch-interval-seconds</code>: 服务注册中心，服务清单缓存更新时间间隔（更新频率），默认30秒</li></ul><p>下面整理了<code>org.springframework.cloud.netflix.eureka.EurekaClientConfigBean</code>中定义的常用配置参数以及对应的说明和默认值,这些参数均以<code>eureka.client</code>为前缀。</p><table><thead><tr><th>参数名</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>enabled</td><td>启用eureka客户端</td><td>true</td></tr><tr><td>registryFetchIntervalSeconds</td><td>从eureka服务端获取注册信息的间隔时间，单位为秒</td><td>30</td></tr><tr><td>instanceInfoReplicationIntervalSeconds</td><td>更新实例信息的变化到Eureka服务端的间隔时间，单位为秒</td><td>30</td></tr><tr><td>initialInstanceInfoReplicationIntervalSeconds</td><td>初始化实例信息到Eureka服务端的间隔时间，单位为秒</td><td>40</td></tr><tr><td>eurekaServiceUrlPollIntervalSeconds</td><td>轮询Eureka服务端地址更改的间隔时间，单位为秒。当我们与<code>Spring Cloud Config</code>配合，动态刷新<code>Eureka</code>的<code>ServiceURL</code>地址时需要关注该参数</td><td>5*60=300(5分钟)</td></tr><tr><td>eurekaServerReadTimeoutSeconds</td><td>读取Eureka Server信息的超时时间，单位为秒</td><td>8</td></tr><tr><td>eurekaServerConnectTimeoutSeconds</td><td>连接Eureka Server的超时时间，单位为秒</td><td>5</td></tr><tr><td>eurekaServerTotalConnections</td><td>从Eureka客户端到所有Eureka服务端的连接总数</td><td>200</td></tr><tr><td>eurekaServerTotalConnectionsPerHost</td><td>从Eureka客户端到每个Eureka服务端主机的连接总数</td><td>50</td></tr><tr><td>eurekaConnectionIdleTimeoutSeconds</td><td>Eureka服务端连接的空闲关闭时间，单位为秒</td><td>30</td></tr><tr><td>heartbeatExecutorThreadPoolSize</td><td>心跳连接池的初始化线程数</td><td>2</td></tr><tr><td>heartbeatExecutorExponentialBackOffBound</td><td>心跳超时重试延迟时间的最大乘数值</td><td>10</td></tr><tr><td>cacheRefreshExecutorThreadPoolSize</td><td>缓存刷新线程池的初始化线程数</td><td>2</td></tr><tr><td>cacheRefreshExecutorExponentialBackOffBound</td><td>缓存刷新重试延迟时间的最大乘数值</td><td>10</td></tr><tr><td>useDnsForFetchingServiceUrls</td><td>使用DNS来获取Eureka服务端的serviceURL</td><td>false</td></tr><tr><td>registerWithEureka</td><td>是否要将自身的实例信息注册到Eureka服务端</td><td>true</td></tr><tr><td>preferSameZoneEureka</td><td>是否偏好使用处于相同Zone的Eureka服务端</td><td>true</td></tr><tr><td>filterOnlyUpInstances</td><td>获取实例时是否过滤，仅保留UP状态的实例</td><td>true</td></tr><tr><td>fetchRegistry</td><td>是否从Eureka服务端获取注册信息</td><td>true</td></tr></tbody></table><p>下面整理了一些<code>org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBean</code>中定义的配置参数以及对应的说明和默认值，这些参数均以<code>eureka.instance</code>为前缀。</p><table><thead><tr><th>参数名</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>preferIpAddress</td><td>是否优先使用IP地址作为主机名的标识</td><td>false</td></tr><tr><td>leaseRenewalIntervalInSeconds</td><td>Eureka客户端向服务端发送心跳的时间间隔，单位为秒</td><td>30</td></tr><tr><td>leaseExpirationDurationInSeconds</td><td>Eureka服务端在收到最后一次心跳之后等待的时间上限，单位为秒。超过该时间之后服务端会将该服务实例从服务清单中剔除，从而禁止服务调用请求被发送到该实例上</td><td>90</td></tr><tr><td>nonSecurePort</td><td>非安全的通信端口号</td><td>80</td></tr><tr><td>securePort</td><td>安全的通信端口号</td><td>443</td></tr><tr><td>nonSecurePortEnabled</td><td>是否启用非安全的通信端口号</td><td>true</td></tr><tr><td>securePortEnabled</td><td>是否启用安全的端口号</td><td>false</td></tr><tr><td>appname</td><td>服务名，默认取spring.application.name的配置值，如果没有则为unknow</td><td></td></tr><tr><td>hostname</td><td>主机名，不配置的时候将根据操作系统的主机名来获取</td><td></td></tr></tbody></table>]]></content>
      
      <categories>
          
          <category> eureka配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eureka配置 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>常用工具</title>
      <link href="/2018/03/29/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
      <url>/2018/03/29/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<h3 id="1、Grepcode"><a href="#1、Grepcode" class="headerlink" title="1、Grepcode"></a>1、<a href="http://grepcode.com/" target="_blank" rel="noopener">Grepcode</a></h3><p>这是一个面向于java开发人员的网站，在这里你可以通过java的projects、classes等各种关键字在线查看它对应的源码，知道对应的project、classes等信息</p><h3 id="2、SearchCode"><a href="#2、SearchCode" class="headerlink" title="2、SearchCode"></a>2、<a href="https://searchcode.com/" target="_blank" rel="noopener">SearchCode</a></h3><p>SearchCode 是一个源码搜索引擎，目前支持从 Github、Bitbucket、Google Code、CodePlex、SourceForge 和 Fedora Project 平台搜索公开的源码。</p><h3 id="3、ProcessOn"><a href="#3、ProcessOn" class="headerlink" title="3、ProcessOn"></a>3、<a href="https://www.processon.com/" target="_blank" rel="noopener">ProcessOn</a></h3><p>ProcessOn是一个在线作图工具的聚合平台，它可以在线画流程图、思维导图、UI原型图、UML、网络拓扑图、组织结构图等等。</p><h3 id="4、json-cn"><a href="#4、json-cn" class="headerlink" title="4、json.cn"></a>4、<a href="https://www.json.cn/" target="_blank" rel="noopener">json.cn</a></h3><p>json在线解析及格式化</p><h3 id="5、bejson"><a href="#5、bejson" class="headerlink" title="5、bejson"></a>5、<a href="http://www.bejson.com/jsonviewernew/" target="_blank" rel="noopener">bejson</a></h3><p>json在线解析及格式化</p><h3 id="6、MaHua-、马克飞象-、Cmd"><a href="#6、MaHua-、马克飞象-、Cmd" class="headerlink" title="6、MaHua 、马克飞象 、Cmd"></a>6、<a href="http://mahua.jser.me/" target="_blank" rel="noopener">MaHua 、马克飞象 、Cmd</a></h3><p>一个在线编辑markdown文档的编辑器</p><h3 id="7、mvnrepository"><a href="#7、mvnrepository" class="headerlink" title="7、mvnrepository"></a>7、<a href="http://mvnrepository.com/" target="_blank" rel="noopener">mvnrepository</a></h3><p>maven依赖地址库</p><h3 id="8、代码在线运行"><a href="#8、代码在线运行" class="headerlink" title="8、代码在线运行"></a>8、<a href="https://tool.lu/coderunner/" target="_blank" rel="noopener">代码在线运行</a></h3><h3 id="9、Google翻译-百度翻译-有道翻译-爱词霸翻译"><a href="#9、Google翻译-百度翻译-有道翻译-爱词霸翻译" class="headerlink" title="9、Google翻译 百度翻译 有道翻译 爱词霸翻译"></a>9、<a href="https://translate.google.cn/" target="_blank" rel="noopener">Google翻译</a> <a href="http://fanyi.baidu.com/" target="_blank" rel="noopener">百度翻译</a> <a href="http://fanyi.youdao.com/" target="_blank" rel="noopener">有道翻译</a> <a href="http://fy.iciba.com/" target="_blank" rel="noopener">爱词霸翻译</a></h3><h3 id="10、AutoJCode"><a href="#10、AutoJCode" class="headerlink" title="10、AutoJCode"></a>10、<a href="http://www.autojcode.com/code/sql2class.jsp" target="_blank" rel="noopener">AutoJCode</a></h3><p>SQL和Java代码互相生成</p><h3 id="11、sql在线美化，格式化，压缩"><a href="#11、sql在线美化，格式化，压缩" class="headerlink" title="11、sql在线美化，格式化，压缩"></a>11、<a href="https://tool.lu/sql/" target="_blank" rel="noopener">sql在线美化，格式化，压缩</a></h3><h3 id="12、编码转换"><a href="#12、编码转换" class="headerlink" title="12、编码转换"></a>12、<a href="http://tool.chinaz.com/tools/unicode.aspx" target="_blank" rel="noopener">编码转换</a></h3><h3 id="13、Cron-常用Cron生成"><a href="#13、Cron-常用Cron生成" class="headerlink" title="13、Cron 常用Cron生成"></a>13、<a href="https://zh.wikipedia.org/zh-sg/Cron" target="_blank" rel="noopener">Cron</a> <a href="http://www.pppet.net/" target="_blank" rel="noopener">常用Cron生成</a></h3><h3 id="14、正则验证"><a href="#14、正则验证" class="headerlink" title="14、正则验证"></a>14、<a href="http://tool.chinaz.com/regex" target="_blank" rel="noopener">正则验证</a></h3><h3 id="15、正在代码生成"><a href="#15、正在代码生成" class="headerlink" title="15、正在代码生成"></a>15、<a href="http://tool.chinaz.com/tools/regexgenerate" target="_blank" rel="noopener">正在代码生成</a></h3><h3 id="16、时间戳转换"><a href="#16、时间戳转换" class="headerlink" title="16、时间戳转换"></a>16、<a href="http://tool.chinaz.com/Tools/unixtime.aspx" target="_blank" rel="noopener">时间戳转换</a></h3><h3 id="17、北美东部时间与北京时间换算"><a href="#17、北美东部时间与北京时间换算" class="headerlink" title="17、北美东部时间与北京时间换算"></a>17、<a href="http://tool.chinaz.com/Tools/unixtime.aspx" target="_blank" rel="noopener">北美东部时间与北京时间换算</a></h3><h3 id="18、加密解密"><a href="#18、加密解密" class="headerlink" title="18、加密解密"></a>18、<a href="http://tool.chinaz.com/tools/textencrypt.aspx" target="_blank" rel="noopener">加密解密</a></h3><h3 id="19、查看网页源代码"><a href="#19、查看网页源代码" class="headerlink" title="19、查看网页源代码"></a>19、<a href="http://s.tool.chinaz.com/tools/pagecode.aspx" target="_blank" rel="noopener">查看网页源代码</a></h3><h3 id="20、单位转换"><a href="#20、单位转换" class="headerlink" title="20、单位转换"></a>20、<a href="https://www.convertworld.com/zh-hans/" target="_blank" rel="noopener">单位转换</a></h3><h3 id="21、在线调色板"><a href="#21、在线调色板" class="headerlink" title="21、在线调色板"></a>21、<a href="http://tool.chinaz.com/Tools/OnlineColor.aspx" target="_blank" rel="noopener">在线调色板</a></h3><h3 id="22、ASCII码对照表"><a href="#22、ASCII码对照表" class="headerlink" title="22、ASCII码对照表"></a>22、<a href="http://tool.oschina.net/commons?type=4" target="_blank" rel="noopener">ASCII码对照表</a></h3><h3 id="24、HTTP状态码"><a href="#24、HTTP状态码" class="headerlink" title="24、HTTP状态码"></a>24、<a href="http://tool.oschina.net/commons?type=5" target="_blank" rel="noopener">HTTP状态码</a></h3><h3 id="25、HTTP-Content-type"><a href="#25、HTTP-Content-type" class="headerlink" title="25、HTTP Content-type"></a>25、<a href="http://tool.oschina.net/commons" target="_blank" rel="noopener">HTTP Content-type</a></h3><h3 id="26、TCP-UDP常见端口参考"><a href="#26、TCP-UDP常见端口参考" class="headerlink" title="26、TCP/UDP常见端口参考"></a>26、<a href="http://tool.oschina.net/commons?type=7" target="_blank" rel="noopener">TCP/UDP常见端口参考</a></h3><h3 id="27、HTML转义字符"><a href="#27、HTML转义字符" class="headerlink" title="27、HTML转义字符"></a>27、<a href="http://tool.oschina.net/commons?type=2" target="_blank" rel="noopener">HTML转义字符</a></h3><h3 id="28、RGB颜色对照表"><a href="#28、RGB颜色对照表" class="headerlink" title="28、RGB颜色对照表"></a>28、<a href="http://tool.oschina.net/commons?type=3" target="_blank" rel="noopener">RGB颜色对照表</a></h3><h3 id="29、对称非对称加解密算法"><a href="#29、对称非对称加解密算法" class="headerlink" title="29、对称非对称加解密算法"></a>29、<a href="http://web.chacuo.net/netrsakeypair" target="_blank" rel="noopener">对称非对称加解密算法</a></h3><h3 id="30、银行联行号查询"><a href="#30、银行联行号查询" class="headerlink" title="30、银行联行号查询"></a>30、<a href="http://lianhanghao.com/index.php" target="_blank" rel="noopener">银行联行号查询</a></h3><h3 id="31、字符生成1-字符生成2-字符生成3"><a href="#31、字符生成1-字符生成2-字符生成3" class="headerlink" title="31、字符生成1  字符生成2  字符生成3"></a>31、<a href="http://patorjk.com/software/taag" target="_blank" rel="noopener">字符生成1</a>  <a href="http://www.network-science.de/ascii/" target="_blank" rel="noopener">字符生成2</a>  <a href="http://www.degraeve.com/img2txt.w" target="_blank" rel="noopener">字符生成3</a></h3><h3 id="32、jdk1-8-api文档"><a href="#32、jdk1-8-api文档" class="headerlink" title="32、jdk1.8 api文档"></a>32、<a href="https://docs.oracle.com/javase/8/docs/api/" target="_blank" rel="noopener">jdk1.8 api文档</a></h3><h3 id="33、a6"><a href="#33、a6" class="headerlink" title="33、a6"></a>33、<a href="http://www.a6a6.org/" target="_blank" rel="noopener">a6</a></h3><h3 id="34、身份证号码生成器"><a href="#34、身份证号码生成器" class="headerlink" title="34、身份证号码生成器"></a>34、<a href="http://www.welefen.com/lab/identify" target="_blank" rel="noopener">身份证号码生成器</a></h3><h3 id="35、NIO入门，讲的超级好"><a href="#35、NIO入门，讲的超级好" class="headerlink" title="35、NIO入门，讲的超级好"></a>35、<a href="https://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html" target="_blank" rel="noopener">NIO入门，讲的超级好</a></h3><h3 id="36、不死鸟-分享为王"><a href="#36、不死鸟-分享为王" class="headerlink" title="36、不死鸟,分享为王"></a>36、<a href="https://lai.yuweining.cn/" target="_blank" rel="noopener">不死鸟,分享为王</a></h3><h3 id="37、分享-GitHub-上有趣、入门级的开源项目"><a href="#37、分享-GitHub-上有趣、入门级的开源项目" class="headerlink" title="37、分享 GitHub 上有趣、入门级的开源项目"></a>37、<a href="https://hellogithub.com/" target="_blank" rel="noopener">分享 GitHub 上有趣、入门级的开源项目</a></h3><h3 id="38、斗图网"><a href="#38、斗图网" class="headerlink" title="38、斗图网"></a>38、<a href="https://www.doutula.com/" target="_blank" rel="noopener">斗图网</a></h3><h3 id="39、在线电子书柜"><a href="#39、在线电子书柜" class="headerlink" title="39、在线电子书柜"></a>39、<a href="https://love2.io/" target="_blank" rel="noopener">在线电子书柜</a></h3><h3 id="40、mybatis-3中文文档"><a href="#40、mybatis-3中文文档" class="headerlink" title="40、mybatis-3中文文档"></a>40、<a href="http://www.mybatis.org/mybatis-3/zh/java-api.html" target="_blank" rel="noopener">mybatis-3中文文档</a></h3><h3 id="41、Hexo文档"><a href="#41、Hexo文档" class="headerlink" title="41、Hexo文档"></a>41、<a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">Hexo文档</a></h3><h3 id="42、各种在线工具"><a href="#42、各种在线工具" class="headerlink" title="42、各种在线工具"></a>42、<a href="https://tool.lu/" target="_blank" rel="noopener">各种在线工具</a></h3><h3 id="43、免费的在线影视网站汇总"><a href="#43、免费的在线影视网站汇总" class="headerlink" title="43、免费的在线影视网站汇总"></a>43、<a href="https://lai.yuweining.cn/archives/531/" target="_blank" rel="noopener">免费的在线影视网站汇总</a></h3><h3 id="44、youku-qq-baidu-vip视频免费看-I"><a href="#44、youku-qq-baidu-vip视频免费看-I" class="headerlink" title="44、youku/qq/baidu vip视频免费看 I"></a>44、<a href="https://lai.yuweining.cn/vip" target="_blank" rel="noopener">youku/qq/baidu vip视频免费看 I</a></h3><h3 id="45、youku-qq-baidu-vip视频免费看-II"><a href="#45、youku-qq-baidu-vip视频免费看-II" class="headerlink" title="45、youku/qq/baidu vip视频免费看 II"></a>45、<a href="http://yun.baiyug.cn/" target="_blank" rel="noopener">youku/qq/baidu vip视频免费看 II</a></h3><h3 id="46、Json转换为pojo"><a href="#46、Json转换为pojo" class="headerlink" title="46、Json转换为pojo"></a>46、<a href="http://www.jsonschema2pojo.org/" target="_blank" rel="noopener">Json转换为pojo</a></h3><h3 id="47、开源中国工具集"><a href="#47、开源中国工具集" class="headerlink" title="47、开源中国工具集"></a>47、<a href="http://tool.oschina.net/" target="_blank" rel="noopener">开源中国工具集</a></h3><h3 id="48、代码管理coding"><a href="#48、代码管理coding" class="headerlink" title="48、代码管理coding"></a>48、<a href="https://coding.net/" target="_blank" rel="noopener">代码管理coding</a></h3><h3 id="49、百度脑图"><a href="#49、百度脑图" class="headerlink" title="49、百度脑图"></a>49、<a href="http://naotu.baidu.com/" target="_blank" rel="noopener">百度脑图</a></h3><h3 id="50、前端开源CDN"><a href="#50、前端开源CDN" class="headerlink" title="50、前端开源CDN"></a>50、<a href="http://www.bootcdn.cn/" target="_blank" rel="noopener">前端开源CDN</a></h3><h3 id="51、代码格式化查错"><a href="#51、代码格式化查错" class="headerlink" title="51、代码格式化查错"></a>51、<a href="http://web.chacuo.net/formatjava" target="_blank" rel="noopener">代码格式化查错</a></h3><h3 id="52、开发者图条"><a href="#52、开发者图条" class="headerlink" title="52、开发者图条"></a>52、<a href="https://toutiao.io/" target="_blank" rel="noopener">开发者图条</a></h3><h3 id="53、2345工具箱，各种小工具"><a href="#53、2345工具箱，各种小工具" class="headerlink" title="53、2345工具箱，各种小工具"></a>53、<a href="http://tools.2345.com/" target="_blank" rel="noopener">2345工具箱，各种小工具</a></h3><h3 id="54、各种网址导航No-1"><a href="#54、各种网址导航No-1" class="headerlink" title="54、各种网址导航No.1"></a>54、<a href="http://www.gitnavi.com/" target="_blank" rel="noopener">各种网址导航No.1</a></h3>]]></content>
      
      <categories>
          
          <category> 常用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 常用工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之管理</title>
      <link href="/2017/06/09/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E7%AE%A1%E7%90%86/"/>
      <url>/2017/06/09/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★"><a href="#重要星级-★★★" class="headerlink" title="重要星级 ★★★"></a>重要星级 ★★★</h6><hr><h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><p>Redis的作者Salvatore Sanfilippo曾经发表过Redis宣言，其中提到了Redis以简洁为美。同样在安全层面Redis也没有做太多的工作。  </p><h3 id="1、可信的环境"><a href="#1、可信的环境" class="headerlink" title="1、可信的环境"></a>1、可信的环境</h3><p>Redis的安全设计是在“Redis运行在可信环境”这个前提下做出的。在生产环境运行时不能允许外界直接连接到Redis服务器上，而应该通过应用程序进行中转，运行在可信的环境中是保证Redis安全的最重要方法。<br>Redis的默认配置会接受来自任何地址发送来的请求，即在任何一个拥有公网IP的服务器上启动Redis服务器，都可以被外界直接访问到。要更改这一设置，在配置文件中修改bind参数，如只允许本机应用连接Redis，可以将bind参数改成：  </p><pre><code>bind 127.0.0.1</code></pre><p>如果想要绑定多个地址，中间采用空格隔开，配置多个即可。  </p><pre><code>bind 127.0.0.1 192.168.100.238</code></pre><h3 id="2、数据库密码"><a href="#2、数据库密码" class="headerlink" title="2、数据库密码"></a>2、数据库密码</h3><p>除此之外，还可以通过配置文件中的<code>requirepass</code>参数为Redis设置一个密码。例如：  </p><pre><code>requirepass 12345678</code></pre><p>客户端每次连接到Redis时都需要发送密码，否则Redis会拒绝执行客户端发来的命令。<br>例如：  </p><pre><code>127.0.0.1:6379&gt; info defaultNOAUTH Authentication required.127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required.</code></pre><p>发送密码需要使用AUTH命令，就像这样：  </p><pre><code>127.0.0.1:6379&gt; auth 123456OK127.0.0.1:6379&gt; client listid=145 addr=127.0.0.1:55057 fd=5 name= age=9 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client</code></pre><p>由于Redis的性能极高，并且输入错误密码后Redis并不会进行主动延迟（考虑到Redis的单线程模型），所以攻击者可以通过穷举法破解Redis的密码，因此设置密码时一定要选择复杂的密码。<br><strong>提示：配置Redis复制的时候如果主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置主数据库的密码，以使从数据库连接主数据库时自动使用AUTH命令认证。</strong>  </p><h3 id="3、重命名命令"><a href="#3、重命名命令" class="headerlink" title="3、重命名命令"></a>3、重命名命令</h3><p>Redis支持在配置文件中将命令重命名，比如将FLUSHALL 命令重命名成一个比较复杂的名字，以保证只有自己的应用可以使用该命令。就像下面这样：  </p><pre><code>rename-command FLUSHALL QKSYSJK</code></pre><p>如果希望直接禁用某个命令可以将命令重命名成空字符串：  </p><pre><code>rename-command FLUSHALL &quot;&quot;</code></pre><p>无论设置密码还是重命名命令，都需要保证配置文件的安全性，否则就没有任何意义了。  </p><h2 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h2><p>Redis通信协议是Redis客户端与Redis之间交流的语言，通信协议规定了命令和返回值的格式。了解Redis通信协议后不仅可以理解AOF文件的格式和主从复制时主数据库向从数据库发送的内容等，还可以开发自己的客户端。<br>Redis支持两种通信协议，一种是二进制安全的统一请求协议（unified request protocol），另一种是比较直观的便于在telnet程序中输入的简单协议。这两种协议只是命令格式有区别，命令返回值的格式是一样的。  </p><h3 id="1、简单协议"><a href="#1、简单协议" class="headerlink" title="1、简单协议"></a>1、简单协议</h3><p>简单协议适合在telnet程序中和Redis通信。简单协议的命令格式就是将命令和各个参数使用空格分隔开，如“EXISTS foo ”、“SET foo bar”等。由于Redis解析简单协议时只是简单地以空格分隔参数，所以无法输入二进制字符。我们可以通过telnet程序测试：  </p><pre><code>[admin@KFCS2 redis-stable]$ telnet  127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.set foo bar-NOAUTH Authentication required.auth 123456+OKset foo bar +OKget foo$3barlpush plist 1 2 3          :3lrange plist 0 -1*3$13$12$11errorcommand-ERR unknown command &apos;errorcommand&apos;</code></pre><p>我们在telnet程序中输入的5条命令恰好展示了Redis5种返回类型的格式，上面章节介绍了这5种返回值类型在redis-cli中的展现形式，这些展现形式是经过了redis-cli封装的，而上面的内容才是Redis真正返回的格式。下面分别介绍。<br>1、错误回复<br>错误回复（error reply）以-开头，并在后面跟上错误信息，最后以\r\n结尾：<br>-ERR unknown command ‘errorcommand’\r\n</p><p>2、状态回复<br>状态回复（status reply）以+开头，并在后面跟上状态信息，最后以\r\n结尾：<br>+OK\r\n</p><p>3、整数回复<br>整数回复（integer reply）以：开头，并在后面跟上数字，最后以\r\n结尾：<br>:3\r\n</p><p>4、字符串回复<br>字符串回复（bulk reply）以$开头，并在后面跟上字符串的长度，并以以\r\n分隔，接着是字符串的内容和\r\n：<br>$3\r\nbar\r\n<br>如果返回值是空结果nil，则会返回$-1以和空字符串相区别。</p><p>5、多行字符串回复<br>多行字符串回复（multi-bulk reply）以<em>开头，并在后面跟上字符串回复的组数，并以\r\n分隔。接着后面跟的就是字符串回复的具体内容了：  </em>3\r\n$1\r\n3\r\n$1\r\n2\r\n$1\r\n1\r\n</p><h3 id="2、统一请求协议"><a href="#2、统一请求协议" class="headerlink" title="2、统一请求协议"></a>2、统一请求协议</h3><p>统一请求协议是从Redis1.2开始加入的，其命令格式和多行字符串回复的格式很类似，如 SET foo bar 的统一请求协议写法是*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$3\r\nbar\r\n。还是使用telnet进行演示：  </p><pre><code>[admin@KFCS2 redis-stable]$ telnet  127.0.0.1 6379Trying 127.0.0.1...Connected to 127.0.0.1.Escape character is &apos;^]&apos;.*3$3  SET$3    foo$3bar-NOAUTH Authentication required.auth 123456+OK</code></pre><p>同样发送命令时指定了后面字符串的长度，所以命令的每个参数都可以包含二进制的字符。统一请求协议的返回值格式和简单协议一样。<br>Redis的AOF文件和主从复制时主数据库向从数据库发送的内容都是用了统一请求协议。如果要开发一个和Redis直接通信的客户端，推荐使用此协议。如果只是想通过telnet向Redis服务器发送命令则使用简单协议就可以了。  </p><h2 id="管理工具"><a href="#管理工具" class="headerlink" title="管理工具"></a>管理工具</h2><p>工欲善其事必先利其器。在使用Redis的时候如果能够有效利用Redis的各种管理工具，将会大大方便开发和管理。  </p><h3 id="1、redis-cli"><a href="#1、redis-cli" class="headerlink" title="1、redis-cli"></a>1、redis-cli</h3><p>作为Redis自带的命令行客户端，你可以从任何安装有Redis的服务器中找到它，所以对于管理Redis而言redis-cli是最简单实用的工具。<br>redis-cli可以执行大部分的Redis命令，包括查看数据库信息的INFO命令，更改数据库设置的CONFIG命令和强制进行RDB快照的SAVE命令等。下面介绍几个管理Redis时非常有用的命令。<br>1、耗时命令日志<br>当一条命令执行时间超时限制时，Redis会将该命令的执行时间等信息加入耗时命令日志（slow log）以供开发者查看。可以通过配置文件<code>slowlog-log-slower-than</code> 参数设置这一限制，要注意单位是微妙（1000 000微妙相当于1秒），默认值是10 000。耗时命令日志存储在内存中，可以通过配置文件的<code>slowlog-max-len</code>参数来限制记录的条数。为了产生一些耗时命令日志作为演示，这里将<code>slowlog-log-slower-than</code>参数值设置为0，即记录所有命令。如果设置为负数则会关闭耗时命令日志。如：  </p><pre><code>127.0.0.1:6379&gt; slowlog get 1) 1) (integer) 16    2) (integer) 1497011605    3) (integer) 52    4) 1) &quot;set&quot;       2) &quot;foo&quot;       3) &quot;bar&quot; 2) 1) (integer) 15    2) (integer) 1497011599    3) (integer) 6    4) 1) &quot;get&quot;       2) &quot;foo&quot;</code></pre><p>每条日志都由以下4个部分组成：<br>（1）改日志唯一ID<br>（2）改命令执行的UNIX时间<br>（3）改命令的耗时时间，单位是微妙<br>（4）命令及其参数  </p><p>2、命令监控<br>Redis提供了MONITOR命令来监控Redis执行的所有命令，redis-cli同样支持这个命令，如在redis-cli中执行MONITOR： </p><pre><code>127.0.0.1:6379&gt; monitorOK</code></pre><p>这时Redis执行的任何命令都会在redis-cli中打印出来，如我们打开另一个redis-cli执行SET foo bar命令，在之前的redis-cli中会输出如下内容：  </p><pre><code>1497012041.878429 [0 127.0.0.1:55062] &quot;auth&quot; &quot;123456&quot;1497012053.311366 [0 127.0.0.1:55062] &quot;set&quot; &quot;foo&quot; &quot;bar&quot;</code></pre><p>MONITOR命令非常影响Redis的性能，一个客户端使用MONITOR命令会降低Redis将近一半的负载能力。所以MONITOR命令只适合用来调试和纠错。</p><h3 id="2、采用phpRedisAdmin"><a href="#2、采用phpRedisAdmin" class="headerlink" title="2、采用phpRedisAdmin"></a>2、采用phpRedisAdmin</h3><p>Redis有一款使用PHP开发的网页管理工具phpRedisAdmin。phpRedisAdmin支持以树结构查看键列表，编辑键值，导入/导出数据库数据，查看数据库信息和查看键信息等功能。  </p><h3 id="3、Rdbtools"><a href="#3、Rdbtools" class="headerlink" title="3、Rdbtools"></a>3、Rdbtools</h3><p>Rdbtools是一个Redis快照文件解析器，它可以根据快照文件导出JSON数据文件、分析Redis中每个键的占用空间情况等。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis安全 </tag>
            
            <tag> redis数据库密码 </tag>
            
            <tag> redis命令重命名 </tag>
            
            <tag> redis通信协议 </tag>
            
            <tag> redis管理工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之集群</title>
      <link href="/2017/06/05/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E9%9B%86%E7%BE%A4/"/>
      <url>/2017/06/05/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E9%9B%86%E7%BE%A4/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>即使使用哨兵，此时的Redis集群的每个数据库依然存有集群中的所有数据，从而导致集群的总数据存储量受限于可用存储内存最小的数据库节点，形成木桶效应。由于Redis中的所有数据都是基于内存存储，这一问题就尤为突出了，尤其是当使用Redis做了持久化存储服务使用时。<br>对Redis进行水平扩容，在旧版Redis中通常使用客户端分片来解决这个问题，即启动多个Redis数据库节点，由客户端决定每个键交由哪个数据库节点存储，下次客户端读取该键值时直接到该节点读取。这样可以实现将整个数据分布存储在N个数据库节点中，每个节点只存放总数据量的1/N。但对于需要扩容的场景来说，在客户端分片后，如果想增加更多的节点，就需要对数据进行手工迁移，同时在迁移的过程中为了保证数据的一致性，还需要将集群暂时下线，相对比较复杂。<br>考虑到Redis实例非常轻量的特点，可以采用预分片技术（presharding）来在一定程度上避免此问题，具体来说是在节点部署初期，就提前考虑日后的存储规模，建立足够多的实例（如128个节点），初期数据很少，所以每个节点存储的数据也非常少，但由于节点轻量的特性，数据之外的内存开销并不大，这使得只需要很少的服务器即可运行这些实例。日后存储规模扩大后，所要做的不过是将某些实例迁移到其他服务器上，而不需要对所有数据进行重新分片并进行集群下线和数据迁移了。<br>无论如何，客户端分片终归是有非常多的缺点，比如维护成本高，增加、移除节点较繁琐等。Redis3.0版的一大特性就是支持集群（Cluster，注意与本章标题–广义的“集群”相区别）功能。集群的特点在于拥有和单机实例同样的性能，同时在网络分区后能够提供一定的可访问性以及对主数据库故障恢复的支持。另外集群支持几乎所有的单机实例支持的命令，对于涉及多键的命令（如MGET），如果每个键都位于同一个节点中，则可以正常支持，否则会提示错误。除此之外集群还有一个限制是只能使用默认的0号数据库，如果执行SELECT切换数据库则会提示错误。<br>哨兵与集群是两个独立的功能，但从特性来看哨兵可以视为集群的子集，当不需要数据分片或者已经在客户端进行分片的场景下哨兵就足够使用了，但如果需要进行水平扩容，则集群是一个非常好的选择。  </p><h3 id="1、配置集群"><a href="#1、配置集群" class="headerlink" title="1、配置集群"></a>1、配置集群</h3><p>使用集群，只需要将每个数据库节点的cluster-enabled配置选项打开即可。每个集群中至少需要3个主数据库才能正常运行。<br>为了演示集群的应用场景以及故障恢复等操作，这里以配置一个3主3从的集群系统为例。首先建立启动6个Redis实例，需要注意的是配置文件应该打开cluster-enabled。一个示例配置为：  </p><pre><code>port 6380cluster-enabled yes  </code></pre><p>其中port参数修改成实际的端口即可。这里假设6个实例的端口分别是6380、6381、6382、6383、6384和6385。集群会将当前节点记录的集群状态持久化地存储在指定文件中，这个文件默认为当前工作目录下的nodes.conf文件。每个节点对应的文件必须不同，否则会造成启动失败，所以启动节点时要注意最后为每个节点使用不同的工作目录，或者是通过cluster-config-file选项修改持久化文件的名称：  </p><pre><code>cluster-config-file nodes.conf  </code></pre><p>启动后，可以使用Redis命令行客户端连接任意一个节点使用INFO命令来判断集群是否正常启用了：  </p><pre><code>192.168.100.238:6381&gt; info cluster# Clustercluster_enabled:1</code></pre><p>其中cluster_enabled为1表示集群正常启用了。现在每个节点都是完全独立的，要将它们加入同一个集群中还需要几个步骤。Redis源代码中提供了一个辅助工具redis-trib.rb可以非常方便地完成这一任务。因为redis-trib.rb使用Ruby语言编写的，所以运行前需要在服务器上安装Ruby程序，具体安装方法请查阅相关文档。redis-trib.rb依赖于gem包redis，可执行gem install redis来安装。使用redis-trib.rb来初始化集群，只需要执行：  </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-trib.rb create --replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385</code></pre><p>其中create参数表示要初始化集群，–replicas 1表示每个主数据库拥有的从数据库个数为1，所以集群共有3（6/2）个主数据库以及3个从数据库。执行完成后，redis-trib.rb会输出如下内容：  </p><pre><code>--未执行集群时&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:6380127.0.0.1:6381127.0.0.1:6382Adding replica 127.0.0.1:6383 to 127.0.0.1:6380Adding replica 127.0.0.1:6384 to 127.0.0.1:6381Adding replica 127.0.0.1:6385 to 127.0.0.1:6382M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) masterM: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) masterM: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) masterS: 50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383   replicates bec0f2a8743b6636cf53cd5611137dd9a5ee72f3S: 6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384   replicates a24810378b2ee15efbbef8bbf285872198ef6902S: 4c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385   replicates e18b9946f5c4db8b170b395a6de8204ab56237f9Can I set the above configuration? (type &apos;yes&apos; to accept): yes--已执行过集群后[admin@KFCS3 redis-stable]$ ./src/redis-trib.rb create --replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385&gt;&gt;&gt; Creating cluster[ERR] Node 127.0.0.1:6382 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.</code></pre><p>上实例2表示节点已分配插槽。上例1输出内容包括集群具体的分配方案，如果觉得没问题则输入yes来开始创建。下面根据上面的输出详细讲解集群创建的过程。<br>首先redis-trib.rb会以客户端的形式尝试连接所有节点，并发送PING命令以确定节点能够正常服务。如果有任何节点无法连接，则创建失败。同时发送INFO命令获取每个节点的运行ID以及是否开启了集群功能（即cluster_enabled为1）。<br>准备就绪后集群会向每个节点发送CLUSTER MEET 命令，格式为CLUSTER MEET ip port，这个命令用来告诉当前节点指定ip和port上在运行的节点也是集群的的一部分，从而使得6个节点最终可以纳入一个集群。<br>然后redis-trib.rb会分配主从数据库节点，分配的原则是尽量保证每个主数据库运行在不同的IP地址上，同时每个从数据库和主数据库均不运行在同一个IP地址上，以保证系统的容灾能力。分配结果如下：  </p><pre><code>Using 3 masters:127.0.0.1:6380127.0.0.1:6381127.0.0.1:6382Adding replica 127.0.0.1:6383 to 127.0.0.1:6380Adding replica 127.0.0.1:6384 to 127.0.0.1:6381Adding replica 127.0.0.1:6385 to 127.0.0.1:6382</code></pre><p>其中主数据库是6380、6381和6382端口上的节点（以下使用端口来指代节点），6383是6380的从数据库，6384是6381的从数据库，6385是6382的从数据库。分配完成后，会为每个主数据库分配插槽，分配插槽的过程其实就是分配哪些键归哪些节点负责。之后对每个要成为子数据库的节点发送CLUSTER REPLICATE 主数据库的运行ID 来讲当前节点转换成从数据库并复制指定运行ID的节点（主数据库）。<br>此时整个集群的过程即创建完毕，使用Redis命令行客户端连接任意一个节点执行CLUSTER NODES 可以获得集群中的所有节点信息，如在6380执行：  </p><pre><code>127.0.0.1:6380&gt; cluster nodes50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383 slave bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 0 1496677290597 4 connectede18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382 master - 0 1496677293602 3 connected 10923-163836054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384 slave a24810378b2ee15efbbef8bbf285872198ef6902 0 1496677294603 5 connectedbec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380 myself,master - 0 0 1 connected 0-54604c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385 slave e18b9946f5c4db8b170b395a6de8204ab56237f9 0 1496677292600 6 connecteda24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381 master - 0 1496677295605 2 connected 5461-10922</code></pre><p>从上面的输出中可以看到所有节点的运行ID、地址和端口、角色、状态以及负责的插槽等信息，后文会进行解读。redis-trib.rb是一个非常好用的辅助工具，其本质是通过执行Redis命令来实现集群管理的任务。如果有兴趣可以尝试不借助redis-trib.rb，手动建立一次集群。      </p><h3 id="2、节点的增加"><a href="#2、节点的增加" class="headerlink" title="2、节点的增加"></a>2、节点的增加</h3><p> 前面介绍过redis-trib.rb是使用CLUSTER MEET 命令来使每个节点认识集群中的其他节点的，可想而知如果要向集群中加入新节点，也需要使用CLUSTER MEET 命令实现。加入新节点非常简单，只需要向新节点（以下记着A）发送如下命令:  </p><pre><code>CLUSTER MEET ip port  </code></pre><p>ip和port是集群中任意一个节点的地址和端口号，A接受到客户端发来的命令后，会与该地址和端口号的节点B进行握手，使B将A认作当前集群中的一员。当B与A握手成功后，B会使用Gossip协议将节点A的信息通知给集群中的每一个节点。通过这一方式，即使集群中有多个节点，也只需要选择MEET 其中任意一个节点，即可使新节点最终加入整个集群。  </p><h3 id="3、插槽的分配"><a href="#3、插槽的分配" class="headerlink" title="3、插槽的分配"></a>3、插槽的分配</h3><p>新的节点加入集群后有两种选择，要么使用CLUSTER REPLICATE 命令复制每个数据库来以从数据库的形式运行，要么向集群申请分配插槽（solt）来以主数据库的形式运行。在一个集群中，所有的键会被分配给16384个插槽，而每个主数据库会负责处理其中的一部分插槽。现在回头来看上面创建集群时的输出：  </p><pre><code>M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) masterM: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) masterM: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) master</code></pre><p>上面的每一行表示一个主数据库的信息，其中可以看到6380负责处理0~5460折5461个插槽，6381负责处理5461~10922这5462个插槽，6382负责处理10923~16383这5461个插槽。虽然redis-trib.rb初始化集群分配给每个节点的插槽都是连续的，但是实际上Redis并没有限制，可以将任意的几个插槽分配给任意的节点负责。<br>在介绍如何将插槽分配给指定的节点前，先来介绍键和插槽的对应关系。Redis将每个键的键名的有效部分使用CRC16算法计算出散列值，然后取对16384的余数。这样使得每个键都可以分配到16384个插槽中，进而分配的指定的一个节点中处理。这里键名的有效部分是指：<br>（1）如果键名包含{符号，且在{符合后面存在}符号，并且{和}之间有至少一个字符，则有效部分是指{和}之间的内容。<br>（2）如果不满足上一条规则，那么整个键名为有效部分。<br>例如，键hello.world的有效部分为“hello.world”，键{user102}:last.name的有效部分为“user102”。如本节引言所说，如果命令涉及多个键（如MGET），只有当所有键都位于同一个节点时Redis才能正常支持。利用键的分配规则，可以将所有相关的键的有效部分设置成相同的值使得相关键都能分配到同一个节点以支持多键操作。比如，{user102}:first.name和{user102}:last.name会被分配到同一个节点，所以可以使用MGET {user102}:first.name {user102}:last.name 来同时获取两个键的值。介绍完键与插槽的对应关系后，接下来再来介绍如何将插槽分配给指定节点。插槽的分配分为如下几种情况。<br>（1）插槽之前没有被分配过，现在想分配给指定节点。<br>（2）插槽之前被分配过，现在想移动到指定节点。<br>其中第一种情况使用CLUSTER ADDSLOTS命令来实现，redis-trib.rb也是通过该命令在创建集群时为新节点分配插槽的。<strong>CLUSTER ADDSLOTS</strong>命令的用法为：  </p><pre><code>CLUSTER ADDSLOTS  slot1 [slot2] ... [slotN]</code></pre><p>如想将100和101两个插槽分配给某个节点，只需要在该节点执行：CLUSTER ADDSLOTS 100 101即可。如果指定插槽已经分配过了，则会提示：  </p><pre><code>127.0.0.1:6380&gt; cluster addslots 100 101(error) ERR Slot 100 is already busy  </code></pre><p>可以通过命令 <strong>CLUSTER SLOTS</strong> 来查看插槽分配情况，如：  </p><pre><code>127.0.0.1:6380&gt; cluster slots1) 1) (integer) 10923   2) (integer) 16383   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6382      3) &quot;e18b9946f5c4db8b170b395a6de8204ab56237f9&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6385      3) &quot;4c9ec5e346ac451d6d44df4d817112fdac3f6da6&quot;2) 1) (integer) 0   2) (integer) 5460   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6380      3) &quot;bec0f2a8743b6636cf53cd5611137dd9a5ee72f3&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6383      3) &quot;50c78a069f7d4a052d0f3e4c83083e6279b49acb&quot;3) 1) (integer) 5461   2) (integer) 10922   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;  </code></pre><p>其中返回结果的格式很容易理解，一共3条记录，每条记录的前两个表示插槽的开始号码和结束号码，后面的值则为负责该插槽的节点，包括主数据库和所有的从数据库，主数据库始终在第一位。<br>对于情况2，处理起来就相对复杂一些，不过redis-trib.rb提供了比较方便的方式来对插槽进行迁移。我们首先使用redis-trib.rb将一个插槽从6380迁移到6381，然后再介绍如何不使用redis-trib.rb来完成迁移。首先执行如下命令：  </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-trib.rb reshard 127.0.0.1:6380</code></pre><p>其中reshard表示告诉redis-trib.rb要重新分片，127.0.0.1:6380是集群中任意一个节点的地址和端口，redis-trib.rb会自动获取集群信息。接下来redis-trib.rb将会询问具体如何进行重新分片，首先会询问想要迁移多少个插槽：  </p><pre><code>How many slots do you want to move (from 1 to 16384)?</code></pre><p>我们只需要迁移一个，所以输入1后回车。接下来redis-trib.rb会询问要把插槽迁移到哪个节点： </p><pre><code>How many slots do you want to move (from 1 to 16384)? 1What is the receiving node ID? </code></pre><p>可以通过<strong>CLUSTER NODES</strong>命令获取6381的运行ID,这里是a24810378b2ee15efbbef8bbf285872198ef6902，输入并回车。接着最后异步是询问从那个节点移除插槽：  </p><pre><code>What is the receiving node ID? a24810378b2ee15efbbef8bbf285872198ef6902Please enter all the source node IDs.  Type &apos;all&apos; to use all the nodes as source nodes for the hash slots.  Type &apos;done&apos; once you entered all the source nodes IDs.Source node #1:all</code></pre><p>我们输入6380对应的ID按回车后输入done再按回车确认即可。接下来输入yes来确认重新分片方案，重新分片即告成功。</p><pre><code>Ready to move 1 slots.  Source nodes:    M: bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380   slots:0-5460 (5461 slots) master   1 additional replica(s)    M: e18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382   slots:10923-16383 (5461 slots) master   1 additional replica(s)  Destination node:    M: a24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381   slots:5461-10922 (5462 slots) master   1 additional replica(s)  Resharding plan:    Moving slot 0 from bec0f2a8743b6636cf53cd5611137dd9a5ee72f3Do you want to proceed with the proposed reshard plan (yes/no)? yesMoving slot 0 from 127.0.0.1:6380 to 127.0.0.1:6381:</code></pre><p>使用<strong>CLUSTER SLOTS</strong>命令获取当前插槽的分配情况如下：  </p><pre><code>127.0.0.1:6380&gt; cluster slots1) 1) (integer) 10923   2) (integer) 16383   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6382      3) &quot;e18b9946f5c4db8b170b395a6de8204ab56237f9&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6385      3) &quot;4c9ec5e346ac451d6d44df4d817112fdac3f6da6&quot;2) 1) (integer) 1   2) (integer) 5460   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6380      3) &quot;bec0f2a8743b6636cf53cd5611137dd9a5ee72f3&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6383      3) &quot;50c78a069f7d4a052d0f3e4c83083e6279b49acb&quot;3) 1) (integer) 0--多出来的第0号插槽   2) (integer) 0   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;4) 1) (integer) 5461   2) (integer) 10922   3) 1) &quot;127.0.0.1&quot;      2) (integer) 6381      3) &quot;a24810378b2ee15efbbef8bbf285872198ef6902&quot;   4) 1) &quot;127.0.0.1&quot;      2) (integer) 6384      3) &quot;6054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c&quot;</code></pre><p>可以看到现在比之前多了一条记录，第0号插槽已经有6381负责，此时重新分片成功。那么redis-trib.rb实现重新分片的原理是什么呢？我们不妨不借助redis-trib.rb手工进行重新分片，使用如下命令即可：  </p><pre><code>CLUSTER SETSLOTS 插槽号 NODE 新节点的运行ID</code></pre><p>如想要把0号插槽迁移回6380：  </p><pre><code>127.0.0.1:6380&gt; cluster nodes50c78a069f7d4a052d0f3e4c83083e6279b49acb 127.0.0.1:6383 slave bec0f2a8743b6636cf53cd5611137dd9a5ee72f3 0 1496714712675 4 connectede18b9946f5c4db8b170b395a6de8204ab56237f9 127.0.0.1:6382 master - 0 1496714710672 3 connected 10923-163836054c3053a0f50a9b8f6dc2e9134d6b1ce25e90c 127.0.0.1:6384 slave a24810378b2ee15efbbef8bbf285872198ef6902 0 1496714711674 7 connectedbec0f2a8743b6636cf53cd5611137dd9a5ee72f3 127.0.0.1:6380 myself,master - 0 0 1 connected 1-54604c9ec5e346ac451d6d44df4d817112fdac3f6da6 127.0.0.1:6385 slave e18b9946f5c4db8b170b395a6de8204ab56237f9 0 1496714710172 6 connecteda24810378b2ee15efbbef8bbf285872198ef6902 127.0.0.1:6381 master - 0 1496714706668 7 connected 0 5461-10922127.0.0.1:6380&gt; cluster setslot 0 node bec0f2a8743b6636cf53cd5611137dd9a5ee72f3OK</code></pre><p>此时重新使用CLUSTER SLOTS 查看插槽的分配情况，可以看到已经恢复如初了。然而这样迁移插槽的前提是插槽中并没有任何键，因为使用CLUSTER SETSLOT 命令迁移插槽时并不会连同相应的键一起迁移，这就造成了客户端在指定节点无法找到未迁移的键，造成这些键对客户端来说“丢失了”，为此需要手工获取插槽中存储在哪些键，然后将每个键迁移到新的节点中才行。手工获取某个插槽存在哪些键的方法是：  </p><pre><code>CLUSTER GETKEYSINSLOT 插槽号 要返回的键的数量</code></pre><p>之后对每个键，使用MIGRATE命令将其迁移到目标节点：  </p><pre><code>MIGRATE 目标节点地址 目标节点端口 键名 数据库号码 超时时间 [COPY] [REPLACE]</code></pre><p>其中COPY选项表示不将键从当前数据库中删除，而是复制一份副本。REPLACE表示如果目标节点存在同名键，则覆盖。因为集群模式只能使用0号数据库，所以数据库号码始终未0。如要把键abc从当前节点（如6381）迁移到6380：  </p><pre><code>MIGRATE 127.0.0.1 127.0.0.1 6380 abc 0 15999 REPLACE</code></pre><p>至此，我们已经知道如果将插槽委派给其他节点，并同时将当前节点中的插槽下所有的键迁移到目标节点中。然而还有最后一个是如果要迁移的数据量比较大，整个过程会话费较长时间，那么究竟在什么时候执行 CLUSTER SETSLOT 命令来完成插槽的交接呢？如果在键迁移未完成时执行，那么客户端就会尝试在新的节点读取键值，此时还没迁移完成，自然有可能读取不到键值，从而造成相关键的临时“丢失”。相反，如果在键迁移完成后在执行，那么在迁移时客户端会在旧的节点读取键值，然后有些键已经迁移到新节点上了，同样也会造成键的临时“丢失”。那么redis-trib.rb工具是如何解决这个问题的呢？Redis提供了如下两个命令用来实现在集群不下线的情况下迁移数据：  </p><pre><code>CLUSTER SETSLOT 插槽号 MIGRATING 新节点的运行IDCLUSTER SETSLOT 插槽号 IMPORTING 原节点的运行ID</code></pre><p>进行迁移时，假设要把0号插槽从A迁移到B，此时redis-trib.rb会依次执行如下操作。<br>（1）在B执行CLUSTER SETSLOT 0 IMPORTING A。<br>（2）在A执行CLUSTER SETSLOT 0 MIGRATING B。<br>（3）执行CLUSTER GETKEYSINSLOT 0 获取0号插槽的键列表。<br>（4）对第3步获取的每个键执行MIGRATE命令，将其从A迁移到B。<br>（5）执行CLUSTER SETSLOT 0 NODE B 来完成迁移。<br>从上面的步骤来看redis-trib.rb多了1和2两个步骤，这两个步骤就是为了解决迁移过程中键的临时“丢失”问题。首先执行完前两步后，当客户端向A请求插槽0中的键时，如果键存在（即尚未被迁移），则正常处理，如果不存在，则返回一个ASK跳转请求，告诉客户端这个键在B里，如下图所示，客户端接受到ASK跳转请求后，首先向B发送ASKING命令，然后再重新发送之前的命令。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/askA.png" alt="客户端请求A节点，服务器返回ASK情况">  </p><p>相反，当客户端向B请求插槽0中的键，如果前面执行了ASKING命令，则返回键值内容，否则返回MOVED跳转请求，如下图所示，这样一来客户端只有能够处理ASK跳转，则可以在数据库迁移时自动从正确的节点获取到相应的键值，避免了键在迁移过程中临时“丢失”的问题。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/askB.png" alt="客户端请求B节点，根据是否前面执行过ASKING，则返回不同"> </p><h3 id="4、获取与插槽对应的节点"><a href="#4、获取与插槽对应的节点" class="headerlink" title="4、获取与插槽对应的节点"></a>4、获取与插槽对应的节点</h3><p>对于指定的键，可以根据前面讲述的算法来计算其属于哪个插槽，但是如何获取某一个键有哪一个节点负责呢？<br>实际上，当客户端向集群中的任意一个节点发送命令后，该节点会判断相应的键是否在当前节点中，如果键在该节点中，则会像单机实例一样正确处理该命令；如果键不在该节点中，就会返回一个MOVE重定向请求，告诉客户端这个键目前由哪个节点负责，然后客户端再将同样的请求项目表节点重新发送一次以获取结果。<br>一些语言的redis库支持代理MOVE请求，所以对于开发者而言命令重定向的过程是透明的，使用集群与使用单机实例并没有什么不同。然而也有些语言库并不支持集群，这时就需要在客户端编码处理了。<br>还是以上面的集群配置为例，键foo实际应该由6382节点负责，如果尝试在6380节点执行与键foo相关的命令，就会有如下输出：  </p><pre><code>127.0.0.1:6380&gt; set foo bar(error) MOVED 12182 127.0.0.1:6382</code></pre><p>返回的是一个MOVE重定向请求，12182表示foo所属的插槽号，127.0.0.1:6382则是负责该插槽的节点地址和端口，客户端收到重定向请求后，应该将命令重新向6382节点发送一次：  </p><pre><code>127.0.0.1:6382&gt; set foo barOK</code></pre><p>Redis命令行客户端提供了集群模式来支持自动重定向，使用-c参数来启用： </p><pre><code>[admin@KFCS3 redis-stable_01]$ ./src/redis-cli -p 6380127.0.0.1:6380&gt; get foo(error) MOVED 12182 127.0.0.1:6382--加了c参数之后[admin@KFCS3 redis-stable_01]$ ./src/redis-cli -c -p 6380127.0.0.1:6380&gt; get foo-&gt; Redirected to slot [12182] located at 127.0.0.1:6382&quot;bar&quot;</code></pre><p>可见加入了-c参数后，如果当前节点并不负责要处理的键，Redis命令行客户端会进行自动命令重定向。而这一过程正是每个支持集群的客户端应该实现的。<br>然而相比单机实例，集群的命令重定向也增加了命令的请求次数，原先只需要执行一次的命令现在有可能需要依次发向两个节点，算上往返时延，可以说请求重定向对性能还是有些影响的。<br>为了解决这一问题，当发现新的重定向请求时，客户端应该在重新向正确节点发送命令的同时，缓存插槽的路由信息，即记录下当前插槽时由哪个节点负责的。这样每次发起命令时，客户端首先计算相关键是属于哪个插槽的，然后根据缓存的路由判断插槽有哪个节点负责。考虑到插槽总数相对少（16384个），缓存所有插槽的路由信息后，每次命令将均只发向正确的节点，从而达到和单机实例同样的性能。  </p><h3 id="5、故障恢复"><a href="#5、故障恢复" class="headerlink" title="5、故障恢复"></a>5、故障恢复</h3><p>在一个集群中，每个节点都会定期向其他节点发送PING命令，并通过有没有收到回复来判断目标节点是否已经下线了。具体来说，集群中的每个节点每隔1秒钟就会随机选择5个节点，然后选择其中最久没有响应的节点发送PING命令。<br>如果一定时间内目标节点没有响应回复，则发送PING命令的节点会认为目标节点疑似下线（PFALL）。疑似下线可以与哨兵的主观下线类比，两者都表示某一节点从自身的角度认为目标节点时下线状态。需要一定数量的节点都认为该节点疑似下线才可以，这一过程具体为：<br>（1）一旦节点A认为节点B是疑似下线状态，就会在集群中传播该消息，所有其他节点收到消息后都会记录下这一信息；<br>（2）当集群中的某一节点C收集到半数以上的节点认为B是疑似下线的状态时，就会将B标记为下线（FALL），并且向集群中的其他节点传播该消息，从而使得B在整个集群中下线。<br>在集群中，当一个数据库下线时，就会出现一部分插槽无法写入的问题。这时如果该主数据库拥有至少一个从数据库，集群就进行故障恢复操作来将其中一个从数据库转变成主数据库来保证集群的完整。选择哪个从数据库来作为主数据库的过程与哨兵中选择领头哨兵的过程一样，都是基于Raft算法，过程如下：<br>（1）发现其复制的主数据下线的从数据库（下面称作A）向每个集群中的节点发送请求，要求对方选自己成为主数据库。<br>（2）如果收到请求的节点没有选过其他人，则会同意将A设置成主数据库。<br>（3）如果A发现有超过集群中节点总数一半的节点同意选自己成为主数据库，则A则成为主数据库。<br>（4）当有多个从数据库节点同时参选主数据库，则会出现没有任何节点当选的可能。此时每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。<br>当某个从数据库当选为主数据库后，会通过命令SLAVEOF NO ONE 将自己转换成主数据库，并将旧的主数据库的插槽转换给自己负责。<br>如果一个至少负责一个插槽的主数据库下线且没有相应的从数据库可以进行故障恢复，则整个集群默认会进入下线状态无法继续工作。如果想在这种情况下使集群仍然能正常工作，可以修改配置cluster-require-full-coverage为no（默认为yes）：  </p><pre><code>cluster-require-full-converage no</code></pre>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis集群 </tag>
            
            <tag> redis-trib.rb集群辅助工具 </tag>
            
            <tag> 集群（cluster）插槽slot </tag>
            
            <tag> 节点（node）的插槽（slot）分配 </tag>
            
            <tag> 键归属的插槽 </tag>
            
            <tag> 集群故障恢复 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之哨兵</title>
      <link href="/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%93%A8%E5%85%B5/"/>
      <url>/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%93%A8%E5%85%B5/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h2><p>Redis中的复制的原理和使用方式，在一个典型的一主多从的Redis系统中，从数据库在整个系统中起到了数据冗余备份和读写分离的作用。当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然后整个过程相对麻烦且需要人工介入，难以实现自动化。为此，Redis2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。  </p><h3 id="1、什么是哨兵"><a href="#1、什么是哨兵" class="headerlink" title="1、什么是哨兵"></a>1、什么是哨兵</h3><p>顾名思义，哨兵的作用就是监控Redis系统的运行状况。它的功能包含以下两个。<br>（1）监控主数据库和从数据库是否正常运行。<br>（2）主数据库出现故障时自动将从数据库转换为主数据库。<br>哨兵是一个独立的进程，使用哨兵的一个典型架构如下图:  </p><p><img src="http://op7wplti1.bkt.clouddn.com/sentinelMonitor.png" alt="哨兵监控">  </p><p>在一个一主多从的Redis系统中，可以使用多个哨兵进行监控任务以保证系统足够稳健，如下图所示。注意，此时不仅哨兵会同时监控主数据库和从数据库，哨兵之间也会相互监控。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/multiSentinel.png" alt="一主多从Redis集群多哨兵监控">  </p><h3 id="2、实例讲解"><a href="#2、实例讲解" class="headerlink" title="2、实例讲解"></a>2、实例讲解</h3><p>在理解哨兵的原理前，我们首先实际使用一下哨兵，来了解哨兵是如何工作的。为了简单起见，我们将建立三个Redis的集群（一主两从）。我们使用Redis命令行客户端来获取复制状态，以保证复制配置正确。<br>首先是主数据库：  </p><pre><code>--236服务器127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.100.237,port=6379,state=online,offset=151945,lag=1slave1:ip=192.168.100.238,port=6379,state=online,offset=152104,lag=0master_repl_offset:152104repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:152103  </code></pre><p>可见其连接了两个从数据库，配置正确。然后用相同的方法查看两个从数据库的配置：  </p><pre><code>--237服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:159045slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  --238服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:1master_sync_in_progress:0slave_repl_offset:160972slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  </code></pre><p>当出现的信息如上时，即证明一主二从的配置已经成功了。接下来配置哨兵。建立一个配置文件，如sentinel.conf，内容为：  </p><pre><code>sentinel monitor mymaster 192.168.100.236 6379 1  </code></pre><p>其中mymaster表示要监控的主数据库的名字，可以自己定义一个。这个名字必须仅有大小写字母、数字和“.-_”这三种字符组成。后面2个参数表示主数据库的地址和端口号，这里我们要监控的是主数据库236。最后一个1表示最低通过票数。接下来启动sentinel进程，并将上述配置的路径传递给哨兵：  </p><pre><code>[root@KFCS1 src]# ./redis-sentinel ../sentinel.conf  </code></pre><p>需要注意的是，配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自动发现所有复制该主数据库的从数据库。启动哨兵后，哨兵输出内容如下：  </p><pre><code>Sentinel ID is 5f9becd72d6c4e8d7e5c0a06836b1b79a8ad055014246:X 02 Jun 17:39:46.909 # +monitor master mymaster 192.168.100.236 6379 quorum 114246:X 02 Jun 17:39:46.911 * +slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:39:46.938 * +slave slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 6379</code></pre><p>其中+slave表示新发现了从数据库，可见哨兵成功地发现了两个从数据库。现在哨兵已经在监控这3个Redis实例了，这时我们将主数据库关闭（杀死进程或使用SHUTDOWN命令），等待指定时间后（可以配置，默认为30秒），哨兵会输出如下内容：  </p><pre><code>14246:X 02 Jun 17:40:34.699 # +sdown master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.700 # +odown master mymaster 192.168.100.236 6379 #quorum 1/1  </code></pre><p>其中+sdown表示哨兵主观认为主数据库停止服务了，而+odown则表示哨兵客观认为主数据库停止服务了，关于主观和客观的区别后文会详细介绍。此时哨兵开始执行故障恢复，即挑选一个从数据库，将其升格为主数据库，输出如下：  </p><pre><code>14246:X 02 Jun 17:40:34.700 # +try-failover master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.714 # +vote-for-leader 5f9becd72d6c4e8d7e5c0a06836b1b79a8ad0550 214246:X 02 Jun 17:40:34.714 # +elected-leader master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.714 # +failover-state-select-slave master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.815 # +selected-slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.815 * +failover-state-send-slaveof-noone slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:34.891 * +failover-state-wait-promotion slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.072 # +promoted-slave slave 192.168.100.238:6379 192.168.100.238 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.072 # +failover-state-reconf-slaves master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:35.134 * +slave-reconf-sent slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.104 * +slave-reconf-inprog slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.104 * +slave-reconf-done slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.186 # +failover-end master mymaster 192.168.100.236 637914246:X 02 Jun 17:40:36.186 # +switch-master mymaster 192.168.100.236 6379 192.168.100.238 637914246:X 02 Jun 17:40:36.186 * +slave slave 192.168.100.237:6379 192.168.100.237 6379 @ mymaster 192.168.100.238 637914246:X 02 Jun 17:40:36.187 * +slave slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 6379  </code></pre><p>+try-failover表示哨兵开始进行故障恢复，+failover-end表示哨兵完成故障恢复，期间涉及的内容比较复杂，包括领头哨兵的选举、备选从数据库的选择等，放到后面介绍，此处只需要关注最后3条输出。+switch-master表示主数据库从236转换到了238，即238服务器升格为主数据库，同时两个+slave则列出了新的主数据库的2个从数据库。其中236就是之前停止服务的主数据库，可见哨兵并没有彻底清除停止服务的实例信息，这是因为停止服务的实例有可能会在之后的某个时间恢复服务，这时哨兵会让其重新加入进来，所以当实例停止服务后，哨兵会更新该实例的信息，使得当其重新加入后可以按照当前信息继续对外提供服务。此例中236主数据库实例停止服务了，而238服务器的从数据库已经升格为主数据库，当236实例恢复服务后，会转变为238实例的从数据库来运行，所以哨兵将236服务器实例的信息修改成了238实例的从数据库。<br>故障恢复完成后，可以使用Redis命令行客户端重新检查237/238两台服务器上的实例信息：  </p><pre><code>--237服务器127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.238master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:308379slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0--238服务器127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.100.237,port=6379,state=online,offset=311494,lag=1master_repl_offset:311494repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:311493  </code></pre><p>可以看到238服务器上实例已经确实升格为主数据库了，同时237服务器上的实例是其从数据库。整个故障恢复过程就此完成。那么我们重新启动236服务器上的Redis实例，监控到的日志输出如下:  </p><pre><code>14246:X 02 Jun 17:42:27.637 # -sdown slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 637914246:X 02 Jun 17:42:37.643 * +convert-to-slave slave 192.168.100.236:6379 192.168.100.236 6379 @ mymaster 192.168.100.238 6379</code></pre><p>-sdown表示实例236已经恢复服务了（与+sdown相反）同时+convert-to-slave表示将236服务器的实例设置为238服务器实例的从数据库。这时使用Redis命令行客户端查看236实例的复制信息为：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.238master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:333678slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0  </code></pre><p>同时238端口的复制信息为:  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.100.237,port=6379,state=online,offset=311494,lag=1slave1:ip=192.168.100.236,port=6379,state=online,offset=311494,lag=0master_repl_offset:311494repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:311493</code></pre><p>正如预期一样，238实例的从数据库变为了2个，236成功恢复服务。</p><h3 id="3、实现原理"><a href="#3、实现原理" class="headerlink" title="3、实现原理"></a>3、实现原理</h3><p>一个哨兵进程启动时会读取配置文件的内容，通过如下的配置找出需要监控的主数据库：  </p><pre><code>sentinel monitor master-name ip redis-port quorum</code></pre><p>其中master-name是一个由大小写字母、数字和“.-_”组成的主数据库的名字，因为考虑到故障恢复后当前监控的系统的主数据库的地址和端口号会产生变化，所以哨兵提供了命令可以通过主数据库的名字获取当前系统的主数据库的地址和端口号。<br>ip 表示当前系统中主数据库的地址，而redis-port则表示端口号。<br>quorum用来表示执行故障恢复操作前至少需要几个哨兵节点同意。一个哨兵节点可以同时监控多个Redis主从系统，只需要提供多个sentinel monitor 配置即可，例如：  </p><pre><code>sentinel monitor mymaster 127.0.0.1 6379 2sentinel monitor othermaster 192.168.100.238 6379 1</code></pre><p>同时多个哨兵节点也可以同时监控同一个Redis主从系统，从而形成网状结构。具体实践时如何协调哨兵与主从系统的数量关系将在后文介绍。<br>配置文件中还可以定义其他监控相关的参数，每个配置选项都包含主数据的名字使得监控不同主数据库时可以使用不同的配置参数。如：  </p><pre><code>sentinel down-after-milliseconds mymaster 60000sentinel down-after-milliseconds othermaster 10000</code></pre><p>上面的两行配置分别配置了mymaster和othermaster的sentinel down-after-milliseconds选项分别为60000和10000。<br>哨兵启动后，会与要监控的主数据库建立两条连接，这两条连接的建立方式与普通的Redis客户端无异。其中一条连接用来订阅该主数据库的__sentinel__:hello频道以获取其他同样监控该数据库的哨兵节点的信息，另外哨兵也需要定期向主数据库发送INFO等命令来获取主数据库本身的信息，因为之前介绍过当客户端的连接进入订阅模式时就不能再执行其他命令了，所以这时哨兵会使用另外一条连接来发送这些命令。和主数据库的连接建立完成后，哨兵会定时执行下面3个操作。<br>（1）每10秒哨兵会向主数据库和从数据库发送INFO命令。<br>（2）每2秒哨兵会向主数据库和从数据库的__sentinel__:hello频道发送自己的信息。<br>（3）每1秒哨兵会向主数据库、从数据库和其他哨兵节点发送PING命令。<br>这3个操作贯穿哨兵进程的整个生命周期中，非常重要，可以说了解了这3个操作的意义就能够了解哨兵工作原理的一半内容了。<br>首先，发送INFO命令使得哨兵可以获得当前数据库的相关信息（包括运行ID、复制信息等）从而实现新节点的自动发现。前面说配置哨兵监控Redis主从系统时只需要指定主数据库的信息即可，因为哨兵正是借助INFO命令来获取所有复制该主数据库的从数据库信息的。启动后，哨兵向主数据库发送INFO命令，通过解析返回结果来得知从数据库列表，而后对每个从数据库同样建立2个连接，2个连接的作用和前面介绍的与主数据库建立的2个连接完全一致。在此之后哨兵会每10秒定时向已知的所有主从数据库发送INFO命令来获取信息更新并进行相应操作，比如对新增的从数据库建立连接并加入监控列表，对主从数据库的角色变化（由故障恢复操作引起）进行信息更新等。<br>接下来哨兵向主从数据库的__sentinel__:hello频道发送信息来与同样监控该数据库的哨兵分享自己的信息。发送的消息内容为：  </p><blockquote><p>&lt;哨兵的地址&gt;,&lt;哨兵的端口&gt;,&lt;哨兵的运行ID&gt;,&lt;哨兵的配置版本&gt;,&lt;主数据的名字&gt;,&lt;主数据库的地址&gt;,&lt;主数据库的端口&gt;,&lt;主数据库的配置版本&gt;  </p></blockquote><p>可以看到消息包括的哨兵的基本信息，以及其监控的数据库的信息。前文介绍过，哨兵会订阅每个其监控的数据库的__sentinel__:hello频道，所以当其他哨兵收到消息后，会判断发送消息的哨兵是不是新发现的哨兵。如果是则将其加入已发现的哨兵列表中并创建一个到其的连接（与数据库不同，哨兵与哨兵之间只会创建一条连接用来发送PING命令，而不需要创建另外一条连接来订阅频道，因为哨兵只需要订阅数据库的频道即可实现自动发现其他哨兵）。同时哨兵会判断信息中主数据的配置版本，如果该版本比当前记录的主数据库的版本高，则更新主数据库的数据。配置版本的作用将在后面介绍。<br>实现了自动发现从数据库和其他哨兵节点后，哨兵要做的就是定时监控这些数据库和节点有没有停止服务。这是通过每隔一定时间向这些节点发送PING命令实现的。时间间隔与down-after-milliseconds选项有关，当down-after-milliseconds的值小于1秒时，哨兵会每隔down-after-milliseconds指定的时间发送一次PING命令，当down-after-milliseconds的值大于1秒时，哨兵会每隔1秒发送一次PING命令。如：  </p><pre><code>--每隔1秒发送一次PING命令sentinel down-after-milliseconds mymaster 60000--每隔600毫秒发送一次PING命令sentinel down-after-milliseconds mymaster 600</code></pre><p>当超过down-after-milliseconds选项指定时间后，如果被PING的数据库或节点仍然未进行回复，则哨兵认为其主观下线(subjectively down)。主观下线表示从当前的哨兵进程看来，该节点已经下线。如果该节点是主数据库，则哨兵会进一步判断是否需要对其进行故障恢复：哨兵发送SENTINEL is-master-down-by-addr命令询问其他哨兵节点以了解他们是否也认为该主数据库主观下线，如果达到指定数量时，哨兵会认为其客观下线（objectively down），并选举领头的哨兵节点对主从系统发起故障恢复。这个指定数量即为前文介绍的quorum参数。如下配置：  </p><pre><code>sentinel monitor mymaster 127.0.0.1 6379 2</code></pre><p>该配置表示只有当至少2个sentinel节点（包括当前节点）认为该主数据库主观下线时，当前哨兵节点才会认为该主数据库客观下线。进行接下来的选举领头哨兵步骤。<br>虽然当前哨兵节点发现了主数据库客观下线，需要故障恢复，但是故障恢复需要有领头的哨兵来完成，这样可以保证同一时间只有一个哨兵节点来执行故障恢复。选举领头哨兵的过程使用后了Raft算法，具体如下：<br>（1）发现主数据库客观下线的哨兵节点（下面称作A）向每个哨兵节点发送命令，要求对方选自己成为领头哨兵。<br>（2）如果目标哨兵节点没有选过其他人，则会同意将A设置成领头哨兵。<br>（3）如果A发现有超过半数且超过quorum参数值的哨兵节点同意选自己成为领头哨兵，则A成功成为领头哨兵。<br>（4）当有多个哨兵节点同时参选领头哨兵，则会出现没有任何节点当选的可能。此时每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。<br>具体过程可以参考Raft算法的过程<a href="http://www.cnblogs.com/mindwind/p/5231986.html" target="_blank" rel="noopener">http://www.cnblogs.com/mindwind/p/5231986.html</a>。因为要成为领头哨兵必须有超过半数的哨兵节点支持，所以每次选举最多只会选出一个领头哨兵。<br>选出领头哨兵后，领头哨兵将会开始对主数据库进行故障恢复。故障恢复的过程相对简单，具体如下：<br>首先领头哨兵将从停止服务的主数据库的从数据库中挑选一个充当新的主数据库。挑选的依据如下：<br>（1）所有在线的从数据库中，选择优先级最高的从数据库。优先级可以通过slave-priority选项来设置。<br>（2）如果有多个最高优先级的从数据库，则复制的命令偏移量越大（即复制越完整）越优先。<br>（3）如果以上条件都一样，则选择运行ID较小的从数据库。<br>选出一个从数据库后，领头哨兵将向从数据库发送SLAVEOF NO ONE 命令使其升格为主数据库。而后领头哨兵向其他从数据库发送SLAVEOF命令来使其成为新主数据库的从数据库。最后一步则是更新内部的记录，将已经停止服务的旧的主数据库更新成为新的主数据库的从数据库，使得当其恢复服务时自动以从数据库的身份继续服务。  </p><h3 id="4、哨兵的部署"><a href="#4、哨兵的部署" class="headerlink" title="4、哨兵的部署"></a>4、哨兵的部署</h3><p>哨兵以独立进程的方式对一个主从系统进行监控，监控的效果好坏与否取决于哨兵的视角是否有代表性。如果一个主从系统中配置的哨兵较少，哨兵对整个系统的判断的可靠性就会降低。极端情况下，当只有一个哨兵时，哨兵本身就可能会发生单点故障。整体来讲，相对稳妥的哨兵部署方案是使得哨兵的视角尽可能地与每个节点的视角一致，即：<br>（1）为每个节点（无论是主数据库还是从数据库）部署一个哨兵。<br>（2）使每个哨兵与其对应的节点网络环境相同或相近。<br>这样的部署方案可以保证哨兵的视角拥有较高的代表性和可靠性。举例：当网络分区后，如果哨兵认为某个分区是主要分区，即意味着从每个节点观察，该分区均为主分区。同时设置quorum的值为N/2+1（其中N为哨兵节点数量），这样使得只有当大部分哨兵节点同意后才会进行故障恢复。<br>当系统中的节点较多时，考虑到每个哨兵都会和系统中的所有节点建立连接，为每个节点分配一个哨兵会产生较多连接，尤其是当进行客户端分片时使用多个哨兵节点监控多个主数据库会因为Redis不支持连接复用而产生大量冗余连接，同时如果Redis节点负载较高，会在一定程度上影响其对哨兵的回复以及与其节点的通信。所以配置哨兵时还需要根据实际的生产环境情况进行选择。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis哨兵监控 </tag>
            
            <tag> 哨兵（sentinel）的实现原理 </tag>
            
            <tag> 哨兵的配置 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之复制</title>
      <link href="/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%A4%8D%E5%88%B6/"/>
      <url>/2017/06/02/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E5%A4%8D%E5%88%B6/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此，Redis提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。  </p><h3 id="1、配置"><a href="#1、配置" class="headerlink" title="1、配置"></a>1、配置</h3><p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库（slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/masterSlave.png" alt="Redis一主多从数据库示意图">  </p><p>在Redis中使用复制功能非常容易，只需要在从数据库的配置文件中加入“slaveof 主数据库地址 主数据库端口”即可，主数据库无需进行任何配置。为了能够更直观地展示复制的流程，下面将实现一个最简化的复制系统。我们在1台服务器上启动2个Redis实例，监听不同端口，其中一个作为主数据库，另一个作为从数据库。首先我们不加任何参数来启动一个Redis实例作为主数据库： </p><pre><code>redis-server redis.conf</code></pre><p>该实例默认监听6379端口。然后加上slaveof参数启动另一个Redis实例作为从数据库，并让其监听6380端口：  </p><pre><code>redis-server --port 6380 --slaveof 127.0.0.1 6379</code></pre><p>此时在主数据库中的任何数据变化都会自动同步到从数据库中。我们打开redis-cli实例A并连接到主数据库： </p><pre><code>redis-cli -p 6379</code></pre><p>再打开redis-cli实例B并连接到从数据库：  </p><pre><code>redis-cli -p 6380</code></pre><p>这是我们使用INFO命令来分别在实例A和实例B中获取Replication节点的相关信息：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.100.237,port=6379,state=online,offset=1346,lag=1master_repl_offset:1346repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:1345</code></pre><p>可以看到，实例A的角色（上面输出中的role）是master，即主数据库，同时已连接的从数据库（上面输出中的connected_slaves）的个数为1。同样在实例B中获取相应的信息为：  </p><pre><code>127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.100.236master_port:6379master_link_status:upmaster_last_io_seconds_ago:4master_sync_in_progress:0slave_repl_offset:1714slave_priority:100slave_read_only:0connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0</code></pre><p>这里可以看到，实例B的role是slave，即从数据库，同时其主数据的地址为127.0.0.1，端口为6379。在实例A中使用SET命令设置一个键的值： </p><pre><code>127.0.0.1:6379&gt; set foo barOK</code></pre><p>此时在实例B中就可以获得该值了：  </p><pre><code>127.0.0.1:6379&gt; get foo&quot;bar&quot;</code></pre><p>默认情况下，从数据库是只读的，如果直接修改从数据库的数据库会出现错误： </p><pre><code>127.0.0.1:6379&gt; set foo bar(error) READONLY You can&apos;t write against a read only slave.</code></pre><p>可以通过设置从数据库的slave-read-only为no以使从数据库可写，但是因为对从数据库的任何更改都不会同步给任何其他数据库，并且一旦主数据库中更新了对应的数据就会覆盖从数据库中的改动，所以通常的场景下不应该设置从数据库可写，以免导致易被忽略的潜在应用逻辑错误。<br>配置多台从数据库的方法也一样，在所有的从数据库的配置文件中都加上slaveof 参数指向同一个主数据库即可。除了通过配置文件或命令行参数设置slaveof 参数，还可以在运行时使用slaveof命令修改：  </p><pre><code>slaveof 127.0.0.1 6379</code></pre><p>如果该数据库已经是其他主数据库的从数据库了，SLAVEOF命令会停止和原来数据库的同步转而和新数据库同步。此外对于从数据库来说，还可以使用SLAVEOF NO ONE 命令来使当前数据库停止接受其他数据库的同步并转换成为主数据库。  </p><h3 id="2、原理"><a href="#2、原理" class="headerlink" title="2、原理"></a>2、原理</h3><p>了解Redis复制的原理对日后运维有很大帮助，包括如何规划节点，如何处理节点故障等。下面将详细介绍Redis实现复制的过程。<br>当一个从数据库启动后，会向主数据库发送SYNC命令。同时主数据库接收到SYNC命令后会开始在后台保存快照（即RDB持久化的过程），并将保存快照期间接收到的命令缓存起来。当快照完成后，Redis会将快照文件和所有缓存的命令发送给从数据库。从数据库收到后，会载入快照文件并执行收到的缓存的命令。以上过程称为复制初始化。复制初始化结束后，主数据库每当收到写命令时就会将命令同步给从数据库，从而保证主从数据库数据一致。<br>当主从数据库之间的连接断开重连后，Redis2.6以及之前的版本会重新进行复制初始化（即主数据库保存快照并传送给从数据库），即使从数据库可能仅有几条命令没有收到，主数据库也必须要将数据库里的所有数据重新传送给从数据库。这使得主从数据库断线重连后的数据恢复过程效率很低下，在网络环境不好的时候这一问题尤其明显。Redis2.8版的一个重要改进就是断线重连能够支持有条件的增量数据传输，当从数据库重新连接上主数据库后，主数据库只需要将断线期间执行的命令传送给从数据库，从而大大提高Redis复制的实用性。<br>下面将从具体协议角度详细介绍复制初始化的过程。由于Redis服务器使用TCP协议通信，所以我们可以使用telnet工具伪装成一个从数据库来与主数据库通信。首先在命令行中连接主数据库（默认端口为6379，假设目前没有任何从数据库连接）：  </p><pre><code>[admin@KFCS2 ~]$ telnet 192.168.100.236 6379Trying 192.168.100.236...Connected to 192.168.100.236.Escape character is &apos;^]&apos;.</code></pre><p>然后作为从数据库，我们先要发送PING命令确认主数据库是否可以连接： </p><pre><code>ping+PONG</code></pre><p>主数据库会回复+PONG。如果没有收到主数据库的回复，则向用户提示错误。如果主数据库需要密码才能连接，我们还要发送AUTH命令进行验证。而后向主数据库发送REPLCONF命令说明自己的端口号：  </p><pre><code>replconf listening-port 6379 +OK</code></pre><p>这时就可以开通同步的过程了：向主数据库发送SYNC命令开始同步，此时主数据库发送回快照文件和缓存命令。目前主数据库中只有一个foo键，所以收到的内容如下：  </p><pre><code>sync$90REDIS0007    redis-ver3.2.5  </code></pre><p>从数据库会将收到的内容写入到硬盘上的临时文件中，当写入完成后从数据库会用该临时文件替换RDB快照文件（RDB快照文件的位置就是持久化时配置的位置，由dir和dbfilename两个参数确定），之后的操作就和RDB持久化时启动恢复的过程一样了。需要注意的是在同步过程中从数据库并不会阻塞，而是可以继续处理客户端发来的命令。默认情况下，从数据库会用同步前的数据对命令进行响应。可以配置slave-serve-stale-data 参数为no来使从数据库在同步完成前对所有命令（除了INFO和SLAVEOF）都回复错误:”SYNC with master in progress.”<br>复制初始化阶段结束后，主数据库执行的任何会导致数据变化的命令都会异步地传送给从数据库，这一过程为复制同步阶段。同步的内容和Redis通信协议一样，比如我们在主数据库中执行了SET foo bar，通过telnet我们收到了： </p><pre><code>set$3foo$3bar*1$4</code></pre><p>复制同步阶段会贯穿整个主从同步过程的始终，直到主从关系终止为止。<br>在复制的过程中，快照无论在主数据库还是从数据库中都起了很大的作用，只要执行复制就会进行快照，即使我们关闭了RDB方式的持久化（通过删除所有save参数）。Redis2.8.18之后支持了无硬盘复制。<br>（1）乐观复制<br>Redis采用了乐观复制（optimistic replication）的复制策略，容忍在一定时间内主从数据库的内容是不同的，但是两者的数据会最终同步。具体来说，Redis在主从数据库之间复制数据的过程本身是异步的，这意味着，主数据库执行完客户端请求的命令后会立即将命令在主数据库的执行结果返回给客户端，并异步地将命令同步给从数据库，而不会等待从数据库接收到改该命令后再返回给客户端。这一特性保证了启用复制后主数据库的性能不会受到影响，但另一方面也会产生一个主从数据库数据不一致的时间窗口，当主数据库执行一条写命令后，主数据库的数据已经发生的变动，然而在主数据库将该命令传送给从数据库之前，如果两个数据库之前的网络连接断开了，此时二者之间数据就会是不一致的。从这个角度来看，主数据库是无法得知某个命令最终同步给了多少个从数据库的，不过Redis提供了两个配置选项来限制只有当数据至少同步给指定数量的从数据库时，主数据库才是可写的：  </p><pre><code>min-slaves-to-write 3min-slaves-max-lag 10</code></pre><p>上面的配置中，min-slaves-to-write表示只有当3个或3个以上的从数据库连接到主数据库时，主数据库才是可写的，否则会返回错误，例如：  </p><pre><code>set foo bar(error) NOREPLICAS Not enough good slaves to write</code></pre><p>min-slaves-max-lag表示允许从数据库最长失去连接的时间，如果从数据库最后与主数据库联系（即发送REPLCONF ACK命令）的时间小于这个值，则认为从数据还在保持与主数据库的连接。举个例子，按上面的配置，主数据库假设与3个从数据库相连，其中一个从数据库上一次与主数据库联系是9秒前，这时主数据库可以正常接受写入，一旦1秒过后这台从数据库依旧没有活动，则主数据库认为目前连接的从数据库只有2个，从而拒绝写入。这一特性默认是关闭的，在分布式系统中，打开并合理配置该选项后可以降低主从架构中因为网络分区导致的数据不一致的问题。  </p><h3 id="3、图结构"><a href="#3、图结构" class="headerlink" title="3、图结构"></a>3、图结构</h3><p>从数据库不仅可以接受主数据库的同步数据，自己也可以同时作为主数据库存在，形成类似图的结构，如下图，数据库A的数据会同步到B和C中，而B中的数据会同步到D和E中。向B中写入数据不会同步到A或C中，只会同步到D和E中。  </p><p><img src="http://op7wplti1.bkt.clouddn.com/slaveWithSlave.png" alt="slave也可再拥有slave">  </p><h3 id="4、读写分离与一致性"><a href="#4、读写分离与一致性" class="headerlink" title="4、读写分离与一致性"></a>4、读写分离与一致性</h3><p>通过复制可以实现读写分离，以提高服务器的负载能力。在常见的场景中（如电子商务网站），读的频率大于写，当单机的Redis无法应付大量的读请求时（尤其是较耗资源的请求，如SORT命令等）可以通过复制功能建立多个从数据库节点，主数据库只进行写操作，而从数据库负责读操作。这种一主多从的结果很适合读多写少的场景，而当单个的主数据库不能满足需求时，就需要使用Redis3.0推出的集群功能。  </p><h3 id="5、从数据库持久化"><a href="#5、从数据库持久化" class="headerlink" title="5、从数据库持久化"></a>5、从数据库持久化</h3><p>另一个相对耗时的操作是持久化，为了提高性能，可以通过复制功能建立一个（或多个）从数据库，并在从数据库中启用持久化，同时在主数据库中禁用持久化。当从数据库奔溃重启后主数据库会自动将数据同步过来，所以无需担心数据丢失。然后当主数据库奔溃时，情况就稍显复杂了。手工通过从数据库数据恢复主数据库数据时，需要严格按照以下两部进行。<br>（1）在从数据中使用SLAVEOF NO ONE 命令将从数据库提升成主数据库继续服务。<br>（2）启动之前奔溃的主数据库，然后使用SLAVEOF命令将其设置成新的主数据库的从数据库，即可将数据同步回来。  </p><p><strong>注意：当开启复制且主数据关闭持久化功能时，一定不要使用Supervisor以及类似的进程管理工具令主数据库奔溃后自动重启。同样当主数据所在的服务器因故关闭时，也要避免直接重新启动。这是因为当数据库重新启动后，因为没有开启持久化功能，所以数据库中的所有数据都被清空，这时从数据库依然会从主数据库中接受收据，使得所有从数据库也被清空，导致从数据库的持久化失去意义。</strong>  </p><p>无论哪种情况，手工维护从数据库或主数据库的重启以及数据恢复都相对麻烦，好在Redis提供了一种自动化方案哨兵来实现这一过程，避免了手工维护的麻烦和容易出错的问题。 </p><h3 id="6、无硬盘复制"><a href="#6、无硬盘复制" class="headerlink" title="6、无硬盘复制"></a>6、无硬盘复制</h3><p>Redis复制的工作原理时介绍了复制是基于RDB方式的持久化实现的，即主数据库端在后台保存RDB快照，从数据库端则接受并载入快照文件。这样的实现有点是可以显著地简化逻辑，复用已有代码，但是缺点也很明显。<br>（1）当数据库禁用RDB快照时（即删除了所有的配置文件中的save语句）。如果执行了复制初始化操作，Redis依然会生成RDB快照，所以下次启动后主数据库会以该快照恢复数据。因为复制发生的时间不确定，这使得恢复的数据可能是任何时间点的。<br>（2）因为复制初始化时需要在硬盘中创建RDB快照文件，所以如果硬盘性能很慢（如网络硬盘）时这一过程会对性能产生影响。举例来说，当使用Redis作缓存系统时，因为不需要持久化，所以服务器的硬盘读写速度可能较差。但是当该缓存系统使用一主多从的集群架构时，每次和从数据同步，Redis都会执行一次快照，同时对硬盘进行读写，导致性能降低。因此从2.8.18版本开始，Redis引入了无硬盘复制选项，开启该选项时，Redis在与从数据库进行复制初始化时将不会将快照内容存储到硬盘上，而是直接通过网络发送给从数据库，避免了硬盘的性能瓶颈。<br>目前无硬盘复制的功能还在试验阶段，可以在配置文件中使用如下配置来开启该功能：  </p><pre><code>repl-diskless-sync yes</code></pre><h3 id="7、增量复制"><a href="#7、增量复制" class="headerlink" title="7、增量复制"></a>7、增量复制</h3><p>在介绍复制的原理时提到当主从数据库连接断开后，从数据库会发送SYNC命令来重新进行一次完成的复制操作。这样即使断开期间数据库的变化很小（甚至没有），也需要将数据库中的所有数据重新快照并传送一次。在正常的网络应用环境中，这种实现方式显然不太理想。Redis2.8版相对2.6版的重要更新之一就是实现了主从断线重连的情况下的增量复制。增量复制是基于如下三点实现：<br>（1）从数据库会存储主数据库的运行ID（run id）。每个Redis运行实例均会拥有一个唯一的运行ID，每当实例重启后，就会自动生成一个新的运行ID。<br>（2）在复制同步阶段，主数据库每将一个命令传送给从数据库时，都会同时把该命令存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围。<br>（3）同时，从数据库接收到主数据库传来的命令时，会记录下该命令的偏移量。<br>这三点是实现增量复制的基础。回到之前介绍主从通信流程，可以看到，当主从连接准备就绪后，从数据库会发送一条SYNC命令来告诉主数据库可以开始把所有数据同步过来了。而2.8版以后，不再发送SYNC命令，取而代之的是发送PSYNC，格式为“PSYNC 主数据库的运行id 断开前最新的命令偏移量”。主数据库收到PSYNC命令后，会执行以下判断来决定此次重连是否可以执行增量复制。<br>（1）首先主数据库会判断从数据库传送的运行ID是否和自己的运行ID相同。这一步骤的意义在于确保从数据库之前确实是和自己同步的，以免从数据库拿到错误的数据（比如主数据库在断线重启过，会造成数据的不一致）。<br>（2）然后判断从数据库最后同步成功的命令偏移量是否在积压队列中，如果在则可以执行增量复制，并将积压队列中的相应的命令发送给从数据库。如果此次重连不满足增量复制的条件，主数据库会进行一次全部同步（即与Redis2.6的过程相同）。大部分情况下，增量复制的过程对开发者来说是完全透明的，开发者不需要关心增量复制的具体细节。2.8版本的主数据库也可以正常地和旧版本的从数据库同步（通过接受SYNC命令），同样2.8版本的从数据库也可以与旧版本的主数据库同步（通过发送SYNC命令）。唯一需要开发者设置的就是积压队列的大小了。<br>积压队列的本质上是一个固定长度的循环队列，默认情况下积压队列的大小为1MB，可以通过配置文件的repl-backlog-size选项来调整。很容易理解的是，积压队列越大，其允许的主从数据库断线的时间就越长。根据主从数据库之间的网络状态，设置一个合理的积压队列很重要。因为积压队列存储的内容是命令本身，如SET foo bar，所以估算积压队列的大小只需要估计主从数据库断线的时间中主数据库可能执行的命令的大小即可。与积压队列相关的另一个配置是repl-backlog-ttl，即当所有从数据库与主数据库断开连接后，经过多久时间可以释放积压队列的内存空间。默认时间是1小时。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis主从模式 </tag>
            
            <tag> redis复制 </tag>
            
            <tag> redis一主多从模式 </tag>
            
            <tag> redis复制原理 </tag>
            
            <tag> redis复制初始化 </tag>
            
            <tag> redis增量复制 </tag>
            
            <tag> redis积压队列 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之持久化</title>
      <link href="/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><p>Redis的强劲性能很大程度上市由于将其所有数据都存储在了内存中，然而当Redis重启后，所有存储在内存中的数据就会丢失。在一些情况下，我们希望在重启后能保证数据不丢失，例如：<br>（1）将Redis作为数据库使用时。<br>（2）将Redis作为缓存服务器，但缓存被穿透后会对性能造成较大影响，所有缓存同时失效会导致缓存雪崩，从而使服务无法响应。<br>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘中，使得重启后可以根据硬盘中的记录恢复数据。这一过程就是持久化。Redis支持两种方式的持久化，一种是RDB方式，另一种是AOF方式。前者会根据指定的规则“定时”将内存中的数据存储在硬盘上，而后者在每次执行命令后将命令本身记录下来。两种持久化方式可以单独使用其中一种，但更多情况下是将二者结合使用。  </p><h2 id="RDB方式"><a href="#RDB方式" class="headerlink" title="RDB方式"></a>RDB方式</h2><p>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据生成一份副本存储在硬盘上，这个过程即为“快照”。Redis会在以下几种情况下对数据进行快照：  </p><ol><li>根据配置规则进行自动快照  </li><li>用户执行SAVE或GBSAVE命令手动快照  </li><li>执行FLUSHALL命令  </li><li>执行复制（replication）时。  </li></ol><h3 id="1、根据配置规则自动快照"><a href="#1、根据配置规则自动快照" class="headerlink" title="1、根据配置规则自动快照"></a>1、根据配置规则自动快照</h3><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间窗口M和改动的键的个数N。每当时间M内被更改的键的个数大于N时，即符合自动快照条件。例如Redis安装目录中包含的样例配置文件中预置的3个条件：  </p><pre><code>save 900 1save 300 10save 60 10000</code></pre><p>每条快照条件占一行，并且以save参数开头。同时可以存在多个条件，条件之间是“或”的关系。就这个例子而言，save 900 1的意思是在15分钟（900秒）内有一个或一个以上的键被更改则进行快照。同理save 300 10表示在300秒内至少有10个键被修改则进行快照。  </p><h3 id="2、用户执行SAVE或BGSAVE命令手动快照"><a href="#2、用户执行SAVE或BGSAVE命令手动快照" class="headerlink" title="2、用户执行SAVE或BGSAVE命令手动快照"></a>2、用户执行SAVE或BGSAVE命令手动快照</h3><p>除了让Redis自动进行快照外，当服务重启、手动迁移以及备份时我们也会需要手动执行快照操作。Redis提供了2个命令来完成这一任务。  </p><h4 id="1、SAVE命令"><a href="#1、SAVE命令" class="headerlink" title="1、SAVE命令"></a>1、SAVE命令</h4><p>当执行SAVE命令时，Redis同步地进行快照操作，在快照执行的过程中会阻塞所有来自客户端的请求。当数据库中的数据比较多时，这一过程会导致Redis较长时间不相应，所以要尽量避免在生产环境使用这一命令。  </p><h4 id="2、BGSAVE命令"><a href="#2、BGSAVE命令" class="headerlink" title="2、BGSAVE命令"></a>2、BGSAVE命令</h4><p>需要手动执行快照时推荐使用BGSAVE命令。BGSAVE命令可以在后台异步地进行数据快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后Redis会立即返回OK表示开始执行快照操作，如果想知道快照是否完成，可以通过LASTSAVE命令获取最近一次成功执行快照的时间，返回结果是一个Unix时间戳，如：  </p><pre><code>127.0.0.1:6379&gt; lastsave(integer) 1496286152  </code></pre><p>执行自动快照时，Redis采用的策略即是异步快照。  </p><h3 id="3、执行FLUSHALL命令"><a href="#3、执行FLUSHALL命令" class="headerlink" title="3、执行FLUSHALL命令"></a>3、执行FLUSHALL命令</h3><p>当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是，不论清空数据库的过程是否触发了自动快照条件，只要自动快照条件不为空，Redis就会执行一次快照操作。例如，当定义的快照条件为当一秒内修改10000个键时进行自动快照，而当数据库里只有一个键时，执行FLUSHALL命令也会触发快照，即使这一过程实际上只有一个键被修改了。当没有定义自动快照条件时，执行FLUSHALL则不会进行快照。  </p><h3 id="4、执行复制时"><a href="#4、执行复制时" class="headerlink" title="4、执行复制时"></a>4、执行复制时</h3><p>当设置了主从模式时，Redis会在复制初始化时进行自动快照。当使用复制操作时，即使没有自定义自动快照条件，并且也没有手动执行过快照操作，也会生成RDB快照文件。  </p><h3 id="快照原理"><a href="#快照原理" class="headerlink" title="快照原理"></a>快照原理</h3><p>理清Redis实现快照的过程对我们了解快照文件的特性有很大帮助。Redis默认会将快照文件存储在Redis当前进程的工作目录中的dump.rdb文件中，可以通过配置<strong>dir</strong>和<strong>dofilename</strong>两个参数分别指定快照文件的存储路径和文件名。快照过程如下：<br>（1）Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；<br>（2）父进程继续接受并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；<br>（3）当子进程写入完所有数据后会用临时文件替换掉旧的RDB文件，至此一次快照操作完成。  </p><p><strong>提示：在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。写时复制策略也保证了在fork的时刻虽然看上去生成了两份内存副本，但实际上内存的占用量并不会增加一倍。这就意味着当系统内存只有2GB，而Redis数据库的内存有1.5GB时，执行fork后内存使用量不会增加到3GB（超出物理内存）。为此需要确保Linux系统允许应用程序申请超过可用内存（物理内存和交换分区）的空间，方法是在/etc/sysctl.conf文件中加入vm.overcommit_memory=1，然后重启系统或者执行sysctl vm.overcommit_memory=1确保设置生效。另外需要注意的是，当进行快照的过程中，如果写入操作较多，造成fork前后数据差异较大，是会使得内存占用量显著超过实际数据大小的，因为内存中不仅保存了当前的数据库数据，而且保存着fork时刻的内存数据。进行内存用量估算时很容易忽略这一问题，造成内存用量超限。 </strong> </p><p>通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。<br>Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录1000万个字符串类型建、大小为1GB的快照文件载入到内存中需要花费20~30秒。<br>通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能否接受的范围。例如，使用Redis存储缓存数据时，丢失最近几秒的数据或者丢失最近更新的几十个键并不会有很大的影响。如果数据相对重要，希望将损失降到最小，则可以使用AOF方式进行持久化。  </p><h2 id="AOF方式"><a href="#AOF方式" class="headerlink" title="AOF方式"></a>AOF方式</h2><p>当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程终止导致的数据丢失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这一过程显然会降低Redis性能，但是大部分情况下这个影响是可以接受的，另外使用较快的硬盘可以提高AOF的性能。  </p><h3 id="1、开启AOF"><a href="#1、开启AOF" class="headerlink" title="1、开启AOF"></a>1、开启AOF</h3><p>默认情况下Redis没有开始AOF（append only file）方式的持久化，可以通过appendonly参数启用：</p><pre><code>appendonly yes  </code></pre><p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：  </p><pre><code>appendfilename appendonly.aof  </code></pre><h3 id="2、AOF实现"><a href="#2、AOF实现" class="headerlink" title="2、AOF实现"></a>2、AOF实现</h3><p>AOF文件以纯文本的形式记录了Redis执行的写命令，例如在开启AOF持久化的情况下执行了如下4个命令:  </p><pre><code>SET foo 1SET foo 2SET foo 3GET foo  </code></pre><p>Redis会将前3条命令写入AOF文件中。AOF文件内容为Redis客户端向Redis发送的原始通信协议的内容，从中可见Redis确实只记录了前3条命令。然而这时有一个问题是前2条命令其实都是冗余的，因为这2执行结果会第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，即使内存中实际的数据可能并没有多少。很自然地，我们希望Redis可以自动优化AOF文件，就上例而言，就是将前两条无用的记录删除，只保留第三条。实际上Redis也正是这样做的，每当达到一定条件时Redis就会自动重写AOF文件，这个条件可以在配置文件中设置：  </p><pre><code>auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb  </code></pre><p>auto-aof-rewrite-percentage参数的意义是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据。auto-aof-rewrite-min-size参数限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。除了让Redis自动执行重写外，我们还可以主动使用BGREWRITEAOF命令手动执行AOF重写。重写的过程只和内存中的数据有关，和之前的AOF文件无关，这与RDB很相似，只不过二者的文件格式完全不同。在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对RDB会慢一些。  </p><h3 id="3、同步硬盘数据"><a href="#3、同步硬盘数据" class="headerlink" title="3、同步硬盘数据"></a>3、同步硬盘数据</h3><p>虽然每次执行更改数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正的写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒回执行一次同步操作，以便将硬盘缓存中的内容真正地写入硬盘，在这30秒的过程中如果系统异常退出则会导致缓存中的数据丢失。一般来讲启用AOF持久化的应用都无法容忍这样的损失，这就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在Redis中我们可以通过appendfsync参数设置同步机制：  </p><pre><code>#appendfsync alwaysappendfsync everysec#appendfsync no   </code></pre><p>默认情况下Redis采用everysec规则，即每秒执行一次同步操作。always表示每次执行写入都会执行同步，这是最安全也是最慢的方式。no表示不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），这是最快但最不安全的方式。一般情况下使用默认值everysec就足够了，即兼顾了性能又保证了安全。<br>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。  </p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis持久化 </tag>
            
            <tag> redis的AOF持久化 </tag>
            
            <tag> redis的RDB持久化 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之Lua脚本</title>
      <link href="/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8BLua%E8%84%9A%E6%9C%AC/"/>
      <url>/2017/06/01/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8BLua%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><p>在进阶章节讲到实现访问频率限制功能，用来限制一个IP地址1分钟最多只能访问100次：  </p><pre><code>$isKeyExists=EXISTS rate.limiting:$IPif $isKeyExists is 1    $times=INCR rate.limiting:$IP    if $times&gt;100        print 访问频率超过限制，请稍后再试        exitelse    MULTI    INCR rate.limiting:$IP    EXPIRE $keyName,60    EXEC  </code></pre><p>当时提到上面的代码会出现竞态条件，解决方法是用WATCH命令检测rate.limiting:$IP键的变动，但是这样做比较麻烦，而且还需要判断事务是否因为键被改动而没有执行。除此之外这段代码在不适用管道的情况下最多要向Redis请求5条命令，在网络传输上会浪费很多时间。<br>我们这时最希望就是Redis直接提供一个“RATELIMITING”命令用来实现访问频率限制功能，这个命令只需要我们提供键名、时间限制和在时间限制内最多访问的次数三个参数就可以直接返回访问频率是否超限。就像下面这样：  </p><pre><code>if RATELIMITING rate.limiting:$IP,60 100    print 访问频率超过限制，请稍后再试else     #没有超限，其他业务处理  </code></pre><p>这种方式不仅代码简单、没有竞态条件（Redis的命令都是原子的），而且减少了通过网络发送和接收命令的传输开销。然而可惜的是Redis并没有提供这个命令，不过我们可以使用Redis脚本功能自己定义新的命令。  </p><h3 id="1、脚本介绍"><a href="#1、脚本介绍" class="headerlink" title="1、脚本介绍"></a>1、脚本介绍</h3><p>Redis在2.6版推出了脚本功能，允许开发者用Lua语言编写脚本传到Redis中执行。在Lua脚本中可以调用大部分的Redis命令，也就是说可以写一段Lua脚本发送给Redis执行。使用脚本的好处：<br>（1）减少网络开销。复合操作需要向Redis发送多次请求，如上例，而是用脚本功能完成同样的操作只需要发送一个请求即可，减少了网络往返时延。<br>（2）原子操作。Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。换句话说在编写脚本的过程中无需担心会出现竞态条件，也就无需使用事务。事务可以完成的所有功能都可以用脚本来实现。<br>（3）复用。客户端发送的脚本会永久存储在Redis中，这就意味着其他客户端（可以是其他语言开发的项目）可以复用这一脚本而不需要使用代码完成同样的逻辑。  </p><h3 id="2、实例：访问频率限制"><a href="#2、实例：访问频率限制" class="headerlink" title="2、实例：访问频率限制"></a>2、实例：访问频率限制</h3><p>因为无需考虑事务，使用Redis脚本实现访问频率限制非常简单。Lua代码如下：  </p><pre><code>local time=redis.call(&apos;incr&apos;,KEYS[1])if times==1 then --KEYS[1]键刚创建，所以为其设置生存时间    redis.call(&apos;expire&apos;,KEYS[1],ARGV[1])endif times &gt;tonumber(ARGV[2]) then    return 0endreturn 1  </code></pre><p>这段代码实现的功能与我们之前所做的类似，不过简洁了很多，即使不了解Lua语言也能猜出来大概意思。那么，该如何测试这个脚本呢？首先我们把这段代码存为ratelimiting.lua然后在命令行输入：<br>redis-cli –eval /path/to/ratelimiting.lua rate.limiting:127.0.0.1 , 10 3，其中–eval参数是告诉redis-cli读取并运行后面的Lua脚本，/path/to/ratelimiting.lua是ratelimiting.lua文件的位置，后面跟着的是传给Lua脚本的参数。其中“，”前的rate.limiting:127.0.0.1是要操作的键，可以在脚本中使用KEYS[1]获取，“，”后面的10和3是参数，在脚本中能够使用ARGV[1]/ARGV[2]获得。结合脚本的内容可知这行命令的作用是将访问频率限制为每10秒最多3次，所以在终端中不断地运行此命令会发现当访问频率在10秒内小于或等于3次时返回1，否则返回0。<br><strong>注意：上面命令中的“，”两边的空格不能省略，否则会出错。</strong>  </p><h2 id="Lua-语法学习"><a href="#Lua-语法学习" class="headerlink" title="Lua 语法学习"></a>Lua 语法学习</h2><p>请参见一些网络学习地址或学习书籍，本人收集地址如下：</p><blockquote><p><a href="http://book.luaer.cn/" target="_blank" rel="noopener">Lua程序设计</a><br><a href="http://manual.luaer.cn/" target="_blank" rel="noopener">Lua在线手册</a><br><a href="http://lua-users.org/wiki/" target="_blank" rel="noopener">Lua WIKI</a><br><a href="https://github.com/wenquan0hf/lua/blob/master/TOC.md" target="_blank" rel="noopener">GitHub Lua教程</a><br><a href="http://www.runoob.com/lua/lua-tutorial.html" target="_blank" rel="noopener">Lua菜鸟教程</a>  </p></blockquote><h2 id="Redis与Lua"><a href="#Redis与Lua" class="headerlink" title="Redis与Lua"></a>Redis与Lua</h2><p>编写Redis脚本的目的就是读写Redis的数据，本章主要介绍Redis与Lua交互的方法。  </p><h3 id="1、在脚本中调用Redis命令"><a href="#1、在脚本中调用Redis命令" class="headerlink" title="1、在脚本中调用Redis命令"></a>1、在脚本中调用Redis命令</h3><p>在脚本中可以使用redis.call函数调用Redis命令。就像这样：  </p><pre><code>redis.call(&apos;set&apos;,&apos;foo&apos;,&apos;bar&apos;)local value=redis.call(&apos;get&apos;,&apos;foo&apos;) --value的值为bar</code></pre><p>redis.call函数的返回值就是Redis命令的执行结果。Redis命令的返回值有5种类型，redis.call函数会将这5种类型的回复转换成对应的Lua的数据类型，具体的对应规则如下表（空结果比较特殊，其对应为Lua的false）。 </p><table><thead><tr><th>Redis返回值类型</th><th>Lua数据类型</th></tr></thead><tbody><tr><td>整数回复</td><td>数字类型</td></tr><tr><td>字符串回复</td><td>字符串类型</td></tr><tr><td>多行字符串回复</td><td>表类型（数组形式）</td></tr><tr><td>状态回复</td><td>表类型（只有一个ok字段存储状态信息）</td></tr><tr><td>错误回复</td><td>表类型（只有一个err字段存储错误信息）  </td></tr></tbody></table><p>Redis还提供了了redis.pcall函数，功能与redis.call相同，唯一区别是当命令执行出错时redis.pcall会记录错误并继续执行，而redis.call会直接返回错误，不会继续执行。  </p><h3 id="2、从脚本中返回值"><a href="#2、从脚本中返回值" class="headerlink" title="2、从脚本中返回值"></a>2、从脚本中返回值</h3><p>在很多情况下都需要脚本返回值，比如前面的访问频率限制脚本会返回频率是否超限。在脚本中可以使用return语句将值返回给客户端，如果没有执行return语句则会默认返回nil。因为我们可以向调用其他Redis内置命令一样调用我们自己写的脚本，所以同样Redis会自动将脚本返回值的Lua数据类型转换成Redis的返回值类型。具体的转换规则见下表（其中Lua的false比较特殊，会被转换成空结果）。  </p><table><thead><tr><th>Lua数据类型</th><th>Redis返回值类型</th></tr></thead><tbody><tr><td>数字类型</td><td>整数回复（Lua的数字类型会被自动转换成整数）</td></tr><tr><td>字符串类型</td><td>字符串回复</td></tr><tr><td>表类型（数组形式）</td><td>多行字符串回复</td></tr><tr><td>表类型（只有一个ok字段存储状态信息）</td><td>状态回复</td></tr><tr><td>表类型（只有一个err字段存储错误信息）</td><td>错误回复  </td></tr></tbody></table><h3 id="3、脚本相关命令"><a href="#3、脚本相关命令" class="headerlink" title="3、脚本相关命令"></a>3、脚本相关命令</h3><h4 id="1-EVAL命令"><a href="#1-EVAL命令" class="headerlink" title="1.EVAL命令"></a>1.EVAL命令</h4><p>编写完脚本后最重要的就是在程序中执行脚本。Redis提供了EVAL命令可以使开发者像调用其他Redis内指命令一样调用脚本。EVAL命令的格式是：EVAL 脚本内容 key参数的数量 [key…] [arg …]。可以通过key和arg这两类参数向脚本传递数据，他们的值可以在脚本中分别使用KEYS和ARGV两个类型的全局变量访问。比如希望用脚本功能实现一个SET命令,脚本内容是这样：  </p><pre><code>return redis.call(&apos;SET&apos;,KEYS[1],ARGV[1])  </code></pre><p>现在打开redis-cli执行此脚本</p><pre><code>127.0.0.1:6379&gt; eval &quot;return redis.call(&apos;SET&apos;,KEYS[1],ARGV[1])&quot; 1 foo barOK127.0.0.1:6379&gt; get foo&quot;bar&quot;  </code></pre><p>其中要读写的键名应该作为key参数，其他的数据都作为arg参数。<br><strong>注意：EVAL命令依据第二个参数将后面的所有参数分别存入脚本中的KEYS和ARGV两个表类型的全局变量中。当脚本不需要任务参数时也不能省略这个参数（设为0）</strong>。  </p><h4 id="2-EVALSHA命令"><a href="#2-EVALSHA命令" class="headerlink" title="2.EVALSHA命令"></a>2.EVALSHA命令</h4><p>考虑到在脚本比较长的情况下，如果每次调用脚本都需要将这个脚本传给Redis会占用较多的带宽。为了解决这个问题，Redis提供了EVALSHA命令允许开发者通过脚本内容的SHA1摘要来执行脚本，改命令的用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要。<br>Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中，执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了则执行脚本，否则会返回错误：“NOSCRIPT No matching script.Please use EVAL.”,在程序中使用EVALSHA命令的一般流程：<br>（1）先计算脚本的SHA1摘要，并使用EVALSHA命令执行脚本。<br>（2）获得返回值，如果返回“NOSCRIPT”错误则使用EVAL命令重新执行脚本。<br>虽然这一流程略显麻烦，但值得庆幸的是很多编程语言的Redis客户端都会代替开发者完成这一流程。比如使用node_redis客户端执行EVAL命令时，node_redis会先尝试执行EVALSHA命令，如果失败才会执行EVAL命令。  </p><h2 id="深入脚本"><a href="#深入脚本" class="headerlink" title="深入脚本"></a>深入脚本</h2><h3 id="1、KEYS与ARGV"><a href="#1、KEYS与ARGV" class="headerlink" title="1、KEYS与ARGV"></a>1、KEYS与ARGV</h3><p>前面提到过向脚本传递参数分为KEYS和ARGV两类，前者表示要操作的键名，后者表示非键名参数。但事实上这一要求并不是强制的，比如 EVAL “return redis.call(‘get’,KEYS[1])” 1 user:Bob可以获得user:Bob的键值，同样还可以使用EVAL “return redis.call(‘get’,’user:’ .. ARGV[1])” 0 Bob完成同样的功能，此时我们虽然并未按照Redis的规则使用KEYS参数传递键名，但还是获得了正确的结果。<br>虽然规则不是强制的，但不遵守规则依然有一定代价。Redis3.0版带有集群的功能，集群的作用是将数据库中的键分散到不同的节点上。这意味着在脚本执行前就需要知道脚本会操作哪些键以便于找到对应的节点，所以如果脚本中的键名没有使用KEYS参数传递则无法兼容集群。  </p><h3 id="2、沙盒与随机数"><a href="#2、沙盒与随机数" class="headerlink" title="2、沙盒与随机数"></a>2、沙盒与随机数</h3><p>Redis脚本禁止使用Lua标准库中与文件或系统调用相关函数，在脚本中只允许对Redis的数据进行处理。并且Redis还通过禁用脚本的全局变量的方式保证每个脚本都要是相对隔离的，不会相互干扰。<br>使用沙盒不仅是为了保证服务器的安全性，而且还确保了脚本的执行结果只和脚本本身和执行时传递的参数有关，不依赖外界条件（如 系统时间、系统中某个文件内容、其他脚本执行结果等。）这是因为在执行复制和AOF持久化操作时记录的是脚本的内容而不是脚本调用命令，所以必须保证在脚本内容和参数一样的前提下的执行结果是一样的。  </p><h3 id="3、其他脚本相关命令"><a href="#3、其他脚本相关命令" class="headerlink" title="3、其他脚本相关命令"></a>3、其他脚本相关命令</h3><p>除了EVAL和EVALSHA外，Redis还提供了了其他4个脚本相关的命令，一般都会被客户端封装起来，开发者很少能使用到。<br>（1）、将脚本加入缓存：SCRIPT LOAD<br>每次执行EVAL命令时Redis都会将脚本的SHA1摘要加入到脚本缓存中，以便下次客户端可以使用EVALSHA命令调用该脚本。如果只是希望将脚本加入脚本缓存而不执行则可以使用SCRIPT LOAD命令，返回值是脚本的SHA1摘要。如：  </p><pre><code>127.0.0.1:6379&gt; script load &quot;return 1&quot;&quot;e0e1f9fabfc9d4800c877a703b823ac0578ff8db&quot;  </code></pre><p>（2）、判断脚本是否已经被缓存：SCRIPT EXISTS<br>SCRIPT EXISTS 命令可以同时查找1个或多个脚本的SHA1摘要是否被缓存，如：  </p><pre><code>127.0.0.1:6379&gt; script exists e0e1f9fabfc9d4800c877a703b823ac0578ff8db1) (integer) 1  </code></pre><p>（3）、清空脚本缓存：SCRIPT FLUSH<br>Redis将脚本的SHA1摘要加入到脚本缓存后会永久保留，不会删除，但可以手动使用SCRIPT FLUSH命令清空脚本缓存：  </p><pre><code>127.0.0.1:6379&gt; script flushOK  </code></pre><p>（4）、强制终止当前脚本的执行：SCRIPT KILL<br>如果想终止当前正在执行的脚本可以使用SCRIPT KILL命令。  </p><h3 id="4、原子性和执行时间"><a href="#4、原子性和执行时间" class="headerlink" title="4、原子性和执行时间"></a>4、原子性和执行时间</h3><p>Redis的脚本执行时原子的，即脚本执行期间Redis不会执行其他命令。所有的命令都必须等待脚本执行完成后才能执行。为了防止某个脚本执行时间过长导致Redis无法提供服务（比如陷入死循环），Redis提供了<strong>lua-time-limit</strong>参数限制脚本的最长运行时间，默认为5秒钟。当脚本运行时间超过这一限制后，Redis将开始接受其他命令但不会执行（以确保脚本的原子性，因为此时脚本并没有被终止），而是会返回“BUSY”错误。限制我们可以打开2个redis-cli实例A和B来测试一下。首先A中执行一个死循环脚本：  </p><pre><code>127.0.0.1:6379&gt; eval &quot;while true do end&quot; 0  --死循环  </code></pre><p>然后在另一个B客户端执行一条命令:  </p><pre><code>127.0.0.1:6379&gt; get foo(error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE.  </code></pre><p>这时实例B中命令并没有马上返回结果，因为、Redis已经被实例A发送的死循环脚本阻塞了，无法执行其他命令。且等待5秒钟之后实例B收到了“BUSY”错误，此时Redis虽然可以接受任何命令，但实际会执行的只有两个命令：SCRIPT KILL 和SHUTDOWN NOSAVE。在实例B中执行SCRIPT KILL命令可以终止当前脚本的运行，并且此时实例A中会返回错误:  </p><pre><code>--实例A127.0.0.1:6379&gt; script killOK  --实例B127.0.0.1:6379&gt; eval &quot;while true do end&quot; 0(error) ERR Error running script (call to f_694a5fe1ddb97a4c6a1bf299d9537c7d3d0f84e7): @user_script:1: Script killed by user with SCRIPT KILL... (343.29s)</code></pre><p>需要注意的是如果当前执行的脚本对Redis的数据进行了修改（如调用SET、LPUSH或DEL等命令）则SCRIPT KILL 命令不会终止脚本的运行以防止脚本只执行了一部分。因为如果脚本只执行了一部分就被终止，会违背脚本的原子性要求，即脚本中的所有命令都要么执行，要么都不执行。比如在实例A中执行：  </p><pre><code>127.0.0.1:6379&gt; eval &quot;redis.call(&apos;SET&apos;,&apos;foo&apos;,&apos;bar&apos;) while true do end&quot; 0--死循环卡住  </code></pre><p>5秒钟后尝试在B中终止该脚本：  </p><pre><code>127.0.0.1:6379&gt; script kill(error) UNKILLABLE Sorry the script already executed write commands against the dataset. You can either wait the script termination or kill the server in a hard way using the SHUTDOWN NOSAVE command.  </code></pre><p>这是只能通过SHUTDOWN NOSAVE命令强制终止Redis。SHUTDOWN NOSAVE命令与SHUTDOWN命令的区别在于前者将不会进行持久化操作，这意味着所有发生在上一次快照后的数据库修改都会丢失。由于Redis脚本非常高效，所以在大部分情况下都不用担心脚本的性能。但同时由于脚本的强大功能，很多原本在程序中执行的逻辑都可以放到脚本中执行，这时就需要开发者根据具体的应用权衡到底哪些任务适合交给脚本。通常来说不应该在脚本中进行大量耗时的运算，因为毕竟Redis是单进程单线程执行脚本，而程序却能够多进程多线程运行。  </p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis使用Lua脚本 </tag>
            
            <tag> Lua脚本 </tag>
            
            <tag> EVAL及EVALSHA </tag>
            
            <tag> KEYS与ARGV </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之提高篇III</title>
      <link href="/2017/05/26/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87III/"/>
      <url>/2017/05/26/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87III/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="消息通知"><a href="#消息通知" class="headerlink" title="消息通知"></a>消息通知</h2><p>任务队列顾名思义，就是“传递任务的队列”。与任务队列进行交互的尸体有两类，一类是生产者（producer），一类是消费者（consumer）。生产者会将需要处理的任务放入队列中，而消费者则不断地从队列中读入任务信息并执行。<br>使用任务队列有如下好处：<br>（1）松耦合。生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产者和消费者可以由不同的团队使用不同的编程语言编写。<br>（2）易于扩展消费者可以有多个，而且可以分布在不同的服务器中，借此可以轻易地降低单台服务器的负载。</p><p><img src="http://op7wplti1.bkt.clouddn.com/producerandConsumer.png" alt="多个消费者消费生产者放入队列的任务"></p><h3 id="1、Redis实现任务队列"><a href="#1、Redis实现任务队列" class="headerlink" title="1、Redis实现任务队列"></a>1、Redis实现任务队列</h3><p>说到任务队列自然想到之前介绍的LPUSH和RPOP命令实现队列的概念。如果要实现队列，只需要让生产者将任务使用LPUSH命令加入某个键中，另一边让消费者不断地使用RPOP命令从该键中取出任务即可。消费者伪代码如下：  </p><pre><code>loop //无限循环读取任务队列中的内容    $task=RPOP queue    if $task        //如果任务队列中有任务执行它        execute($task)    else        //如果没有则等待1秒以免过于频繁请求数据        wait 1 second</code></pre><p>到此一个使用Redis实现的简单任务队列就写好了。不好还有一点不完美的地方:当任务队列中没有任务时消费者每秒都会调用一次RPOP命令查看是否有新任务。如果可以实现一旦有新任务队列就通知消费者就好了。其实借助BRPOP命令就可以实现这一的需求。<br>BRPOP命令和RPOP命令相似，唯一的区别是当列表中没有元素时BRPOP命令会一直阻塞住连接，知道有新元素加入。如上代码可改为： </p><pre><code>loop    //如果任务队列中没有新任务，BRPOP命令会一直阻塞，不会执行execute()。    $task=BRPOP queue,0    //返回值是数组，数组第二个元素时我们需要的任务。    execute($task[1])</code></pre><p>BRPOP命令接受2个参数，第一个是键名，第二个是超时时间，单位是秒。当超过了此时间仍然没有获得新元素就会返回nil。上例中超时时间为“0”，表示不限制等待的时间，即如果没有新元素加入列表就会永远组塞下去。<br>当获得一个元素后BPOP命令返回二个值，分别是键名和元素值。为了测试BPOP命令，我们可以打开2个redis-cli实例，在实例A中：  </p><pre><code>127.0.0.1:6379&gt; brpop queue 0</code></pre><p>键入回车后实例1会处于阻塞状态，这时在实例B中向queue中加入一个元素： </p><pre><code>127.0.0.1:6379&gt; lpush queue task(integer) 1</code></pre><p>在LPUSH命令执行后实例A马上就返回了结果： </p><pre><code>127.0.0.1:6379&gt; brpop queue 01) &quot;queue&quot;2) &quot;task&quot;(73.70s)</code></pre><p>同时会发现queue中的元素已经被取走： </p><pre><code>127.0.0.1:6379&gt; llen queue(integer) 0</code></pre><p>除了BRPOP命令外，Redis还提供了BLPOP，和BRPOP的区别在于从队列取元素时BLPOP会从左边取。  </p><h3 id="2、优先级队列"><a href="#2、优先级队列" class="headerlink" title="2、优先级队列"></a>2、优先级队列</h3><p>BRPOP命令可以同时接受多个键，其完整的命令格式为BRPOP key [key …] timeout，如BRPOP queue:1 queue:2 0。意义是同时检测多个键，如果所有键都没有元素则阻塞，如果其中有一个键有元素则会从该键中弹出元素。例如，打开两个redis-cli实例，在实例A中:  </p><pre><code>127.0.0.1:6379&gt; BLPOP queue:1 queue:2 queue:3 0</code></pre><p>在实例B中：  </p><pre><code>127.0.0.1:6379&gt; lpush queue:2 task(integer) 1</code></pre><p>则实例A中返回： </p><pre><code>1) &quot;queue:2&quot;2) &quot;task&quot;(15.54s)</code></pre><p>如果多个键都有元素则按照从左到右的顺序取第一个的一个元素。我们现在queue:2和queue:3中各加入一个元素： </p><pre><code>127.0.0.1:6379&gt; lpush queue:2 task2(integer) 1127.0.0.1:6379&gt; lpush queue:3 task3(integer) 1</code></pre><p>然后执行BRPOP命令：  </p><pre><code>127.0.0.1:6379&gt; BRPOP queue:1 queue:2 queue:3 01) &quot;queue:2&quot;2) &quot;task2&quot;</code></pre><p>借此特性可以实现区分优先级的任务队列。我们分别使用queue:confirm.email和queue：notification.email两个键存储发送确认邮件（注册网站需要发送确认邮箱正确性邮件）和发送通知邮件（一旦有新博客文章就发送邮件信息提醒）两种任务，然后将消费者的代码改为： </p><pre><code>loop    $task=BRPOP queue:confirm.email,queue:notification.email,0    execute($task[1])</code></pre><p>这时一旦发送确认邮件的任务被加入到queue:confirm.email队列中，无论queue:notification.email还有多少任务，消费者都会优先完成发送确认邮件的任务。  </p><h3 id="3、发布-订阅模式"><a href="#3、发布-订阅模式" class="headerlink" title="3、发布/订阅模式"></a>3、发布/订阅模式</h3><p>除了实现任务队列外，Redis还提供了一组命令可以让开发者实现“发布/订阅”（publish/subscribe）模式。“发布/订阅”模式同样可以实现进程间的消息传递，其原理是这样的：<br>“发布/订阅”模式中包含两种角色，分别是发布者和订阅者。订阅者可以订阅一个或若干个频道（channel），而发布者可以向指定的频道发送消息，所有订阅此频道的订阅者都会收到此消息。发布者发布消息的命令是publish，用法是publish channel message，如向channel1.1发送“hello”： </p><pre><code>127.0.0.1:6379&gt; publish channel1.1 hello(integer) 0</code></pre><p>这样消息就发出去了。PUBLISH命令的返回值表示接收到这条消息的订阅者数量。因为此时没有客户端订阅channel1.1，所以返回0。发出去的消息不会被持久化，也就是说当有客户端订阅channel1.1后只能收到后续发布到该频道的消息，之前发送的就收不到了。订阅频道的命令时SUBSCRIBE，可以同时订阅多个频道，用法是SUBSCRIBE channel [channel …]。现在新开一个redis-cli实例A，用它来订阅channel1.1： </p><pre><code>127.0.0.1:6379&gt; subscribe channel1.1Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;channel1.1&quot;3) (integer) 1</code></pre><p>执行SUBSCRIBE命令后客户端会进入订阅状态，处于此状态下的客户端不能使用除SUBSCRIBE/UNSUBSCRIBE/PSUBSCRIBE/PUNSUBSCRIBE这4个属于“发布/订阅”模式的命令之外的其他命令，否则会报错。<br>进入订阅状态后客户端可能收到三种类型的回复。每种类型的回复都包含3个值，第一个值是消息的类型，根据消息类型的不同，第二、第三个值的含义也不同。消息类型可能取值有：<br>（1）Subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个值是当前客户端订阅的频道数量。<br>（2）message。这个类型的回复使我们最关心的，它表示接受到的消息。第二个值表示产生消息的频道名称，第三个是消息的内容。<br>（3）unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值是当前客户端订阅频道的数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他非“发布/订阅”模式的命令了。<br>上例中当实例A订阅了channel1.1进入订阅状态后收到了一条subscribe类型的回复，这时我们打开另一个redis-cli实例B，并向channel1.1发送一条消息：  </p><pre><code>127.0.0.1:6379&gt; publish channel1.1 hello(integer) 1</code></pre><p>返回值为1表示有一个客户端订阅了channel1.1，此时实例A收到了类型为message的回复：<br>127.0.0.1:6379&gt; subscribe channel1.1</p><pre><code>Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;channel1.1&quot;3) (integer) 11) &quot;message&quot;2) &quot;channel1.1&quot;3) &quot;hello&quot;</code></pre><p>使用UNSUBSCRIBE命令可以取消订阅指定的频道，用法为UNSUBSCRIBE [channel [channel…]]，如果不指定频道则会取消订阅所有频道。  </p><h3 id="4、按照规则订阅"><a href="#4、按照规则订阅" class="headerlink" title="4、按照规则订阅"></a>4、按照规则订阅</h3><p>除了可以使用SUBSCRIBE命令订阅指定名称的频道外，还可以使用PSUBSCRIBE命令订阅指定的规则。规则支持glob风格通配符格式，如：  </p><pre><code>127.0.0.1:6379&gt; psubscribe channel.?*Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;channel.?*&quot;3) (integer) 1</code></pre><p>规则channel.?*可以匹配channel.1和channel.10但不会匹配channel.。这时在实例B中发送消息：  </p><pre><code>127.0.0.1:6379&gt; publish channel.1 hello(integer) 2</code></pre><p>返回结果是2因为2个实例客户端都订阅了channel.1频道。实例psubscribe channel.?*收到的回复是：  </p><pre><code>1) &quot;pmessage&quot;2) &quot;channel.?*&quot;3) &quot;channel.1&quot;4) &quot;hello&quot;</code></pre><p>第一个值表示这条消息是通过PSUBSCRIBE命令订阅频道而收到的======，第二个值表示订阅时用的通配符，第三个值表示实际收到的消息的频道，第四个值则是消息内容。 </p><p>提示：使用PSUBSCRIBE命令可以重复订阅一个频道，如某客户端执行了PSUBSCRIBE channel.? channel.?*，这时向channel.2发布消息后该客户端会收到2条消息，而同时PUBLISH命令返回的值也是2而不是1。同样的，如果有另一个客户端执行了SUBSCRIBE channel.10和PSUBSCRIBE channel.?*的话，向channel.10发送命令该客户端也会收到两条消息（但是是两种类型，message和pmessage），同时publish命令会返回2。<br>PUNSUBSCRIBE命令可以推定指定的规则，用法是PUNSUBSCRIBE [pattern [pattern …]]，如果没有参数则会退订所有规则。  </p><p><strong>注意：使用PUNSUBSCRIBE命令只能退订通过PSUBSCRIBE命令订阅的规则，不会影响直接通过SUBSCRIBE命令订阅的频道；同样UNSUBSCRIBE命令也不会影响通过PSUBSCRIBE命令订阅的规则。另外容易出错的是使用PUNSUBSCRIBE命令退订某个规则时不会将其中的通配符展开，而是进行严格的字符串匹配，所以PUNSUBSCRIBE * 无法退订channel.* 规则，而是必须使用PUNSUBSCRIBE channel.*才能退订。</strong>  </p><h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>客户端和Redis使用TCP协议连接。不论是客户端向Redis发送命令还是Redis向客户端返回命令的执行结果，都需要经过网络传输，这两个部分的总耗时称为往返时延。根据网络性能不同，往返时延也不同，大致来说到本地回环地址（loop back address）的往返时延在数量级上相当于Redis处理一条简单命令（如LPUSH list 1 2 3）的时间。如果执行较多的命令，每个命令的往返时延累加起来对性能还是有一定影响的。<br>在执行多个命令时每条命令都需要等待上一条命令执行完（即收到Redis的返回结果）才能执行，即使命令不需要上一条命令的执行结果。如要获得post:1、post:2和post:3这3个键中的title字段，需要执行三条命令，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/executeCommand.png" alt="不使用管道时多条命令执行示意图">  </p><p>Redis的底层通信协议对管道（pipelining）提供了支持。通过管道可以一次性发动多条命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出。管道通过减少客户端与Redis的通信次数来实现降低往返时延累计值的目的，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/pipeExecute.png" alt="管道执行多条命令示意图">  </p><h2 id="节省空间"><a href="#节省空间" class="headerlink" title="节省空间"></a>节省空间</h2><p>相比于硬盘而言，内存在今天仍然显得比较昂贵。而Redis是一个基于内存的数据库，所有的数据都存储在内存中，所以如何优化存储，减少内存空间占用对成本控制来说是一个非常重要的话题。  </p><h3 id="1、精简键名和键值"><a href="#1、精简键名和键值" class="headerlink" title="1、精简键名和键值"></a>1、精简键名和键值</h3><p>精简键名和键值是最直观的减少内存占用的方式，如将键名very.important.person:20改成VIP:20。当然精简键名一定要把握尺度，不能单纯为了节约空间而使用不易理解的键名（比如将VIP:20修改为V:20，这样既不易维护，还容易造成命名冲突）。又比如一个存储用户性别的字符串类型键的取值是male和female，我们可以将其修改成m和f来为每条记录节约几个字节空间（更好的办法是使用0和1来表示性别）。  </p><h3 id="2、内部编码优化"><a href="#2、内部编码优化" class="headerlink" title="2、内部编码优化"></a>2、内部编码优化</h3><p>有时候仅凭精简键名和键值所减少的空间并不足以满足需求，这时就需要根据Redis内部的编码规则来节省更多的空间。Redis为每种数据类型都提供了两种内部编码方式，以散列类型为例，散列类型是通过散列表实现，这样就可以实现O（1）时间复杂度的查找、赋值操作，然而当键中元素很少的时候，O（1）的操作并不会比O（n）有明显的性能提高，所以这种情况下Redis会采用一种更为紧凑但性能稍差（获取元素的时间复杂度为O（n））的内部编码方式。内部编码方式的选择对于开发者来说是透明的，Redis会根据实际情况自动调整。当键中元素变多时Redis会自动将该键的内部编码方式转换成散列表。如果想查看一个键的内部编码方式可以使用OBJECT ENCODING 命令，如：  </p><pre><code>127.0.0.1:6379&gt; type score:2string127.0.0.1:6379&gt; get score:2&quot;100&quot;127.0.0.1:6379&gt; object encoding score:2&quot;int&quot;127.0.0.1:6379&gt; type post:5hash127.0.0.1:6379&gt; object encoding post:5&quot;ziplist&quot;</code></pre><p>Redis的每个键值都是使用一个redisObject结构体保存的，redisObject的定义如下：  </p><pre><code>typedef struct redisObject{    unsigned type:4;    unsigned notused:2;    unsigned encoding:4;    unsigned lru:22; /* lru time(relative to server.lruclock) */    int refcount;    void *ptr;} robj;</code></pre><p>其中type字段表示的是键值的数据类型，取值可以是如下内容：  </p><pre><code>#define REDIS_STRING 0#define REDIS_LIST 1#define REDIS_SET 2#define REDIS_ZSET 3#define REDIS_HASH 4</code></pre><p>encoding字段表示的就是Redis键值内部编码方式，取值如下：  </p><pre><code>#define REDIS_ENCODING_RAW 0 /* Raw representation */#define REDIS_ENCODING_INT 1 /* Encoded as integer */#define REDIS_ENCODING_HT 2  /* Encoded as hash table */#define REDIS_ENCODING_ZIPMAP 3 /* Encoded as zipmap */#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define REDIS_ENCODING_INTSET 6 /* Encoded as intset */#define REDIS_ENCODING_SKIPLIST 7 /* Encoded as skiplist */</code></pre><p>各个数据类型可能采用的内部编码方式及其相应的OBJECT ENCODING 命令执行结果如下：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/redisEncoding.png" alt="Redis每种数据类型都采用二种编码方式中的一种存储"></p><h4 id="1、字符串类型"><a href="#1、字符串类型" class="headerlink" title="1、字符串类型"></a>1、字符串类型</h4><p>Redis使用一个sdshdr类型的变量来存储字符串，而redisObject的ptr字段指向的是该变量的地址。sdshdr的定义如下： </p><pre><code>struct sdshdr{    int len;    int free;    char buf[];}</code></pre><p>其中len字段表示的是字符串的长度，free字段表示buf中的剩余空间，而buf字段存储的才是字符串的内容。所以当执行SET key foobar时，存储键值需要占用的空间是sizeof(redisObject)+sizeof(sdshdr)+strlen(“foobar”)=30字节，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/strstructure.png" alt="字符串键值的存储结构">  </p><p>而当键值内容可以用一个64位有符号整数表示时，Redis会将键值转换成long类型来存储。如SET key 123456，实际占用空间是sizeof(redisObject)=16字节，比存储“foobar”节省了一般的存储空间，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/strstructure2.png" alt="字符串键值的存储结构2">   </p><p>redisObject中的refcount字段存储的是该键值被引用数量，即一个键值可以被多个键引用。Redis启动后会预先建立10000个分别存储从0到9999这些数字的redisObject类型变量作为共享对象，如果要设置的字符串在这10000个数字内（如SET key1 123）则可以直接引用共享对象而不用再建立一个redisObject了，也就是说存储键值占用的空间是0字节，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/shareObject.png" alt="Redis直接引用共享对象">  </p><p>由此可见，使用字符串类型键存储对象ID这种小数字是非常节省存储空间的，Redis只需存储键名和一个对共享对象的引用即可。<br><strong>提示：当通过配置文件参数maxmemory设置了Redis可用的最大空间大小时，Redis不会使用共享对象，因为对于每个键值都需要使用一个redisObject来记录其LRU信息。</strong>  </p><h4 id="2、散列类型"><a href="#2、散列类型" class="headerlink" title="2、散列类型"></a>2、散列类型</h4><p>散列类型的内部编码方式可能是REDIS_ENCODING_HT或REDIS_ENCODING_ZIPLIST。在配置文件中可以定义使用REDIS_ENCODING_ZIPLIST方式编码散列表类型的时机：  </p><pre><code>hash-max-ziplist-entries 512hash-max-ziplist-value 64</code></pre><p>当散列类型键的字段个数少于hash-max-ziplist-entries参数值且每个字段名和字段值的长度都小于hash-max-ziplist-value 参数值（单位为字节）时，Redis就会使用REDIS_ENCODING_ZIPLIST来存储该键，否则就会使用REDIS_ENCODING_HT。转换过程是透明的，每当键值变更后Redis都会自动判断是否满足条件来完成转换。  </p><p>REDIS_ENCODING_HT编码即散列表，可以实现O（1）时间复杂度的赋值取值等操作，其字段和字段值都是使用redisObject存储的，所以前面讲到的字符串类型键值的优化方法同样适用于散列类型键的字段和字段值。  </p><p>提示 Redis的键值对存储也是通过散列表实现的，与REDIS_ENCODING_HT编码方式类似，但键名并非使用redisObject存储，所以键名“123456”并不会比“abcdef”占用更少空间。之所以不对键名进行优化是因为绝大多数情况下键名都不会是纯数字。  </p><pre><code>补充知识 Redis支持多数据库，每个数据库中的数据都是通过结构体redisDb存储。redisDb的定义如下：  typedef struct redisDb{    dict *dict; /* The keyspace for this DB */    dict *expires; /* Timeout of keys with a timeout set */    dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) */    dict *ready_keys; /* Blocked keys that received a PUSH */    dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */    int id;} redisDb;dict类型就是散列表结构，expires存储的是数据的过期时间。当Redis启动时会根据配置文件中databases参数指定的数量创建若干个redisDb类型变量存储不同数据库中的数据。</code></pre><p>REDIS_ENCODING_ZIPLIST编码类型是一种紧凑的编码格式，它牺牲了部分读取性能以换取极高的空间利用率，适合在元素较少的时使用。该编码类型同样还在列表类型和有序集合类型中使用。REDIS_ENCODING_ZIPLIST编码结构下图所示:  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_bmjg.png" alt="REDIS_ENCODING_ZIPLIST编码的内存结构"><br>其中zlbytes是uint32_t类型，表示整个结构占用的空间。zltail也是uint32_t类型，表示到最后一个元素的偏移，记录zltail是的程序可以直接定位到尾部元素而无需遍历整个结构，执行从尾部弹出（对列表类型而言）等操作时速度更快。zllen是uint16_t类型，存储的是元素的数量。zlend是一个单字节标识，标记结构的末尾，值永远是255。<br>在REDIS_ENCODING_ZIPLIST中每个元素由4个部分组成。第一个部分用来存储前一个元素的大小以实现倒序查找，当前一个元素的大小小于245字节时第一个部分占用1个字节，否则会占用5个字节。</p><p>第二、三个部分分别是元素的编码类型和元素大小，当元素的大小小于或等于63个字节时，元素的编码类型是ZIP_STR_06B（即0&lt;&lt;6），同时第三个部分用6个二进制位来记录元素的长度，所以第二、三个部分总占用空间是1字节。当元素的大小大于63且小于或等于16383字节时，第二、三个部分总占用空间是2字节。当元素的大小大于16383字节时，第二、三个部分总占用空间是5字节。<br>第四个部分是元素的实际内容，如果元素可以转换成数字的话Redis会使用相应的数字类型来存储以节省空间，并用第二、第三个部分来表示数字的类型（int16_t/int32_t等）。使用REDIS_ENCODING_ZIPLIST编码存储散列类型时元素的排列方式是：元素1存储字段1，元素2存储字段值1，以此类推，如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_2.png" alt="使用REDIS_ENCODING_ZIPLIST编码存储散列类型内存结构">    </p><p>例如，当执行命令HSET hkey foo bar 命令后，hkey键值的内存结构如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/REDIS_ENCODING_ZIPLIST_3.png" alt="使用REDIS_ENCODING_ZIPLIST编码存储散列类型内存结构2">   </p><p>下次需要执行HSET hkey foo anothervalue 时Redis需要从头开始找到值为foo的元素（查找时每次都会跳过一个元素以保证只查找字段名），找到后删除其下一个元素，并将新值anothervalue 插入。删除和插入都需要移动后面的内存数据，而且查找操作也需要遍历才能完成，可想而知当散列键中的数据多时性能将很低，所以不宜将<strong>hash-max-ziplist-entries</strong>和<strong>hash-max-ziplist-value</strong> 两个参数设置得很大。  </p><h4 id="3、列表类型"><a href="#3、列表类型" class="headerlink" title="3、列表类型"></a>3、列表类型</h4><p>列表类型的内部编码方式可能是REDIS_ENCODING_LINKEDLIST或REDIS_ENCODING_ZIPLIST。同样在配置文件中可以使用REDIS_ENCODING_ZIPLIST方式编码的时机:  </p><pre><code>list-max-ziplist-entries 512list-max-ziplist-value 64</code></pre><p>具体转换方式和散列类型一样，REDIS_ENCODING_LINKEDLIST编码方式即双向链表，链表中的每个元素是用redisObject存储的，所以此种编码方式下的元素值的优化方法与字符串的键值相同。<br>而是用REDIS_ENCODING_ZIPLIST编码方式时具体的表现和散列类型一样，由于REDIS_ENCODING_ZIPLIST编码方式同样支持倒序访问，所以采用此种编码方式时获取两端的数据依然较快。  </p><h4 id="4、集合类型"><a href="#4、集合类型" class="headerlink" title="4、集合类型"></a>4、集合类型</h4><p>集合类型的内部编码方式可能是REDIS_ENCODING_HT或REDIS_ENCODING_INTSET。当集中的所有元素都是整数且元素的个数小于配置文件中的set-max-intset-entries参数指定值（默认512）时Redis会使用REDIS_ENCODING_INTSET编码存储该集合，否则会使用REDIS_ENCODING_HT来存储。REDIS_ENCODING_INTSET编码存储结构体intset的定义如下： </p><pre><code>typedef struct intset{    uint32_t encoding;    uint32_t length;    int8_t contents[];} intset;</code></pre><p>其中contents存储的就是集合中的元素值，根据encoding的不同，每个元素占用的字节大小不同。默认encoding是INTSET_ENC_INT16（即2个字节），当新增加的整数元素无法使用2个字节表示时，Redis会将该集合的encoding升级为INTSET_ENC_INT32（即2个字节）并调整之前所有元素的位置和长度，同样集合的encoding还可升级为INTSET_ENC_INT64（即8个字节）。<br>REDIS_ENCODING_INTSET编码以有序的方式存储元素（所以使用SMEMBERS命令获得的结果是有序的），使得可以使用二分算法查找元素。然后无论是添加还是删除元素，Redis都需要调整后面元素的内存位置，所以当集合中元素太多时性能较差。当新增加的元素不是整数或集合中的元素数量超过了set-max-intset-entries参数指定值时，Redis会自动将该集合的存储结构转换成REDIS_ENCODING_HT。  </p><h4 id="5、有序集合类型"><a href="#5、有序集合类型" class="headerlink" title="5、有序集合类型"></a>5、有序集合类型</h4><p>有序集合类型的内部编码方式可能是REDIS_ENCODING_SKIPLIST或REDIS_ENCODING_ZIPLIST。同样在配置文件中可以使用REDIS_ENCODING_ZIPLIST方式编码的时机:  </p><pre><code>zset-max-ziplist-entries 128zset-max-ziplist-value 64</code></pre><p>具体规则和散列表一样。当编码方式是REDIS_ENCODING_SKIPLIST时，Redis使用散列表和跳跃列表（skip list）两种数据结构来存储有序集合类型键值，其中散列表用来存储元素值与元素分数的映射关系以实现O（1）时间复杂度的ZSCORE等命令。跳跃列表用来存储元素的分数及其到元素值的映射以实现排序的功能。Redis对跳跃表的实现进行了几点修改，其中包括允许跳跃列表中的元素（即分数）相同，还有为跳跃链表每个节点增加了指向前一个元素的指针以实现倒序查找。采用此种编码方式时，元素值是使用redisObject存储的，所以可以使用字符串类型键值的优化方式优化元素值，而元素的分数是使用double类型存储的。<br>使用REDIS_ENCODING_ZIPLIST编码时有序集合存储的方式按照“元素1的值，元素1的分数，元素2的值，元素2的分数”的顺序排列，并且分数是有序的。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis任务队列 </tag>
            
            <tag> Redis优先级队列 </tag>
            
            <tag> Redis发布订阅 </tag>
            
            <tag> Redis管道概念 </tag>
            
            <tag> Redis键值存储详解 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之提高篇II</title>
      <link href="/2017/05/26/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87II/"/>
      <url>/2017/05/26/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87II/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="Redis排序"><a href="#Redis排序" class="headerlink" title="Redis排序"></a>Redis排序</h2><h3 id="1、有序集合的集合操作"><a href="#1、有序集合的集合操作" class="headerlink" title="1、有序集合的集合操作"></a>1、有序集合的集合操作</h3><p>集合类型提供了强大的集合操作命令，但是如果需要排序就要用到有序集合类型。Redis作者在设计Redis的命令时考虑到了不同类型的使用场景，对于不常用到的或者在不损失过多性能的前提下可以使用现有命令来实现的功能，Redis就不会单独提供命令来实现。这一原则使得Redis在拥有强大功能的同时保持着相对精简的命令。<br>有序集合常见的使用场景是大数据排序，如游戏玩家排行榜，所有很少会需要获得键中的全部数据。同样Redis认为开发者在做完交集、并集运算后不需要直接获得全部结果，而是会希望将结果存入新的键中以便后续处理。这解释了为什么有序集合只有ZINTERSTORE和ZUNIONSTORE命令而没有ZINTER和ZUNION命令。<br>当然实际使用中确实会有直接获取集合运算结果的情况，除了等待Redis加入相关命令，我们还可以使用multi，zinterstore，zrange，del和exec这5个命令自己实现ZINTER。  </p><h3 id="2、SORT命令"><a href="#2、SORT命令" class="headerlink" title="2、SORT命令"></a>2、SORT命令</h3><p>SORT命令可以对列表类型、集合类型和有序集合类型键进行排序，并且可以完成与关系型数据库中的链接查询相类似的任务。如：  </p><pre><code>//对结合类型进行操作SMEMBERS tag:java:posts1) &quot;1&quot;2) &quot;2&quot;3) &quot;6&quot;4) &quot;10&quot;5) &quot;12&quot;127.0.0.1:6379&gt; sort tag:java:posts DESC1) &quot;12&quot;2) &quot;10&quot;3) &quot;6&quot;4) &quot;2&quot;5) &quot;1&quot;//对列表类型进行操作127.0.0.1:6379&gt; lpush mylist 4 2 6 1 3 7(integer) 6127.0.0.1:6379&gt; sort mylist1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;5) &quot;6&quot;6) &quot;7&quot;//对有序集合类型排序会忽略元素的分数，只针对元素自身的值进行排序127.0.0.1:6379&gt; zadd myset 50 2 40 3 20 1 60 5(integer) 4127.0.0.1:6379&gt; sort myset1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;5&quot;</code></pre><p>除了可以排列数字，SORT命令还可以通过ALPHA参数实现按照字典顺序排列非数字元素，如：  </p><pre><code>127.0.0.1:6379&gt; lpush mylist a c e d B C A(integer) 7127.0.0.1:6379&gt; 127.0.0.1:6379&gt; sort mylist(error) ERR One or more scores can&apos;t be converted into double127.0.0.1:6379&gt; sort mylist alpha1) &quot;a&quot;2) &quot;A&quot;3) &quot;B&quot;4) &quot;c&quot;5) &quot;C&quot;6) &quot;d&quot;7) &quot;e&quot;</code></pre><p>SORT命令还支持LIMIT参数来返回指定范围的结果。用法和SQL语句一样，LIMIT offset count，表示跳过前offset个元素并获取之后的count个元素。SORT命令参数可以组合使用，如：  </p><pre><code>127.0.0.1:6379&gt; sort tag:java:posts DESC1) &quot;12&quot;2) &quot;10&quot;3) &quot;6&quot;4) &quot;2&quot;5) &quot;1&quot;127.0.0.1:6379&gt; sort tag:java:posts DESC limit 1 21) &quot;10&quot;2) &quot;6&quot;127.0.0.1:6379&gt; sort tag:java:posts DESC limit 1 31) &quot;10&quot;2) &quot;6&quot;3) &quot;2&quot;</code></pre><h3 id="3、BY参数"><a href="#3、BY参数" class="headerlink" title="3、BY参数"></a>3、BY参数</h3><p>很多情况下列表（或集合、有序集合）中存储的元素值代表的是对象ID（如标签集合中存储的是文章对象的ID），单纯对这些ID自身排序有时意义并不大。更多的时候我们希望根据ID对应的对象的某个属性进行排序。我们可以通过有序集合键来存储文章ID列表，以修改时间作为有序集合的分数，所有文章的ID顺序和文章的发布时间（或更新时间）并不是完全一致。因此对ID本身排序就没什么意义了。使用散列表存储文章对象，其中time字段的值就是文章的发布时间。假设现在我们知道ID为“2”、”6“、”12“和”26“的四篇文章的time值分别为”1352619200“，”1352619600“，”1352620100“和”1352620000“（Unix时间）。如果要按照文章的发布时间递减排列结果应为”12“，”26“，”6“，”2“。位了获得这一的结果，需要使用SORT命令的另一个强大的参数BY。<br>BY参数的语法为“BY 参考键”。其中参考键可以是字符串类型键或者是散列类型键的某个字段（表示为键名-&gt;字段名）。如果提供了BY参数，SORT命令将不再依据元素自身的值排序，而是对每个元素使用元素的值替换参考键中的第一个“*”并获取其值，然后依据该值对元素排序。如：  </p><pre><code>//添加测试数据127.0.0.1:6379&gt; hmset post:2 time 1352619200 name java编程思想 price 86.6OK127.0.0.1:6379&gt; hmset post:26 time 1352620000 name java核心技术 price 98.2OK127.0.0.1:6379&gt; hmset post:12 time 1352620000 name Java并发编程的艺术 price 43.5OK127.0.0.1:6379&gt; hmset post:6 time 1352619600  name java2 price 2.5OK127.0.0.1:6379&gt; hmset post:5 time 1352622221 name java3 price 15OK127.0.0.1:6379&gt; ZRANGE tag:java:posts 0 -11) &quot;2&quot;2) &quot;6&quot;3) &quot;12&quot;4) &quot;26&quot;5) &quot;5&quot;//使用BY参数按post对象的time属性倒序，且26和12的time值相同时，我们发现26在前12在后127.0.0.1:6379&gt; sort tag:java:posts BY post:\*-&gt;time DESC 1) &quot;5&quot;2) &quot;26&quot;3) &quot;12&quot;4) &quot;6&quot;5) &quot;2&quot;</code></pre><p><strong>上例中SORT命令会去读取post:2、post:6、post:12、post:26、post:5几个散列键中的time字段的值并以此决定tag:java:posts键中各个文章ID的顺序。 </strong> </p><p>除了散列类型之外，参考键还可以是字符串类型，如：  </p><pre><code>127.0.0.1:6379&gt; lpush sortList 2 1 3(integer) 3127.0.0.1:6379&gt; set score:1 50OK127.0.0.1:6379&gt; set score:2 100OK127.0.0.1:6379&gt; set score:3 -10OK127.0.0.1:6379&gt; sort sortList by score:\* DESC1) &quot;2&quot;2) &quot;1&quot;3) &quot;3&quot;</code></pre><p>当参考键名不包含“*”时（即常量键名，与元素值无关），SORT命令将不会执行排序操作，因为Redis认为这种情况时没有意义的（因为所有要比较的值都一样）。例如：  </p><pre><code>127.0.0.1:6379&gt; sort sortList by abc1) &quot;3&quot;2) &quot;1&quot;3) &quot;2&quot;</code></pre><p>例中abc是常量名（甚至abc键可以不存在），此时SORT的结果与LRANGE的结果相同，没有执行排序操作。在不需要排序但需要借助SORT命令获得与元素相关联的数据时，常量键是很有用的。如果几个元素的参考键值相同，则SORT命令会再去比较元素本身的值来决定元素的顺序。如：  </p><pre><code>127.0.0.1:6379&gt; lpush sortList 4(integer) 4127.0.0.1:6379&gt; set score:4 50OK127.0.0.1:6379&gt; sort sortList BY score:\* DESC1) &quot;2&quot;2) &quot;4&quot; //4的参考值和1一样也是50，但比较元素本身4比1大，所以4在前3) &quot;1&quot;4) &quot;3&quot;</code></pre><p>当某个元素的参考键不存在时，会默认参考键的值为0：  </p><pre><code>127.0.0.1:6379&gt; LPUSH sortList 5(integer) 5127.0.0.1:6379&gt; sort sortList BY score:\* DESC1) &quot;2&quot;2) &quot;4&quot;3) &quot;1&quot;4) &quot;5&quot;//默认参考键的值为0，比3的参考键的值（-10）要大，所以排列在3前5) &quot;3&quot;</code></pre><p>补充：参考键虽然支持散列类型，但是“*”只能在“-&gt;”符号前面（即键名部分）才有用，在“-&gt;”后（即字段名部分）会被当成字段名本身而不会作为占位符被元素值替换，即常量键名。但是实际运行时会发现一个有趣的结果：  </p><pre><code>127.0.0.1:6379&gt; sort sortList BY somekey-&gt;somefield:\*1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;5) &quot;5&quot;</code></pre><p>上面提到了当参数键名是常量键名时SORT命令将不会执行排序操作，然而上面例子中确实进行了排序，而且只是对元素本身进行排序。这是因为Redis判断参考键名是不是常量键名的方式是判断参考键名中是否包含“*”，而somekey-&gt;somefield:*中包含“*”所以不是常量键名。所以在排序的时候Redis对每个元素都会读取键somekey中的somefield:*字段（”*“不会被替换），无论能否获得其值，每个元素的参考键值是相同的，所以Redis会按照元素本身的大小排列。  </p><h3 id="4、GET参数"><a href="#4、GET参数" class="headerlink" title="4、GET参数"></a>4、GET参数</h3><p>GET参数不影响排序，它的作用是使SORT命令的返回结果不再是元素自身的值，而是GET参数中指定的键值。GET参数的规则和BY参数一样，GET参数也支持字符串类型和散列类型的键，并使用“*”作为占位符。要实现在排序后直接返回ID对应的文章标题，代码如下：  </p><pre><code>//按post的time属性倒序，返回post的name属性值127.0.0.1:6379&gt; sort tag:java:posts BY post:\*-&gt;time DESC GET post:\*-&gt;name1) &quot;java3&quot;2) &quot;java\xe6\xa0\xb8\xe5\xbf\x83\xe6\x8a\x80\xe6\x9c\xaf&quot;3) &quot;Java\xe5\xb9\xb6\xe5\x8f\x91\xe7\xbc\x96\xe7\xa8\x8b\xe7\x9a\x84\xe8\x89\xba\xe6\x9c\xaf&quot;4) &quot;java2&quot;5) &quot;java\xe7\xbc\x96\xe7\xa8\x8b\xe6\x80\x9d\xe6\x83\xb3&quot;</code></pre><p>在一个SORT命令中可以有多个GET参数（而BY参数只有一个），所以还可以如下使用：  </p><pre><code>127.0.0.1:6379&gt; sort tag:java:posts BY post:\*-&gt;time DESC GET post:\*-&gt;name GET post:\*-&gt;time 1) &quot;java3&quot; 2) &quot;1352622221&quot; 3) &quot;java\xe6\xa0\xb8\xe5\xbf\x83\xe6\x8a\x80\xe6\x9c\xaf&quot; 4) &quot;1352620000&quot; 5) &quot;Java\xe5\xb9\xb6\xe5\x8f\x91\xe7\xbc\x96\xe7\xa8\x8b\xe7\x9a\x84\xe8\x89\xba\xe6\x9c\xaf&quot; 6) &quot;1352620000&quot; 7) &quot;java2&quot; 8) &quot;1352619600&quot; 9) &quot;java\xe7\xbc\x96\xe7\xa8\x8b\xe6\x80\x9d\xe6\x83\xb3&quot;10) &quot;1352619200&quot;</code></pre><p>可见有N个GET参数，每个元素返回的结果就有N行。如果还需要返回文章的ID，可以使用GET #,也就是说GET# 会返回元素本身 </p><pre><code>127.0.0.1:6379&gt; sort tag:java:posts BY post:\*-&gt;time DESC GET post:\*-&gt;name GET post:\*-&gt;time GET # 1) &quot;java3&quot; 2) &quot;1352622221&quot; 3) &quot;5&quot; 4) &quot;java\xe6\xa0\xb8\xe5\xbf\x83\xe6\x8a\x80\xe6\x9c\xaf&quot; 5) &quot;1352620000&quot; 6) &quot;26&quot; 7) &quot;Java\xe5\xb9\xb6\xe5\x8f\x91\xe7\xbc\x96\xe7\xa8\x8b\xe7\x9a\x84\xe8\x89\xba\xe6\x9c\xaf&quot; 8) &quot;1352620000&quot; 9) &quot;12&quot;10) &quot;java2&quot;11) &quot;1352619600&quot;12) &quot;6&quot;13) &quot;java\xe7\xbc\x96\xe7\xa8\x8b\xe6\x80\x9d\xe6\x83\xb3&quot;14) &quot;1352619200&quot;15) &quot;2&quot;</code></pre><h3 id="5、STORE参数"><a href="#5、STORE参数" class="headerlink" title="5、STORE参数"></a>5、STORE参数</h3><p>默认情况下SORT会直接返回排序结果，如果希望保存排序结果，可以使用STORE参数。如果希望把记过保存到sort.result键中：  </p><pre><code>127.0.0.1:6379&gt; sort tag:java:posts BY post:\*-&gt;time DESC GET post:\*-&gt;name GET post:\*-&gt;time GET # STORE sort.result(integer) 15127.0.0.1:6379&gt; lrange sort.result 0 -1 1) &quot;java3&quot; 2) &quot;1352622221&quot; 3) &quot;5&quot; 4) &quot;java\xe6\xa0\xb8\xe5\xbf\x83\xe6\x8a\x80\xe6\x9c\xaf&quot; 5) &quot;1352620000&quot; 6) &quot;26&quot; 7) &quot;Java\xe5\xb9\xb6\xe5\x8f\x91\xe7\xbc\x96\xe7\xa8\x8b\xe7\x9a\x84\xe8\x89\xba\xe6\x9c\xaf&quot; 8) &quot;1352620000&quot; 9) &quot;12&quot;10) &quot;java2&quot;11) &quot;1352619600&quot;12) &quot;6&quot;13) &quot;java\xe7\xbc\x96\xe7\xa8\x8b\xe6\x80\x9d\xe6\x83\xb3&quot;14) &quot;1352619200&quot;15) &quot;2&quot;</code></pre><p>保存后的键的类型为列表类型，如果键已经存在则会覆盖它。加上STORE参数后SORT命令的返回值为结果的个数。STORE参数常用来结合EXPIRE命令缓存排序结果，如下面的伪代码：  </p><pre><code>//判断是否存在之前排序结果的缓存$isCacheExists=Exists cache.sortif $isCacheExists is 1    //如果存在直接返回    return LRANGE cache.sort,0 -1else     //如果不存在，则使用SORT命令排序并将结果存入cache.sort键中作为缓存    $sortResult=SORT some.list STORE cache.sort    //设置生成时间为10分钟    EXPIRE cache.sort,600    //返回排序结果    return $sortResult</code></pre><h3 id="6、性能优化"><a href="#6、性能优化" class="headerlink" title="6、性能优化"></a>6、性能优化</h3><p>SORT是Redis中最强大最复杂的命令之一，如果使用不好很容易成为性能瓶颈。SORT命令的时间复杂度是O（n+mlogm），其中n表示要排序的列表（集合或有序集合）中的元素个数，m表示要返回的元素个数。当n较大的时候SORT命令的性能相对较低，并且Redis在排序前会建立一个长度为n的容器来存储待排序的元素，虽然是一个临时的过程，但如果同时进行较多的大数据量排序操作则会严重影响性能。<br>所以开发中使用SORT命令时需要注意以下几点：<br>（1）尽可能减少待排序键中元素数量（使n尽可能小）。<br>（2）使用LIMIT参数只获取需要的数据（使m尽可能小）。<br>（3）如果要排序的数据量较大，尽可能使用STORE参数将结果缓存。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis命令 </tag>
            
            <tag> SORT排序 </tag>
            
            <tag> Redis排序 </tag>
            
            <tag> SORT参数讲解 </tag>
            
            <tag> 排序性能 </tag>
            
            <tag> 排序缓存 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南之提高篇I</title>
      <link href="/2017/05/24/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87I/"/>
      <url>/2017/05/24/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%E4%B9%8B%E6%8F%90%E9%AB%98%E7%AF%87I/</url>
      <content type="html"><![CDATA[<h6 id="重要星级-★★★★★"><a href="#重要星级-★★★★★" class="headerlink" title="重要星级 ★★★★★"></a>重要星级 ★★★★★</h6><hr><h2 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h2><h3 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h3><p>Redis中的事务（transaction）是一组命令集合。事务同命令一样都是redis的最小执行单位，一个事务中的命令要么都执行，要么都不执行。事务的应用非常普遍，如银行转账过程中A给B汇款，首先系统从A的账户将钱划走，然后向B的账户增加相应的金额。这二个步骤必须属于同一个事务，要么全执行，要么全不执行。否则只执行第一步，钱就凭空消失了，这显然让人无法接受。<br>事务的原理是先将属于一个事务的命令发送给Redis，然后再让Redis依次执行这个命令。如：</p><pre><code>127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; sadd &quot;user:1:following&quot; 2QUEUED127.0.0.1:6379&gt; sadd &quot;user:2:followers&quot; 1QUEUED127.0.0.1:6379&gt; exec1) (integer) 12) (integer) 1</code></pre><p>以上代码演示了事务的使用方式。首先使用multi命令告诉Redis：“下面我发给你的命令属于同一个事务，你先不要执行，而是把他们暂时存起来。”Redis回答：“OK。” 而后我们发送了2个sadd命令来实现关注和被关注的操作，可以看到Redis遵守了承若，没有执行这些命令，而是返回QUEUED表示这两条命令已经进入等待执行的事务队列中了。<br>当把所有同一个事务中的执行的命令都发给Redis后，我们使用EXEC命令告诉Redis将等待执行的事务队列中所有命令（即刚才所有返回QUEUED的命令）按照发送顺序依次执行。EXEC命令的返回值就是这些命令的返回值组成的列表，返回值顺序和命令的顺序相同。<br>Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。<br>除此之外，Redis的事务还能保证一个事务内的命令依次执行而不被其他命令插入。试想客户端A需要执行几条命令，同时客户端B发送了一条命令，如果不适用事务，则客户端B的命令可能会插入到客户端A的几条命令中执行。如果不希望发生这种情况，也可以使用事务。</p><h3 id="2、错误处理"><a href="#2、错误处理" class="headerlink" title="2、错误处理"></a>2、错误处理</h3><p>如果事务中某个命令执行出错，Redis会怎么处理呢？  </p><h4 id="（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。如："><a href="#（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。如：" class="headerlink" title="（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。如："></a>（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。如：</h4><pre><code>127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set key valueQUEUED127.0.0.1:6379&gt; set key(error) ERR wrong number of arguments for &apos;set&apos; command127.0.0.1:6379&gt; errorcommand key(error) ERR unknown command &apos;errorcommand&apos;127.0.0.1:6379&gt; exec(error) EXECABORT Transaction discarded because of previous errors.</code></pre><p>跟在MULTI命令后执行了3个命令：一个是正确命令，成功地加入了事务队列；其余二个命令都有语法错误。而只要有一个命令有语法错误，执行EXEC命令后Redis就会直接返回错误，连语法正确的命令也不会执行。  </p><h4 id="（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。如："><a href="#（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。如：" class="headerlink" title="（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。如："></a>（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。如：</h4><pre><code>127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set key 1QUEUED127.0.0.1:6379&gt; sadd key 2QUEUED127.0.0.1:6379&gt; set key 3QUEUED127.0.0.1:6379&gt; exec1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) OK127.0.0.1:6379&gt; get key&quot;3&quot;</code></pre><p>可见虽然sadd key 2出现了错误，但是set key 3 依然执行了。<br>Redis的事务没有关系型数据库事务提供的回滚（rollback）功能。为此开发者必须在事务执行出错后自己收拾烂摊子（将事务恢复到执行前的状态等）<br>不过由于Redis不支持回滚功能，也是的Redis在事务上可以保持简洁和快速。  </p><h3 id="3、WATCH命令"><a href="#3、WATCH命令" class="headerlink" title="3、WATCH命令"></a>3、WATCH命令</h3><p>我们知道在一个事务中只有当所有命令都依次执行完后才能得到每个结果的返回值，可是有些情况下需要先获得一条命令的返回值，然后再根据这个值执行下一条命令。例如，介绍INCR命令时曾经说过使用GET 和SET命令自己实现incr函数会出现竞态条件，伪代码如下：  </p><pre><code>def incr($key)    $value=GET $key    if not $value            $value=0    $value=$value+1    SET $key,$value    return $value</code></pre><p>因为事务中的每一个命令的执行结果都是最后一期返回的，所以无法将前一条命令的结果作为下一条命令的参数，即在执行SET命令时无法获得GET命令的返回值，也就无法做到增1的功能。所以无法使用事务来实现incr函数。<br>为了解决这个问题，我们需要换种思路。即在GET获得键值后保证该键值不被其他客户端修改，直到函数执行完成后才允许其他客户端修改该键值，这样也可以防止竞态条件。要实现这一思路需要请出事务家族中的另一位成员：WATCH。WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值）。如：</p><pre><code>127.0.0.1:6379&gt; set key 1OK127.0.0.1:6379&gt; watch keyOK127.0.0.1:6379&gt; set key 2OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set key 3QUEUED127.0.0.1:6379&gt; exec(nil)127.0.0.1:6379&gt; get key&quot;2&quot;</code></pre><p>上面例子在执行WATCH命令后、事务执行前修改了key的值（即set key 2），所以最后的事务中的命令SET key 3没有执行，EXEC命令返回空结果。学会了WATCH命令就可以通过事务自己实现incr函数了，伪代码如下：  </p><pre><code>def incr($key)    WATCH $key    $value=GET $key    if not $value            $value=0    $value=$value+1    MULTI    SET $key,$value    result=EXEC    return result[0]</code></pre><p><strong>提示：由于WATCH命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，而不能保证其他客户端不修改这一键值，所以我们需要在EXEC执行失败后重新执行整个函数。</strong><br>执行EXEC命令后会取消对所有键的监控，如果不想执行事务中的命令也可以使用UNWATCH命令来取消监控。比如我们要实现hsetxx函数，作用于HSETNX命令类似，只不过是仅当字段存在时才赋值。为了避免竞态条件我们使用事务来完成这一功能：</p><pre><code>def hsetxx($key,$field,$value)    WATCH $key    $isFieldExists =HEXISTS $key,$field    if $isFieldExists is 1        MULTI        HSET $key,$field,$value        EXEC    else        UNWATCH    return $isFieldExists</code></pre><p>在代码中会判断要赋值的字段是否存在，如果字段不存在的话就不执行事务中的命令，但需要使用UNWATCH命令来保证下一个事务的执行不会受到影响。</p><h2 id="生存时间"><a href="#生存时间" class="headerlink" title="生存时间"></a>生存时间</h2><h3 id="1、命令"><a href="#1、命令" class="headerlink" title="1、命令"></a>1、命令</h3><p>EXPIRE命令的使用方法为EXPIRE key seconds，其中seconds参数表示键的生存时间，单位是秒。如想要让session:2345 键在15分钟后删除：  </p><pre><code>127.0.0.1:6379&gt; set session:2345 1234OK127.0.0.1:6379&gt; expire session:2345 900(integer) 1</code></pre><p>EXPIRE命令返回1表示设置成功，返回0表示键不存在或设置失败。例如：  </p><pre><code>127.0.0.1:6379&gt; del session:2345(integer) 1127.0.0.1:6379&gt; expire session:2345 900(integer) 0</code></pre><p>如果想知道一个键还有多久时间删除，可以使用TTL命令。返回值为键的剩余时间（单位是秒）。</p><pre><code>127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; expire foo 20(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 8127.0.0.1:6379&gt; ttl foo(integer) 4127.0.0.1:6379&gt; ttl foo(integer) 1127.0.0.1:6379&gt; ttl foo(integer) -2127.0.0.1:6379&gt; get foo(nil)</code></pre><p>可见随着时间的不同，foo键的生存时间逐渐减少，20秒后foo键会被删除。当然不存在时TTL命令会返回-1，另外同样会返回-1的是没有为键设置生存时间（即永久存在的，这是建立一个键之后的默认情况）。</p><pre><code>127.0.0.1:6379&gt; set k1 v1OK127.0.0.1:6379&gt; ttl k1(integer) -1127.0.0.1:6379&gt; ttl k3(integer) -1</code></pre><p>如果想取消键的生存时间设置（即将键恢复成永久的），可以使用PERSIST命令。如果生存时间被成功清除则返回1；否则返回0（因为键不存在或键本来就是永久的）：  </p><pre><code>127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; persist foo --键本来就是永久的则返回0(integer) 0127.0.0.1:6379&gt; expire foo 20(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 15127.0.0.1:6379&gt; persist foo --键有生存时间则设置为永久，成功返回1(integer) 1127.0.0.1:6379&gt; ttl foo</code></pre><p>除了PERSIST命令之外，使用SET或GETSET命令为键赋值也会同时清除键的生存时间，例如：  </p><pre><code>127.0.0.1:6379&gt; expire foo 20(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 11127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; ttl foo(integer) -1</code></pre><p>使用EXPIRE命令会重新设置键的生存时间，如：  </p><pre><code>127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; expire foo 20(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 18127.0.0.1:6379&gt; expire foo 30(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 27</code></pre><p>其他只对键值进行操作的命令（如：INCR/LPUSH/HSET/ZREM）均不会影响键的生存时间。<br>EXPIRE命令的seconds参数必须是整数，所以最小单位是1秒。如果想要更精确的控制键的生存时间应该使用PEXPIRE命令，PEXPIRE命令与EXPIRE的唯一区别是前者的时间单位是毫秒，即PEXPIRE key 1000与EXPIRE key 1等价。对应地可以用PTTL 命令以毫秒为单位返回键的剩余时间。<br><strong>提示：如果使用WATCH命令监测一个拥有生存时间的键，该键时间到期自动删除并不会被WATCH命令认为该键被改变，也就不会影响事务的执行。</strong><br>另外还有2个相对不太常用的命令：EXPIREAT和PEXPIREAT。<br>EXPIREAT命令与EXPIRE命令的差别在于前者使用unix时间作为第二个参数表示键的生存时间的截止时间。PEXPIREAT命令与EXPIREAT命令的区别是前者的时间单位是毫秒。如：  </p><pre><code>127.0.0.1:6379&gt; set foo valOK127.0.0.1:6379&gt; get foo&quot;val&quot;127.0.0.1:6379&gt; EXPIREAT foo 1498473048362 --时间戳，截止到年月日时分秒(integer) 1127.0.0.1:6379&gt; ttl foo(integer) 1496977350307127.0.0.1:6379&gt; ttl foo(integer) 1496977350301127.0.0.1:6379&gt; PEXPIREAT foo 1498473048362000 --时间戳，截止到年月日时分秒，毫秒为单位(integer) 1127.0.0.1:6379&gt; pttl foo(integer) 1496977350234675</code></pre><h3 id="2、访问频率限制策略"><a href="#2、访问频率限制策略" class="headerlink" title="2、访问频率限制策略"></a>2、访问频率限制策略</h3><ul><li>实现访问频率限制1<br>如需要限制每个用户（以IP计）一段时间的最大访问量。如：<br>每分钟用户最多能访问某系统100个界面，思路是对每个用户使用一个名为“rate.limiting:用户ID”的字符串类型键，每次用户访问则使用INCR 命令递增该键的键值，如果递增后的值是1（第一次访问页面），则同时还要设置该键的生存时间为1分钟。这样每次用户访问页面时都读取该键的键值，如果超过100就表明该用户的访问频次超过了限制，需要提示用户稍后访问。该键每分钟自动被删除，所以下一分钟用户的访问次数又会重新计算，也就达到了限制访问频率的目的。伪代码如下：  </li></ul><pre><code>$isKeyExists=EXISTE rate.limiting:$IPif $isKeyExists is 1    $times=INCR rate.limiting:$IP    if $times&gt;100        print 访问频率超过了限制，请稍后再试        exitelse    //第一次访问设置生存时间    INCR rate.limiting:$IP    EXPIRE $keyName,60</code></pre><p>上述代码存在一个不太明显的问题：假如程序执行完倒数第二行后突然因为某种原因退出了，没能够为该键设置生存时间，那么该键会永久存在，导致使用对应IP的用户在管理员手动删除该键前最多只能访问100次，这是一个很严重的问题。<br>为了保证建立键和为键设置生存时间一起执行，可以使用上面学习的事务功能，修改后代码如下：  </p><pre><code>$isKeyExists=EXISTE rate.limiting:$IPif $isKeyExists is 1    $times=INCR rate.limiting:$IP    if $times&gt;100        print 访问频率超过了限制，请稍后再试        exitelse    //第一次访问设置生存时间,并通过事务保证原子性    MULTI    INCR rate.limiting:$IP    EXPIRE $keyName,60    EXEC</code></pre><ul><li>实现访问频率限制2<br>事实上，上述代码仍然有个问题：如果一个用户在一分钟的第一秒访问了一次，在同一分钟的最后一秒访问了99次，又在下一分钟的第一秒访问了100次，这样的访问是可以通过现在的访问频率限制的，但实际上该用户在2秒钟内访问了199次，这与每个用户每分钟只能访问100次的限制差距较大。尽管这种情况比较极端，但在一些场合中还是需要粒度更小的控制方案。如果要精确控制每分钟最多访问100次，需要记录下用户每次访问的时间。因此对每个用户，我们使用一个列表类型的键来记录他最近100次访问时间。一旦键中的元素超过100个，就判断时间最早的元素距现在的时间是否小于1分钟。如果是则表示最近一分钟的访问次数超过了100频次限制；如果不是就将限制的时间加入到列表中，同时把最早的元素删除掉。伪代码如下：  </li></ul><pre><code>$listLength=LLEN rate.limiting:$IPif $listLength &lt;100    //访问次数不超过限制就加入    LPUSH rate.limiting:$IP,now()else    //超过限制就根据时差分情况    $time=LINDEX rate.limiting:$IP,-1    //如果最早的一次访问距离现在不超过1分钟，说明访问密集已经超出频次限制     if now()-$time&lt;60        print 访问频率超过限制，请稍后再试    else    //说明最早的访问到距离现在已超过一分钟，没有超出限制    LPUSH rate.limiting:$IP,now()    //踢掉最右端的元素（即最早访问时间）    LTRIM rate.limiting:$IP,0,99</code></pre><p>由于需要记录每次访问的时间，所以当要限制“A时间最多访问B次”时，如果“B”的数值较大，比方法会占用较多的存储空间，实际使用时还需要开发者自己权衡。除此之外该方法也会出现竞态条件。  </p><h3 id="3、实现缓存（缓存占用内存解决方案）"><a href="#3、实现缓存（缓存占用内存解决方案）" class="headerlink" title="3、实现缓存（缓存占用内存解决方案）"></a>3、实现缓存（缓存占用内存解决方案）</h3><p>为了提高网站的负载能力，常常需要将一些访问频率较高但是对CPU或IO资源消耗较大的操作结果缓存起来，并希望让这些缓存过段时间自动过期。比如教务网站要对全校所有学生的各个科目成绩汇总排名，并在首页上显示前10名学生姓名，由于计算过程较耗资源，所以可以将结果使用Redis的字符串缓存起来。由于学生成绩总在不断变化，需要每隔二小时就重新计算一次排名，这可以通过给键设置生存时间的方式实现。每次用户访问首页时程序先去查询缓存是否存在，如果存在则直接使用缓存的值；否则重新计算排名并将结果赋值给该键并同时设置该键的生存时间为2小时。伪代码如下：  </p><pre><code>$rank=GET cache:rankif not $rank    $rank=计算排名...    MULTI    SET cache:rank,$rank    EXPIRE cache:rank,7200    EXEC</code></pre><p>然后在一些场合中这种方法并不能满足需求。当服务器内存有限时，如果大量使用缓存键且生存时间设置的过长就会导致Redis占满内存；另一方面如果为了防止Redis占用内存过大而将缓存键的生存时间设得太短，就可能导致缓存命中率过低并且大量内存白白闲置。实际开发中会发现很难为缓存键设置合理的生存时间，为此可以限制Redis能够使用的最大内存，并让Redis按照一定的规则淘汰不需要的缓存键，这种方式只将Redis用作缓存系统时非常有用。<br>具体的设置方法为：修改配置文件中的maxmemory参数，限制Redis最大可用内存大小（单位是字节），当超出这个限制时Redis会根据maxmemory-policy参数指定的策略来删除不需要的键，直到Redis内存小于指定内存。<br>maxmemory-policy支持规则如下，其中LRU（Least Recently Used）算法即“最近最少使用”，其认为最近最少使用的键在未来一段时间内也不会被用到，即当需要时这些键是可以被删除的。  </p><table><thead><tr><th>规则</th><th>说明</th></tr></thead><tbody><tr><td>volatile-lru</td><td>使用LRU算法删除一个键（只针对设置了生存时间的键）</td></tr><tr><td>allkeys-lru</td><td>使用LRU算法删除一个键</td></tr><tr><td>volatile-random</td><td>随机删除一个键（只针对设置了生存时间的键）</td></tr><tr><td>allkeys-random</td><td>随机删除一个键</td></tr><tr><td>volatile-ttl</td><td>删除生存时间最近的一个键</td></tr><tr><td>noevication</td><td>不删除键，值返回错误</td></tr></tbody></table><p>如当maxmemory-policy设置为allkeys-lru时，一旦Redis占用的内存超过了限制，Redis会不断删除数据中最近最少使用的键，直到占用的内存小于限制值。</p><p><strong>LRU(Least Recently Used)最近最少使用：事实上Redis并不会准确地将整个数据库中最久未被使用的键删除，而是每次从数据库中随机取3个键并删除这3个键中最久未被使用的键。删除生存时间最接近的键的实现方法也是这样。“3”这个数字可以通过Redis的配置文件中的maxmemory-samples参数设置。</strong></p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis命令 </tag>
            
            <tag> redis事务 </tag>
            
            <tag> 生存时间 </tag>
            
            <tag> 缓存 </tag>
            
            <tag> 访问频率限制 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南-命令阶段III</title>
      <link href="/2017/05/24/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5III/"/>
      <url>/2017/05/24/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5III/</url>
      <content type="html"><![CDATA[<h2 id="有序集合类型"><a href="#有序集合类型" class="headerlink" title="有序集合类型"></a>有序集合类型</h2><p>在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每个元素都是不同的，但是他们的分数却可以相同。 </p><p>有序集合类型和列表类型的区别：<br>（1）二者都是有序的。<br>（2）二者都可以获得某一范围的元素。  </p><p>（3）列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会较慢，所以它更加适合实现如“新鲜事”或“日志”这样的很少访问中间元素的应用。<br>（4）有序集合类型是使用散列表和跳跃表（skip list）实现的，所以即使读取位于中间部分的数据速度也很快（时间复杂度O（logN））。<br>（5）列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。<br>（6）有序集合要比列表类型更耗费内存。</p><h3 id="1、命令"><a href="#1、命令" class="headerlink" title="1、命令"></a>1、命令</h3><ul><li>增加元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZADD key score member [score member ...]</span><br></pre></td></tr></table></figure><p>ZADD命令用来向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。ZADD命令的返回值是新加入到集合的元素的个数（不包含之前已经存在的元素）。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd scores 89 tom 67 peter 100 david</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; zadd scores 76 peter --如果元素已存在，用新分数替换原有分数</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; zadd test 17E+307 a --分数支持双精度</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd test 1.5 a </span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; zadd test 1.5 b</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd test +inf c --分数赋值为正无穷大</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zadd test -inf d --分数设置为负无穷大</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p><strong>+inf表示正无穷大<br>-inf表示负无穷大</strong></p><ul><li>获得元素的分数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ZSCORE key member</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; ZRANGE scores 0 -1 withscores</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;76&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">4) &quot;89&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br><span class="line">127.0.0.1:6379&gt; zscore scores tom</span><br><span class="line">&quot;89</span><br></pre></td></tr></table></figure><ul><li>获得排名在某个范围的元素列表  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZRANGE key start stop [WITHSCORES]</span><br><span class="line">ZREVRANGE key start stop [WITHSCORES]</span><br></pre></td></tr></table></figure><p>ZRANGE 命令会按照元素的分数从小到大的顺序返回索引从start到stop之间的所有元素（包括两端元素）。ZRANGE命令与LRANGE命令十分相似，如索引都是从0开始，负数代表从后向前查找（-1表示最后一个元素）。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 1 2</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;david&quot;</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;tom&quot;</span><br><span class="line">3) &quot;david&quot;</span><br></pre></td></tr></table></figure><p>如果同时获得元素的分数的话可以在ZRANGE命令尾部加上WITHSCORES参数，这时返回的数据格式就从，“元素1，元素2，…，元素<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">n”变成了“元素1，分数1，元素2，分数2,...,元素n，分数n”。如：</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;76&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">4) &quot;89&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br></pre></td></tr></table></figure></p><p>如果两个元素分数相同，redis会按照字典顺序（即“0”&lt;“9”&lt;”A”&lt;”Z”&lt;”a”&lt;”z” 这样的顺序）来进行排列。<br>ZREVRANGE命令和ZRANGE的唯一不同在于ZREVRANGE命令是按元素的分数从大到小的顺序给出结果。</p><ul><li>获得指定分数范围的元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]</span><br><span class="line">ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]--注意参数</span><br></pre></td></tr></table></figure><p>ZRANGEBYSCORE命令参数虽然多，但是很好理解。该命令按照元素的分数从小到大的顺序返回分数在min和max之间（包括min和max）的元素。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE scores 80 100 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;89&quot;</span><br><span class="line">3) &quot;david&quot;</span><br><span class="line">4) &quot;100&quot;</span><br></pre></td></tr></table></figure><p>如果希望分数范围不包含端点值，可以在分数加上“（”符号。如，希望返回80分到100分的数据，可以含80分，但不包含100分，则修改命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE scores 80 (100 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;89&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE scores 80 100 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;89&quot;</span><br><span class="line">3) &quot;david&quot;</span><br><span class="line">4) &quot;100&quot;</span><br></pre></td></tr></table></figure><p>min和max还支持无穷大，通ZADD命令一样，-inf和+inf分别表示负无穷大和正无穷大。比如你希望得到所有分数高于80分（不包含80分）的人的名单，但你却不知道最高分是多少，这时就可以使用+inf。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEbyscore scores (80 +inf withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;89&quot;</span><br><span class="line">3) &quot;david&quot;</span><br><span class="line">4) &quot;100&quot;</span><br></pre></td></tr></table></figure><p>LIMIT offset count与SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移offset个元素，并且只获取前count个元素。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line"> 1) &quot;admin&quot;</span><br><span class="line"> 2) &quot;69&quot;</span><br><span class="line"> 3) &quot;peter&quot;</span><br><span class="line"> 4) &quot;76&quot;</span><br><span class="line"> 5) &quot;tom&quot;</span><br><span class="line"> 6) &quot;89&quot;</span><br><span class="line"> 7) &quot;david&quot;</span><br><span class="line"> 8) &quot;100&quot;</span><br><span class="line"> 9) &quot;xym&quot;</span><br><span class="line">10) &quot;102&quot;</span><br></pre></td></tr></table></figure><p>获取分数高于60分的从第二个人开始的三个人：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE scores 60 +inf LIMIT 1 3 withscores</span><br><span class="line">1) &quot;peter&quot;</span><br><span class="line">2) &quot;76&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">4) &quot;89&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br></pre></td></tr></table></figure><p>ZREVRANGEBYSCORE 命令不仅是按照元素的分数从大往小的顺序给出结果，而且它的min和max参数的顺序和ZRANGEBYSCORE命令拾相反的。如：  </p><p>获取分数低于100分的前三个人：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrevrangebyscore scores 100 0 LIMIT 0 3 WITHscores</span><br><span class="line">1) &quot;david&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">3) &quot;tom&quot;</span><br><span class="line">4) &quot;89&quot;</span><br><span class="line">5) &quot;peter&quot;</span><br><span class="line">6) &quot;76&quot;</span><br></pre></td></tr></table></figure><ul><li>增加某个元素的分数  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZINCRBY key increment member</span><br></pre></td></tr></table></figure><p>ZINCRBY 命令可以增加一个元素的分数，返回的是更改后的分数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zincrby scores 8 xym</span><br><span class="line">&quot;110&quot;</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line"> 1) &quot;admin&quot;</span><br><span class="line"> 2) &quot;69&quot;</span><br><span class="line"> 3) &quot;peter&quot;</span><br><span class="line"> 4) &quot;76&quot;</span><br><span class="line"> 5) &quot;tom&quot;</span><br><span class="line"> 6) &quot;89&quot;</span><br><span class="line"> 7) &quot;david&quot;</span><br><span class="line"> 8) &quot;100&quot;</span><br><span class="line"> 9) &quot;xym&quot;</span><br><span class="line">10) &quot;110&quot;</span><br></pre></td></tr></table></figure><p>如果指定的元素不存在，redis在执行命令前会先去建立并将它的分数赋为0再去执行操作。</p><h3 id="2、命令拾遗"><a href="#2、命令拾遗" class="headerlink" title="2、命令拾遗"></a>2、命令拾遗</h3><ul><li>获得集合中的元素的数量  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ZCARD key</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; zcard scores</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line"> 1) &quot;admin&quot;</span><br><span class="line"> 2) &quot;69&quot;</span><br><span class="line"> 3) &quot;peter&quot;</span><br><span class="line"> 4) &quot;76&quot;</span><br><span class="line"> 5) &quot;tom&quot;</span><br><span class="line"> 6) &quot;89&quot;</span><br><span class="line"> 7) &quot;david&quot;</span><br><span class="line"> 8) &quot;100&quot;</span><br><span class="line"> 9) &quot;xym&quot;</span><br><span class="line">10) &quot;110&quot;</span><br></pre></td></tr></table></figure><ul><li>获得指定分数范围内的元素个数  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zcount scores (80 +inf</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><ul><li>删除一个或多个元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZREM key member [member ...]</span><br></pre></td></tr></table></figure><p>ZREM 命令的返回值是成功删除的元素数量（不包含本来就不存在的元素）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line"> 1) &quot;admin&quot;</span><br><span class="line"> 2) &quot;69&quot;</span><br><span class="line"> 3) &quot;peter&quot;</span><br><span class="line"> 4) &quot;76&quot;</span><br><span class="line"> 5) &quot;tom&quot;</span><br><span class="line"> 6) &quot;89&quot;</span><br><span class="line"> 7) &quot;david&quot;</span><br><span class="line"> 8) &quot;100&quot;</span><br><span class="line"> 9) &quot;xym&quot;</span><br><span class="line">10) &quot;110&quot;</span><br><span class="line">127.0.0.1:6379&gt; zrem scores tom</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;admin&quot;</span><br><span class="line">2) &quot;69&quot;</span><br><span class="line">3) &quot;peter&quot;</span><br><span class="line">4) &quot;76&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br><span class="line">7) &quot;xym&quot;</span><br><span class="line">8) &quot;110&quot;</span><br></pre></td></tr></table></figure><ul><li>按照排名范围删除元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZREMRANGEBYRANK key start top</span><br></pre></td></tr></table></figure><p>ZREMRANGEBYRANK命令按照元素的分数从小到大的顺序（即索引0表示最小的值）删除处在指定排名范围内的所有元素，并返回删除的元素数量。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;admin&quot;</span><br><span class="line">2) &quot;69&quot;</span><br><span class="line">3) &quot;peter&quot;</span><br><span class="line">4) &quot;76&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br><span class="line">7) &quot;xym&quot;</span><br><span class="line">8) &quot;110&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREMRANGEBYRANK scores 0 1</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;david&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">3) &quot;xym&quot;</span><br><span class="line">4) &quot;110&quot;</span><br></pre></td></tr></table></figure><ul><li>按照分数范围删除元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZREMRANGEBYSCORE key min max</span><br></pre></td></tr></table></figure><p>ZREMRANGEBYSCORE命令会删除指定分数范围内所有元素，参数min和max的特性和ZRANGEBYSCORE命令中的一样。返回值是删除的元素数量。如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;78&quot;</span><br><span class="line">3) &quot;admin&quot;</span><br><span class="line">4) &quot;98&quot;</span><br><span class="line">5) &quot;david&quot;</span><br><span class="line">6) &quot;100&quot;</span><br><span class="line">7) &quot;xym&quot;</span><br><span class="line">8) &quot;110&quot;</span><br><span class="line">127.0.0.1:6379&gt; zremrangebyscore scores (98 101</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;78&quot;</span><br><span class="line">3) &quot;admin&quot;</span><br><span class="line">4) &quot;98&quot;</span><br><span class="line">5) &quot;xym&quot;</span><br><span class="line">6) &quot;110&quot;</span><br></pre></td></tr></table></figure><ul><li>获得元素排名  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZRANK key member</span><br><span class="line">ZREVRANK key member</span><br></pre></td></tr></table></figure><p>ZRANK命令会按照元素分数从小到大的顺序获得指定的元素的排名（从0开始，即分数最小的元素排名为0），ZREVRANK命名相反（分数最大的元素排名为0）。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zrange scores 0 -1 withscores</span><br><span class="line">1) &quot;tom&quot;</span><br><span class="line">2) &quot;78&quot;</span><br><span class="line">3) &quot;admin&quot;</span><br><span class="line">4) &quot;98&quot;</span><br><span class="line">5) &quot;xym&quot;</span><br><span class="line">6) &quot;110&quot;</span><br><span class="line">127.0.0.1:6379&gt; zrank scores xym</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zrevrank scores xym</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><ul><li>计算有序集合的交集  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]</span><br></pre></td></tr></table></figure><p>ZINTERSTORE 命令用来计算多个有序集合的交集并将结果存储在destination键中（同样以有序集合的类型存储），返回值为destination键中元素的个数。destination键中元素的分数是由AGGREGATE参数决定的。<br>（1）当AGGREGATE时SUM（默认值）时，destination键中的元素的分数是每个参与计算的集合中该元素分数的和。如： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd store1 1 a 2 b</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zadd store2 10 a 20 b</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; Zinterstore destStore 2 store1 store2</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zrange destStore 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;11&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;22&quot;</span><br></pre></td></tr></table></figure><p>（2）当AGGREGATE时MIN时，destination键中的元素的分数是每个参与计算的集合中该元素分数的最小值。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zinterstore destStore 2 store1 store2 AGGREGATE min</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zrange destStore 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;2&quot;</span><br></pre></td></tr></table></figure><p>（3）当AGGREGATE时MAX时，destination键中的元素的分数是每个参与计算的集合中该元素分数的最大值。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zinterstore destStore 2 store1 store2 AGGREGATE max</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; zrange destStore 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;10&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;20&quot;</span><br></pre></td></tr></table></figure><p>ZINTERSTORE 命令还能够通过WEIGHTS参数设置每个集合的权重，每个集合在参与计算时元素的分数会被乘上该集合的权重。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zinterstore destStore 2 store1 store2 WEIGHTS 1 0.1</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE destStore 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; zrange store1 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;2&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; zrange store2 0 -1 withscores</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;10&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;20&quot;</span><br></pre></td></tr></table></figure><p><strong>计算方式为：a分数1*1+10*0.1=2，b分数2*1+20*0.1=4，注意如果加WEIGHTS参数，则后面对应每一个有序集合的权重，是多值</strong><br>其他有序集合命令请查阅<a href="http://doc.redisfans.com/" target="_blank" rel="noopener">Redis命令中文在线参考</a></p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis命令 </tag>
            
            <tag> redis五种数据类型 </tag>
            
            <tag> 有序集合（zset） </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南-命令阶段II</title>
      <link href="/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5II/"/>
      <url>/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5II/</url>
      <content type="html"><![CDATA[<h2 id="列表类型"><a href="#列表类型" class="headerlink" title="列表类型"></a>列表类型</h2><p>列表类型（list）可以存储一个有序的字符串列表，常用的操作是向列表二端添加元素或者获取列表的某一个片段。<br>列表类型内部是使用双向链表（double linked list）实现，所以向列表两端添加元素的时间复杂度为O（1），获取越接近两端的元素速度就越快。这意味着即使有几千万个元素的列表，获取头部或尾部的10条就也是极快的（和从只有20个元素的列表中获取头部或尾部的10条记录的速度是一样的）。<br>列表类型适合用来记录日志，可以保证新加入新日志不会受到已有日志数量的影响。列表还可以作为队列、栈结构来使用，与散列表类型最多能容纳字段数量相同，一个列表类型最多能容纳2的32次方-1个元素。</p><h3 id="1、命令"><a href="#1、命令" class="headerlink" title="1、命令"></a>1、命令</h3><ul><li>向列表两端增加元素</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LPUSH key value [value ...]</span><br><span class="line">RPUSH key value [value ...]</span><br></pre></td></tr></table></figure><p>LPUSH 命令用来向列表左边添加元素，返回值表示增加元素后列表的长度。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush numbers 1</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>这时numbers 键中数据如下：</p><p><img src="http://op7wplti1.bkt.clouddn.com/lpush1.png" alt="lpush1之后数据机构模型"></p><p>LPUAH 命令还支持同时增加多个元素，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush numbers 2 3</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><p>LPUSH会先向列表左边加入“2”，然后再加入“3”，所以此时members 键中数据如下：</p><p><img src="http://op7wplti1.bkt.clouddn.com/lpush2.png" alt="lpush2之后数据机构模型"></p><p>向列表右边增加元素使用RPUSH命令，用法和LPUSH命令一样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush numbers 2 3</span><br><span class="line">(integer) 5</span><br></pre></td></tr></table></figure><p>此时numbers键中的数据如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/rpush.png" alt="rpush之后数据机构模型"></p><ul><li>从列表两端弹出元素</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LPOP key </span><br><span class="line">RPOP key</span><br></pre></td></tr></table></figure><p>有进有出，lpop命令可以从列表左边弹出一个元素，lpop命令执行二步操作：第一步是将列表左边的元素从列表中移除，第二部是返回被移除的元素值。如：从numbers列表左边弹出一个元素（也就是“3”）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpop numbers</span><br><span class="line">&quot;3&quot;</span><br></pre></td></tr></table></figure><p>此时numbers键中的数据如下图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/lpop.png" alt="lpop之后数据机构模型"></p><p>同样，rpop命令可以从右边弹出一个元素：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpop numbers</span><br><span class="line">&quot;-1&quot;</span><br></pre></td></tr></table></figure><p>此时numbers键中数据如下：</p><p><img src="http://op7wplti1.bkt.clouddn.com/rpop.png" alt="rpop之后数据机构模型"></p><p><strong>结合上面的4个命令可以使用列表类型来模拟栈和队列的操作：如果想把列表当做栈，则搭配LPUSH和LPOP或RPUSH和RPOP，如果想当成队列，则搭配使用LPUSH和RPOP或RPUSH和LPOP。</strong></p><ul><li>读取列表中元素个数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LLEN key</span><br></pre></td></tr></table></figure><p>当键不存在时LLEN返回0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; llen numbers</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure><ul><li>获取列表片段</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LRANGE key start stop</span><br></pre></td></tr></table></figure><p>LARNGE 命令是列表类型最常用的命令之一，它能够获得列表中的某一片段。LRANGE命令将返回索引从start到stop之间的所有元素（包含两端的元素）。与大多数人的直觉相同，redis的列表起始索引为0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange numbers 0 2</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;0&quot;</span><br></pre></td></tr></table></figure><p>LRANGE 命令也支持负索引，表示从右边开始计算序数，如“-1”表示最右边第一个元素，“-2”表示最右边第二个元素，以此类推：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange numbers -2 -1</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;0&quot;</span><br></pre></td></tr></table></figure><p>显然，LRANGE numbers 0 -1 可以获取列表中所有元素。另外一些特殊情况如下：<br>（1）如果start的索引位置比stop的索引位置靠后，则会返回空列表<br>（2）如果stop大于实际的索引范围，则会返回到列表最后边的元素：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange number 2 1</span><br><span class="line">(empty list or set)</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 1 100</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><ul><li>删除列表中指定的值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LREM key count value</span><br></pre></td></tr></table></figure><p>LREM 命令会删除列表中前count个值为value的元素，返回值是实际删除的元素个数。<br>根据count值得不同，LREM命令执行的方式也会略有差异：  </p><pre><code>1. 当count&gt;0 时LREM命令会从列表左边开始删除前count个值为value的元素；  2. 当count&lt;0 时LREM命令会从列表右边开始删除前|count|个值为value的元素；  3. 当count=0 时LREM命令会删除所有值为value的元素。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; rpush numbers 2</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;0&quot;</span><br><span class="line">4) &quot;2&quot;</span><br><span class="line"></span><br><span class="line">#从右边删除第一个值为&quot;2&quot;的元素</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; lrem numbers -1 2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;0&quot;</span><br></pre></td></tr></table></figure><h3 id="2、命令拾遗"><a href="#2、命令拾遗" class="headerlink" title="2、命令拾遗"></a>2、命令拾遗</h3><ul><li>获得/设置指定索引的元素值  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LINDEX key index --用来返回指定索引的元素，索引从0开始,如果index为负数则表示从右边开始计算索引，最右边元素索引为-1</span><br><span class="line"></span><br><span class="line">LSET key index value --将索引为index的元素赋值为value</span><br></pre></td></tr></table></figure><p>e.g:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;0&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; lindex numbers -2</span><br><span class="line">&quot;1&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; lset numbers -2 20</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;20&quot;</span><br><span class="line">3) &quot;0&quot;</span><br></pre></td></tr></table></figure><ul><li>只保留列表指定片段<br>LTRIM key start end<br>LTRIM命令可以删除指定索引范围之外的所有元素，其指定列表范围的方法和LRANGE命令相同，如：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;20&quot;</span><br><span class="line">3) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt; ltrim numbers 1 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;20&quot;</span><br><span class="line">2) &quot;0&quot;</span><br></pre></td></tr></table></figure><p>LTRIM命令常和LPUSH命令一起使用来限制列表中元素的数量，比如记录日志时我们希望只保留最近100条日志，则每次加入新元素时调用一次LTRIM命令即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LPUSH logs $newLog</span><br><span class="line">LTRIM logs 0 99</span><br></pre></td></tr></table></figure><ul><li>向列表中插入元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LINSERT key BEFORE|AFTER pivot value</span><br></pre></td></tr></table></figure><p>LINSERT命令会首先在列表中从左到右查找值为pivot的元素，然后根据第二个参数是BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。LINSERT命令的返回值为插入后列表元素的个数。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;20&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;20&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt; linsert numbers Before 20 110</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;110&quot;</span><br><span class="line">2) &quot;20&quot;</span><br><span class="line">3) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt; linsert numbers AFTER 20 21 </span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; lrange numbers 0 -1</span><br><span class="line">1) &quot;110&quot;</span><br><span class="line">2) &quot;20&quot;</span><br><span class="line">3) &quot;21&quot;</span><br><span class="line">4) &quot;0&quot;</span><br></pre></td></tr></table></figure><ul><li>将元素从一个列表转到另一个列表  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RPOPLPUSH source destination</span><br></pre></td></tr></table></figure><p>RPOPLPUSH是个很有意思的命令，从名字就可以看出它的功能：先执行RPOP命令再执行LPUSH命令。RPOPLPUSH命令会先从source列表类型键的右边弹出一个元素，然后将其将入到destination列表类型键的左边，并返回这个元素的值，整个过程是原子的。</p><p>当把列表类型作为队列使用时，RPOPLPUSH命令可以很直观地在多个队列中传递数据。当source和destination相同时，RPOPLPUSH命令会不断的将队尾的元素移到队首借助这个特性我们可以实现一个网站监控系统：使用一个队列存储需要监控的网址，然后监控程序不断地使用RPOPLPUSH命令循环取出一个网址来测试可用性。这里使用RPOPLPUSH命令的好处在于程序执行过程中仍然可以不断地向网址列表中加入新网址，而且整个系统容易扩展，允许多个客户端同事处理队列。</p><h2 id="集合类型"><a href="#集合类型" class="headerlink" title="集合类型"></a>集合类型</h2><p>集合类型和列表类型有相似之处，但很容易将他们区分开来，见下表：</p><p>集合类型和列表类型对比</p><table><thead><tr><th>特性</th><th>集合类型</th><th>列表类型</th></tr></thead><tbody><tr><td>存储内容</td><td>至多2的32次方-1</td><td>至多2的32次方-1</td></tr><tr><td>有序性</td><td>否</td><td>是</td></tr><tr><td>唯一性</td><td>是</td><td>否</td></tr></tbody></table><p>集合类型的常用操作是向集合中加入或删除元素，判断某个元素是否存在等，由于集合类型在redis内部是使用值为空的散列表（hash table）实现，所以这些操作的时间复杂度都是O（1）。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算。</p><h3 id="1、命令-1"><a href="#1、命令-1" class="headerlink" title="1、命令"></a>1、命令</h3><ul><li>增加/删除元素</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SADD key member [member ...]</span><br><span class="line">SREM key member [member ...]</span><br></pre></td></tr></table></figure><p>SADD命令用来向集合中增加一个或多个元素，如果键不存在则会自动创建。因为在yige<br> 集合中不能有相同的元素，所以如果要加入的元素已经存在于集合中就会忽略这个元素。<br> 本命令的返回值是成功加入的元素数量（怒略的元素不计算在内）。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd letters a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sadd letters a b c</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><p>第二条命令返回值为2是因为元素“a” 已经存在，所以实际加入了2个元素。<br>SREM 用来从集合中删除一个或多个元素，返回值为成功删除个数，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; srem letters c d</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>由于“d”在集合中不存在，所以只删除了一个元素，返回值为1。</p><ul><li>获得集合中所有元素</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SMEMBERS key</span><br></pre></td></tr></table></figure><p>SMEMBERS命令返回集合中所有元素</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; smembers letters</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;a&quot;</span><br></pre></td></tr></table></figure><ul><li>判断元素是否在集合中<br>SISMEMBER key member<br>判断一个元素是否在集合是一个时间复杂度为O（1）的操作，无论集合中有多少元素，SISMEMBER命令始终可以极快返回结果。当值存在时SISMEMBER返回为1，当值不存在或键不存在时返回0，如：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sismember letters a</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; sismember letters d</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><ul><li>集合间运算</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SDIFF key [key ...]</span><br><span class="line">SINTER key [key ...]</span><br><span class="line">SUNION key [key ...]</span><br></pre></td></tr></table></figure><p>（1）SDIFF命令用来对多个集合执行差集运算。集合A与集合B差集表示为A-B，代表所有属于A且不属于B的元素构成的集合即A-B={x∈A且x∉B }。如图</p><p><img src="http://op7wplti1.bkt.clouddn.com/sdiff.png" alt="sdiff集合差集"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd setA 1 2 3</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; sadd setB 2 3 4</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; Sdiff setA setB</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">127.0.0.1:6379&gt; Sdiff setB setA</span><br><span class="line">1) &quot;4&quot;</span><br></pre></td></tr></table></figure><p>SDIFF命令支持同时传入多个键，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd setC 2 3</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; Sdiff setB setA setC</span><br><span class="line">1) &quot;4&quot;</span><br></pre></td></tr></table></figure><p>计算顺序是先计算setA-setB，再将计算结果与setC做差集。<br>（2）SINTER命令用来对多个集合执行交集运算。集合A与集合B交集表示为A∩B，代表所有属于A且属于B的元素构成的集合，即A∩B={x|x∈A且x∈B}。如图</p><p><img src="http://op7wplti1.bkt.clouddn.com/sinter.png" alt="sinter集合交集"> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sinter setA setB</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;3&quot;</span><br><span class="line">127.0.0.1:6379&gt; sinter setA setB setC</span><br><span class="line">1) &quot;2&quot;</span><br><span class="line">2) &quot;3&quot;</span><br></pre></td></tr></table></figure><p>（3）SUNION命令用来对多个集合执行并集运算。集合A与集合B的并集表示为A∪B，代表所有<br>    属于A或属于B的元素构成的集合，即A∪B={x|x∈A或x∈B }。如    </p><p><img src="http://op7wplti1.bkt.clouddn.com/sunion.png" alt="sunion 集合并集"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sunion setA setB</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line">127.0.0.1:6379&gt; sunion setA setB setC</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br><span class="line">4) &quot;4&quot;</span><br></pre></td></tr></table></figure><h3 id="2、命令拾遗-1"><a href="#2、命令拾遗-1" class="headerlink" title="2、命令拾遗"></a>2、命令拾遗</h3><ul><li>获得集合中元素个数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SCARD key</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; smembers letters</span><br><span class="line">1) &quot;b&quot;</span><br><span class="line">2) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; scard letters</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><ul><li>进行集合运算并将结果存储</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SDIFFSTORE destination key [key ...]</span><br><span class="line">SINTERSTORE destination key [key ...]</span><br><span class="line">SUNIONSTORE destination key [key ...]</span><br></pre></td></tr></table></figure><p>SDIFFSTORE命令和SDIFF命令功能一样，唯一的区别就是前者不会直接返回运算结果，而是将结果存储在destination键中。<br>SINTERSTORE命令常用于需要进行多步集合运算的场景中，如需要先计算差集再将结果和其他键计算交集。</p><ul><li>随机获得集合中的元素  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SRANDMEMBER key [count]</span><br></pre></td></tr></table></figure><p>SRANDMEMBER命令用来随机从集合中获取一个元素，如：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; srandmember letters</span><br><span class="line">&quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember letters</span><br><span class="line">&quot;b&quot;</span><br></pre></td></tr></table></figure><p>还可以通过传递count参数来一次随机获取多个元素，根据count的正负不同，具体表现也不同。<br>（1）当count为正数时，SRANDMEMBER会随机从集合里获得count个不重复的元素，如果count值大于集合中的元素个数，则SRANDMEMBER会返回集合中全部元素。  </p><p>（2）当count为负数时，SRANDMEMBER会随机从集合里获得|count|个元素，这些元素有可能相同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; srandmember letters 2</span><br><span class="line">1) &quot;c&quot;</span><br><span class="line">2) &quot;d&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember letters 2</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember letters -2</span><br><span class="line">1) &quot;d&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember letters -2</span><br><span class="line">1) &quot;c&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; srandmember letters -10</span><br><span class="line"> 1) &quot;b&quot;</span><br><span class="line"> 2) &quot;c&quot;</span><br><span class="line"> 3) &quot;a&quot;</span><br><span class="line"> 4) &quot;b&quot;</span><br><span class="line"> 5) &quot;c&quot;</span><br><span class="line"> 6) &quot;c&quot;</span><br><span class="line"> 7) &quot;b&quot;</span><br><span class="line"> 8) &quot;b&quot;</span><br><span class="line"> 9) &quot;d&quot;</span><br><span class="line">10) &quot;a&quot;</span><br></pre></td></tr></table></figure><p>b出现的 几率比较大（原因参见redis入门指南第65页）</p><ul><li>从集合中弹出一个元素      </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SPOP key</span><br></pre></td></tr></table></figure><p>spop会随机选择一个元素从集合中弹出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; smembers letters</span><br><span class="line">1) &quot;d&quot;</span><br><span class="line">2) &quot;c&quot;</span><br><span class="line">3) &quot;b&quot;</span><br><span class="line">4) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; spop letters</span><br><span class="line">&quot;c&quot;</span><br><span class="line">127.0.0.1:6379&gt; smembers letters</span><br><span class="line">1) &quot;d&quot;</span><br><span class="line">2) &quot;b&quot;</span><br><span class="line">3) &quot;a&quot;</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis命令 </tag>
            
            <tag> redis五种数据类型 </tag>
            
            <tag> 列表（list） </tag>
            
            <tag> 集合（set） </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南-命令阶段I</title>
      <link href="/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5I/"/>
      <url>/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%91%BD%E4%BB%A4%E9%98%B6%E6%AE%B5I/</url>
      <content type="html"><![CDATA[<h2 id="命令热身"><a href="#命令热身" class="headerlink" title="命令热身"></a>命令热身</h2><h3 id="1-获得符合规则的键名列表"><a href="#1-获得符合规则的键名列表" class="headerlink" title="1. 获得符合规则的键名列表"></a>1. 获得符合规则的键名列表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KEYS pattern</span><br></pre></td></tr></table></figure><p>pattern支持glob风格通配符格式，具体规则如下表：<br>符号|含义<br>—|—<br>？|匹配一个字符<br>*|匹配任意个（包括0个）字符<br>[]|匹配括号间任意字符，可以使用“-”符号表示一个范围，如a[b-d]可以匹配ab、ac、ad<br>\x|匹配字符x，用于转义符号。如要匹配？就需要使用 \?</p><h3 id="2-判断键是否存在"><a href="#2-判断键是否存在" class="headerlink" title="2. 判断键是否存在"></a>2. 判断键是否存在</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXISTS key</span><br></pre></td></tr></table></figure><p>如果存在返回1，否则返回0。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; exists test</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; exists noexists</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><h3 id="3-删除键"><a href="#3-删除键" class="headerlink" title="3. 删除键"></a>3. 删除键</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DEL key [key ...]</span><br></pre></td></tr></table></figure><p>可以删除一个或多个键，返回数字是删除键的个数。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; del test</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; del test</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><p>第二次执行del命令返回0，因为test已经被删除了，实际并没有删除任何键，所以返回值为0。</p><p><strong>技巧：DEL 命令的参数不支持通配符，但我们可以结合linux的管道和xargs命令自己实现删除所有符合规则的键。比如要删除所有以”user:*“开头的键,就可以执行redis-cli KEYS “user:*“|xargs redis-cli DEL。另外由于DEL命令支持多个键作为参数，所以还可以执行redis-cli DEL ‘redis-cli KEYS “user:*“‘ 来达到同样的效果，但是性能更好。</strong></p><h3 id="4-获得键值的数据类型"><a href="#4-获得键值的数据类型" class="headerlink" title="4. 获得键值的数据类型"></a>4. 获得键值的数据类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TYPE key</span><br></pre></td></tr></table></figure><p>TYPE 命令用来获取键值的数据类型，返回值可能是string（字符串类型）、hash（散列类型）、list（列表类型）、set（集合类型）、zset（有序集合类型）。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set str str123</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; type str</span><br><span class="line">string --字符串</span><br><span class="line">127.0.0.1:6379&gt; lpush list1 l1 l2 l3 l4</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; type list1</span><br><span class="line">list --列表</span><br><span class="line">127.0.0.1:6379&gt; hmset people:1 name zhangsan age 22 work javacoder</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; type people:1</span><br><span class="line">hash --散列</span><br><span class="line">127.0.0.1:6379&gt; zadd zset1 101 a 102 b</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; type zset1</span><br><span class="line">zset --有序集合</span><br><span class="line">127.0.0.1:6379&gt; sadd set1 java oracle servet spring hibernate</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; type set1</span><br><span class="line">set --集合</span><br></pre></td></tr></table></figure><hr><h2 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h2><p>字符串类型是redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据。你可以用其存储用户邮箱、json化的对象甚至是一张图片。一个字符串类型键允许存储的数据最大容量是512MB。<br>字符串类型是其他4中数据类型的基础，其他数据类型和字符串的差别从某种角度来说只是组织字符串的形式不同。</p><h3 id="1、命令"><a href="#1、命令" class="headerlink" title="1、命令"></a>1、命令</h3><ul><li>取值赋值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET key value</span><br><span class="line">GET key</span><br></pre></td></tr></table></figure><ul><li>递增数字</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INCR key</span><br></pre></td></tr></table></figure><p>前面说过字符串可以存储任何形式的字符串，当存储的字符串是整数形式时，redis提供了一个使用的命令INCR，其作用是让当前键值递增，并返回递增后的值，用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr num</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; incr num</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><p>包括INCR在内的所有redis命令都是原子操作，无论有多少客户端连接到redis执行命令都不可能出现竞态条件。</p><h3 id="2、实践"><a href="#2、实践" class="headerlink" title="2、实践"></a>2、实践</h3><p>提示：redis对于键的命名并没有强制的要求，但比较好的实践是用“对象类型:对象ID:对象属性”来命名一个键，如使用键user:1:friends来存储ID为1的用户的好友列表，对于多个单词则推荐使用“.”分隔，一方面是沿用以前的习惯（redis之前的版本键名不能包含空格等特殊符号），另一方面是在redis-cli中容易输入，无需使用双引号包裹。另外为了日后维护方便，键的命名一定要有意义，如u:f:1的可读性显然不如user:1:friends好（虽然采用较短的名称可以节省存储空间，但由于键值的长度往往大于键名的长度，所以这部分的节省大部分情况下并不如可读性来得重要）。</p><h3 id="3、命令拾遗"><a href="#3、命令拾遗" class="headerlink" title="3、命令拾遗"></a>3、命令拾遗</h3><ul><li>增加指定整数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INCRBY key increment</span><br></pre></td></tr></table></figure><p>INCRBY命令与INCR命令基本一样，只不过前者可以通过increment 参数指定一次增加的数值，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incrby num 20</span><br><span class="line">(integer) 22</span><br><span class="line">127.0.0.1:6379&gt; incrby num 30</span><br><span class="line">(integer) 52</span><br></pre></td></tr></table></figure><ul><li>减少指定的整数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DECR key</span><br><span class="line">DECRBY key decrement</span><br></pre></td></tr></table></figure><p>DECR命令与INCR命令用法相同，只不过时让键值递减，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; decr num</span><br><span class="line">(integer) 51</span><br><span class="line">127.0.0.1:6379&gt; decrby num 30</span><br><span class="line">(integer) 21</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>DECR和INCR及DECRBY和INCRBY是相反的操作，可通过正负数字实现对方相同的功能。</p><ul><li>指定增加浮点数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INCRBYFLOAT key increment</span><br></pre></td></tr></table></figure><p>INCRBYFLOAT命令类似INCRBY 命令，差别是前者可以递增一个双精度浮点数，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incrbyfloat fnum 2.764</span><br><span class="line">&quot;2.764&quot;</span><br><span class="line">127.0.0.1:6379&gt; incrbyfloat fnum 2E+4</span><br><span class="line">&quot;20002.76399999999999935&quot;</span><br></pre></td></tr></table></figure><ul><li>向尾部追加值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">APPEND key value</span><br></pre></td></tr></table></figure><p>APPEND作用是向键值的末尾追加value。如果键不存在则将改键的值设为value，即相当于SET key value。返回值是追加后的字符串长度。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; append key &quot; world&quot;</span><br><span class="line">(integer) 11</span><br><span class="line">127.0.0.1:6379&gt; get hello</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;hello world&quot;</span><br></pre></td></tr></table></figure><p>append命令的第二个参数加双引号，原因是该参数包含了空格，在redis-cli中输入需要双引号以示区分。</p><ul><li>获取字符串长度</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">STRLEN key</span><br></pre></td></tr></table></figure><p>STRLEN命令返回键值的长度，如果键不存在则返回0。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set key 你好</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;\xe4\xbd\xa0\xe5\xa5\xbd&quot;</span><br><span class="line">127.0.0.1:6379&gt; strlen key</span><br><span class="line">(integer) 6</span><br></pre></td></tr></table></figure><ul><li>同时获得/设置多个键值  </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MGET key[key ...]</span><br><span class="line">MSET key value [key value ...]</span><br></pre></td></tr></table></figure><p>MGET/MSET与GET/SET相似，不过MGET/MSET可以同时获得/设置多个键的键值，例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 k4 v4</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get k3</span><br><span class="line">&quot;v3&quot;</span><br><span class="line">127.0.0.1:6379&gt; get k4</span><br><span class="line">&quot;v4&quot;</span><br><span class="line">127.0.0.1:6379&gt; mget k1 k2 k3 k4</span><br><span class="line">1) &quot;v1&quot;</span><br><span class="line">2) &quot;v2&quot;</span><br><span class="line">3) &quot;v3&quot;</span><br><span class="line">4) &quot;v4&quot;</span><br></pre></td></tr></table></figure><ul><li>位操作</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GETBIT key offset --获取字符串类型键指定位置的二进制位的值（0或1），索引从0开始</span><br><span class="line">SETBIT key offset value --设置字符串类型键指定位置的二进制值，返回改位置旧值</span><br><span class="line">BITCOUNT key [start] [end] --获得字符串类型键中值为1的二进制位个数</span><br><span class="line">BITOP operation destkey key [key ...]--对多个字符串类型键进行位运算，并将结果存储在destkey参数指定的键中，bitop支持的操作命令（operation参数）有AND/OR/XOR/NOT。</span><br></pre></td></tr></table></figure><p>一个字节有8个二进制位组成，Redis通过以上命令可以直接对二进制位进行操作。为演示首先准备将foo赋值为bar：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set foo bar</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>bar的三个字母对应的ASCII码分别为98/97/114转换为二进制如下：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/barbin.png" alt="bar的二进制"></p><p>GETBIT命令可以获得一个字符串类型键值指定位置的二进制的值（0/1）索引从0开始：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; getbit foo 0</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; getbit foo 6</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>如果需要获取的二进制的索引超出了键值的二进制的实际长度则默认位值是0：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; getbit foo 100</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><p>SETBIT命令可以设置字符串类型键值指定位置的二进制位的值，返回值是该位置的旧值。如我们要将foo键值设置为aar，可以通过操作将foo键的二进制位的索引第6位设为0，第7位设为1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit foo 6 0</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; setbit foo 7 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; get foo</span><br><span class="line">&quot;aar&quot;</span><br></pre></td></tr></table></figure><p>BITCOUNT 命令可以获得字符串类型键中值是1的二进制位个数，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bitcount foo</span><br><span class="line">(integer) 10</span><br></pre></td></tr></table></figure><p>可以通过参数来限制统计字符的范围，如我们只希望统计前2个字节（即“aa”）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bitcount foo 0 1</span><br><span class="line">(integer) 6</span><br></pre></td></tr></table></figure><p>通过BITOP命令我们可以对bar和aar进行or运算：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set foo1 bar</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set foo2 aar</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; bitop or res foo1 foo2</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; get res</span><br><span class="line">&quot;car&quot;</span><br></pre></td></tr></table></figure><p>运算过程如下图：  </p><p><img src="http://op7wplti1.bkt.clouddn.com/orcalc.png" alt="bit的or操作运算过程"></p><h2 id="散列类型"><a href="#散列类型" class="headerlink" title="散列类型"></a>散列类型</h2><p>redis是采用字典结构以键值对的形式存储数据，而散列类型（hash）的健值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他类型数据，换句话说，散列类型不能嵌套其他的数据类型。一个散列类型键可以包含至多2的32次方-1个字段。</p><p><em>提示：除了散列类型，redis的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。</em></p><p>散列类型适合存储对象：使用对象类别和ID构成键名，使用字段表示对象属性，而字段值则存储属性值。例如要存储ID为2的汽车对象，可以分别使用名为color、name和price的3个字段来存储该辆汽车的颜色、名称和价格。存储结构如图：</p><p><img src="http://op7wplti1.bkt.clouddn.com/hashcar.png" alt="散列表存储汽车对象模型"></p><p>相比关系型数据库（数据是以二维表的形式存储，要求所有记录都拥有同样的属性，无法单独为某条记录增减属性）redis散列类型不存在字段冗余等问题。redis并不要求每个键都依据固定的结构存储，我们完全可以自由的为任何键增减字段而不影响其他键。</p><h3 id="1、命令-1"><a href="#1、命令-1" class="headerlink" title="1、命令"></a>1、命令</h3><ul><li>赋值与取值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HSET key field value --</span><br><span class="line">HGET key field --根据field获取对应键值</span><br><span class="line">HMSET key field value [field value ...]</span><br><span class="line">HMGET key field [field ...]</span><br><span class="line">HGETALL key</span><br></pre></td></tr></table></figure><p>HSET命令用来给字段赋值，而HGET命令用来获得字段值。用法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HSET car price 500</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; HSET car name BMW</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; HGET car name</span><br><span class="line">&quot;BMW&quot;</span><br></pre></td></tr></table></figure><p>HSET命令方便之处在于不区分插入和更新操作，这意味着修改数据时不用事先判断字段是否存在再来决定执行的是插入操作（insert）还是更新（update）操作。当执行的是插入操作时（即之前的字段不存在）HSET命令返回1，当执行的是更新操作时（即之前字段存在）HSET命令返回0。更进一步，当键本身不存在时，HSET命令还会自动创建它。</p><p>当需要同时设置多个字段的值时，可以使用HMSET命令。例如，下面语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HSET key field1 value1</span><br><span class="line">HSET key field2 value2</span><br></pre></td></tr></table></figure><p>可以用HMSET命令改写成</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HMSET key field1 value1 field2 value2</span><br></pre></td></tr></table></figure><p>相应地，HMGET命令可以同时获得多个字段的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HMGET car name price</span><br><span class="line">1) &quot;BMW&quot;</span><br><span class="line">2) &quot;500&quot;</span><br></pre></td></tr></table></figure><p>如果想获取键中所有字段和字段值却不知道键中有哪些字段时（如汽车对象的例子，每个对象拥有的属性都未必相同）应该使用HGETALL命令。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HGETALL car</span><br><span class="line">1) &quot;price&quot;</span><br><span class="line">2) &quot;500&quot;</span><br><span class="line">3) &quot;name&quot;</span><br><span class="line">4) &quot;BMW&quot;</span><br></pre></td></tr></table></figure><ul><li>判断字段是否存在</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEXISTS key field</span><br></pre></td></tr></table></figure><p>HEXISTS 命令用来判断一个字段是否存在。如果存在则返回1，否则返回0（如果键不存在也返回0）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; Hexists car model</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; HSET car model c200</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; Hexists car model</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><ul><li>当字段不存在时赋值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HSETNX key field value</span><br></pre></td></tr></table></figure><p>HSETNX命令和HSET命令类似，区别在于如果字段已经存在，HSETNX命令将不执行任何操作。<br>HSETNX 命令是原子操作，不用担心竞态条件。</p><ul><li>增加数字</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HINCRBY key field increment</span><br><span class="line">127.0.0.1:6379&gt; Hincrby person score 60</span><br><span class="line">(integer) 60</span><br></pre></td></tr></table></figure><ul><li>删除字段</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HDEL key field [field ...]</span><br></pre></td></tr></table></figure><p>HDEL命令可以删除一个或多个字段，返回值是被删除的字段个数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HDEL car price</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; Hgetall car</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;BMW&quot;</span><br><span class="line">3) &quot;model&quot;</span><br><span class="line">4) &quot;c200&quot;</span><br></pre></td></tr></table></figure><h3 id="2、命令拾遗"><a href="#2、命令拾遗" class="headerlink" title="2、命令拾遗"></a>2、命令拾遗</h3><ul><li>只获取字段名或字段值</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HKEYS key</span><br><span class="line">HVALS key</span><br></pre></td></tr></table></figure><p>有时仅仅需要获取键中所有字段的名字而不需要字段值，那么可以使用HKEYS命令，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; Hkeys car</span><br><span class="line">1) &quot;name&quot;</span><br><span class="line">2) &quot;model&quot;</span><br></pre></td></tr></table></figure><p>HVALS命令和HKEYS命令相对应，HVALS命令用来获得键中的所有字段值，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HVALS car</span><br><span class="line">1) &quot;BMW&quot;</span><br><span class="line">2) &quot;c200&quot;</span><br></pre></td></tr></table></figure><ul><li>获得字段数量</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HLEN key</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; Hlen car</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis命令 </tag>
            
            <tag> redis五种数据类型 </tag>
            
            <tag> 字符串（string） </tag>
            
            <tag> 散列表（hash） </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis入门指南-准备阶段</title>
      <link href="/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%87%86%E5%A4%87%E9%98%B6%E6%AE%B5/"/>
      <url>/2017/05/23/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97-%E5%87%86%E5%A4%87%E9%98%B6%E6%AE%B5/</url>
      <content type="html"><![CDATA[<h2 id="一、启动和停止"><a href="#一、启动和停止" class="headerlink" title="一、启动和停止"></a>一、启动和停止</h2><p>redis 可执行文件说明  </p><table><thead><tr><th>文件名</th><th>说明</th></tr></thead><tbody><tr><td>redis-server</td><td>Redis服务器</td></tr><tr><td>redis-cli</td><td>Redis命令行客户端</td></tr><tr><td>redis-benchmark</td><td>Redis性能测试工具</td></tr><tr><td>redis-check-aof</td><td>AOF文件修复工具</td></tr></tbody></table><h3 id="启动redis"><a href="#启动redis" class="headerlink" title="启动redis"></a>启动redis</h3><hr><h4 id="直接启动"><a href="#直接启动" class="headerlink" title="直接启动"></a>直接启动</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server --port 6379</span><br></pre></td></tr></table></figure><p>redis 默认使用6379,通过port参数可自定义端口号</p><h4 id="通过初始化脚本启动redis"><a href="#通过初始化脚本启动redis" class="headerlink" title="通过初始化脚本启动redis"></a>通过初始化脚本启动redis</h4><p>在redis的源代码目录utils下有一个名为redis_init_script的初始化脚本文件，我们需要配置redis的运行方式和持久化文件、日志文件的存储位置等，步骤如下：</p><ol><li><p>配置初始化脚本。将初始化文件复制到/etc/init.d目录中，并更名为redis_端口号，其中端口号表示redis监听的端口号，客户端通过该端口号链接redis。然后修改脚本第6行REDISPORT变量值为同样的端口号。</p></li><li><p>建立需要的文件夹。</p></li></ol><p>需要建立目录及说明</p><table><thead><tr><th>目录名</th><th>说明</th></tr></thead><tbody><tr><td>/etc/redis</td><td>存放redis配置文件</td></tr><tr><td>/var/redis/端口号</td><td>存放redis持久化文件</td></tr></tbody></table><ol start="3"><li>修改配置文件。将配置文件模板复制到/etc/redis目录中，依端口号命名(如：“6379.conf”),然后按下表对文件参数进行编辑。</li></ol><table><thead><tr><th>参数</th><th>值</th><th>说明</th></tr></thead><tbody><tr><td>daemonize</td><td>yes</td><td>使redis依守护进程模式启动</td></tr><tr><td>pidfile</td><td>/var/run/redis_端口号.pid</td><td>设置redis的pid文件位置</td></tr><tr><td>port</td><td>端口号</td><td>设置redis监听的端口号</td></tr><tr><td>dir</td><td>/var/redis/端口号</td><td>设置持久化文件存储位置</td></tr></tbody></table><p>现在就可以使用/etc/init.d/redis_端口号 start来启动redis了，然后执行下面命令让redis随系统自启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-rc.d redis_端口号 defaults</span><br></pre></td></tr></table></figure><hr><h3 id="停止redis"><a href="#停止redis" class="headerlink" title="停止redis"></a>停止redis</h3><p>考虑到redis有可能正在将内存中的数据同步到磁盘中，强制终止redis进程可能导致丢失数据。正确停止redis的方式应该是向redis发送shutdown命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli shutdown</span><br></pre></td></tr></table></figure><p>当redis接受到shutdown命令后，会先断开所有的客户端连接，然后根据配置执行持久化，最后完成退出。</p><p>redis可以妥善处理sigterm信号，所以使用<strong>kill redis 的pid</strong>也可以正常完成退出，效果和使用shutdown命令一样。</p><hr><h2 id="二、Redis的客户端命令"><a href="#二、Redis的客户端命令" class="headerlink" title="二、Redis的客户端命令"></a>二、Redis的客户端命令</h2><p>redis-cli（Redis Command Line Interface）是redis自带的基于命令行的客户端。使用Redis-cli向redis发送命令可以观察不同类型的命令。</p><h3 id="发送命令"><a href="#发送命令" class="headerlink" title="发送命令"></a>发送命令</h3><ol><li>将命令作为redis-cli 的参数执行，如：redis-cli shutdown。redis执行的时候会按照默认配置（服务器地址：127.0.0.1，端口号：6379，链接redis），通过-h和-p参数可以自定义地址和端口号。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379</span><br></pre></td></tr></table></figure><p>可以通过redis-cli ping在测试redis是否和客户端连接正常，如果正常会受到pong。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli ping</span><br><span class="line">pong</span><br></pre></td></tr></table></figure><ol start="2"><li>不带参数运行redis-cli，进入交互模式</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli</span><br><span class="line">127.0.0.1:6379&gt;ping</span><br><span class="line">PONG</span><br><span class="line">127.0.0.1:6379&gt;echo hi</span><br><span class="line">&quot;hi&quot;</span><br></pre></td></tr></table></figure><p>这种方式可以输入多次命令，比较方便</p><h3 id="命令返回值"><a href="#命令返回值" class="headerlink" title="命令返回值"></a>命令返回值</h3><ol><li>状态回复 </li></ol><p>最简单的回复，例如向redis执行set命令redis回复OK，ping命令返回pong，状态回复直接显示状态信息。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; PING</span><br><span class="line">PONG</span><br></pre></td></tr></table></figure><ol start="2"><li>错误回复</li></ol><p>当出现命令不存在或命令格式有错误等情况时redis会返回错误回复（error reply），错误回复以（error）开否并在后面跟上错误信息。如执行一个不存在的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ERRORCOMMAND</span><br><span class="line">(error) ERR unknown command &apos;ERRORCOMMAND&apos;</span><br></pre></td></tr></table></figure><ol start="3"><li>整数回复</li></ol><p>redis虽然没有整数类型，但却提供了一些用于操作整数的命令，如递增键值的incr命令会以整数形式返回递增后的键值。除此之外还有一些其他命令也会返回整数，如可以获取当前数据库中键的数据量的DBSIZE命令等。整数回复（integer reply）以（integer）开头，后面跟上整数数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; incr test</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; dbsize</span><br><span class="line">(integer) 23</span><br></pre></td></tr></table></figure><ol start="4"><li>字符串回复</li></ol><p>字符串回复（bulk reply），为最常见的回复类型，当请求一个字符串类型键的键值或一个其他类型键中某个元素的时候就会得到字符串回复。字符串回复以双引号包裹：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get test</span><br><span class="line">&quot;1&quot;</span><br><span class="line">127.0.0.1:6379&gt; hget car:1 speed</span><br><span class="line">&quot;200km/h&quot;</span><br></pre></td></tr></table></figure><p>特殊情况时当请求的键值不存在时，会得到一个空结果，显示为（nil）。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; get noexists</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><ol start="5"><li>多行字符串回复</li></ol><p>多行字符串回复（multi-bulk reply）也比较常见，当请求一个非字符串类型键的元素列表时就会收到多行字符串回复。多行字符串中每行都以一个序号开头，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line"> 1) &quot;homepageZhdll_20175rank2&quot;</span><br><span class="line"> 2) &quot;clueUserKey:363:4:321102&quot;</span><br><span class="line"> 3) &quot;car:1&quot;</span><br><span class="line"> 4) &quot;homepageCyph_20175rank2&quot;</span><br></pre></td></tr></table></figure><p>特殊情况,当数据库中为空时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; flushdb</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br></pre></td></tr></table></figure><h2 id="三、配置"><a href="#三、配置" class="headerlink" title="三、配置"></a>三、配置</h2><p> redis支持通过配置文件来设置参数选项。启用配置文件的方法是在启动时将配置文件路径作为参数传递给redis-server，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /path/to/redis.conf</span><br></pre></td></tr></table></figure><p>通过启动参数传递同名的配置选项会覆盖配置文件中的参数，像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server /path/to/redis.conf --loglevel warning</span><br></pre></td></tr></table></figure><p>redis提供了配置文件模板位于源代码的根目录中。<br>除此之外还可以在redis运行时通过 config set命令在不重新启动redis服务的情况下动态修改部分redis配置，就像<br>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set loglevel warning</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>并不是所有的命令都可以使用config set命令动态修改，同样在运行的时候也可以使用config get 命令获得redis当前的配置情况，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config get loglevel</span><br><span class="line">1) &quot;loglevel&quot;</span><br><span class="line">2) &quot;warning&quot;</span><br></pre></td></tr></table></figure><p>第一行为选项名，第二行选项值</p><h2 id="四、多数据库"><a href="#四、多数据库" class="headerlink" title="四、多数据库"></a>四、多数据库</h2><p>每个数据库对外都是以0开始的递增命名，redis默认支持16个数据库（0,1,2,3…15）可以通过配置参数databases来修改。客户端与redis建立连接后会自动选择0号数据库，不过可以通过select 命令更换数据库如：选择一号数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; select 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379[1]&gt; get test</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><p>然而这些以数字命名的数据库又与我们理解的数据库有所区别。首选redis不支持自定义数据库名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。另外redis也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完全隔离的，比如flushall 命令可以清空一个redis实例中所有数据库中的数据。综上所述，这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据，而使用1号数据库存储B应用的数据，不同的应用应该使用不同的redis实例存储数据。由于redis非常轻量级，一个空的redis实例占用的内存只有1MB左右，所以不用担心多个redis实例会额外占用很多内存。</p>]]></content>
      
      <categories>
          
          <category> redis系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis配置 </tag>
            
            <tag> redis多数据库 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>常用 Git 命令清单</title>
      <link href="/2017/05/04/%E5%B8%B8%E7%94%A8-Git-%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"/>
      <url>/2017/05/04/%E5%B8%B8%E7%94%A8-Git-%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/</url>
      <content type="html"><![CDATA[<h4 id="作者：-阮一峰"><a href="#作者：-阮一峰" class="headerlink" title="作者： 阮一峰"></a>作者： 阮一峰</h4><h4 id="日期：-2015年12月-9日"><a href="#日期：-2015年12月-9日" class="headerlink" title="日期： 2015年12月 9日"></a>日期： 2015年12月 9日</h4><h4 id="原文：http-www-ruanyifeng-com-blog-2015-12-git-cheat-sheet-html"><a href="#原文：http-www-ruanyifeng-com-blog-2015-12-git-cheat-sheet-html" class="headerlink" title="原文：http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html"></a>原文：<a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html</a></h4><p>我每天使用 Git ，但是很多命令记不住。<br>一般来说，日常使用只要记住下图6个命令，就可以了。但是熟练使用，恐怕要记住60～100个命令。</p><p><img src="http://op7wplti1.bkt.clouddn.com/bg2015120901.png" alt="Git三大区域"></p><p>下面是我整理的常用 Git 命令清单。几个专用名词的译名如下。<br>Workspace：工作区<br>Index / Stage：暂存区<br>Repository：仓库区（或本地仓库）<br>Remote：远程仓库</p><h2 id="一、新建代码库"><a href="#一、新建代码库" class="headerlink" title="一、新建代码库"></a>一、新建代码库</h2><h5 id="在当前目录新建一个Git代码库"><a href="#在当前目录新建一个Git代码库" class="headerlink" title="在当前目录新建一个Git代码库"></a>在当前目录新建一个Git代码库</h5><pre><code>$ git init</code></pre><h5 id="新建一个目录，将其初始化为Git代码库"><a href="#新建一个目录，将其初始化为Git代码库" class="headerlink" title="新建一个目录，将其初始化为Git代码库"></a>新建一个目录，将其初始化为Git代码库</h5><pre><code>$ git init [project-name]</code></pre><h5 id="下载一个项目和它的整个代码历史"><a href="#下载一个项目和它的整个代码历史" class="headerlink" title="下载一个项目和它的整个代码历史"></a>下载一个项目和它的整个代码历史</h5><pre><code>$ git clone [url]</code></pre><h2 id="二、配置"><a href="#二、配置" class="headerlink" title="二、配置"></a>二、配置</h2><p>Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。</p><h5 id="显示当前的Git配置"><a href="#显示当前的Git配置" class="headerlink" title="显示当前的Git配置"></a>显示当前的Git配置</h5><pre><code>$ git config --list</code></pre><h5 id="编辑Git配置文件"><a href="#编辑Git配置文件" class="headerlink" title="编辑Git配置文件"></a>编辑Git配置文件</h5><pre><code>$ git config -e [--global]</code></pre><h5 id="设置提交代码时的用户信息"><a href="#设置提交代码时的用户信息" class="headerlink" title="设置提交代码时的用户信息"></a>设置提交代码时的用户信息</h5><pre><code>$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot;</code></pre><h2 id="三、增加-删除文件"><a href="#三、增加-删除文件" class="headerlink" title="三、增加/删除文件"></a>三、增加/删除文件</h2><h5 id="添加指定文件到暂存区"><a href="#添加指定文件到暂存区" class="headerlink" title="添加指定文件到暂存区"></a>添加指定文件到暂存区</h5><pre><code>$ git add [file1] [file2] ...</code></pre><h5 id="添加指定目录到暂存区，包括子目录"><a href="#添加指定目录到暂存区，包括子目录" class="headerlink" title="添加指定目录到暂存区，包括子目录"></a>添加指定目录到暂存区，包括子目录</h5><pre><code>$ git add [dir]</code></pre><h5 id="添加当前目录的所有文件到暂存区"><a href="#添加当前目录的所有文件到暂存区" class="headerlink" title="添加当前目录的所有文件到暂存区"></a>添加当前目录的所有文件到暂存区</h5><pre><code>$ git add .</code></pre><h5 id="添加每个变化前，都会要求确认"><a href="#添加每个变化前，都会要求确认" class="headerlink" title="添加每个变化前，都会要求确认"></a>添加每个变化前，都会要求确认</h5><h5 id="对于同一个文件的多处变化，可以实现分次提交"><a href="#对于同一个文件的多处变化，可以实现分次提交" class="headerlink" title="对于同一个文件的多处变化，可以实现分次提交"></a>对于同一个文件的多处变化，可以实现分次提交</h5><pre><code>$ git add -p</code></pre><h5 id="删除工作区文件，并且将这次删除放入暂存区"><a href="#删除工作区文件，并且将这次删除放入暂存区" class="headerlink" title="删除工作区文件，并且将这次删除放入暂存区"></a>删除工作区文件，并且将这次删除放入暂存区</h5><pre><code>$ git rm [file1] [file2] ...</code></pre><h5 id="停止追踪指定文件，但该文件会保留在工作区"><a href="#停止追踪指定文件，但该文件会保留在工作区" class="headerlink" title="停止追踪指定文件，但该文件会保留在工作区"></a>停止追踪指定文件，但该文件会保留在工作区</h5><pre><code>$ git rm --cached [file]</code></pre><h5 id="改名文件，并且将这个改名放入暂存区"><a href="#改名文件，并且将这个改名放入暂存区" class="headerlink" title="改名文件，并且将这个改名放入暂存区"></a>改名文件，并且将这个改名放入暂存区</h5><pre><code>$ git mv [file-original] [file-renamed]</code></pre><h2 id="四、代码提交"><a href="#四、代码提交" class="headerlink" title="四、代码提交"></a>四、代码提交</h2><h5 id="提交暂存区到仓库区"><a href="#提交暂存区到仓库区" class="headerlink" title="提交暂存区到仓库区"></a>提交暂存区到仓库区</h5><pre><code>$ git commit -m [message]</code></pre><h5 id="提交暂存区的指定文件到仓库区"><a href="#提交暂存区的指定文件到仓库区" class="headerlink" title="提交暂存区的指定文件到仓库区"></a>提交暂存区的指定文件到仓库区</h5><pre><code>$ git commit [file1] [file2] ... -m [message]</code></pre><h5 id="提交工作区自上次commit之后的变化，直接到仓库区"><a href="#提交工作区自上次commit之后的变化，直接到仓库区" class="headerlink" title="提交工作区自上次commit之后的变化，直接到仓库区"></a>提交工作区自上次commit之后的变化，直接到仓库区</h5><pre><code>$ git commit -a</code></pre><h5 id="提交时显示所有diff信息"><a href="#提交时显示所有diff信息" class="headerlink" title="提交时显示所有diff信息"></a>提交时显示所有diff信息</h5><pre><code>$ git commit -v</code></pre><h5 id="使用一次新的commit，替代上一次提交"><a href="#使用一次新的commit，替代上一次提交" class="headerlink" title="使用一次新的commit，替代上一次提交"></a>使用一次新的commit，替代上一次提交</h5><h5 id="如果代码没有任何新变化，则用来改写上一次commit的提交信息"><a href="#如果代码没有任何新变化，则用来改写上一次commit的提交信息" class="headerlink" title="如果代码没有任何新变化，则用来改写上一次commit的提交信息"></a>如果代码没有任何新变化，则用来改写上一次commit的提交信息</h5><pre><code>$ git commit --amend -m [message]</code></pre><h5 id="重做上一次commit，并包括指定文件的新变化"><a href="#重做上一次commit，并包括指定文件的新变化" class="headerlink" title="重做上一次commit，并包括指定文件的新变化"></a>重做上一次commit，并包括指定文件的新变化</h5><pre><code>$ git commit --amend [file1] [file2] ...</code></pre><h2 id="五、分支"><a href="#五、分支" class="headerlink" title="五、分支"></a>五、分支</h2><h5 id="列出所有本地分支"><a href="#列出所有本地分支" class="headerlink" title="列出所有本地分支"></a>列出所有本地分支</h5><pre><code>$ git branch</code></pre><h5 id="列出所有远程分支"><a href="#列出所有远程分支" class="headerlink" title="列出所有远程分支"></a>列出所有远程分支</h5><pre><code>$ git branch -r</code></pre><h5 id="列出所有本地分支和远程分支"><a href="#列出所有本地分支和远程分支" class="headerlink" title="列出所有本地分支和远程分支"></a>列出所有本地分支和远程分支</h5><pre><code>$ git branch -a</code></pre><h5 id="新建一个分支，但依然停留在当前分支"><a href="#新建一个分支，但依然停留在当前分支" class="headerlink" title="新建一个分支，但依然停留在当前分支"></a>新建一个分支，但依然停留在当前分支</h5><pre><code>$ git branch [branch-name]</code></pre><h5 id="新建一个分支，并切换到该分支"><a href="#新建一个分支，并切换到该分支" class="headerlink" title="新建一个分支，并切换到该分支"></a>新建一个分支，并切换到该分支</h5><pre><code>$ git checkout -b [branch]</code></pre><h5 id="新建一个分支，指向指定commit"><a href="#新建一个分支，指向指定commit" class="headerlink" title="新建一个分支，指向指定commit"></a>新建一个分支，指向指定commit</h5><pre><code>$ git branch [branch] [commit]</code></pre><h5 id="新建一个分支，与指定的远程分支建立追踪关系"><a href="#新建一个分支，与指定的远程分支建立追踪关系" class="headerlink" title="新建一个分支，与指定的远程分支建立追踪关系"></a>新建一个分支，与指定的远程分支建立追踪关系</h5><pre><code>$ git branch --track [branch] [remote-branch]</code></pre><h5 id="切换到指定分支，并更新工作区"><a href="#切换到指定分支，并更新工作区" class="headerlink" title="切换到指定分支，并更新工作区"></a>切换到指定分支，并更新工作区</h5><pre><code>$ git checkout [branch-name]</code></pre><h5 id="切换到上一个分支"><a href="#切换到上一个分支" class="headerlink" title="切换到上一个分支"></a>切换到上一个分支</h5><pre><code>$ git checkout -</code></pre><h5 id="建立追踪关系，在现有分支与指定的远程分支之间"><a href="#建立追踪关系，在现有分支与指定的远程分支之间" class="headerlink" title="建立追踪关系，在现有分支与指定的远程分支之间"></a>建立追踪关系，在现有分支与指定的远程分支之间</h5><pre><code>$ git branch --set-upstream [branch] [remote-branch]</code></pre><h5 id="合并指定分支到当前分支"><a href="#合并指定分支到当前分支" class="headerlink" title="合并指定分支到当前分支"></a>合并指定分支到当前分支</h5><pre><code>$ git merge [branch]</code></pre><h5 id="选择一个commit，合并进当前分支"><a href="#选择一个commit，合并进当前分支" class="headerlink" title="选择一个commit，合并进当前分支"></a>选择一个commit，合并进当前分支</h5><pre><code>$ git cherry-pick [commit]</code></pre><h5 id="删除分支"><a href="#删除分支" class="headerlink" title="删除分支"></a>删除分支</h5><pre><code>$ git branch -d [branch-name]</code></pre><h5 id="删除远程分支"><a href="#删除远程分支" class="headerlink" title="删除远程分支"></a>删除远程分支</h5><pre><code>$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]</code></pre><h2 id="六、标签"><a href="#六、标签" class="headerlink" title="六、标签"></a>六、标签</h2><h5 id="列出所有tag"><a href="#列出所有tag" class="headerlink" title="列出所有tag"></a>列出所有tag</h5><pre><code>$ git tag</code></pre><h5 id="新建一个tag在当前commit"><a href="#新建一个tag在当前commit" class="headerlink" title="新建一个tag在当前commit"></a>新建一个tag在当前commit</h5><pre><code>$ git tag [tag]</code></pre><h5 id="新建一个tag在指定commit"><a href="#新建一个tag在指定commit" class="headerlink" title="新建一个tag在指定commit"></a>新建一个tag在指定commit</h5><pre><code>$ git tag [tag] [commit]</code></pre><h5 id="删除本地tag"><a href="#删除本地tag" class="headerlink" title="删除本地tag"></a>删除本地tag</h5><pre><code>$ git tag -d [tag]</code></pre><h5 id="删除远程tag"><a href="#删除远程tag" class="headerlink" title="删除远程tag"></a>删除远程tag</h5><pre><code>$ git push origin :refs/tags/[tagName]</code></pre><h5 id="查看tag信息"><a href="#查看tag信息" class="headerlink" title="查看tag信息"></a>查看tag信息</h5><pre><code>$ git show [tag]</code></pre><h5 id="提交指定tag"><a href="#提交指定tag" class="headerlink" title="提交指定tag"></a>提交指定tag</h5><pre><code>$ git push [remote] [tag]</code></pre><h5 id="提交所有tag"><a href="#提交所有tag" class="headerlink" title="提交所有tag"></a>提交所有tag</h5><pre><code>$ git push [remote] --tags</code></pre><h5 id="新建一个分支，指向某个tag"><a href="#新建一个分支，指向某个tag" class="headerlink" title="新建一个分支，指向某个tag"></a>新建一个分支，指向某个tag</h5><pre><code>$ git checkout -b [branch] [tag]</code></pre><h2 id="七、查看信息"><a href="#七、查看信息" class="headerlink" title="七、查看信息"></a>七、查看信息</h2><h5 id="显示有变更的文件"><a href="#显示有变更的文件" class="headerlink" title="显示有变更的文件"></a>显示有变更的文件</h5><pre><code>$ git status</code></pre><h5 id="显示当前分支的版本历史"><a href="#显示当前分支的版本历史" class="headerlink" title="显示当前分支的版本历史"></a>显示当前分支的版本历史</h5><pre><code>$ git log</code></pre><h5 id="显示commit历史，以及每次commit发生变更的文件"><a href="#显示commit历史，以及每次commit发生变更的文件" class="headerlink" title="显示commit历史，以及每次commit发生变更的文件"></a>显示commit历史，以及每次commit发生变更的文件</h5><pre><code>$ git log --stat</code></pre><h5 id="搜索提交历史，根据关键词"><a href="#搜索提交历史，根据关键词" class="headerlink" title="搜索提交历史，根据关键词"></a>搜索提交历史，根据关键词</h5><pre><code>$ git log -S [keyword]</code></pre><h5 id="显示某个commit之后的所有变动，每个commit占据一行"><a href="#显示某个commit之后的所有变动，每个commit占据一行" class="headerlink" title="显示某个commit之后的所有变动，每个commit占据一行"></a>显示某个commit之后的所有变动，每个commit占据一行</h5><pre><code>$ git log [tag] HEAD --pretty=format:%s</code></pre><h5 id="显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件"><a href="#显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件" class="headerlink" title="显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件"></a>显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件</h5><pre><code>$ git log [tag] HEAD --grep feature</code></pre><h5 id="显示某个文件的版本历史，包括文件改名"><a href="#显示某个文件的版本历史，包括文件改名" class="headerlink" title="显示某个文件的版本历史，包括文件改名"></a>显示某个文件的版本历史，包括文件改名</h5><pre><code>$ git log --follow [file]$ git whatchanged [file]</code></pre><h5 id="显示指定文件相关的每一次diff"><a href="#显示指定文件相关的每一次diff" class="headerlink" title="显示指定文件相关的每一次diff"></a>显示指定文件相关的每一次diff</h5><pre><code>$ git log -p [file]</code></pre><h5 id="显示过去5次提交"><a href="#显示过去5次提交" class="headerlink" title="显示过去5次提交"></a>显示过去5次提交</h5><pre><code>$ git log -5 --pretty --oneline</code></pre><h5 id="显示所有提交过的用户，按提交次数排序"><a href="#显示所有提交过的用户，按提交次数排序" class="headerlink" title="显示所有提交过的用户，按提交次数排序"></a>显示所有提交过的用户，按提交次数排序</h5><pre><code>$ git shortlog -sn</code></pre><h5 id="显示指定文件是什么人在什么时间修改过"><a href="#显示指定文件是什么人在什么时间修改过" class="headerlink" title="显示指定文件是什么人在什么时间修改过"></a>显示指定文件是什么人在什么时间修改过</h5><pre><code>$ git blame [file]</code></pre><h5 id="显示暂存区和工作区的差异"><a href="#显示暂存区和工作区的差异" class="headerlink" title="显示暂存区和工作区的差异"></a>显示暂存区和工作区的差异</h5><pre><code>$ git diff</code></pre><h5 id="显示暂存区和上一个commit的差异"><a href="#显示暂存区和上一个commit的差异" class="headerlink" title="显示暂存区和上一个commit的差异"></a>显示暂存区和上一个commit的差异</h5><pre><code>$ git diff --cached [file]</code></pre><h5 id="显示工作区与当前分支最新commit之间的差异"><a href="#显示工作区与当前分支最新commit之间的差异" class="headerlink" title="显示工作区与当前分支最新commit之间的差异"></a>显示工作区与当前分支最新commit之间的差异</h5><pre><code>$ git diff HEAD</code></pre><h5 id="显示两次提交之间的差异"><a href="#显示两次提交之间的差异" class="headerlink" title="显示两次提交之间的差异"></a>显示两次提交之间的差异</h5><pre><code>$ git diff [first-branch]...[second-branch]</code></pre><h5 id="显示今天你写了多少行代码"><a href="#显示今天你写了多少行代码" class="headerlink" title="显示今天你写了多少行代码"></a>显示今天你写了多少行代码</h5><pre><code>$ git diff --shortstat &quot;@{0 day ago}&quot;</code></pre><h5 id="显示某次提交的元数据和内容变化"><a href="#显示某次提交的元数据和内容变化" class="headerlink" title="显示某次提交的元数据和内容变化"></a>显示某次提交的元数据和内容变化</h5><pre><code>$ git show [commit]</code></pre><h5 id="显示某次提交发生变化的文件"><a href="#显示某次提交发生变化的文件" class="headerlink" title="显示某次提交发生变化的文件"></a>显示某次提交发生变化的文件</h5><pre><code>$ git show --name-only [commit]</code></pre><h5 id="显示某次提交时，某个文件的内容"><a href="#显示某次提交时，某个文件的内容" class="headerlink" title="显示某次提交时，某个文件的内容"></a>显示某次提交时，某个文件的内容</h5><pre><code>$ git show [commit]:[filename]</code></pre><h5 id="显示当前分支的最近几次提交"><a href="#显示当前分支的最近几次提交" class="headerlink" title="显示当前分支的最近几次提交"></a>显示当前分支的最近几次提交</h5><pre><code>$ git reflog</code></pre><h2 id="八、远程同步"><a href="#八、远程同步" class="headerlink" title="八、远程同步"></a>八、远程同步</h2><h5 id="下载远程仓库的所有变动"><a href="#下载远程仓库的所有变动" class="headerlink" title="下载远程仓库的所有变动"></a>下载远程仓库的所有变动</h5><pre><code>$ git fetch [remote]</code></pre><h5 id="显示所有远程仓库"><a href="#显示所有远程仓库" class="headerlink" title="显示所有远程仓库"></a>显示所有远程仓库</h5><pre><code>$ git remote -v</code></pre><h5 id="显示某个远程仓库的信息"><a href="#显示某个远程仓库的信息" class="headerlink" title="显示某个远程仓库的信息"></a>显示某个远程仓库的信息</h5><pre><code>$ git remote show [remote]</code></pre><h5 id="增加一个新的远程仓库，并命名"><a href="#增加一个新的远程仓库，并命名" class="headerlink" title="增加一个新的远程仓库，并命名"></a>增加一个新的远程仓库，并命名</h5><pre><code>$ git remote add [shortname] [url]</code></pre><h5 id="取回远程仓库的变化，并与本地分支合并"><a href="#取回远程仓库的变化，并与本地分支合并" class="headerlink" title="取回远程仓库的变化，并与本地分支合并"></a>取回远程仓库的变化，并与本地分支合并</h5><pre><code>$ git pull [remote] [branch]</code></pre><h5 id="上传本地指定分支到远程仓库"><a href="#上传本地指定分支到远程仓库" class="headerlink" title="上传本地指定分支到远程仓库"></a>上传本地指定分支到远程仓库</h5><pre><code>$ git push [remote] [branch]</code></pre><h5 id="强行推送当前分支到远程仓库，即使有冲突"><a href="#强行推送当前分支到远程仓库，即使有冲突" class="headerlink" title="强行推送当前分支到远程仓库，即使有冲突"></a>强行推送当前分支到远程仓库，即使有冲突</h5><pre><code>$ git push [remote] --force</code></pre><h5 id="推送所有分支到远程仓库"><a href="#推送所有分支到远程仓库" class="headerlink" title="推送所有分支到远程仓库"></a>推送所有分支到远程仓库</h5><pre><code>$ git push [remote] --all</code></pre><h2 id="九、撤销"><a href="#九、撤销" class="headerlink" title="九、撤销"></a>九、撤销</h2><h5 id="恢复暂存区的指定文件到工作区"><a href="#恢复暂存区的指定文件到工作区" class="headerlink" title="恢复暂存区的指定文件到工作区"></a>恢复暂存区的指定文件到工作区</h5><pre><code>$ git checkout [file]</code></pre><h5 id="恢复某个commit的指定文件到暂存区和工作区"><a href="#恢复某个commit的指定文件到暂存区和工作区" class="headerlink" title="恢复某个commit的指定文件到暂存区和工作区"></a>恢复某个commit的指定文件到暂存区和工作区</h5><pre><code>$ git checkout [commit] [file]</code></pre><h5 id="恢复暂存区的所有文件到工作区"><a href="#恢复暂存区的所有文件到工作区" class="headerlink" title="恢复暂存区的所有文件到工作区"></a>恢复暂存区的所有文件到工作区</h5><pre><code>$ git checkout .</code></pre><h5 id="重置暂存区的指定文件，与上一次commit保持一致，但工作区不变"><a href="#重置暂存区的指定文件，与上一次commit保持一致，但工作区不变" class="headerlink" title="重置暂存区的指定文件，与上一次commit保持一致，但工作区不变"></a>重置暂存区的指定文件，与上一次commit保持一致，但工作区不变</h5><pre><code>$ git reset [file]</code></pre><h5 id="重置暂存区与工作区，与上一次commit保持一致"><a href="#重置暂存区与工作区，与上一次commit保持一致" class="headerlink" title="重置暂存区与工作区，与上一次commit保持一致"></a>重置暂存区与工作区，与上一次commit保持一致</h5><pre><code>$ git reset --hard</code></pre><h5 id="重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变"><a href="#重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变" class="headerlink" title="重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变"></a>重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变</h5><pre><code>$ git reset [commit]</code></pre><h5 id="重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致"><a href="#重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致" class="headerlink" title="重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致"></a>重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致</h5><pre><code>$ git reset --hard [commit]</code></pre><h5 id="重置当前HEAD为指定commit，但保持暂存区和工作区不变"><a href="#重置当前HEAD为指定commit，但保持暂存区和工作区不变" class="headerlink" title="重置当前HEAD为指定commit，但保持暂存区和工作区不变"></a>重置当前HEAD为指定commit，但保持暂存区和工作区不变</h5><pre><code>$ git reset --keep [commit]</code></pre><h5 id="新建一个commit，用来撤销指定commit"><a href="#新建一个commit，用来撤销指定commit" class="headerlink" title="新建一个commit，用来撤销指定commit"></a>新建一个commit，用来撤销指定commit</h5><h5 id="后者的所有变化都将被前者抵消，并且应用到当前分支"><a href="#后者的所有变化都将被前者抵消，并且应用到当前分支" class="headerlink" title="后者的所有变化都将被前者抵消，并且应用到当前分支"></a>后者的所有变化都将被前者抵消，并且应用到当前分支</h5><pre><code>$ git revert [commit]</code></pre><h5 id="暂时将未提交的变化移除，稍后再移入"><a href="#暂时将未提交的变化移除，稍后再移入" class="headerlink" title="暂时将未提交的变化移除，稍后再移入"></a>暂时将未提交的变化移除，稍后再移入</h5><pre><code>$ git stash$ git stash pop</code></pre><h5 id="放弃本地修改强制更新-git-fetch-只是下载远程的库的内容，不做任何的合并-git-reset-把HEAD指向刚刚下载的最新的版本"><a href="#放弃本地修改强制更新-git-fetch-只是下载远程的库的内容，不做任何的合并-git-reset-把HEAD指向刚刚下载的最新的版本" class="headerlink" title="放弃本地修改强制更新(git fetch 只是下载远程的库的内容，不做任何的合并 git reset 把HEAD指向刚刚下载的最新的版本)"></a>放弃本地修改强制更新(git fetch 只是下载远程的库的内容，不做任何的合并 git reset 把HEAD指向刚刚下载的最新的版本)</h5><pre><code>$ git fetch --all$ git reset --hard origin/master </code></pre><h2 id="十、其他"><a href="#十、其他" class="headerlink" title="十、其他"></a>十、其他</h2><h5 id="生成一个可供发布的压缩包"><a href="#生成一个可供发布的压缩包" class="headerlink" title="生成一个可供发布的压缩包"></a>生成一个可供发布的压缩包</h5><pre><code>$ git archive</code></pre>]]></content>
      
      <categories>
          
          <category> Git命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git命令 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Git 常用命令整理</title>
      <link href="/2017/05/03/Git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2017/05/03/Git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>全局配置用户名称、邮箱<br>git config –global user.name ‘xxx’<br>git config –global user.email ‘xxx’</p><p>git init# 初始化Git仓库<br>git add &lt;hello.txt&gt;  # 把所有要提交的文件修改放到暂存区<br>git commit -m ‘add a file’ # 把暂存区的所有内容提交到当前分支<br>git status #掌握工作区状态<br>git diff #查看文件修改内容<br>git log #查看提交历史<br>git log –pretty=oneline  </p><p>git reset –hard HEAD^ #回退到上一个版本<br>HEAD^^(上上版本),HEAD~100(往上100个版本)<br>commit id(版本号) 可回到指定版本<br>git reflog #查看历史命令<br>工作区（Working Directory）<br>版本库（Repository） #.git<br>    stage(index) 暂存区<br>    master Git自动创建的分支<br>    HEAD 指针<br>git diff HEAD – <file> #查看工作区和版本库里最新版本的区别<br>git checkout – <file> #用版本库的版本替换工作区的版本，无论是工作区的修改还是删除，都可以’一键还原’  </file></file></p><pre><code>#丢弃工作区的修改（让文件回到最近一次的git commit或git add时的状态）  </code></pre><p>git reset HEAD <file> #把暂存区的修改撤销掉，重新放回工作区。<br>git rm <file> #删除文件，若文件已提交到版本库，不用担心误删，但是只能恢复文件到最新版本  </file></file></p><p>ssh-keygen -t rsa -C <a href="mailto:&#39;user@example.com" target="_blank" rel="noopener">&#39;user@example.com</a>‘ #创建SSH Key<br>git remote add origin <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:username/repostery.git #关联本地仓库，远程库的名字为origin  </p><pre><code>#第一次使用Git的clone或者push命令连接GitHub时需确认  </code></pre><p>git push -u origin master   #第一次把当前分支master推送到远程，-u参数不但推送，而且将本地的分支和远程的分支关联起来<br>git push origin master #把当前分支master推送到远程<br>git clone <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:username/repostery.git #从远程库克隆一个到本地库  </p><pre><code>#git支持多种协议，包括https，但通过试试支持原生git协议速度最快  </code></pre><p>分支<br>git checkout -b dev #创建并切换分支  </p><pre><code>#相当于git branch dev 和git checkout dev   </code></pre><p>git branch #查看当前分支，当前分支前有个*号<br>git branch <name> #创建分支<br>git checkout <name> #切换分支<br>git merge <name> #合并某个分支到当前分支<br>git branch -d <name> #删除分支<br>git log –graph #查看分支合并图<br>git merge –no-ff -m ‘message’ dev #禁用Fast forward合并dev分支  </name></name></name></name></p><pre><code>#本次合并要创建新的commit，所以要加上-m参数，把commit描述写进去  #Fast forward合并不可查看合并记录  </code></pre><p>git stash #隐藏当前工作现场，等恢复后继续工作<br>git stash list #查看stash记录<br>git stash apply #仅恢复现场，不删除stash内容<br>git stash drop #删除stash内容<br>git stash pop #恢复现场的同时删除stash内容<br>git branch -D <name> #强行删除某个未合并的分支  </name></p><pre><code>#开发新feature最好新建一个分支  </code></pre><p>git remote #查看远程仓库<br>git remote -v #查看远程库详细信息  </p><p>git pull #抓取远程提交<br>git checkout -b branch-name origin/branch-name #在本地创建和远程分支对应的分支<br>git branch –set-upstream branch-name origin/branch-name #建立本地分支和远程分支的关联  </p><p>标签<br>git tag v1.0 #给当前分支最新的commit打标签<br>git tag v0.9 36df530 #给历史提交的commit打标签<br>git tag -a v0.1 -m ‘version 0.1 released’ 3628164 #-a指定标签名，-m指定说明文字<br>git tag -s <tagname> -m ‘blabla’ #可以用PGP签名标签<br>git tag #查看所有标签<br>git show v1.0 #查看标签信息<br>git tag -d v0.1 #删除标签<br>git push origin <tagname> #推送某个标签到远程<br>git push origin –tags #推送所有尚未推送的本地标签  </tagname></tagname></p><p>删除远程标签<br>git tag -d v0.2 #先删除本地标签<br>git push origin :refs/tags/v0.2 #删除远程标签    </p><p>自定义git<br>git config –global color.ui true<br>编写.gitignore文件来忽略某些文件，此文件本身要放到版本库内，并可对其做版本管理<br>git add -f hello.pyc #-f参数强制添加到Git<br>git check-ignore -v hello.pyc　＃检查.gitignore文件的规则<br>简写命令<br>git config –global alias.co checkout #简写checkout命令<br>git config –global alias.st status<br>git config –global alias.ci commit<br>git config –global alias.br branch<br>git config –global alias.unstage ‘reset HEAD’ #撤销暂存区的修改<br>git config –global alias.last ‘log -1’ #查看最近一次的提交<br>git config –global alias.lg “log –color –graph –pretty=format:’%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit”<br>配置文件<br>–global参数时针对当前用户起作用，如果不加，仅针对当前仓库起作用<br>每个仓库的Git配置文件在 .git/config 文件中<br>当前用户的Git配置文件在用户主目录下的 .gitconfig 文件中  </p><p>搭建Git服务器<br>1、安装git sudo apt install git<br>2、创建git用户 sudo adduser git<br>3、创建证书登录，将所有需要登录的用户的公钥导入到/home/git/.ssh/authorized_keys文件，每行一个<br>4、初始化Git仓库<br>    在仓库目录下输入命令 sudo git init –bare sample.git 创建裸仓库（没有工作区）<br>    把owner改为git sudo chown -R git:git sample.git<br>5、禁用shell登录，修改/etc/passwd文件<br>    git:x:1001:1001:,,,:/home/git:/bin/bash<br>    改为：<br>    git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell  </p><p>6、克隆远程仓库<br>git clone git@server:/srv/sample.git  </p><p>附：<br><a href="http://op7wplti1.bkt.clouddn.com/atlassian_git_cheatsheet.pdf" target="_blank" rel="noopener">Git备忘录1</a><br><a href="http://op7wplti1.bkt.clouddn.com/github-git-cheat-sheet.pdf" target="_blank" rel="noopener">Git备忘录2</a></p>]]></content>
      
      <categories>
          
          <category> Git命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git命令 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：Callable、Future和FutureTask</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACallable%E3%80%81Future%E5%92%8CFutureTask/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACallable%E3%80%81Future%E5%92%8CFutureTask/</url>
      <content type="html"><![CDATA[<a id="more"></a><p>在前面的文章中我们讲述了创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。</p><p>　　这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。</p><p>　　如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。</p><p>　　而自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。</p><p>　　今天我们就来讨论一下Callable、Future和FutureTask三个类的使用方法。以下是本文的目录大纲：</p><p>　　一.Callable与Runnable</p><p>　　二.Future</p><p>　　三.FutureTask</p><p>　　四.使用示例</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3949310.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3949310.html</a></p><p>　　</p><h2 id="一-Callable与Runnable"><a href="#一-Callable与Runnable" class="headerlink" title="一.Callable与Runnable"></a>一.Callable与Runnable</h2><p>　　先说一下java.lang.Runnable吧，它是一个接口，在它里面只声明了一个run()方法：  </p><pre><code>public interface Runnable {    public abstract void run();}  </code></pre><p> 　　由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。</p><p>　　Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()：  </p><pre><code>public interface Callable&lt;V&gt; {    /**     * Computes a result, or throws an exception if unable to do so.     *     * @return computed result     * @throws Exception if unable to compute a result     */    V call() throws Exception;}  </code></pre><p> 　　可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。</p><p>　　那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：  </p><pre><code>&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task);  </code></pre><p>　　第一个submit方法里面的参数类型就是Callable。</p><p>　　暂时只需要知道Callable一般是和ExecutorService配合来使用的，具体的使用方法讲在后面讲述。</p><p>　　一般情况下我们使用第一个submit方法和第三个submit方法，第二个submit方法很少使用。</p><h2 id="二-Future"><a href="#二-Future" class="headerlink" title="二.Future"></a>二.Future</h2><p>　　Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。</p><p>　　Future类位于java.util.concurrent包下，它是一个接口：  </p><pre><code>public interface Future&lt;V&gt; {    boolean cancel(boolean mayInterruptIfRunning);    boolean isCancelled();    boolean isDone();    V get() throws InterruptedException, ExecutionException;    V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;}  </code></pre><p> 　　在Future接口中声明了5个方法，下面依次解释每个方法的作用：</p><ul><li>cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。</li><li>isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。</li><li>isDone方法表示任务是否已经完成，若任务完成，则返回true；</li><li>get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回；</li><li>get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。<br>　　也就是说Future提供了三种功能：</li></ul><p>　　1）判断任务是否完成；</p><p>　　2）能够中断任务；</p><p>　　3）能够获取任务执行结果。</p><p>　　因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。</p><h2 id="三-FutureTask"><a href="#三-FutureTask" class="headerlink" title="三.FutureTask"></a>三.FutureTask</h2><p>　　我们先来看一下FutureTask的实现：  </p><pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;</code></pre><p> 　　FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现：  </p><pre><code>public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; {    void run();}  </code></pre><p> 　　可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。</p><p>　　FutureTask提供了2个构造器：  </p><pre><code>public FutureTask(Callable&lt;V&gt; callable) {}public FutureTask(Runnable runnable, V result) {}  </code></pre><p>　　事实上，FutureTask是Future接口的一个唯一实现类。</p><h2 id="四-使用示例"><a href="#四-使用示例" class="headerlink" title="四.使用示例"></a>四.使用示例</h2><p>　　1.使用Callable+Future获取执行结果  </p><pre><code>public class Test {    public static void main(String[] args) {        ExecutorService executor = Executors.newCachedThreadPool();        Task task = new Task();        Future&lt;Integer&gt; result = executor.submit(task);        executor.shutdown();        try {            Thread.sleep(1000);        } catch (InterruptedException e1) {            e1.printStackTrace();        }        System.out.println(&quot;主线程在执行任务&quot;);        try {            System.out.println(&quot;task运行结果&quot;+result.get());        } catch (InterruptedException e) {            e.printStackTrace();        } catch (ExecutionException e) {            e.printStackTrace();        }        System.out.println(&quot;所有任务执行完毕&quot;);    }}class Task implements Callable&lt;Integer&gt;{    @Override    public Integer call() throws Exception {        System.out.println(&quot;子线程在进行计算&quot;);        Thread.sleep(3000);        int sum = 0;        for(int i=0;i&lt;100;i++)            sum += i;        return sum;    }}  </code></pre><p> 　　执行结果：</p><pre><code>子线程在进行计算主线程在执行任务task运行结果4950所有任务执行完毕  </code></pre><p>　　2.使用Callable+FutureTask获取执行结果  </p><pre><code>public class Test {    public static void main(String[] args) {        //第一种方式        ExecutorService executor = Executors.newCachedThreadPool();        Task task = new Task();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task);        executor.submit(futureTask);        executor.shutdown();        //第二种方式，注意这种方式和第一种方式效果是类似的，只不过一个使用的是ExecutorService，一个使用的是Thread        /*Task task = new Task();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task);        Thread thread = new Thread(futureTask);        thread.start();*/        try {            Thread.sleep(1000);        } catch (InterruptedException e1) {            e1.printStackTrace();        }        System.out.println(&quot;主线程在执行任务&quot;);        try {            System.out.println(&quot;task运行结果&quot;+futureTask.get());        } catch (InterruptedException e) {            e.printStackTrace();        } catch (ExecutionException e) {            e.printStackTrace();        }        System.out.println(&quot;所有任务执行完毕&quot;);    }}class Task implements Callable&lt;Integer&gt;{    @Override    public Integer call() throws Exception {        System.out.println(&quot;子线程在进行计算&quot;);        Thread.sleep(3000);        int sum = 0;        for(int i=0;i&lt;100;i++)            sum += i;        return sum;    }}  </code></pre><p> 　　如果为了可取消性而使用 Future 但又不提供可用的结果，则可以声明 Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果。</p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> Callable </tag>
            
            <tag> Future </tag>
            
            <tag> FutureTask </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：CountDownLatch、CyclicBarrier和Semaphore</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACountDownLatch%E3%80%81CyclicBarrier%E5%92%8CSemaphore/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ACountDownLatch%E3%80%81CyclicBarrier%E5%92%8CSemaphore/</url>
      <content type="html"><![CDATA[<a id="more"></a><p>在java1.5中，提供了一些非常有用的辅助类来帮助我们进行并发编程，比如CountDownLatch，CyclicBarrier和Semaphore，今天我们就来学习一下这三个辅助类的用法。</p><p>　　以下是本文目录大纲：</p><p>　　一.CountDownLatch用法</p><p>　　二.CyclicBarrier用法</p><p>　　三.Semaphore用法</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3920397.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3920397.html</a></p><p>　　</p><h2 id="一-CountDownLatch用法"><a href="#一-CountDownLatch用法" class="headerlink" title="一.CountDownLatch用法"></a>一.CountDownLatch用法</h2><p>　　CountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。</p><p>　　CountDownLatch类只提供了一个构造器：</p><pre><code>public CountDownLatch(int count) {  };  //参数count为计数值   　然后下面这3个方法是CountDownLatch类中最重要的方法：public void await() throws InterruptedException { };   //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public void countDown() { };  //将count值减1  </code></pre><p> 　　下面看一个例子大家就清楚CountDownLatch的用法了：  </p><pre><code>public class Test {     public static void main(String[] args) {            final CountDownLatch latch = new CountDownLatch(2);         new Thread(){             public void run() {                 try {                     System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;);                    Thread.sleep(3000);                    System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;);                    latch.countDown();                } catch (InterruptedException e) {                    e.printStackTrace();                }             };         }.start();         new Thread(){             public void run() {                 try {                     System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;);                     Thread.sleep(3000);                     System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;);                     latch.countDown();                } catch (InterruptedException e) {                    e.printStackTrace();                }             };         }.start();         try {             System.out.println(&quot;等待2个子线程执行完毕...&quot;);            latch.await();            System.out.println(&quot;2个子线程已经执行完毕&quot;);            System.out.println(&quot;继续执行主线程&quot;);        } catch (InterruptedException e) {            e.printStackTrace();        }     }}  </code></pre><p> 　　执行结果：</p><pre><code>线程Thread-0正在执行线程Thread-1正在执行等待2个子线程执行完毕...线程Thread-0执行完毕线程Thread-1执行完毕2个子线程已经执行完毕继续执行主线程</code></pre><h2 id="二-CyclicBarrier用法"><a href="#二-CyclicBarrier用法" class="headerlink" title="二.CyclicBarrier用法"></a>二.CyclicBarrier用法</h2><p>　　字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做barrier，当调用await()方法之后，线程就处于barrier了。</p><p>　　CyclicBarrier类位于java.util.concurrent包下，CyclicBarrier提供2个构造器：  </p><pre><code>public CyclicBarrier(int parties, Runnable barrierAction) {}public CyclicBarrier(int parties) {}  </code></pre><p>　　参数parties指让多少个线程或者任务等待至barrier状态；参数barrierAction为当这些线程都达到barrier状态时会执行的内容。</p><p>　　然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本：  </p><pre><code>public int await() throws InterruptedException, BrokenBarrierException { };public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException { };  </code></pre><p> 　　第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务；</p><p>　　第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。</p><p>　　下面举几个例子就明白了：</p><p>　　假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了：  </p><pre><code>public class Test {    public static void main(String[] args) {        int N = 4;        CyclicBarrier barrier  = new CyclicBarrier(N);        for(int i=0;i&lt;N;i++)            new Writer(barrier).start();    }    static class Writer extends Thread{        private CyclicBarrier cyclicBarrier;        public Writer(CyclicBarrier cyclicBarrier) {            this.cyclicBarrier = cyclicBarrier;        }        @Override        public void run() {            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;正在写入数据...&quot;);            try {                Thread.sleep(5000);      //以睡眠来模拟写入数据操作                System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完毕，等待其他线程写入完毕&quot;);                cyclicBarrier.await();            } catch (InterruptedException e) {                e.printStackTrace();            }catch(BrokenBarrierException e){                e.printStackTrace();            }            System.out.println(&quot;所有线程写入完毕，继续处理其他任务...&quot;);        }    }}  </code></pre><p> 　　执行结果：  </p><pre><code>线程Thread-0正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...  </code></pre><p>　　从上面输出结果可以看出，每个写入线程执行完写数据操作之后，就在等待其他线程写入操作完毕。</p><p>　　当所有线程线程写入操作完毕之后，所有线程就继续进行后续的操作了。</p><p>　　如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数：  </p><pre><code>public class Test {    public static void main(String[] args) {        int N = 4;        CyclicBarrier barrier  = new CyclicBarrier(N,new Runnable() {            @Override            public void run() {                System.out.println(&quot;当前线程&quot;+Thread.currentThread().getName());               }        });        for(int i=0;i&lt;N;i++)            new Writer(barrier).start();    }    static class Writer extends Thread{        private CyclicBarrier cyclicBarrier;        public Writer(CyclicBarrier cyclicBarrier) {            this.cyclicBarrier = cyclicBarrier;        }        @Override        public void run() {            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;正在写入数据...&quot;);            try {                Thread.sleep(5000);      //以睡眠来模拟写入数据操作                System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完毕，等待其他线程写入完毕&quot;);                cyclicBarrier.await();            } catch (InterruptedException e) {                e.printStackTrace();            }catch(BrokenBarrierException e){                e.printStackTrace();            }            System.out.println(&quot;所有线程写入完毕，继续处理其他任务...&quot;);        }    }}  </code></pre><p> 　　运行结果：  </p><pre><code>线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-2正在写入数据...线程Thread-3正在写入数据...线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕当前线程Thread-3所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...所有线程写入完毕，继续处理其他任务...  </code></pre><p>　　从结果可以看出，当四个线程都到达barrier状态后，会从四个线程中选择一个线程去执行Runnable。</p><p> 　　下面看一下为await指定时间的效果：  </p><pre><code>public class Test {    public static void main(String[] args) {        int N = 4;        CyclicBarrier barrier  = new CyclicBarrier(N);        for(int i=0;i&lt;N;i++) {            if(i&lt;N-1)                new Writer(barrier).start();            else {                try {                    Thread.sleep(5000);                } catch (InterruptedException e) {                    e.printStackTrace();                }                new Writer(barrier).start();            }        }    }    static class Writer extends Thread{        private CyclicBarrier cyclicBarrier;        public Writer(CyclicBarrier cyclicBarrier) {            this.cyclicBarrier = cyclicBarrier;        }        @Override        public void run() {            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;正在写入数据...&quot;);            try {                Thread.sleep(5000);      //以睡眠来模拟写入数据操作                System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完毕，等待其他线程写入完毕&quot;);                try {                    cyclicBarrier.await(2000, TimeUnit.MILLISECONDS);                } catch (TimeoutException e) {                    // TODO Auto-generated catch block                    e.printStackTrace();                }            } catch (InterruptedException e) {                e.printStackTrace();            }catch(BrokenBarrierException e){                e.printStackTrace();            }            System.out.println(Thread.currentThread().getName()+&quot;所有线程写入完毕，继续处理其他任务...&quot;);        }    }}  </code></pre><p> 　　执行结果：  </p><pre><code>线程Thread-0正在写入数据...线程Thread-2正在写入数据...线程Thread-1正在写入数据...线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3正在写入数据...java.util.concurrent.TimeoutExceptionThread-1所有线程写入完毕，继续处理其他任务...Thread-0所有线程写入完毕，继续处理其他任务...    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)    at java.util.concurrent.CyclicBarrier.await(Unknown Source)    at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)    at java.util.concurrent.CyclicBarrier.await(Unknown Source)    at com.cxh.test1.Test$Writer.run(Test.java:58)java.util.concurrent.BrokenBarrierException    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)    at java.util.concurrent.CyclicBarrier.await(Unknown Source)    at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-2所有线程写入完毕，继续处理其他任务...java.util.concurrent.BrokenBarrierException线程Thread-3写入数据完毕，等待其他线程写入完毕    at java.util.concurrent.CyclicBarrier.dowait(Unknown Source)    at java.util.concurrent.CyclicBarrier.await(Unknown Source)    at com.cxh.test1.Test$Writer.run(Test.java:58)Thread-3所有线程写入完毕，继续处理其他任务...  </code></pre><p>　　上面的代码在main方法的for循环中，故意让最后一个线程启动延迟，因为在前面三个线程都达到barrier之后，等待了指定的时间发现第四个线程还没有达到barrier，就抛出异常并继续执行后面的任务。</p><p>　　另外CyclicBarrier是可以重用的，看下面这个例子：<br>    public class Test {<br>        public static void main(String[] args) {<br>            int N = 4;<br>            CyclicBarrier barrier  = new CyclicBarrier(N);</p><pre><code>        for(int i=0;i&lt;N;i++) {            new Writer(barrier).start();        }        try {            Thread.sleep(25000);        } catch (InterruptedException e) {            e.printStackTrace();        }        System.out.println(&quot;CyclicBarrier重用&quot;);        for(int i=0;i&lt;N;i++) {            new Writer(barrier).start();        }    }    static class Writer extends Thread{        private CyclicBarrier cyclicBarrier;        public Writer(CyclicBarrier cyclicBarrier) {            this.cyclicBarrier = cyclicBarrier;        }        @Override        public void run() {            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;正在写入数据...&quot;);            try {                Thread.sleep(5000);      //以睡眠来模拟写入数据操作                System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完毕，等待其他线程写入完毕&quot;);                cyclicBarrier.await();            } catch (InterruptedException e) {                e.printStackTrace();            }catch(BrokenBarrierException e){                e.printStackTrace();            }            System.out.println(Thread.currentThread().getName()+&quot;所有线程写入完毕，继续处理其他任务...&quot;);        }    }}  </code></pre><p> 　　执行结果：  </p><pre><code>线程Thread-0正在写入数据...线程Thread-1正在写入数据...线程Thread-3正在写入数据...线程Thread-2正在写入数据...线程Thread-1写入数据完毕，等待其他线程写入完毕线程Thread-3写入数据完毕，等待其他线程写入完毕线程Thread-2写入数据完毕，等待其他线程写入完毕线程Thread-0写入数据完毕，等待其他线程写入完毕Thread-0所有线程写入完毕，继续处理其他任务...Thread-3所有线程写入完毕，继续处理其他任务...Thread-1所有线程写入完毕，继续处理其他任务...Thread-2所有线程写入完毕，继续处理其他任务...CyclicBarrier重用线程Thread-4正在写入数据...线程Thread-5正在写入数据...线程Thread-6正在写入数据...线程Thread-7正在写入数据...线程Thread-7写入数据完毕，等待其他线程写入完毕线程Thread-5写入数据完毕，等待其他线程写入完毕线程Thread-6写入数据完毕，等待其他线程写入完毕线程Thread-4写入数据完毕，等待其他线程写入完毕Thread-4所有线程写入完毕，继续处理其他任务...Thread-5所有线程写入完毕，继续处理其他任务...Thread-6所有线程写入完毕，继续处理其他任务...Thread-7所有线程写入完毕，继续处理其他任务...  </code></pre><p>　　从执行结果可以看出，在初次的4个线程越过barrier状态后，又可以用来进行新一轮的使用。而CountDownLatch无法进行重复使用。</p><h2 id="三-Semaphore用法"><a href="#三-Semaphore用法" class="headerlink" title="三.Semaphore用法"></a>三.Semaphore用法</h2><p>　　Semaphore翻译成字面意思为 信号量，Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。</p><p>　　Semaphore类位于java.util.concurrent包下，它提供了2个构造器：  </p><pre><code>public Semaphore(int permits) {          //参数permits表示许可数目，即同时可以允许多少线程进行访问    sync = new NonfairSync(permits);}public Semaphore(int permits, boolean fair) {    //这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可    sync = (fair)? new FairSync(permits) : new NonfairSync(permits);}  </code></pre><p> 　　下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：  </p><pre><code>public void acquire() throws InterruptedException {  }     //获取一个许可public void acquire(int permits) throws InterruptedException { }    //获取permits个许可public void release() { }          //释放一个许可public void release(int permits) { }    //释放permits个许可  </code></pre><p>　　acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。</p><p>　　release()用来释放许可。注意，在释放许可之前，必须先获获得许可。</p><p>　　这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法：  </p><pre><code>public boolean tryAcquire() { };    //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { };  //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回falsepublic boolean tryAcquire(int permits) { }; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回falsepublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { }; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false  </code></pre><p> 　　另外还可以通过availablePermits()方法得到可用的许可数目。</p><p>　　下面通过一个例子来看一下Semaphore的具体使用：</p><p>　　假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：  </p><pre><code>public class Test {    public static void main(String[] args) {        int N = 8;            //工人数        Semaphore semaphore = new Semaphore(5); //机器数目        for(int i=0;i&lt;N;i++)            new Worker(i,semaphore).start();    }    static class Worker extends Thread{        private int num;        private Semaphore semaphore;        public Worker(int num,Semaphore semaphore){            this.num = num;            this.semaphore = semaphore;        }        @Override        public void run() {            try {                semaphore.acquire();                System.out.println(&quot;工人&quot;+this.num+&quot;占用一个机器在生产...&quot;);                Thread.sleep(2000);                System.out.println(&quot;工人&quot;+this.num+&quot;释放出机器&quot;);                semaphore.release();                       } catch (InterruptedException e) {                e.printStackTrace();            }        }    }}  </code></pre><p>  　　执行结果：  </p><pre><code>工人0占用一个机器在生产...工人1占用一个机器在生产...工人2占用一个机器在生产...工人4占用一个机器在生产...工人5占用一个机器在生产...工人0释放出机器工人2释放出机器工人3占用一个机器在生产...工人7占用一个机器在生产...工人4释放出机器工人5释放出机器工人1释放出机器工人6占用一个机器在生产...工人3释放出机器工人7释放出机器工人6释放出机器</code></pre><p>　　</p><p>　　下面对上面说的三个辅助类进行一个总结：</p><p>　　1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：</p><p>　　　　CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；</p><p>　　　　而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；</p><p>　　　　另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。</p><p>　　2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。</p><blockquote><p>参考资料：</p><p>《Java编程思想》</p><p><a href="http://www.itzhai.com/the-introduction-and-use-of-a-countdownlatch.html" target="_blank" rel="noopener">http://www.itzhai.com/the-introduction-and-use-of-a-countdownlatch.html</a></p><p><a href="http://leaver.me/archives/3220.html" target="_blank" rel="noopener">http://leaver.me/archives/3220.html</a></p><p><a href="http://developer.51cto.com/art/201403/432095.htm" target="_blank" rel="noopener">http://developer.51cto.com/art/201403/432095.htm</a></p><p><a href="http://blog.csdn.net/yanhandle/article/details/9016329" target="_blank" rel="noopener">http://blog.csdn.net/yanhandle/article/details/9016329</a></p><p><a href="http://blog.csdn.net/cutesource/article/details/5780740" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/5780740</a></p><p><a href="http://www.cnblogs.com/whgw/archive/2011/09/29/2195555.html" target="_blank" rel="noopener">http://www.cnblogs.com/whgw/archive/2011/09/29/2195555.html</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> CountDownLatch </tag>
            
            <tag> CyclicBarrier </tag>
            
            <tag> Semaphore </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：线程池的使用</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>在前面的文章中，我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：</p><p>　　如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。</p><p>　　那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？</p><p>　　在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。</p><p>　　以下是本文的目录大纲：</p><p>　　一.Java中的ThreadPoolExecutor类</p><p>　　二.深入剖析线程池实现原理</p><p>　　三.使用示例</p><p>　　四.如何合理配置线程池的大小　</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3932921.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3932921.html</a></p><p>　</p><h2 id="一-Java中的ThreadPoolExecutor类"><a href="#一-Java中的ThreadPoolExecutor类" class="headerlink" title="一.Java中的ThreadPoolExecutor类"></a>一.Java中的ThreadPoolExecutor类</h2><p>　　<strong>java.uitl.concurrent.ThreadPoolExecutor</strong>类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。</p><p>　　在ThreadPoolExecutor类中提供了四个构造方法：</p><pre><code>public class ThreadPoolExecutor extends AbstractExecutorService {    .....    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,            BlockingQueue&lt;Runnable&gt; workQueue);    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,            BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory);    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,            BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler);    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,        BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);    ...}</code></pre><p> 　　从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。</p><p> 　　下面解释下一下构造器中各个参数的含义：</p><p>corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；<br>maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；<br>keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；<br>unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性：</p><pre><code>TimeUnit.DAYS;               //天TimeUnit.HOURS;             //小时TimeUnit.MINUTES;           //分钟TimeUnit.SECONDS;           //秒TimeUnit.MILLISECONDS;      //毫秒TimeUnit.MICROSECONDS;      //微妙TimeUnit.NANOSECONDS;       //纳秒</code></pre><p>workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： </p><pre><code>ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue;  </code></pre><p>　　ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。</p><p>threadFactory：线程工厂，主要用来创建线程；<br>handler：表示当拒绝处理任务时的策略，有以下四种取值：  </p><pre><code>ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务  </code></pre><p> 　　具体参数的配置与线程池的关系将在下一节讲述。</p><p>　　从上面给出的ThreadPoolExecutor类的代码可以知道，ThreadPoolExecutor继承了AbstractExecutorService，我们来看一下AbstractExecutorService的实现：</p><pre><code>public abstract class AbstractExecutorService implements ExecutorService {    protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { };    protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { };    public Future&lt;?&gt; submit(Runnable task) {};    public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { };    public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { };    private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                            boolean timed, long nanos)        throws InterruptedException, ExecutionException, TimeoutException {    };    public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException, ExecutionException {    };    public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                           long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException {    };    public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException {    };    public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                                         long timeout, TimeUnit unit)        throws InterruptedException {    };}  </code></pre><p> 　　AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。</p><p>　　我们接着看ExecutorService接口的实现：</p><pre><code>public interface ExecutorService extends Executor {    void shutdown();    boolean isShutdown();    boolean isTerminated();    boolean awaitTermination(long timeout, TimeUnit unit)        throws InterruptedException;    &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);    &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);    Future&lt;?&gt; submit(Runnable task);    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException;    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                                  long timeout, TimeUnit unit)        throws InterruptedException;    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException, ExecutionException;    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                    long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;}        </code></pre><p> 　　而ExecutorService又是继承了Executor接口，我们看一下Executor接口的实现： </p><pre><code>public interface Executor {    void execute(Runnable command);}  </code></pre><p> 　　到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。</p><p>　　Executor是一个顶层接口，在它里面只声明了一个方法execute(Runnable)，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的；</p><p>　　然后ExecutorService接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等；</p><p>　　抽象类AbstractExecutorService实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法；</p><p>　　然后ThreadPoolExecutor继承了类AbstractExecutorService。</p><p>　　在ThreadPoolExecutor类中有几个非常重要的方法：</p><pre><code>execute()submit()shutdown()shutdownNow()</code></pre><p> 　　execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。</p><p>　　submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果（Future相关内容将在下一篇讲述）。</p><p>　　shutdown()和shutdownNow()是用来关闭线程池的。</p><p>　　还有很多其他的方法：</p><p>　　比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。</p><h2 id="二-深入剖析线程池实现原理"><a href="#二-深入剖析线程池实现原理" class="headerlink" title="二.深入剖析线程池实现原理"></a>二.深入剖析线程池实现原理</h2><p>　　在上一节我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解：</p><p>　　1.线程池状态</p><p>　　2.任务的执行</p><p>　　3.线程池中的线程初始化</p><p>　　4.任务缓存队列及排队策略</p><p>　　5.任务拒绝策略</p><p>　　6.线程池的关闭</p><p>　　7.线程池容量的动态调整</p><p>1.线程池状态</p><p>　　在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态：</p><pre><code>volatile int runState;static final int RUNNING    = 0;static final int SHUTDOWN   = 1;static final int STOP       = 2;static final int TERMINATED = 3;  </code></pre><p> 　　runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性；</p><p>　　下面的几个static final变量表示runState可能的几个取值。</p><p>　　当创建线程池后，初始时，线程池处于RUNNING状态；</p><p>　　如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕；</p><p>　　如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；</p><p>　　当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。</p><p>2.任务的执行</p><p>　　在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量：</p><pre><code>private final BlockingQueue&lt;Runnable&gt; workQueue;              //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock();   //线程池的主要状态锁，对线程池状态（比如线程池大小                                                              //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();  //用来存放工作集private volatile long  keepAliveTime;    //线程存货时间    private volatile boolean allowCoreThreadTimeOut;   //是否允许为核心线程设置存活时间private volatile int   corePoolSize;     //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int   maximumPoolSize;   //线程池最大能容忍的线程数private volatile int   poolSize;       //线程池中当前的线程数private volatile RejectedExecutionHandler handler; //任务拒绝策略private volatile ThreadFactory threadFactory;   //线程工厂，用来创建线程private int largestPoolSize;   //用来记录线程池中曾经出现过的最大线程数private long completedTaskCount;   //用来记录已经执行完毕的任务个数  </code></pre><p> 　　每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。</p><p>　　corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子：</p><p>　　假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。</p><p>　　因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；</p><p>　　当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；</p><p>　　如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；</p><p>　　然后就将任务也分配给这4个临时工人做；</p><p>　　如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。</p><p>　　当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。</p><p>　　这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。</p><p>　　也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。</p><p>　　不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。</p><p>　　largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。</p><p>　　下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。</p><p>　　在ThreadPoolExecutor类中，最核心的任务提交方法是execute()方法，虽然通过submit也可以提交任务，但是实际上submit方法里面最终调用的还是execute()方法，所以我们只需要研究execute()方法的实现原理即可：</p><pre><code>public void execute(Runnable command) {    if (command == null)        throw new NullPointerException();    if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) {        if (runState == RUNNING &amp;&amp; workQueue.offer(command)) {            if (runState != RUNNING || poolSize == 0)                ensureQueuedTaskHandled(command);        }        else if (!addIfUnderMaximumPoolSize(command))            reject(command); // is shutdown or saturated    }}  </code></pre><p> 　　上面的代码可能看起来不是那么容易理解，下面我们一句一句解释：</p><p>　　首先，判断提交的任务command是否为null，若是null，则抛出空指针异常；</p><p>　　接着是这句，这句要好好理解一下：</p><pre><code>if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command))</code></pre><p> 　　由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。</p><p>　　如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行</p><pre><code>addIfUnderCorePoolSize(command)</code></pre><p>　　如果执行完addIfUnderCorePoolSize这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。</p><p>　　如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断：</p><pre><code>if (runState == RUNNING &amp;&amp; workQueue.offer(command))</code></pre><p> 　　如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行：</p><pre><code>addIfUnderMaximumPoolSize(command)  </code></pre><p>　　如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。</p><p>　　回到前面：</p><pre><code>if (runState == RUNNING &amp;&amp; workQueue.offer(command))  </code></pre><p> 　　这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断：</p><pre><code>if (runState != RUNNING || poolSize == 0)  </code></pre><p> 　　这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行：</p><pre><code>ensureQueuedTaskHandled(command)  </code></pre><p> 　　进行应急处理，从名字可以看出是保证 添加到任务缓存队列中的任务得到处理。</p><p>　　我们接着看2个关键方法的实现：addIfUnderCorePoolSize和addIfUnderMaximumPoolSize：</p><pre><code>private boolean addIfUnderCorePoolSize(Runnable firstTask) {    Thread t = null;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try {        if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING)            t = addThread(firstTask);        //创建线程去执行firstTask任务            } finally {        mainLock.unlock();    }    if (t == null)        return false;    t.start();    return true;}</code></pre><p> 　　这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心吃大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，因为有可能在其他线程中调用了shutdown或者shutdownNow方法。然后就是执行</p><pre><code>t = addThread(firstTask);</code></pre><p> 　　这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。</p><p>　　我们来看一下addThread方法的实现：</p><pre><code>private Thread addThread(Runnable firstTask) {    Worker w = new Worker(firstTask);    Thread t = threadFactory.newThread(w);  //创建一个线程，执行任务        if (t != null) {        w.thread = t;            //将创建的线程的引用赋值为w的成员变量                workers.add(w);        int nt = ++poolSize;     //当前线程数加1                if (nt &gt; largestPoolSize)            largestPoolSize = nt;    }    return t;}</code></pre><p> 　　在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。</p><p>　　下面我们看一下Worker类的实现：</p><pre><code>private final class Worker implements Runnable {    private final ReentrantLock runLock = new ReentrantLock();    private Runnable firstTask;    volatile long completedTasks;    Thread thread;    Worker(Runnable firstTask) {        this.firstTask = firstTask;    }    boolean isActive() {        return runLock.isLocked();    }    void interruptIfIdle() {        final ReentrantLock runLock = this.runLock;        if (runLock.tryLock()) {            try {        if (thread != Thread.currentThread())        thread.interrupt();            } finally {                runLock.unlock();            }        }    }    void interruptNow() {        thread.interrupt();    }    private void runTask(Runnable task) {        final ReentrantLock runLock = this.runLock;        runLock.lock();        try {            if (runState &lt; STOP &amp;&amp;                Thread.interrupted() &amp;&amp;                runState &gt;= STOP)            boolean ran = false;            beforeExecute(thread, task);   //beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据            //自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等                        try {                task.run();                ran = true;                afterExecute(task, null);                ++completedTasks;            } catch (RuntimeException ex) {                if (!ran)                    afterExecute(task, ex);                throw ex;            }        } finally {            runLock.unlock();        }    }    public void run() {        try {            Runnable task = firstTask;            firstTask = null;            while (task != null || (task = getTask()) != null) {                runTask(task);                task = null;            }        } finally {            workerDone(this);   //当任务队列中没有任务时，进行清理工作                }    }}  </code></pre><p> 　　它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样：</p><pre><code>Thread t = new Thread(w);  </code></pre><p> 　　相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。</p><p>　　既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了：</p><pre><code>public void run() {    try {        Runnable task = firstTask;        firstTask = null;        while (task != null || (task = getTask()) != null) {            runTask(task);            task = null;        }    } finally {        workerDone(this);    }}</code></pre><p> 　　从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从任务缓存队列里面去取，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现：</p><pre><code>Runnable getTask() {    for (;;) {        try {            int state = runState;            if (state &gt; SHUTDOWN)                return null;            Runnable r;            if (state == SHUTDOWN)  // Help drain queue                r = workQueue.poll();            else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) //如果线程数大于核心池大小或者允许为核心池线程设置空闲时间，                //则通过poll取任务，若等待一定的时间取不到任务，则返回null                r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS);            else                r = workQueue.take();            if (r != null)                return r;            if (workerCanExit()) {    //如果没取到任务，即r为null，则判断当前的worker是否可以退出                if (runState &gt;= SHUTDOWN) // Wake up others                    interruptIdleWorkers();   //中断处于空闲状态的worker                return null;            }            // Else retry        } catch (InterruptedException ie) {            // On interruption, re-check runState        }    }}</code></pre><p> 　　在getTask中，先判断当前线程池状态，如果runState大于SHUTDOWN（即为STOP或者TERMINATED），则直接返回null。</p><p>　　如果runState为SHUTDOWN或者RUNNING，则从任务缓存队列取任务。</p><p>　　如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。</p><p>　　然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现：</p><pre><code>private boolean workerCanExit() {    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    boolean canExit;    //如果runState大于等于STOP，或者任务缓存队列为空了    //或者  允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1    try {        canExit = runState &gt;= STOP ||            workQueue.isEmpty() ||            (allowCoreThreadTimeOut &amp;&amp;             poolSize &gt; Math.max(1, corePoolSize));    } finally {        mainLock.unlock();    }    return canExit;}</code></pre><p> 　　也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现：</p><pre><code>void interruptIdleWorkers() {    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try {        for (Worker w : workers)  //实际上调用的是worker的interruptIfIdle()方法            w.interruptIfIdle();    } finally {        mainLock.unlock();    }}  </code></pre><p> 　　从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中：</p><pre><code>void interruptIfIdle() {    final ReentrantLock runLock = this.runLock;    if (runLock.tryLock()) {    //注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的                                //如果成功获取了锁，说明当前worker处于空闲状态        try {    if (thread != Thread.currentThread())       thread.interrupt();        } finally {            runLock.unlock();        }    }}</code></pre><p>  　　这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。</p><p> 　　我们再看addIfUnderMaximumPoolSize方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的：</p><pre><code>private boolean addIfUnderMaximumPoolSize(Runnable firstTask) {    Thread t = null;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try {        if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING)            t = addThread(firstTask);    } finally {        mainLock.unlock();    }    if (t == null)        return false;    t.start();    return true;}  </code></pre><p> 　　看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。</p><p>　　到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下：</p><p>　　1）首先，要清楚corePoolSize和maximumPoolSize的含义；</p><p>　　2）其次，要知道Worker是用来起到什么作用的；</p><p>　　3）要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点：</p><ul><li>如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务；</li><li>如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；</li><li>如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；</li><li>如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。<br>3.线程池中的线程初始化</li></ul><p>　　默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。</p><p>　　在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到：</p><ul><li>prestartCoreThread()：初始化一个核心线程；</li><li><p>prestartAllCoreThreads()：初始化所有核心线程<br>　　下面是这2个方法的实现：</p><p>  public boolean prestartCoreThread() {</p><pre><code>return addIfUnderCorePoolSize(null); //注意传进去的参数是null</code></pre><p>  }</p><p>  public int prestartAllCoreThreads() {</p><pre><code>int n = 0;while (addIfUnderCorePoolSize(null))//注意传进去的参数是null    ++n;return n;</code></pre><p>  }<br>　　注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的</p><p>r = workQueue.take();<br>　　即等待任务队列中有任务。</p></li></ul><p>4.任务缓存队列及排队策略</p><p>　　在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。</p><p>　　workQueue的类型为BlockingQueue<runnable>，通常可以取下面三种类型：</runnable></p><p>　　1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小；</p><p>　　2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；</p><p>　　3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。</p><p>5.任务拒绝策略</p><p>　　当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：</p><pre><code>ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务  </code></pre><p>6.线程池的关闭</p><p>　　ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中：</p><ul><li>shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务</li><li>shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务<br>7.线程池容量的动态调整</li></ul><p>　　ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()，</p><ul><li>setCorePoolSize：设置核心池大小</li><li>setMaximumPoolSize：设置线程池最大能创建的线程数目大小<br>　　当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。</li></ul><h2 id="三-使用示例"><a href="#三-使用示例" class="headerlink" title="三.使用示例"></a>三.使用示例</h2><p>　　前面我们讨论了关于线程池的实现原理，这一节我们来看一下它的具体使用：</p><pre><code>public class Test {     public static void main(String[] args) {             ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS,                  new ArrayBlockingQueue&lt;Runnable&gt;(5));         for(int i=0;i&lt;15;i++){             MyTask myTask = new MyTask(i);             executor.execute(myTask);             System.out.println(&quot;线程池中线程数目：&quot;+executor.getPoolSize()+&quot;，队列中等待执行的任务数目：&quot;+             executor.getQueue().size()+&quot;，已执行玩别的任务数目：&quot;+executor.getCompletedTaskCount());         }         executor.shutdown();     } }class MyTask implements Runnable {    private int taskNum;    public MyTask(int num) {        this.taskNum = num;    }    @Override    public void run() {        System.out.println(&quot;正在执行task &quot;+taskNum);        try {            Thread.currentThread().sleep(4000);        } catch (InterruptedException e) {            e.printStackTrace();        }        System.out.println(&quot;task &quot;+taskNum+&quot;执行完毕&quot;);    }}</code></pre><p> 　　执行结果：</p><pre><code>正在执行task 0线程池中线程数目：1，队列中等待执行的任务数目：0，已执行玩别的任务数目：0线程池中线程数目：2，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 1线程池中线程数目：3，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 2线程池中线程数目：4，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 3线程池中线程数目：5，队列中等待执行的任务数目：0，已执行玩别的任务数目：0正在执行task 4线程池中线程数目：5，队列中等待执行的任务数目：1，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：2，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：3，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：4，已执行玩别的任务数目：0线程池中线程数目：5，队列中等待执行的任务数目：5，已执行玩别的任务数目：0线程池中线程数目：6，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 10线程池中线程数目：7，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 11线程池中线程数目：8，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 12线程池中线程数目：9，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 13线程池中线程数目：10，队列中等待执行的任务数目：5，已执行玩别的任务数目：0正在执行task 14task 3执行完毕task 0执行完毕task 2执行完毕task 1执行完毕正在执行task 8正在执行task 7正在执行task 6正在执行task 5task 4执行完毕task 10执行完毕task 11执行完毕task 13执行完毕task 12执行完毕正在执行task 9task 14执行完毕task 8执行完毕task 5执行完毕task 7执行完毕task 6执行完毕task 9执行完毕</code></pre><p>　　从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。</p><p>　　不过在javadoc中，并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池：</p><pre><code>Executors.newCachedThreadPool();        //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor();   //创建容量为1的缓冲池Executors.newFixedThreadPool(int);    //创建固定容量大小的缓冲池  </code></pre><p> 　　下面是这三个静态方法的具体实现;</p><pre><code>public static ExecutorService newFixedThreadPool(int nThreads) {    return new ThreadPoolExecutor(nThreads, nThreads,                                  0L, TimeUnit.MILLISECONDS,                                  new LinkedBlockingQueue&lt;Runnable&gt;());}public static ExecutorService newSingleThreadExecutor() {    return new FinalizableDelegatedExecutorService        (new ThreadPoolExecutor(1, 1,                                0L, TimeUnit.MILLISECONDS,                                new LinkedBlockingQueue&lt;Runnable&gt;()));}public static ExecutorService newCachedThreadPool() {    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                  60L, TimeUnit.SECONDS,                                  new SynchronousQueue&lt;Runnable&gt;());}  </code></pre><p>　　从它们的具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好了。</p><p>　　newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue；</p><p>　　newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue；</p><p>　　newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。</p><p>　　实际中，如果Executors提供的三个静态方法能满足要求，就尽量使用它提供的三个方法，因为自己去手动配置ThreadPoolExecutor的参数有点麻烦，要根据实际任务的类型和数量来进行配置。</p><p>　　另外，如果ThreadPoolExecutor达不到要求，可以自己继承ThreadPoolExecutor类进行重写。</p><h2 id="四-如何合理配置线程池的大小"><a href="#四-如何合理配置线程池的大小" class="headerlink" title="四.如何合理配置线程池的大小"></a>四.如何合理配置线程池的大小</h2><p>　　本节来讨论一个比较重要的话题：如何合理配置线程池大小，仅供参考。</p><p>　　一般需要根据任务的类型来配置线程池大小：</p><p>　　如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1</p><p>　　如果是IO密集型任务，参考值可以设置为2*NCPU</p><p>　　当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 </p><blockquote><p>参考资料：</p><p><a href="http://ifeve.com/java-threadpool/" target="_blank" rel="noopener">http://ifeve.com/java-threadpool/</a></p><p><a href="http://blog.163.com/among_1985/blog/static/275005232012618849266/" target="_blank" rel="noopener">http://blog.163.com/among_1985/blog/static/275005232012618849266/</a></p><p><a href="http://developer.51cto.com/art/201203/321885.htm" target="_blank" rel="noopener">http://developer.51cto.com/art/201203/321885.htm</a></p><p><a href="http://blog.csdn.net/java2000_wl/article/details/22097059" target="_blank" rel="noopener">http://blog.csdn.net/java2000_wl/article/details/22097059</a></p><p><a href="http://blog.csdn.net/cutesource/article/details/6061229" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/6061229</a></p><p><a href="http://blog.csdn.net/xieyuooo/article/details/8718741" target="_blank" rel="noopener">http://blog.csdn.net/xieyuooo/article/details/8718741</a></p><p>《JDK API 1.6》</p></blockquote>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> 阻塞队列 </tag>
            
            <tag> Executors </tag>
            
            <tag> ThreadPoolExecutor </tag>
            
            <tag> AbstractExecutorService </tag>
            
            <tag> ExecutorService </tag>
            
            <tag> Executor </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：阻塞队列</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/</url>
      <content type="html"><![CDATA[<p>在前面几篇文章中，我们讨论了同步容器(Hashtable、Vector），也讨论了并发容器（ConcurrentHashMap、CopyOnWriteArrayList），这些工具都为我们编写多线程程序提供了很大的方便。今天我们来讨论另外一类容器：阻塞队列。</p><p>　　在前面我们接触的队列都是非阻塞队列，比如PriorityQueue、LinkedList（LinkedList是双向链表，它实现了Dequeue接口）。</p><p>　　使用非阻塞队列的时候有一个很大问题就是：它不会对当前线程产生阻塞，那么在面对类似消费者-生产者的模型时，就必须额外地实现同步策略以及线程间唤醒策略，这个实现起来就非常麻烦。但是有了阻塞队列就不一样了，它会对当前线程产生阻塞，比如一个线程从一个空的阻塞队列中取元素，此时线程会被阻塞直到阻塞队列中有了元素。当队列中有元素后，被阻塞的线程会自动被唤醒（不需要我们编写代码去唤醒）。这样提供了极大的方便性。</p><p>　　本文先讲述一下java.util.concurrent包下提供主要的几种阻塞队列，然后分析了阻塞队列和非阻塞队列的中的各个方法，接着分析了阻塞队列的实现原理，最后给出了一个实际例子和几个使用场景。</p><p>　　一.几种主要的阻塞队列</p><p>　　二.阻塞队列中的方法 VS 非阻塞队列中的方法</p><p>　　三.阻塞队列的实现原理</p><p>　　四.示例和使用场景</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p> 　　<a href="http://www.cnblogs.com/dolphin0520/p/3932906.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3932906.html</a></p><h2 id="一-几种主要的阻塞队列"><a href="#一-几种主要的阻塞队列" class="headerlink" title="一.几种主要的阻塞队列"></a>一.几种主要的阻塞队列</h2><p>　　自从Java 1.5之后，在java.util.concurrent包下提供了若干个阻塞队列，主要有以下几个：</p><p>　　ArrayBlockingQueue：基于数组实现的一个阻塞队列，在创建ArrayBlockingQueue对象时必须制定容量大小。并且可以指定公平性与非公平性，默认情况下为非公平的，即不保证等待时间最长的队列最优先能够访问队列。</p><p>　　LinkedBlockingQueue：基于链表实现的一个阻塞队列，在创建LinkedBlockingQueue对象时如果不指定容量大小，则默认大小为Integer.MAX_VALUE。</p><p>　　PriorityBlockingQueue：以上2种队列都是先进先出队列，而PriorityBlockingQueue却不是，它会按照元素的优先级对元素进行排序，按照优先级顺序出队，每次出队的元素都是优先级最高的元素。注意，此阻塞队列为无界阻塞队列，即容量没有上限（通过源码就可以知道，它没有容器满的信号标志），前面2种都是有界队列。</p><p>　　DelayQueue：基于PriorityQueue，一种延时阻塞队列，DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue也是一个无界队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。</p><h2 id="二-阻塞队列中的方法-VS-非阻塞队列中的方法"><a href="#二-阻塞队列中的方法-VS-非阻塞队列中的方法" class="headerlink" title="二.阻塞队列中的方法 VS 非阻塞队列中的方法"></a>二.阻塞队列中的方法 VS 非阻塞队列中的方法</h2><p>1.非阻塞队列中的几个主要方法：</p><p>　　add(E e):将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则会抛出异常；</p><p>　　remove()：移除队首元素，若移除成功，则返回true；如果移除失败（队列为空），则会抛出异常；</p><p>　　offer(E e)：将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则返回false；</p><p>　　poll()：移除并获取队首元素，若成功，则返回队首元素；否则返回null；</p><p>　　peek()：获取队首元素，若成功，则返回队首元素；否则返回null</p><p>　　对于非阻塞队列，一般情况下建议使用offer、poll和peek三个方法，不建议使用add和remove方法。因为使用offer、poll和peek三个方法可以通过返回值判断操作成功与否，而使用add和remove方法却不能达到这样的效果。注意，非阻塞队列中的方法都没有进行同步措施。</p><p>2.阻塞队列中的几个主要方法：</p><p>　　阻塞队列包括了非阻塞队列中的大部分方法，上面列举的5个方法在阻塞队列中都存在，但是要注意这5个方法在阻塞队列中都进行了同步措施。除此之外，阻塞队列提供了另外4个非常有用的方法：</p><p>　　put(E e)</p><p>　　take()</p><p>　　offer(E e,long timeout, TimeUnit unit)</p><p>　　poll(long timeout, TimeUnit unit)</p><p>　　</p><p>　　put方法用来向队尾存入元素，如果队列满，则等待；</p><p>　　take方法用来从队首取元素，如果队列为空，则等待；</p><p>　　offer方法用来向队尾存入元素，如果队列满，则等待一定的时间，当时间期限达到时，如果还没有插入成功，则返回false；否则返回true；</p><p>　　poll方法用来从队首取元素，如果队列空，则等待一定的时间，当时间期限达到时，如果取到，则返回null；否则返回取得的元素；</p><h2 id="三-阻塞队列的实现原理"><a href="#三-阻塞队列的实现原理" class="headerlink" title="三.阻塞队列的实现原理"></a>三.阻塞队列的实现原理</h2><p>　　前面谈到了非阻塞队列和阻塞队列中常用的方法，下面来探讨阻塞队列的实现原理，本文以ArrayBlockingQueue为例，其他阻塞队列实现原理可能和ArrayBlockingQueue有一些差别，但是大体思路应该类似，有兴趣的朋友可自行查看其他阻塞队列的实现源码。</p><p>　　首先看一下ArrayBlockingQueue类中的几个成员变量：  </p><pre><code>public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;,java.io.Serializable {    private static final long serialVersionUID = -817911632652898426L;    /** The queued items  */    private final E[] items;    /** items index for next take, poll or remove */    private int takeIndex;    /** items index for next put, offer, or add. */    private int putIndex;    /** Number of items in the queue */    private int count;    /*    * Concurrency control uses the classic two-condition algorithm    * found in any textbook.    */    /** Main lock guarding all access */    private final ReentrantLock lock;    /** Condition for waiting takes */    private final Condition notEmpty;    /** Condition for waiting puts */    private final Condition notFull;}</code></pre><p> 　　可以看出，ArrayBlockingQueue中用来存储元素的实际上是一个数组，takeIndex和putIndex分别表示队首元素和队尾元素的下标，count表示队列中元素的个数。</p><p>　　lock是一个可重入锁，notEmpty和notFull是等待条件。</p><p>　　下面看一下ArrayBlockingQueue的构造器，构造器有三个重载版本：  </p><pre><code>public ArrayBlockingQueue(int capacity) {}public ArrayBlockingQueue(int capacity, boolean fair) {}public ArrayBlockingQueue(int capacity, boolean fair,                          Collection&lt;? extends E&gt; c) {}</code></pre><p> 　　第一个构造器只有一个参数用来指定容量，第二个构造器可以指定容量和公平性，第三个构造器可以指定容量、公平性以及用另外一个集合进行初始化。</p><p>　　然后看它的两个关键方法的实现：put()和take()：  </p><pre><code>public void put(E e) throws InterruptedException {    if (e == null) throw new NullPointerException();    final E[] items = this.items;    final ReentrantLock lock = this.lock;    lock.lockInterruptibly();    try {        try {            while (count == items.length)                notFull.await();        } catch (InterruptedException ie) {            notFull.signal(); // propagate to non-interrupted thread            throw ie;        }        insert(e);    } finally {        lock.unlock();    }}</code></pre><p> 　　从put方法的实现可以看出，它先获取了锁，并且获取的是可中断锁，然后判断当前元素个数是否等于数组的长度，如果相等，则调用notFull.await()进行等待，如果捕获到中断异常，则唤醒线程并抛出异常。</p><p>　　当被其他线程唤醒时，通过insert(e)方法插入元素，最后解锁。</p><p>　　我们看一下insert方法的实现：  </p><pre><code>private void insert(E x) {    items[putIndex] = x;    putIndex = inc(putIndex);    ++count;    notEmpty.signal();}</code></pre><p> 　　它是一个private方法，插入成功后，通过notEmpty唤醒正在等待取元素的线程。</p><p>　　下面是take()方法的实现：  </p><pre><code>public E take() throws InterruptedException {    final ReentrantLock lock = this.lock;    lock.lockInterruptibly();    try {        try {            while (count == 0)                notEmpty.await();        } catch (InterruptedException ie) {            notEmpty.signal(); // propagate to non-interrupted thread            throw ie;        }        E x = extract();        return x;    } finally {        lock.unlock();    }}</code></pre><p> 　　跟put方法实现很类似，只不过put方法等待的是notFull信号，而take方法等待的是notEmpty信号。在take方法中，如果可以取元素，则通过extract方法取得元素，下面是extract方法的实现：  </p><pre><code>private E extract() {    final E[] items = this.items;    E x = items[takeIndex];    items[takeIndex] = null;    takeIndex = inc(takeIndex);    --count;    notFull.signal();    return x;}  </code></pre><p> 　　跟insert方法也很类似。</p><p>　　其实从这里大家应该明白了阻塞队列的实现原理，事实它和我们用Object.wait()、Object.notify()和非阻塞队列实现生产者-消费者的思路类似，只不过它把这些工作一起集成到了阻塞队列中实现。</p><h2 id="四-示例和使用场景"><a href="#四-示例和使用场景" class="headerlink" title="四.示例和使用场景"></a>四.示例和使用场景</h2><p>　　下面先使用Object.wait()和Object.notify()、非阻塞队列实现生产者-消费者模式：  </p><pre><code>public class Test {    private int queueSize = 10;    private PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;(queueSize);    public static void main(String[] args)  {        Test test = new Test();        Producer producer = test.new Producer();        Consumer consumer = test.new Consumer();        producer.start();        consumer.start();    }    class Consumer extends Thread{        @Override        public void run() {            consume();        }        private void consume() {            while(true){                synchronized (queue) {                    while(queue.size() == 0){                        try {                            System.out.println(&quot;队列空，等待数据&quot;);                            queue.wait();                        } catch (InterruptedException e) {                            e.printStackTrace();                            queue.notify();                        }                    }                    queue.poll();          //每次移走队首元素                    queue.notify();                    System.out.println(&quot;从队列取走一个元素，队列剩余&quot;+queue.size()+&quot;个元素&quot;);                }            }        }    }    class Producer extends Thread{        @Override        public void run() {            produce();        }        private void produce() {            while(true){                synchronized (queue) {                    while(queue.size() == queueSize){                        try {                            System.out.println(&quot;队列满，等待有空余空间&quot;);                            queue.wait();                        } catch (InterruptedException e) {                            e.printStackTrace();                            queue.notify();                        }                    }                    queue.offer(1);        //每次插入一个元素                    queue.notify();                    System.out.println(&quot;向队列取中插入一个元素，队列剩余空间：&quot;+(queueSize-queue.size()));                }            }        }    }}</code></pre><p> 　　这个是经典的生产者-消费者模式，通过阻塞队列和Object.wait()和Object.notify()实现，wait()和notify()主要用来实现线程间通信。</p><p>　　具体的线程间通信方式（wait和notify的使用）在后续问章中会讲述到。</p><p>　　下面是使用阻塞队列实现的生产者-消费者模式：  </p><pre><code>public class Test {    private int queueSize = 10;    private ArrayBlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;Integer&gt;(queueSize);    public static void main(String[] args)  {        Test test = new Test();        Producer producer = test.new Producer();        Consumer consumer = test.new Consumer();        producer.start();        consumer.start();    }    class Consumer extends Thread{        @Override        public void run() {            consume();        }        private void consume() {            while(true){                try {                    queue.take();                    System.out.println(&quot;从队列取走一个元素，队列剩余&quot;+queue.size()+&quot;个元素&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }    }    class Producer extends Thread{        @Override        public void run() {            produce();        }        private void produce() {            while(true){                try {                    queue.put(1);                    System.out.println(&quot;向队列取中插入一个元素，队列剩余空间：&quot;+(queueSize-queue.size()));                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }    }}  </code></pre><p> 　　有没有发现，使用阻塞队列代码要简单得多，不需要再单独考虑同步和线程间通信的问题。</p><p>　　在并发编程中，一般推荐使用阻塞队列，这样实现可以尽量地避免程序出现意外的错误。</p><p>　　阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。还有其他类似的场景，只要符合生产者-消费者模型的都可以使用阻塞队列。</p><p>　　参考资料：</p><p>　　《Java编程实战》</p><p>　　<a href="http://ifeve.com/java-blocking-queue/" target="_blank" rel="noopener">http://ifeve.com/java-blocking-queue/</a></p><p>　　<a href="http://endual.iteye.com/blog/1412212" target="_blank" rel="noopener">http://endual.iteye.com/blog/1412212</a></p><p>　　<a href="http://blog.csdn.net/zzp_403184692/article/details/8021615" target="_blank" rel="noopener">http://blog.csdn.net/zzp_403184692/article/details/8021615</a></p><p>　　<a href="http://www.cnblogs.com/juepei/p/3922401.html" target="_blank" rel="noopener">http://www.cnblogs.com/juepei/p/3922401.html</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> 阻塞队列 </tag>
            
            <tag> ArrayBlockingQueue </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：ConcurrentModificationException异常原因和解决方法</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9AConcurrentModificationException%E5%BC%82%E5%B8%B8%E5%8E%9F%E5%9B%A0%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9AConcurrentModificationException%E5%BC%82%E5%B8%B8%E5%8E%9F%E5%9B%A0%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>在前面一篇文章中提到，对Vector、ArrayList在迭代的时候如果同时对其进行修改就会抛出java.util.ConcurrentModificationException异常。下面我们就来讨论以下这个异常出现的原因以及解决办法。</p><p>　　以下是本文目录大纲：</p><p>　　一.ConcurrentModificationException异常出现的原因</p><p>　　二.在单线程环境下的解决办法</p><p>　　三.在多线程环境下的解决方法</p><p>　　若有不正之处请多多谅解，并欢迎批评指正</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3933551.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3933551.html</a></p><h2 id="一-ConcurrentModificationException异常出现的原因"><a href="#一-ConcurrentModificationException异常出现的原因" class="headerlink" title="一.ConcurrentModificationException异常出现的原因"></a>一.ConcurrentModificationException异常出现的原因</h2><p>　　先看下面这段代码：</p><pre><code>public class Test {    public static void main(String[] args)  {        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();        list.add(2);        Iterator&lt;Integer&gt; iterator = list.iterator();        while(iterator.hasNext()){            Integer integer = iterator.next();            if(integer==2)                list.remove(integer);        }    }}  </code></pre><p> 　　运行结果：</p><p><img src="http://op7wplti1.bkt.clouddn.com/251050400793404.jpg" alt="操作集合迭代器结果">　　</p><p>　　从异常信息可以发现，异常出现在<strong>checkForComodification()</strong>方法中。</p><p>　　我们不忙看checkForComodification()方法的具体实现，我们先根据程序的代码一步一步看ArrayList源码的实现：</p><p>　　首先看ArrayList的iterator()方法的具体实现，查看源码发现在ArrayList的源码中并没有iterator()这个方法，那么很显然这个方法应该是其父类或者实现的接口中的方法，我们在其父类AbstractList中找到了iterator()方法的具体实现，下面是其实现代码：</p><pre><code>public Iterator&lt;E&gt; iterator() {    return new Itr();}</code></pre><p> 　　从这段代码可以看出返回的是一个指向Itr类型对象的引用，我们接着看Itr的具体实现，在AbstractList类中找到了Itr类的具体实现，它是AbstractList的一个成员内部类，下面这段代码是Itr类的所有实现：</p><pre><code>private class Itr implements Iterator&lt;E&gt; {    int cursor = 0;    int lastRet = -1;    int expectedModCount = modCount;    public boolean hasNext() {           return cursor != size();    }    public E next() {           checkForComodification();        try {        E next = get(cursor);        lastRet = cursor++;        return next;        } catch (IndexOutOfBoundsException e) {        checkForComodification();        throw new NoSuchElementException();        }    }    public void remove() {        if (lastRet == -1)        throw new IllegalStateException();           checkForComodification();        try {        AbstractList.this.remove(lastRet);        if (lastRet &lt; cursor)            cursor--;        lastRet = -1;        expectedModCount = modCount;        } catch (IndexOutOfBoundsException e) {        throw new ConcurrentModificationException();        }    }    final void checkForComodification() {        if (modCount != expectedModCount)        throw new ConcurrentModificationException();    }}  </code></pre><p> 　　首先我们看一下它的几个成员变量：</p><p>　　cursor：表示下一个要访问的元素的索引，从next()方法的具体实现就可看出</p><p>　　lastRet：表示上一个访问的元素的索引</p><p>　　expectedModCount：表示对ArrayList修改次数的期望值，它的初始值为modCount。</p><p>　　modCount是AbstractList类中的一个成员变量</p><pre><code>protected transient int modCount = 0;</code></pre><p> 　　该值表示对List的修改次数，查看ArrayList的add()和remove()方法就可以发现，每次调用add()方法或者remove()方法就会对modCount进行加1操作。</p><p>　　好了，到这里我们再看看上面的程序：</p><p>　　当调用list.iterator()返回一个Iterator之后，通过Iterator的hashNext()方法判断是否还有元素未被访问，我们看一下hasNext()方法，hashNext()方法的实现很简单：</p><pre><code>public boolean hasNext() {    return cursor != size();}</code></pre><p> 　　如果下一个访问的元素下标不等于ArrayList的大小，就表示有元素需要访问，这个很容易理解，如果下一个访问元素的下标等于ArrayList的大小，则肯定到达末尾了。</p><p>　　然后通过Iterator的next()方法获取到下标为0的元素，我们看一下next()方法的具体实现：</p><pre><code>public E next() {    checkForComodification(); try {    E next = get(cursor);    lastRet = cursor++;    return next; } catch (IndexOutOfBoundsException e) {    checkForComodification();    throw new NoSuchElementException(); }}</code></pre><p> 　　这里是非常关键的地方：首先在next()方法中会调用checkForComodification()方法，然后根据cursor的值获取到元素，接着将cursor的值赋给lastRet，并对cursor的值进行加1操作。初始时，cursor为0，lastRet为-1，那么调用一次之后，cursor的值为1，lastRet的值为0。注意此时，modCount为0，expectedModCount也为0。</p><p>　　接着往下看，程序中判断当前元素的值是否为2，若为2，则调用list.remove()方法来删除该元素。</p><p>　　我们看一下在ArrayList中的remove()方法做了什么：</p><pre><code>public boolean remove(Object o) {    if (o == null) {        for (int index = 0; index &lt; size; index++)            if (elementData[index] == null) {                fastRemove(index);                return true;            }    } else {        for (int index = 0; index &lt; size; index++)            if (o.equals(elementData[index])) {                fastRemove(index);                return true;            }    }    return false;}private void fastRemove(int index) {    modCount++;    int numMoved = size - index - 1;    if (numMoved &gt; 0)        System.arraycopy(elementData, index+1, elementData, index,                numMoved);    elementData[--size] = null; // Let gc do its work}</code></pre><p> 　　通过remove方法删除元素最终是调用的fastRemove()方法，在fastRemove()方法中，首先对modCount进行加1操作（因为对集合修改了一次），然后接下来就是删除元素的操作，最后将size进行减1操作，并将引用置为null以方便垃圾收集器进行回收工作。</p><p>　　那么注意此时各个变量的值：对于iterator，其expectedModCount为0，cursor的值为1，lastRet的值为0。</p><p>　　对于list，其modCount为1，size为0。</p><p>　　接着看程序代码，执行完删除操作后，继续while循环，调用hasNext方法()判断，由于此时cursor为1，而size为0，那么返回true，所以继续执行while循环，然后继续调用iterator的next()方法：</p><p>　　注意，此时要注意next()方法中的第一句：checkForComodification()。</p><p>　　在checkForComodification方法中进行的操作是：</p><pre><code>final void checkForComodification() {    if (modCount != expectedModCount)    throw new ConcurrentModificationException();}</code></pre><p> 　　如果modCount不等于expectedModCount，则抛出ConcurrentModificationException异常。</p><p>　　很显然，此时modCount为1，而expectedModCount为0，因此程序就抛出了ConcurrentModificationException异常。</p><p>　　到这里，想必大家应该明白为何上述代码会抛出ConcurrentModificationException异常了。</p><p>　　关键点就在于：调用list.remove()方法导致modCount和expectedModCount的值不一致。</p><p>　　注意，像使用for-each进行迭代实际上也会出现这种问题。</p><h2 id="二-在单线程环境下的解决办法"><a href="#二-在单线程环境下的解决办法" class="headerlink" title="二.在单线程环境下的解决办法"></a>二.在单线程环境下的解决办法</h2><p>　　既然知道原因了，那么如何解决呢？</p><p>　　其实很简单，细心的朋友可能发现在Itr类中也给出了一个remove()方法：</p><pre><code>public void remove() {    if (lastRet == -1)    throw new IllegalStateException();       checkForComodification();    try {    AbstractList.this.remove(lastRet);    if (lastRet &lt; cursor)        cursor--;    lastRet = -1;    expectedModCount = modCount;    } catch (IndexOutOfBoundsException e) {    throw new ConcurrentModificationException();    }}  </code></pre><p> 　　在这个方法中，删除元素实际上调用的就是list.remove()方法，但是它多了一个操作：</p><pre><code>expectedModCount = modCount;  </code></pre><p> 　　因此，在迭代器中如果要删除元素的话，需要调用Itr类的remove方法。</p><p>　　将上述代码改为下面这样就不会报错了：</p><pre><code>public class Test {    public static void main(String[] args)  {        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();        list.add(2);        Iterator&lt;Integer&gt; iterator = list.iterator();        while(iterator.hasNext()){            Integer integer = iterator.next();            if(integer==2)                iterator.remove();   //注意这个地方        }    }}  </code></pre><h2 id="三-在多线程环境下的解决方法"><a href="#三-在多线程环境下的解决方法" class="headerlink" title="三.在多线程环境下的解决方法"></a>三.在多线程环境下的解决方法</h2><p>　　上面的解决办法在单线程环境下适用，但是在多线程下适用吗？看下面一个例子：</p><pre><code>public class Test {    static ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();    public static void main(String[] args)  {        list.add(1);        list.add(2);        list.add(3);        list.add(4);        list.add(5);        Thread thread1 = new Thread(){            public void run() {                Iterator&lt;Integer&gt; iterator = list.iterator();                while(iterator.hasNext()){                    Integer integer = iterator.next();                    System.out.println(integer);                    try {                        Thread.sleep(100);                    } catch (InterruptedException e) {                        e.printStackTrace();                    }                }            };        };        Thread thread2 = new Thread(){            public void run() {                Iterator&lt;Integer&gt; iterator = list.iterator();                while(iterator.hasNext()){                    Integer integer = iterator.next();                    if(integer==2)                        iterator.remove();                  }            };        };        thread1.start();        thread2.start();    }}  </code></pre><p> 　　运行结果：</p><p><img src="http://op7wplti1.bkt.clouddn.com/251432442989726.jpg" alt="多线程下操作集合问题">　　</p><p>　　有可能有朋友说ArrayList是非线程安全的容器，换成Vector就没问题了，实际上换成Vector还是会出现这种错误。</p><p>　　原因在于，虽然Vector的方法采用了synchronized进行了同步，但是由于Vector是继承的AbstarctList，因此通过Iterator来访问容器的话，事实上是不需要获取锁就可以访问。那么显然，由于使用iterator对容器进行访问不需要获取锁，在多线程中就会造成当一个线程删除了元素，由于modCount是AbstarctList的成员变量，因此可能会导致在其他线程中modCount和expectedModCount值不等。</p><p>　　就比如上面的代码中，很显然iterator是线程私有的，</p><p>　　初始时，线程1和线程2中的modCount、expectedModCount都为0，</p><p>　　当线程2通过iterator.remove()删除元素时，会修改modCount值为1，并且会修改线程2中的expectedModCount的值为1，</p><p>　　而此时线程1中的expectedModCount值为0，虽然modCount不是volatile变量，不保证线程1一定看得到线程2修改后的modCount的值，但是也有可能看得到线程2对modCount的修改，这样就有可能导致线程1中比较expectedModCount和modCount不等，而抛出异常。</p><p>　　因此一般有2种解决办法：</p><p>　　1）在使用iterator迭代的时候使用synchronized或者Lock进行同步；</p><p>　　2）使用并发容器CopyOnWriteArrayList代替ArrayList和Vector。</p><p>　　关于并发容器的内容将在下一篇文章中讲述。</p><blockquote><p>参考资料：</p><p><a href="http://blog.csdn.net/izard999/article/details/6708738" target="_blank" rel="noopener">http://blog.csdn.net/izard999/article/details/6708738</a></p><p><a href="http://www.2cto.com/kf/201403/286536.html" target="_blank" rel="noopener">http://www.2cto.com/kf/201403/286536.html</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：同步容器</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%90%8C%E6%AD%A5%E5%AE%B9%E5%99%A8/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%90%8C%E6%AD%A5%E5%AE%B9%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>为了方便编写出线程安全的程序，Java里面提供了一些线程安全类和并发工具，比如：同步容器、并发容器、阻塞队列、Synchronizer（比如CountDownLatch）。今天我们就来讨论下同步容器。</p><p>　　以下是本文的目录大纲：</p><p>　　一.为什么会出现同步容器？</p><p>　　二.Java中的同步容器类</p><p>　　三.同步容器的缺陷</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3933404.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3933404.html</a></p><h2 id="一-为什么会出现同步容器？"><a href="#一-为什么会出现同步容器？" class="headerlink" title="一.为什么会出现同步容器？"></a>一.为什么会出现同步容器？</h2><p>　　在Java的集合容器框架中，主要有四大类别：List、Set、Queue、Map。</p><p>　　List、Set、Queue接口分别继承了Collection接口，Map本身是一个接口。</p><p>　　注意Collection和Map是一个顶层接口，而List、Set、Queue则继承了Collection接口，分别代表数组、集合和队列这三大类容器。</p><p>　　像ArrayList、LinkedList都是实现了List接口，HashSet实现了Set接口，而Deque（双向队列，允许在队首、队尾进行入队和出队操作）继承了Queue接口，PriorityQueue实现了Queue接口。另外LinkedList（实际上是双向链表）实现了了Deque接口。</p><p>　　像ArrayList、LinkedList、HashMap这些容器都是非线程安全的。</p><p>　　如果有多个线程并发地访问这些容器时，就会出现问题。</p><p>　　因此，在编写程序时，必须要求程序员手动地在任何访问到这些容器的地方进行同步处理，这样导致在使用这些容器的时候非常地不方便。</p><p>　　所以，Java提供了同步容器供用户使用。</p><h2 id="二-Java中的同步容器类"><a href="#二-Java中的同步容器类" class="headerlink" title="二.Java中的同步容器类"></a>二.Java中的同步容器类</h2><p>　　在Java中，同步容器主要包括2类：</p><p>　　1）Vector、Stack、HashTable</p><p>　　2）Collections类中提供的静态工厂方法创建的类</p><p>　　Vector实现了List接口，Vector实际上就是一个数组，和ArrayList类似，但是Vector中的方法都是synchronized方法，即进行了同步措施。</p><p>　　Stack也是一个同步容器，它的方法也用synchronized进行了同步，它实际上是继承于Vector类。</p><p>　　HashTable实现了Map接口，它和HashMap很相似，但是HashTable进行了同步处理，而HashMap没有。</p><p>　　Collections类是一个工具提供类，注意，它和Collection不同，Collection是一个顶层的接口。在Collections类中提供了大量的方法，比如对集合或者容器进行排序、查找等操作。最重要的是，在它里面提供了几个静态工厂方法来创建同步容器类，如下图所示：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241522011748498.jpg" alt="Collections类创建同步器方法">　　　　</p><h2 id="三-同步容器的缺陷"><a href="#三-同步容器的缺陷" class="headerlink" title="三.同步容器的缺陷"></a>三.同步容器的缺陷</h2><p>　　从同步容器的具体实现源码可知，同步容器中的方法采用了synchronized进行了同步，那么很显然，这必然会影响到执行性能，另外，同步容器就一定是真正地完全线程安全吗？不一定，这个在下面会讲到。</p><p>　　我们首先来看一下传统的非同步容器和同步容器的性能差异，我们以ArrayList和Vector为例：</p><p>1.性能问题</p><p>　　我们先通过一个例子看一下Vector和ArrayList在插入数据时性能上的差异：</p><pre><code>public class Test {    public static void main(String[] args) throws InterruptedException {        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();        Vector&lt;Integer&gt; vector = new Vector&lt;Integer&gt;();        long start = System.currentTimeMillis();        for(int i=0;i&lt;100000;i++)            list.add(i);        long end = System.currentTimeMillis();        System.out.println(&quot;ArrayList进行100000次插入操作耗时：&quot;+(end-start)+&quot;ms&quot;);        start = System.currentTimeMillis();        for(int i=0;i&lt;100000;i++)            vector.add(i);        end = System.currentTimeMillis();        System.out.println(&quot;Vector进行100000次插入操作耗时：&quot;+(end-start)+&quot;ms&quot;);    }}  </code></pre><p>　　这段代码在我机器上跑出来的结果是：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241549434409962.jpg" alt="同步容器性能测试1">　　</p><p>　　进行同样多的插入操作，Vector的耗时是ArrayList的两倍。</p><p>　　这只是其中的一方面性能问题上的反映。</p><p>　　另外，由于Vector中的add方法和get方法都进行了同步，因此，在有多个线程进行访问时，如果多个线程都只是进行读取操作，那么每个时刻就只能有一个线程进行读取，其他线程便只能等待，这些线程必须竞争同一把锁。</p><p>　　因此为了解决同步容器的性能问题，在Java 1.5中提供了并发容器，位于java.util.concurrent目录下，并发容器的相关知识将在下一篇文章中讲述。</p><p>2.同步容器真的是安全的吗？</p><p>　　也有有人认为Vector中的方法都进行了同步处理，那么一定就是线程安全的，事实上这可不一定。看下面这段代码：</p><pre><code>public class Test {    static Vector&lt;Integer&gt; vector = new Vector&lt;Integer&gt;();    public static void main(String[] args) throws InterruptedException {        while(true) {            for(int i=0;i&lt;10;i++)                vector.add(i);            Thread thread1 = new Thread(){                public void run() {                    for(int i=0;i&lt;vector.size();i++)                        vector.remove(i);                };            };            Thread thread2 = new Thread(){                public void run() {                    for(int i=0;i&lt;vector.size();i++)                        vector.get(i);                };            };            thread1.start();            thread2.start();            while(Thread.activeCount()&gt;10)   {            }        }    }}  </code></pre><p>　　在我机器上运行的结果：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241614562532701.jpg" alt="同步容器多线程操作问题">　　</p><p>　　正如大家所看到的，这段代码报错了：数组下标越界。</p><p>　　也许有朋友会问：Vector是线程安全的，为什么还会报这个错？很简单，对于Vector，虽然能保证每一个时刻只能有一个线程访问它，但是不排除这种可能：</p><p>　　当某个线程在某个时刻执行这句时：</p><pre><code>for(int i=0;i&lt;vector.size();i++)    vector.get(i);</code></pre><p>　　假若此时vector的size方法返回的是10，i的值为9</p><p>　　然后另外一个线程执行了这句：</p><pre><code>for(int i=0;i&lt;vector.size();i++)    vector.remove(i);  </code></pre><p>　　将下标为9的元素删除了。</p><p>　　那么通过get方法访问下标为9的元素肯定就会出问题了。</p><p>　　因此为了保证线程安全，必须在方法调用端做额外的同步措施，如下面所示：</p><pre><code>public class Test {    static Vector&lt;Integer&gt; vector = new Vector&lt;Integer&gt;();    public static void main(String[] args) throws InterruptedException {        while(true) {            for(int i=0;i&lt;10;i++)                vector.add(i);            Thread thread1 = new Thread(){                public void run() {                    synchronized (Test.class) {   //进行额外的同步                        for(int i=0;i&lt;vector.size();i++)                            vector.remove(i);                    }                };            };            Thread thread2 = new Thread(){                public void run() {                    synchronized (Test.class) {                        for(int i=0;i&lt;vector.size();i++)                            vector.get(i);                    }                };            };            thread1.start();            thread2.start();            while(Thread.activeCount()&gt;10)   {            }        }    }}</code></pre><ol start="3"><li>ConcurrentModificationException异常</li></ol><p>　　在对Vector等容器并发地进行迭代修改时，会报ConcurrentModificationException异常，关于这个异常将会在后续文章中讲述。</p><p>　　但是在并发容器中不会出现这个问题。</p><p>　　参考资料：</p><p>　　《深入理解Java虚拟机》</p><p>　　《Java并发编程实战》</p><p>　　<a href="http://thinkgeek.diandian.com/post/2012-03-24/17905694" target="_blank" rel="noopener">http://thinkgeek.diandian.com/post/2012-03-24/17905694</a></p><p>　　<a href="http://blog.csdn.net/cutesource/article/details/5780740" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/5780740</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> 集合 </tag>
            
            <tag> 同步容器 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：深入剖析ThreadLocal</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90ThreadLocal/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90ThreadLocal/</url>
      <content type="html"><![CDATA[<p>想必很多朋友对ThreadLocal并不陌生，今天我们就来一起探讨下ThreadLocal的使用方法和实现原理。首先，本文先谈一下对ThreadLocal的理解，然后根据ThreadLocal类的源码分析了其实现原理和使用需要注意的地方，最后给出了两个应用场景。</p><p>　　以下是本文目录大纲：</p><p>　　一.对ThreadLocal的理解</p><p>　　二.深入解析ThreadLocal类</p><p>　　三.ThreadLocal的应用场景</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p> 　　<a href="http://www.cnblogs.com/dolphin0520/p/3920407.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3920407.html</a></p><h2 id="一-对ThreadLocal的理解"><a href="#一-对ThreadLocal的理解" class="headerlink" title="一.对ThreadLocal的理解"></a>一.对ThreadLocal的理解</h2><p>　　ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。可能很多朋友都知道ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。</p><p>　　这句话从字面上看起来很容易理解，但是真正理解并不是那么容易。</p><p>　　我们还是先来看一个例子：</p><pre><code>class ConnectionManager {    private static Connection connect = null;    public static Connection openConnection() {        if(connect == null){            connect = DriverManager.getConnection();        }        return connect;    }    public static void closeConnection() {        if(connect!=null)            connect.close();    }}</code></pre><p> 　　假设有这样一个数据库链接管理类，这段代码在单线程中使用是没有任何问题的，但是如果在多线程中使用呢？很显然，在多线程中使用会存在线程安全问题：第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect；第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。</p><p>　　所以出于线程安全的考虑，必须将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理。</p><p>　　这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。</p><p>　　那么大家来仔细分析一下这个问题，这地方到底需不需要将connect变量进行共享？事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。</p><p>　　到这里，可能会有朋友想到，既然不需要在线程之间共享这个变量，可以直接这样处理，在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样：</p><pre><code>class ConnectionManager {    private  Connection connect = null;    public Connection openConnection() {        if(connect == null){            connect = DriverManager.getConnection();        }        return connect;    }    public void closeConnection() {        if(connect!=null)            connect.close();    }}class Dao{    public void insert() {        ConnectionManager connectionManager = new ConnectionManager();        Connection connection = connectionManager.openConnection();        //使用connection进行操作        connectionManager.closeConnection();    }}</code></pre><p> 　　这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不尽严重影响程序执行效率，还可能导致服务器压力巨大。</p><p>　　那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。</p><p>　　但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。</p><h2 id="二-深入解析ThreadLocal类"><a href="#二-深入解析ThreadLocal类" class="headerlink" title="二.深入解析ThreadLocal类"></a>二.深入解析ThreadLocal类</h2><p>　　在上面谈到了对ThreadLocal的一些理解，那我们下面来看一下具体ThreadLocal是如何实现的。</p><p>　　先了解一下ThreadLocal类提供的几个方法：</p><pre><code>public T get() { }public void set(T value) { }public void remove() { }protected T initialValue() { }</code></pre><p> 　　get()方法是用来获取ThreadLocal在当前线程中保存的变量副本，set()用来设置当前线程中变量的副本，remove()用来移除当前线程中变量的副本，initialValue()是一个protected方法，一般是用来在使用时进行重写的，它是一个延迟加载方法，下面会详细说明。</p><p>　　首先我们来看一下ThreadLocal类是如何为每个线程创建一个变量的副本的。</p><p>　　先看下get方法的实现：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241027152537015.jpg" alt="ThreadLocal get方法实现">　　</p><p> 　　第一句是取得当前线程，然后通过getMap(t)方法获取到一个map，map的类型为ThreadLocalMap。然后接着下面获取到&lt;key,value&gt;键值对，注意这里获取键值对传进去的是  this，而不是当前线程t。</p><p>　　如果获取成功，则返回value值。</p><p>　　如果map为空，则调用setInitialValue方法返回value。</p><p>　　我们上面的每一句来仔细分析：</p><p>　　首先看一下getMap方法中做了什么：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241028044719452.jpg" alt="ThreadLocal getMap方法实现"></p><p>　　可能大家没有想到的是，在getMap中，是调用当期线程t，返回当前线程t中的一个成员变量threadLocals。</p><p>　　那么我们继续取Thread类中取看一下成员变量threadLocals是什么：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241029514406632.jpg" alt="threadLocals">　　</p><p>　　实际上就是一个ThreadLocalMap，这个类型是ThreadLocal类的一个内部类，我们继续取看ThreadLocalMap的实现：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241031330495608.jpg" alt="ThreadLocalMap">　　</p><p>　　可以看到ThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。</p><p>　　然后再继续看setInitialValue方法的具体实现：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241034465033208.jpg" alt="setInitialValue"></p><p>　　很容易了解，就是如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现：</p><p><img src="http://op7wplti1.bkt.clouddn.com/241038005189081.jpg" alt="createMap">　　</p><p>　　至此，可能大部分朋友已经明白了ThreadLocal是如何为每个线程创建变量的副本的：</p><p>　　首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。</p><p>　　初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。</p><p>　　然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。</p><p>　　下面通过一个例子来证明通过ThreadLocal能达到在每个线程中创建变量副本的效果：</p><pre><code>public class Test {    ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;();    ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;();    public void set() {        longLocal.set(Thread.currentThread().getId());        stringLocal.set(Thread.currentThread().getName());    }    public long getLong() {        return longLocal.get();    }    public String getString() {        return stringLocal.get();    }    public static void main(String[] args) throws InterruptedException {        final Test test = new Test();        test.set();        System.out.println(test.getLong());        System.out.println(test.getString());        Thread thread1 = new Thread(){            public void run() {                test.set();                System.out.println(test.getLong());                System.out.println(test.getString());            };        };        thread1.start();        thread1.join();        System.out.println(test.getLong());        System.out.println(test.getString());    }}</code></pre><p> 　　这段代码的输出结果为:  </p><p><img src="http://op7wplti1.bkt.clouddn.com/241058553934886.jpg" alt="result">　　</p><p>　　从这段代码的输出结果可以看出，在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。最后一次在main线程再次打印副本值是为了证明在main线程中和thread1线程中的副本值确实是不同的。</p><p>　　总结一下：</p><p>　　1）实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的；</p><p>　　2）为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal；</p><p>　　3）在进行get之前，必须先set，否则会报空指针异常；</p><p>　　    如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。</p><p>　　　 因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。</p><p><img src="http://op7wplti1.bkt.clouddn.com/241109342846403.jpg" alt="initialValue">　　</p><p>　　看下面这个例子：</p><p>　　</p><pre><code>public class Test {    ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;();    ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;();    public void set() {        longLocal.set(Thread.currentThread().getId());        stringLocal.set(Thread.currentThread().getName());    }    public long getLong() {        return longLocal.get();    }    public String getString() {        return stringLocal.get();    }    public static void main(String[] args) throws InterruptedException {        final Test test = new Test();        System.out.println(test.getLong());        System.out.println(test.getString());        Thread thread1 = new Thread(){            public void run() {                test.set();                System.out.println(test.getLong());                System.out.println(test.getString());            };        };        thread1.start();        thread1.join();        System.out.println(test.getLong());        System.out.println(test.getString());    }}</code></pre><p> 　　在main线程中，没有先set，直接get的话，运行时会报空指针异常。</p><p>　　但是如果改成下面这段代码，即重写了initialValue方法：</p><pre><code>public class Test {    ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(){        protected Long initialValue() {            return Thread.currentThread().getId();        };    };    ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(){;        protected String initialValue() {            return Thread.currentThread().getName();        };    };    public void set() {        longLocal.set(Thread.currentThread().getId());        stringLocal.set(Thread.currentThread().getName());    }    public long getLong() {        return longLocal.get();    }    public String getString() {        return stringLocal.get();    }    public static void main(String[] args) throws InterruptedException {        final Test test = new Test();        test.set();        System.out.println(test.getLong());        System.out.println(test.getString());        Thread thread1 = new Thread(){            public void run() {                test.set();                System.out.println(test.getLong());                System.out.println(test.getString());            };        };        thread1.start();        thread1.join();        System.out.println(test.getLong());        System.out.println(test.getString());    }}  </code></pre><p> 　　就可以直接不用先set而直接调用get了。</p><h2 id="三-ThreadLocal的应用场景"><a href="#三-ThreadLocal的应用场景" class="headerlink" title="三.ThreadLocal的应用场景"></a>三.ThreadLocal的应用场景</h2><p>　　最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。</p><p>　　如：</p><pre><code>private static ThreadLocal&lt;Connection&gt; connectionHolder= new ThreadLocal&lt;Connection&gt;() {    public Connection initialValue() {        return DriverManager.getConnection(DB_URL);    }};public static Connection getConnection() {    return connectionHolder.get();}  </code></pre><p> 　　下面这段代码摘自：</p><p>　　<a href="http://www.iteye.com/topic/103804" target="_blank" rel="noopener">http://www.iteye.com/topic/103804</a></p><pre><code>private static final ThreadLocal threadSession = new ThreadLocal();public static Session getSession() throws InfrastructureException {    Session s = (Session) threadSession.get();    try {        if (s == null) {            s = getSessionFactory().openSession();            threadSession.set(s);        }    } catch (HibernateException ex) {        throw new InfrastructureException(ex);    }    return s;}</code></pre><p>　　参考资料：</p><p>　　《深入理解Java虚拟机》</p><p>　　《Java编程思想》</p><blockquote><p>　　<a href="http://ifeve.com/thread-management-10/" target="_blank" rel="noopener">http://ifeve.com/thread-management-10/</a></p><p>　　<a href="http://www.ibm.com/developerworks/cn/java/j-threads/index3.html" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/java/j-threads/index3.html</a></p><p>　　<a href="http://www.iteye.com/topic/103804" target="_blank" rel="noopener">http://www.iteye.com/topic/103804</a></p><p>　　<a href="http://www.iteye.com/topic/777716" target="_blank" rel="noopener">http://www.iteye.com/topic/777716</a></p><p>　　<a href="http://www.iteye.com/topic/757478" target="_blank" rel="noopener">http://www.iteye.com/topic/757478</a></p><p>　　<a href="http://blog.csdn.net/ghsau/article/details/15732053" target="_blank" rel="noopener">http://blog.csdn.net/ghsau/article/details/15732053</a></p><p>　　<a href="http://ispring.iteye.com/blog/162982" target="_blank" rel="noopener">http://ispring.iteye.com/blog/162982</a></p><p>　　<a href="http://blog.csdn.net/imzoer/article/details/8262101" target="_blank" rel="noopener">http://blog.csdn.net/imzoer/article/details/8262101</a></p><pre><code>http://www.blogjava.net/wumi9527/archive/2010/09/10/331654.html</code></pre><p>　　<a href="http://bbs.csdn.net/topics/380049261" target="_blank" rel="noopener">http://bbs.csdn.net/topics/380049261</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> Java并发编程 </tag>
            
            <tag> ThreadLocal </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：volatile关键字解析</title>
      <link href="/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9Avolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%A7%A3%E6%9E%90/"/>
      <url>/2017/05/01/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9Avolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%A7%A3%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。</p><p>　　volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。</p><p>　　以下是本文的目录大纲：</p><p>　　一.内存模型的相关概念</p><p>　　二.并发编程中的三个概念</p><p>　　三.Java内存模型</p><p>　　四..深入剖析volatile关键字</p><p>　　五.使用volatile关键字的场景</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3920373.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3920373.html</a></p><h2 id="一-内存模型的相关概念"><a href="#一-内存模型的相关概念" class="headerlink" title="一.内存模型的相关概念"></a>一.内存模型的相关概念</h2><p>　　大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。</p><p>　　也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：</p><pre><code>i = i + 1;</code></pre><p> 　　当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。</p><p>　　这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。</p><p>　　比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？</p><p>　　可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。</p><p>　　最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。</p><p>　　也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。</p><p>　　为了解决缓存不一致性问题，通常来说有以下2种解决方法：</p><p>　　1）通过在总线加LOCK#锁的方式</p><p>　　2）通过缓存一致性协议</p><p>　　这2种方式都是硬件层面上提供的方式。</p><p>　　在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。</p><p>　　但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。</p><p>　　所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。</p><p><img src="http://op7wplti1.bkt.clouddn.com/212219343783699.jpg" alt="主内存和工作内存交换数据"></p><h2 id="二-并发编程中的三个概念"><a href="#二-并发编程中的三个概念" class="headerlink" title="二.并发编程中的三个概念"></a>二.并发编程中的三个概念</h2><p>　　在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念：</p><p>1.原子性</p><p>　　原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p><p>　　一个很经典的例子就是银行账户转账问题：</p><p>　　比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。</p><p>　　试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。</p><p>　　所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。</p><p>　　同样地反映到并发编程中会出现什么结果呢？</p><p>　　举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？</p><pre><code>i = 9;</code></pre><p> 　　假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。</p><p>　　那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。</p><p>2.可见性</p><p>　　可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p><p>　　举个简单的例子，看下面这段代码：</p><pre><code>//线程1执行的代码int i = 0;i = 10;//线程2执行的代码j = i;</code></pre><p> 　　假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。</p><p>　　此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.</p><p>　　这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。</p><p>3.有序性</p><p>　　有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：</p><pre><code>int i = 0;              boolean flag = false;i = 1;                //语句1  flag = true;          //语句2</code></pre><p> 　　上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。</p><p>　　下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。</p><p>　　比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。</p><p>　　但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：</p><pre><code>int a = 10;    //语句1int r = 2;    //语句2a = a + 3;    //语句3r = a*a;     //语句4</code></pre><p> 　　这段代码有4个语句，那么可能的一个执行顺序是：</p><p><img src="http://op7wplti1.bkt.clouddn.com/212305263939989.jpg" alt="语句执行顺序"></p><p>　　</p><p>　　那么可不可能是这个执行顺序呢： 语句2   语句1    语句4   语句3</p><p>　　不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。</p><p>　　虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子：</p><pre><code>//线程1:context = loadContext();   //语句1inited = true;             //语句2//线程2:while(!inited ){  sleep()}doSomethingwithconfig(context);</code></pre><p> 　　上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。</p><p> 　　从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。</p><p>　　也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。</p><h2 id="三-Java内存模型"><a href="#三-Java内存模型" class="headerlink" title="三.Java内存模型"></a>三.Java内存模型</h2><p>　　在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。</p><p>　　在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。</p><p>　　Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。</p><p>　　举个简单的例子：在java中，执行下面这个语句：</p><pre><code>i  = 10;</code></pre><p> 　　执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。</p><p>　　那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？</p><p>1.原子性</p><p>　　在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。</p><p>　　上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：</p><p>　　请分析以下哪些操作是原子性操作：</p><pre><code>x = 10;         //语句1y = x;         //语句2x++;           //语句3x = x + 1;     //语句4</code></pre><p> 　　咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。</p><p>　　语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。</p><p>　　语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。</p><p>　　同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。</p><p> 　　所以上面4个语句只有语句1的操作具备原子性。</p><p>　　也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。</p><p>　　不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。</p><p>　　从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。</p><p>2.可见性</p><p>　　对于可见性，Java提供了volatile关键字来保证可见性。</p><p>　　当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。</p><p>　　而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。</p><p>　　另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。</p><p>3.有序性</p><p>　　在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。</p><p>　　在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。</p><p>　　另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。</p><p>　　下面就来具体介绍下happens-before原则（先行发生原则）：</p><p>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作<br>锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作<br>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作<br>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C<br>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作<br>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生<br>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行<br>对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始<br>　　这8条原则摘自《深入理解Java虚拟机》。</p><p>　　这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。</p><p>　　下面我们来解释一下前4条规则：</p><p>　　对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。</p><p>　　第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。</p><p>　　第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。</p><p>　　第四条规则实际上就是体现happens-before原则具备传递性。</p><h2 id="四-深入剖析volatile关键字"><a href="#四-深入剖析volatile关键字" class="headerlink" title="四.深入剖析volatile关键字"></a>四.深入剖析volatile关键字</h2><p>　　在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。</p><p>1.volatile关键字的两层语义</p><p>　　一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：</p><p>　　1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。</p><p>　　2）禁止进行指令重排序。</p><p>　　先看一段代码，假如线程1先执行，线程2后执行：</p><pre><code>//线程1boolean stop = false;while(!stop){    doSomething();}//线程2stop = true;</code></pre><p> 　　这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。</p><p>　　下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。</p><p>　　那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。</p><p>　　但是用volatile修饰之后就变得不一样了：</p><p>　　第一：使用volatile关键字会强制将修改的值立即写入主存；</p><p>　　第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；</p><p>　　第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。</p><p>　　那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。</p><p>　　那么线程1读取到的就是最新的正确的值。</p><p>2.volatile保证原子性吗？</p><p>　　从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？</p><p>　　下面看一个例子：</p><pre><code>public class Test {    public volatile int inc = 0;    public void increase() {        inc++;    }    public static void main(String[] args) {        final Test test = new Test();        for(int i=0;i&lt;10;i++){            new Thread(){                public void run() {                    for(int j=0;j&lt;1000;j++)                        test.increase();                };            }.start();        }        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完            Thread.yield();        System.out.println(test.inc);    }}</code></pre><p> 　　大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。</p><p>　　可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。</p><p>　　这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。</p><p>　　在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：</p><p>　　假如某个时刻变量inc的值为10，</p><p>　　线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；</p><p>　　然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。</p><p>　　然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。</p><p>　　那么两个线程分别进行了一次自增操作后，inc只增加了1。</p><p>　　解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。</p><p>　　根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。</p><p>　　把上面的代码改成以下任何一种都可以达到效果：</p><p>　　采用synchronized：</p><pre><code>public class Test {    public  int inc = 0;    public synchronized void increase() {        inc++;    }    public static void main(String[] args) {        final Test test = new Test();        for(int i=0;i&lt;10;i++){            new Thread(){                public void run() {                    for(int j=0;j&lt;1000;j++)                        test.increase();                };            }.start();        }        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完            Thread.yield();        System.out.println(test.inc);    }}  </code></pre><p>　　采用Lock：</p><pre><code>public class Test {    public  int inc = 0;    Lock lock = new ReentrantLock();    public  void increase() {        lock.lock();        try {            inc++;        } finally{            lock.unlock();        }    }    public static void main(String[] args) {        final Test test = new Test();        for(int i=0;i&lt;10;i++){            new Thread(){                public void run() {                    for(int j=0;j&lt;1000;j++)                        test.increase();                };            }.start();        }        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完            Thread.yield();        System.out.println(test.inc);    }}  </code></pre><p>　　采用AtomicInteger：  </p><pre><code>public class Test {    public  AtomicInteger inc = new AtomicInteger();    public  void increase() {        inc.getAndIncrement();    }    public static void main(String[] args) {        final Test test = new Test();        for(int i=0;i&lt;10;i++){            new Thread(){                public void run() {                    for(int j=0;j&lt;1000;j++)                        test.increase();                };            }.start();        }        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完            Thread.yield();        System.out.println(test.inc);    }}  </code></pre><p>　　在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。</p><p>3.volatile能保证有序性吗？</p><p>　　在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。</p><p>　　volatile关键字禁止指令重排序有两层意思：</p><p>　　1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；</p><p>　　2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。</p><p>　　可能上面说的比较绕，举个简单的例子：  </p><pre><code>//x、y为非volatile变量//flag为volatile变量x = 2;        //语句1y = 0;        //语句2flag = true;  //语句3x = 4;         //语句4y = -1;       //语句5</code></pre><p> 　　由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。</p><p>　　并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。</p><p>　　那么我们回到前面举的一个例子： </p><pre><code>//线程1:context = loadContext();   //语句1inited = true;             //语句2//线程2:while(!inited ){  sleep()}doSomethingwithconfig(context);</code></pre><p> 　　前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。</p><p>　　这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。</p><p>4.volatile的原理和实现机制</p><p>　　前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。</p><p>　　下面这段话摘自《深入理解Java虚拟机》：</p><p>　　“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”</p><p>　　lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：</p><p>　　1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；</p><p>　　2）它会强制将对缓存的修改操作立即写入主存；</p><p>　　3）如果是写操作，它会导致其他CPU中对应的缓存行无效。</p><h2 id="五-使用volatile关键字的场景"><a href="#五-使用volatile关键字的场景" class="headerlink" title="五.使用volatile关键字的场景"></a>五.使用volatile关键字的场景</h2><p>　　synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：</p><p>　　1）对变量的写操作不依赖于当前值</p><p>　　2）该变量没有包含在具有其他变量的不变式中</p><p>　　实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。</p><p>　　事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。</p><p>　　下面列举几个Java中使用volatile的几个场景。</p><p>1.状态标记量  </p><pre><code>volatile boolean flag = false;while(!flag){    doSomething();}public void setFlag() {    flag = true;}  volatile boolean inited = false;//线程1:context = loadContext();  inited = true;            //线程2:while(!inited ){sleep()}doSomethingwithconfig(context);</code></pre><p>2.double check</p><pre><code>class Singleton{    private volatile static Singleton instance = null;    private Singleton() {    }    public static Singleton getInstance() {        if(instance==null) {            synchronized (Singleton.class) {                if(instance==null)                    instance = new Singleton();            }        }        return instance;    }}</code></pre><p> 　　至于为何需要这么写请参考：</p><p>　　《Java 中的双重检查（Double-Check）》<a href="http://blog.csdn.net/dl88250/article/details/5439024" target="_blank" rel="noopener">http://blog.csdn.net/dl88250/article/details/5439024</a></p><p>　　和<a href="http://www.iteye.com/topic/652440" target="_blank" rel="noopener">http://www.iteye.com/topic/652440</a></p><p>　　参考资料：</p><p>　　《Java编程思想》</p><p>　　《深入理解Java虚拟机》</p><p>　　<a href="http://jiangzhengjun.iteye.com/blog/652532" target="_blank" rel="noopener">http://jiangzhengjun.iteye.com/blog/652532</a></p><p>　　<a href="http://blog.sina.com.cn/s/blog_7bee8dd50101fu8n.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_7bee8dd50101fu8n.html</a></p><p>　　<a href="http://ifeve.com/volatile/" target="_blank" rel="noopener">http://ifeve.com/volatile/</a></p><p>　　<a href="http://blog.csdn.net/ccit0519/article/details/11241403" target="_blank" rel="noopener">http://blog.csdn.net/ccit0519/article/details/11241403</a></p><p>　　<a href="http://blog.csdn.net/ns_code/article/details/17101369" target="_blank" rel="noopener">http://blog.csdn.net/ns_code/article/details/17101369</a></p><p>　　<a href="http://www.cnblogs.com/kevinwu/archive/2012/05/02/2479464.html" target="_blank" rel="noopener">http://www.cnblogs.com/kevinwu/archive/2012/05/02/2479464.html</a></p><p>　　<a href="http://www.cppblog.com/elva/archive/2011/01/21/139019.html" target="_blank" rel="noopener">http://www.cppblog.com/elva/archive/2011/01/21/139019.html</a></p><p>　　<a href="http://ifeve.com/volatile-array-visiblity/" target="_blank" rel="noopener">http://ifeve.com/volatile-array-visiblity/</a></p><p>　　<a href="http://www.bdqn.cn/news/201312/12579.shtml" target="_blank" rel="noopener">http://www.bdqn.cn/news/201312/12579.shtml</a></p><p>　　<a href="http://exploer.blog.51cto.com/7123589/1193399" target="_blank" rel="noopener">http://exploer.blog.51cto.com/7123589/1193399</a></p><p>　　<a href="http://www.cnblogs.com/Mainz/p/3556430.html" target="_blank" rel="noopener">http://www.cnblogs.com/Mainz/p/3556430.html</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> volatile </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：Lock</title>
      <link href="/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ALock/"/>
      <url>/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9ALock/</url>
      <content type="html"><![CDATA[<p>在上一篇文章中我们讲到了如何使用关键字synchronized来实现同步访问。本文我们继续来探讨这个问题，从Java 5之后，在java.util.concurrent.locks包下提供了另外一种方式来实现同步访问，那就是Lock。</p><p>　　也许有朋友会问，既然都可以通过synchronized来实现同步访问了，那么为什么还需要提供Lock？这个问题将在下面进行阐述。本文先从synchronized的缺陷讲起，然后再讲述java.util.concurrent.locks包下常用的有哪些类和接口，最后讨论以下一些关于锁的概念方面的东西</p><p>　　以下是本文目录大纲：</p><p>　　一.synchronized的缺陷</p><p>　　二.java.util.concurrent.locks包下常用的类</p><p>　　三.锁的相关概念介绍</p><p>　　若有不正之处请多多谅解，并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p> 　　<a href="http://www.cnblogs.com/dolphin0520/p/3923167.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3923167.html</a></p><h2 id="一-synchronized的缺陷"><a href="#一-synchronized的缺陷" class="headerlink" title="一.synchronized的缺陷"></a>一.synchronized的缺陷</h2><p>　　synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？</p><p>　　在上面一篇文章中，我们了解到如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：</p><p>　　1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；</p><p>　　2）线程执行发生异常，此时JVM会让线程自动释放锁。</p><p>　　那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一下，这多么影响程序执行效率。</p><p>　　因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。</p><p>　　再举个例子：当有多个线程读写文件时，读操作和写操作会发生冲突现象，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。</p><p>　　但是采用synchronized关键字来实现同步的话，就会导致一个问题：</p><p>　　如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。</p><p>　　因此就需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，通过Lock就可以办到。</p><p>　　另外，通过Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的。</p><p>　　总结一下，也就是说Lock提供了比synchronized更多的功能。但是要注意以下几点：</p><p>　　1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问；</p><p>　　2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。</p><h2 id="二-java-util-concurrent-locks包下常用的类"><a href="#二-java-util-concurrent-locks包下常用的类" class="headerlink" title="二.java.util.concurrent.locks包下常用的类"></a>二.java.util.concurrent.locks包下常用的类</h2><p>　　下面我们就来探讨一下java.util.concurrent.locks包中常用的类和接口。</p><p>　　1.Lock</p><p>　　首先要说明的就是Lock，通过查看Lock的源码可知，Lock是一个接口：  </p><pre><code>public interface Lock {    void lock();    void lockInterruptibly() throws InterruptedException;    boolean tryLock();    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;    void unlock();    Condition newCondition();}</code></pre><p> 　　下面来逐个讲述Lock接口中每个方法的使用，lock()、tryLock()、tryLock(long time, TimeUnit unit)和lockInterruptibly()是用来获取锁的。unLock()方法是用来释放锁的。newCondition()这个方法暂且不在此讲述，会在后面的线程协作一文中讲述。</p><p>　　在Lock中声明了四个方法来获取锁，那么这四个方法有何区别呢？</p><p>　　首先lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。</p><p>　　由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用Lock来进行同步的话，是以下面这种形式去使用的：</p><pre><code>Lock lock = ...;lock.lock();try{    //处理任务}catch(Exception ex){}finally{    lock.unlock();   //释放锁}</code></pre><p>　　tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。</p><p>　　tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。</p><p>　　所以，一般情况下通过tryLock来获取锁时是这样使用的:  </p><pre><code>Lock lock = ...;if(lock.tryLock()) {     try{         //处理任务     }catch(Exception ex){     }finally{         lock.unlock();   //释放锁     } }else {    //如果不能获取锁，则直接做其他事情}</code></pre><p> 　　lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。</p><p>　　由于lockInterruptibly()的声明中抛出了异常，所以lock.lockInterruptibly()必须放在try块中或者在调用lockInterruptibly()的方法外声明抛出InterruptedException。</p><p>　　因此lockInterruptibly()一般的使用形式如下：</p><pre><code>public void method() throws InterruptedException {    lock.lockInterruptibly();    try {       //.....    }    finally {        lock.unlock();    }  }</code></pre><p>　　注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。</p><p>　　因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。</p><p>　　而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。</p><p>　　2.ReentrantLock</p><p>　　ReentrantLock，意思是“可重入锁”，关于可重入锁的概念在下一节讲述。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。</p><p>　　例子1，lock()的正确使用方法</p><pre><code>public class Test {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    public static void main(String[] args)  {        final Test test = new Test();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();    }  public void insert(Thread thread) {    Lock lock = new ReentrantLock();    //注意这个地方    lock.lock();    try {        System.out.println(thread.getName()+&quot;得到了锁&quot;);        for(int i=0;i&lt;5;i++) {            arrayList.add(i);        }    } catch (Exception e) {        // TODO: handle exception    }finally {        System.out.println(thread.getName()+&quot;释放了锁&quot;);        lock.unlock();    }}}</code></pre><p> 　　各位朋友先想一下这段代码的输出结果是什么？</p><pre><code>Thread-0得到了锁Thread-1得到了锁Thread-0释放了锁Thread-1释放了锁</code></pre><p>　　也许有朋友会问，怎么会输出这个结果？第二个线程怎么会在第一个线程释放锁之前得到了锁？原因在于，在insert方法中的lock变量是局部变量，每个线程执行该方法时都会保存一个副本，那么理所当然每个线程执行到lock.lock()处获取的是不同的锁，所以就不会发生冲突。</p><p>　　知道了原因改起来就比较容易了，只需要将lock声明为类的属性即可。 </p><pre><code>public class Test {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    private Lock lock = new ReentrantLock();    //注意这个地方    public static void main(String[] args)  {        final Test test = new Test();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();    }      public void insert(Thread thread) {        lock.lock();        try {            System.out.println(thread.getName()+&quot;得到了锁&quot;);            for(int i=0;i&lt;5;i++) {                arrayList.add(i);            }        } catch (Exception e) {            // TODO: handle exception        }finally {            System.out.println(thread.getName()+&quot;释放了锁&quot;);            lock.unlock();        }    }}</code></pre><p> 　　这样就是正确地使用Lock的方法了。</p><p>　　例子2，tryLock()的使用方法</p><pre><code>public class Test {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    private Lock lock = new ReentrantLock();    //注意这个地方    public static void main(String[] args)  {        final Test test = new Test();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();        new Thread(){            public void run() {                test.insert(Thread.currentThread());            };        }.start();    }      public void insert(Thread thread) {        if(lock.tryLock()) {            try {                System.out.println(thread.getName()+&quot;得到了锁&quot;);                for(int i=0;i&lt;5;i++) {                    arrayList.add(i);                }            } catch (Exception e) {                // TODO: handle exception            }finally {                System.out.println(thread.getName()+&quot;释放了锁&quot;);                lock.unlock();            }        } else {            System.out.println(thread.getName()+&quot;获取锁失败&quot;);        }    }}</code></pre><p> 　　输出结果：</p><pre><code>Thread-0得到了锁Thread-1获取锁失败Thread-0释放了锁</code></pre><p>　　例子3，lockInterruptibly()响应中断的使用方法：</p><pre><code>public class Test {    private Lock lock = new ReentrantLock();       public static void main(String[] args)  {        Test test = new Test();        MyThread thread1 = new MyThread(test);        MyThread thread2 = new MyThread(test);        thread1.start();        thread2.start();        try {            Thread.sleep(2000);        } catch (InterruptedException e) {            e.printStackTrace();        }        thread2.interrupt();    }      public void insert(Thread thread) throws InterruptedException{        lock.lockInterruptibly();   //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出        try {              System.out.println(thread.getName()+&quot;得到了锁&quot;);            long startTime = System.currentTimeMillis();            for(    ;     ;) {                if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE)                    break;                //插入数据            }        }        finally {            System.out.println(Thread.currentThread().getName()+&quot;执行finally&quot;);            lock.unlock();            System.out.println(thread.getName()+&quot;释放了锁&quot;);        }      }}class MyThread extends Thread {    private Test test = null;    public MyThread(Test test) {        this.test = test;    }    @Override    public void run() {        try {            test.insert(Thread.currentThread());        } catch (InterruptedException e) {            System.out.println(Thread.currentThread().getName()+&quot;被中断&quot;);        }    }}</code></pre><p>　　运行之后，发现thread2能够被正确中断。</p><p>　　3.ReadWriteLock</p><p>　　ReadWriteLock也是一个接口，在它里面只定义了两个方法：</p><pre><code>public interface ReadWriteLock {    /**     * Returns the lock used for reading.     *     * @return the lock used for reading.     */    Lock readLock();    /**     * Returns the lock used for writing.     *     * @return the lock used for writing.     */    Lock writeLock();}</code></pre><p> 　　一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。</p><p>　　4.ReentrantReadWriteLock</p><p>　　ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。</p><p>　　下面通过几个例子来看一下ReentrantReadWriteLock具体用法。</p><p>　　假如有多个线程要同时进行读操作的话，先看一下synchronized达到的效果：</p><pre><code>public class Test {    private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();    public static void main(String[] args)  {        final Test test = new Test();        new Thread(){            public void run() {                test.get(Thread.currentThread());            };        }.start();        new Thread(){            public void run() {                test.get(Thread.currentThread());            };        }.start();    }      public synchronized void get(Thread thread) {        long start = System.currentTimeMillis();        while(System.currentTimeMillis() - start &lt;= 1) {            System.out.println(thread.getName()+&quot;正在进行读操作&quot;);        }        System.out.println(thread.getName()+&quot;读操作完毕&quot;);    }}</code></pre><p> 　　这段程序的输出结果会是，直到thread1执行完读操作之后，才会打印thread2执行读操作的信息。</p><pre><code>Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0读操作完毕Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1读操作完毕  </code></pre><p>　　而改成用读写锁的话：</p><pre><code>public class Test {    private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();    public static void main(String[] args)  {        final Test test = new Test();        new Thread(){            public void run() {                test.get(Thread.currentThread());            };        }.start();        new Thread(){            public void run() {                test.get(Thread.currentThread());            };        }.start();    }      public void get(Thread thread) {        rwl.readLock().lock();        try {            long start = System.currentTimeMillis();            while(System.currentTimeMillis() - start &lt;= 1) {                System.out.println(thread.getName()+&quot;正在进行读操作&quot;);            }            System.out.println(thread.getName()+&quot;读操作完毕&quot;);        } finally {            rwl.readLock().unlock();        }    }}  </code></pre><p> 　　此时打印的结果为：</p><pre><code>Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0读操作完毕Thread-1读操作完毕</code></pre><p>　　说明thread1和thread2在同时进行读操作。</p><p>　　这样就大大提升了读操作的效率。</p><p>　　不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。</p><p>　　如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。</p><p>　　关于ReentrantReadWriteLock类中的其他方法感兴趣的朋友可以自行查阅API文档。</p><p>　　5.Lock和synchronized的选择</p><p>　　总结来说，Lock和synchronized有以下几点不同：</p><p>　　1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；</p><p>　　2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；</p><p>　　3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；</p><p>　　4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。</p><p>　　5）Lock可以提高多个线程进行读操作的效率。</p><p>　　在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。</p><h2 id="三-锁的相关概念介绍"><a href="#三-锁的相关概念介绍" class="headerlink" title="三.锁的相关概念介绍"></a>三.锁的相关概念介绍</h2><p>　　在前面介绍了Lock的基本使用，这一节来介绍一下与锁相关的几个概念。</p><p>　　1.可重入锁</p><p>　　如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。</p><p>　　看下面这段代码就明白了： </p><pre><code>class MyClass {    public synchronized void method1() {        method2();    }    public synchronized void method2() {    }}</code></pre><p> 　　上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。</p><p>　　而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。</p><p>　　2.可中断锁</p><p>　　可中断锁：顾名思义，就是可以相应中断的锁。</p><p>　　在Java中，synchronized就不是可中断锁，而Lock是可中断锁。</p><p>　　如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。</p><p>　　在前面演示lockInterruptibly()的用法时已经体现了Lock的可中断性。</p><p>　　3.公平锁</p><p>　　公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。</p><p>　　非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。</p><p>　　在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。</p><p>　　而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。</p><p>　　看一下这2个类的源代码就清楚了：<br><img src="http://op7wplti1.bkt.clouddn.com/201642145495232.jpg" alt="ReentrantLockSource">　　</p><p>　　在ReentrantLock中定义了2个静态内部类，一个是NotFairSync，一个是FairSync，分别用来实现非公平锁和公平锁。</p><p>　　我们可以在创建ReentrantLock对象时，通过以下方式来设置锁的公平性：</p><pre><code>ReentrantLock lock = new ReentrantLock(true);</code></pre><p> 　　如果参数为true表示为公平锁，为fasle为非公平锁。默认情况下，如果使用无参构造器，则是非公平锁。</p><p> <img src="http://op7wplti1.bkt.clouddn.com/201646038317744.jpg" alt="ReentrantLockConst">　　</p><p>　　另外在ReentrantLock类中定义了很多方法，比如：</p><p>　　isFair()        //判断锁是否是公平锁</p><p>　　isLocked()    //判断锁是否被任何线程获取了</p><p>　　isHeldByCurrentThread()   //判断锁是否被当前线程获取了</p><p>　　hasQueuedThreads()   //判断是否有线程在等待该锁</p><p>　　在ReentrantReadWriteLock中也有类似的方法，同样也可以设置为公平锁和非公平锁。不过要记住，ReentrantReadWriteLock并未实现Lock接口，它实现的是ReadWriteLock接口。</p><p>　　4.读写锁</p><p>　　读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。</p><p>　　正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。</p><p>　　ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。</p><p>　　可以通过readLock()获取读锁，通过writeLock()获取写锁。</p><p>　　上面已经演示过了读写锁的使用方法，在此不再赘述。</p><p>参考资料：</p><p>　　<a href="http://blog.csdn.net/ns_code/article/details/17487337" target="_blank" rel="noopener">http://blog.csdn.net/ns_code/article/details/17487337</a></p><p>　　<a href="http://houlinyan.iteye.com/blog/1112535" target="_blank" rel="noopener">http://houlinyan.iteye.com/blog/1112535</a></p><p>　　<a href="http://ifeve.com/locks/" target="_blank" rel="noopener">http://ifeve.com/locks/</a></p><p>　　<a href="http://ifeve.com/read-write-locks/" target="_blank" rel="noopener">http://ifeve.com/read-write-locks/</a></p><p>　　<a href="http://blog.csdn.net/fancyerii/article/details/6783224" target="_blank" rel="noopener">http://blog.csdn.net/fancyerii/article/details/6783224</a></p><p>　　<a href="http://blog.csdn.net/ghsau/article/details/7461369/" target="_blank" rel="noopener">http://blog.csdn.net/ghsau/article/details/7461369/</a></p><p>　　<a href="http://blog.csdn.net/zhaozhenzuo/article/details/37109015" target="_blank" rel="noopener">http://blog.csdn.net/zhaozhenzuo/article/details/37109015</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> Lock </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：synchronized</title>
      <link href="/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9Asynchronized/"/>
      <url>/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9Asynchronized/</url>
      <content type="html"><![CDATA[<p>虽然多线程编程极大地提高了效率，但是也会带来一定的隐患。比如说两个线程同时往一个数据库表中插入不重复的数据，就可能会导致数据库中插入了相同的数据。今天我们就来一起讨论下线程安全问题，以及Java中提供了什么机制来解决线程安全问题。</p><p>　　以下是本文的目录大纲：</p><p>　　一.什么时候会出现线程安全问题？</p><p>　　二.如何解决线程安全问题？</p><p>　　三.synchronized同步方法或者同步块</p><p>　　若有不正之处，请多多谅解并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3923737.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3923737.html</a></p><h2 id="一-什么时候会出现线程安全问题？"><a href="#一-什么时候会出现线程安全问题？" class="headerlink" title="一.什么时候会出现线程安全问题？"></a>一.什么时候会出现线程安全问题？</h2><p>　　在单线程中不会出现线程安全问题，而在多线程编程中，有可能会出现同时访问同一个资源的情况，这种资源可以是各种类型的的资源：一个变量、一个对象、一个文件、一个数据库表等，而当多个线程同时访问同一个资源的时候，就会存在一个问题：</p><p>　　由于每个线程执行的过程是不可控的，所以很可能导致最终的结果与实际上的愿望相违背或者直接导致程序出错。</p><p>　　举个简单的例子：</p><p>　　现在有两个线程分别从网络上读取数据，然后插入一张数据库表中，要求不能插入重复的数据。</p><p>　　那么必然在插入数据的过程中存在两个操作：</p><p>　　1）检查数据库中是否存在该条数据；</p><p>　　2）如果存在，则不插入；如果不存在，则插入到数据库中。</p><p>　　假如两个线程分别用thread-1和thread-2表示，某一时刻，thread-1和thread-2都读取到了数据X，那么可能会发生这种情况：</p><p>　　thread-1去检查数据库中是否存在数据X，然后thread-2也接着去检查数据库中是否存在数据X。</p><p>　　结果两个线程检查的结果都是数据库中不存在数据X，那么两个线程都分别将数据X插入数据库表当中。</p><p>　　这个就是线程安全问题，即多个线程同时访问一个资源时，会导致程序运行结果并不是想看到的结果。</p><p>　　这里面，这个资源被称为：临界资源（也有称为共享资源）。</p><p>　　也就是说，当多个线程同时访问临界资源（一个对象，对象中的属性，一个文件，一个数据库等）时，就可能会产生线程安全问题。</p><p>　　不过，当多个线程执行一个方法，方法内部的局部变量并不是临界资源，因为方法是在栈上执行的，而Java栈是线程私有的，因此不会产生线程安全问题。</p><h2 id="二-如何解决线程安全问题？"><a href="#二-如何解决线程安全问题？" class="headerlink" title="二.如何解决线程安全问题？"></a>二.如何解决线程安全问题？</h2><p>　　那么一般来说，是如何解决线程安全问题的呢？</p><p>　　基本上所有的并发模式在解决线程安全问题时，都采用“序列化访问临界资源”的方案，即在同一时刻，只能有一个线程访问临界资源，也称作同步互斥访问。</p><p>　　通常来说，是在访问临界资源的代码前面加上一个锁，当访问完临界资源后释放锁，让其他线程继续访问。</p><p>　　在Java中，提供了两种方式来实现同步互斥访问：synchronized和Lock。</p><p>　　本文主要讲述synchronized的使用方法，Lock的使用方法在下一篇博文中讲述。</p><h2 id="三-synchronized同步方法或者同步块"><a href="#三-synchronized同步方法或者同步块" class="headerlink" title="三.synchronized同步方法或者同步块"></a>三.synchronized同步方法或者同步块</h2><p>　　在了解synchronized关键字的使用方法之前，我们先来看一个概念：互斥锁，顾名思义：能到达到互斥访问目的的锁。</p><p>　　举个简单的例子：如果对临界资源加上互斥锁，当一个线程在访问该临界资源时，其他线程便只能等待。</p><p>　　在Java中，每一个对象都拥有一个锁标记（monitor），也称为监视器，多线程同时访问某个对象时，线程只有获取了该对象的锁才能访问。</p><p>　　在Java中，可以使用synchronized关键字来标记一个方法或者代码块，当某个线程调用该对象的synchronized方法或者访问synchronized代码块时，这个线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，这个线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。</p><p>　　下面通过几个简单的例子来说明synchronized关键字的使用：</p><p>　　1.synchronized方法</p><p>　　下面这段代码中两个线程分别调用insertData对象插入数据：</p><pre><code>public class Test {    public static void main(String[] args)  {        final InsertData insertData = new InsertData();        new Thread() {            public void run() {                insertData.insert(Thread.currentThread());            };        }.start();        new Thread() {            public void run() {                insertData.insert(Thread.currentThread());            };        }.start();    }  }class InsertData {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    public void insert(Thread thread){        for(int i=0;i&lt;5;i++){            System.out.println(thread.getName()+&quot;在插入数据&quot;+i);            arrayList.add(i);        }    }}</code></pre><p>　　此时程序的输出结果为：<br><img src="http://op7wplti1.bkt.clouddn.com/191740073939985.jpg" alt="synTest1">　　</p><p>　　说明两个线程在同时执行insert方法。</p><p>　　而如果在insert方法前面加上关键字synchronized的话，运行结果为：<br>    class InsertData {<br>        private ArrayList<integer> arrayList = new ArrayList<integer>();</integer></integer></p><pre><code>    public synchronized void insert(Thread thread){        for(int i=0;i&lt;5;i++){            System.out.println(thread.getName()+&quot;在插入数据&quot;+i);            arrayList.add(i);        }    }}</code></pre><p>　　<br><img src="http://op7wplti1.bkt.clouddn.com/191742096284061.jpg" alt="synTest2"></p><p>　　从上输出结果说明，Thread-1插入数据是等Thread-0插入完数据之后才进行的。说明Thread-0和Thread-1是顺序执行insert方法的。</p><p>　　这就是synchronized方法。</p><p>　　不过有几点需要注意：</p><p>　　1）当一个线程正在访问一个对象的synchronized方法，那么其他线程不能访问该对象的其他synchronized方法。这个原因很简单，因为一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized方法。</p><p>　　2）当一个线程正在访问一个对象的synchronized方法，那么其他线程能访问该对象的非synchronized方法。这个原因很简单，访问非synchronized方法不需要获得该对象的锁，假如一个方法没用synchronized关键字修饰，说明它不会使用到临界资源，那么其他线程是可以访问这个方法的，</p><p>　　3）如果一个线程A需要访问对象object1的synchronized方法fun1，另外一个线程B需要访问对象object2的synchronized方法fun1，即使object1和object2是同一类型），也不会产生线程安全问题，因为他们访问的是不同的对象，所以不存在互斥问题。</p><p>　　2.synchronized代码块</p><p>　　synchronized代码块类似于以下这种形式：<br>    synchronized(synObject) {</p><pre><code>}</code></pre><p>　　当在某个线程中执行这段代码块，该线程会获取对象synObject的锁，从而使得其他线程无法同时访问该代码块。</p><p>　　synObject可以是this，代表获取当前对象的锁，也可以是类中的一个属性，代表获取该属性的锁。</p><p>　　比如上面的insert方法可以改成以下两种形式：</p><pre><code>class InsertData {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    public void insert(Thread thread){        synchronized (this) {            for(int i=0;i&lt;100;i++){                System.out.println(thread.getName()+&quot;在插入数据&quot;+i);                arrayList.add(i);            }        }    }}class InsertData {    private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();    private Object object = new Object();    public void insert(Thread thread){        synchronized (object) {            for(int i=0;i&lt;100;i++){                System.out.println(thread.getName()+&quot;在插入数据&quot;+i);                arrayList.add(i);            }        }    }}</code></pre><p>　　从上面可以看出，synchronized代码块使用起来比synchronized方法要灵活得多。因为也许一个方法中只有一部分代码只需要同步，如果此时对整个方法用synchronized进行同步，会影响程序执行效率。而使用synchronized代码块就可以避免这个问题，synchronized代码块可以实现只对需要同步的地方进行同步。</p><p>　　另外，每个类也会有一个锁，它可以用来控制对static数据成员的并发访问。</p><p>　　并且如果一个线程执行一个对象的非static synchronized方法，另外一个线程需要执行这个对象所属类的static synchronized方法，此时不会发生互斥现象，因为访问static synchronized方法占用的是类锁，而访问非static synchronized方法占用的是对象锁，所以不存在互斥现象。</p><p>看下面这段代码就明白了：</p><pre><code>public class Test {    public static void main(String[] args)  {        final InsertData insertData = new InsertData();        new Thread(){            @Override            public void run() {                insertData.insert();            }        }.start();         new Thread(){            @Override            public void run() {                insertData.insert1();            }        }.start();    }  }class InsertData {     public synchronized void insert(){        System.out.println(&quot;执行insert&quot;);        try {            Thread.sleep(5000);        } catch (InterruptedException e) {            e.printStackTrace();        }        System.out.println(&quot;执行insert完毕&quot;);    }    public synchronized static void insert1() {        System.out.println(&quot;执行insert1&quot;);        System.out.println(&quot;执行insert1完毕&quot;);    }}</code></pre><p>　　执行结果;<br><img src="http://op7wplti1.bkt.clouddn.com/192113596129599.jpg" alt="syncTest3">　　</p><p>　　第一个线程里面执行的是insert方法，不会导致第二个线程执行insert1方法发生阻塞现象。</p><p>　　下面我们看一下synchronized关键字到底做了什么事情，我们来反编译它的字节码看一下，下面这段代码反编译后的字节码为：</p><pre><code>public class InsertData {    private Object object = new Object();    public void insert(Thread thread){        synchronized (object) {        }    }    public synchronized void insert1(Thread thread){    }    public void insert2(Thread thread){    }}  </code></pre><p><img src="http://op7wplti1.bkt.clouddn.com/192052201909119.jpg" alt="fanbianyi"></p><p>　　从反编译获得的字节码可以看出，synchronized代码块实际上多了monitorenter和monitorexit两条指令。monitorenter指令执行时会让对象的锁计数加1，而monitorexit指令执行时会让对象的锁计数减1，其实这个与操作系统里面的PV操作很像，操作系统里面的PV操作就是用来控制多个线程对临界资源的访问。对于synchronized方法，执行中的线程识别该方法的 method_info 结构是否有 ACC_SYNCHRONIZED 标记设置，然后它自动获取对象的锁，调用方法，最后释放锁。如果有异常发生，线程自动释放锁。</p><p>　　</p><p>　　<strong>有一点要注意：对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。</strong></p><p>　　参考资料：</p><p>　　《Java编程思想》</p><p>　　<a href="http://ifeve.com/synchronized-blocks/" target="_blank" rel="noopener">http://ifeve.com/synchronized-blocks/</a></p><p>　　<a href="http://ifeve.com/java-synchronized/" target="_blank" rel="noopener">http://ifeve.com/java-synchronized/</a></p><p>　　<a href="http://blog.csdn.net/ns_code/article/details/17199201" target="_blank" rel="noopener">http://blog.csdn.net/ns_code/article/details/17199201</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> synchronized </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程：Thread类的使用</title>
      <link href="/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9AThread%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9AThread%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>在前面2篇文章分别讲到了线程和进程的由来、以及如何在Java中怎么创建线程和进程。今天我们来学习一下Thread类，在学习Thread类之前，先介绍与线程相关知识：线程的几种状态、上下文切换，然后接着介绍Thread类中的方法的具体使用。</p><p>　　以下是本文的目录大纲：</p><p>　　一.线程的状态</p><p>　　二.上下文切换</p><p>　　三.Thread类中的方法</p><p>　　若有不正之处，请多多谅解并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p> 　　<a href="http://www.cnblogs.com/dolphin0520/p/3920357.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3920357.html</a></p><h2 id="一-线程的状态"><a href="#一-线程的状态" class="headerlink" title="一.线程的状态"></a>一.线程的状态</h2><p>　　在正式学习Thread类中的具体方法之前，我们先来了解一下线程有哪些状态，这个将会有助于后面对Thread类中的方法的理解。</p><p>　　线程从创建到最终的消亡，要经历若干个状态。一般来说，线程包括以下这几个状态：创建(new)、就绪(runnable)、运行(running)、阻塞(blocked)、time waiting、waiting、消亡（dead）。</p><p>　　当需要新起一个线程来执行某个子任务时，就创建了一个线程。但是线程创建之后，不会立即进入就绪状态，因为线程的运行需要一些条件（比如内存资源，在前面的JVM内存区域划分一篇博文中知道程序计数器、Java栈、本地方法栈都是线程私有的，所以需要为线程分配一定的内存空间），只有线程运行需要的所有条件满足了，才进入就绪状态。</p><p>　　当线程进入就绪状态后，不代表立刻就能获取CPU执行时间，也许此时CPU正在执行其他的事情，因此它要等待。当得到CPU执行时间之后，线程便真正进入运行状态。</p><p>　　线程在运行状态过程中，可能有多个原因导致当前线程不继续运行下去，比如用户主动让线程睡眠（睡眠一定的时间之后再重新执行）、用户主动让线程等待，或者被同步块给阻塞，此时就对应着多个状态：time waiting（睡眠或等待一定的事件）、waiting（等待被唤醒）、blocked（阻塞）。</p><p>　　当由于突然中断或者子任务执行完毕，线程就会被消亡。</p><p>　　下面这副图描述了线程从创建到消亡之间的状态：<br><img src="http://op7wplti1.bkt.clouddn.com/061045374695226.jpg" alt="threadLife"></p><p>　　在有些教程上将blocked、waiting、time waiting统称为阻塞状态，这个也是可以的，只不过这里我想将线程的状态和Java中的方法调用联系起来，所以将waiting和time waiting两个状态分离出来。</p><h2 id="二-上下文切换"><a href="#二-上下文切换" class="headerlink" title="二.上下文切换"></a>二.上下文切换</h2><p>　　对于单核CPU来说（对于多核CPU，此处就理解为一个核），CPU在一个时刻只能运行一个线程，当在运行一个线程的过程中转去运行另外一个线程，这个叫做线程上下文切换（对于进程也是类似）。</p><p>　　由于可能当前线程的任务并没有执行完毕，所以在切换时需要保存线程的运行状态，以便下次重新切换回来时能够继续切换之前的状态运行。举个简单的例子：比如一个线程A正在读取一个文件的内容，正读到文件的一半，此时需要暂停线程A，转去执行线程B，当再次切换回来执行线程A的时候，我们不希望线程A又从文件的开头来读取。</p><p>　　因此需要记录线程A的运行状态，那么会记录哪些数据呢？因为下次恢复时需要知道在这之前当前线程已经执行到哪条指令了，所以需要记录程序计数器的值，另外比如说线程正在进行某个计算的时候被挂起了，那么下次继续执行的时候需要知道之前挂起时变量的值时多少，因此需要记录CPU寄存器的状态。所以一般来说，线程上下文切换过程中会记录程序计数器、CPU寄存器状态等数据。</p><p>　　说简单点的：对于线程的上下文切换实际上就是 存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。</p><p>　　虽然多线程可以使得任务执行的效率得到提升，但是由于在线程切换时同样会带来一定的开销代价，并且多个线程会导致系统资源占用的增加，所以在进行多线程编程时要注意这些因素。</p><h2 id="三-Thread类中的方法"><a href="#三-Thread类中的方法" class="headerlink" title="三.Thread类中的方法"></a>三.Thread类中的方法</h2><p>　　通过查看java.lang.Thread类的源码可知：<br><img src="http://op7wplti1.bkt.clouddn.com/182136581436496.jpg" alt="threadSource"></p><p>　　Thread类实现了Runnable接口，在Thread类中，有一些比较关键的属性，比如name是表示Thread的名字，可以通过Thread类的构造器中的参数来指定线程名字，priority表示线程的优先级（最大值为10，最小值为1，默认值为5），daemon表示线程是否是守护线程，target表示要执行的任务。</p><p>　　下面是Thread类中常用的方法：</p><p>　　以下是关系到线程运行状态的几个方法：</p><p>　　1）start方法</p><p>　　start()用来启动一个线程，当调用start方法后，系统才会开启一个新的线程来执行用户定义的子任务，在这个过程中，会为相应的线程分配需要的资源。</p><p>　　2）run方法</p><p>　　run()方法是不需要用户来调用的，当通过start方法启动一个线程之后，当线程获得了CPU执行时间，便进入run方法体去执行具体的任务。注意，继承Thread类必须重写run方法，在run方法中定义具体要执行的任务。</p><p>　　3）sleep方法</p><p>　　sleep方法有两个重载版本：</p><pre><code>sleep(long millis)     //参数为毫秒sleep(long millis,int nanoseconds)    //第一参数为毫秒，第二个参数为纳秒</code></pre><p>　　sleep相当于让线程睡眠，交出CPU，让CPU去执行其他的任务。</p><p>　　但是有一点要非常注意，sleep方法不会释放锁，也就是说如果当前线程持有对某个对象的锁，则即使调用sleep方法，其他线程也无法访问这个对象。看下面这个例子就清楚了：</p><pre><code>public class Test {    private int i = 10;    private Object object = new Object();    public static void main(String[] args) throws IOException  {        Test test = new Test();        MyThread thread1 = test.new MyThread();        MyThread thread2 = test.new MyThread();        thread1.start();        thread2.start();    }     class MyThread extends Thread{        @Override        public void run() {            synchronized (object) {                i++;                System.out.println(&quot;i:&quot;+i);                try {                    System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;进入睡眠状态&quot;);                    Thread.currentThread().sleep(10000);                } catch (InterruptedException e) {                    // TODO: handle exception                }                System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;睡眠结束&quot;);                i++;                System.out.println(&quot;i:&quot;+i);            }        }    }}</code></pre><p> 　　输出结果：<br><img src="http://op7wplti1.bkt.clouddn.com/191016230185255.jpg" alt="result">　　</p><p>　　从上面输出结果可以看出，当Thread-0进入睡眠状态之后，Thread-1并没有去执行具体的任务。只有当Thread-0执行完之后，此时Thread-0释放了对象锁，Thread-1才开始执行。</p><p>　　注意，如果调用了sleep方法，必须捕获InterruptedException异常或者将该异常向上层抛出。当线程睡眠时间满后，不一定会立即得到执行，因为此时可能CPU正在执行其他的任务。所以说调用sleep方法相当于让线程进入阻塞状态。</p><p>　　4）yield方法</p><p>　　调用yield方法会让当前线程交出CPU权限，让CPU去执行其他的线程。它跟sleep方法类似，同样不会释放锁。但是yield不能控制具体的交出CPU的时间，另外，yield方法只能让拥有相同优先级的线程有获取CPU执行时间的机会。</p><p>　　注意，调用yield方法并不会让线程进入阻塞状态，而是让线程重回就绪状态，它只需要等待重新获取CPU执行时间，这一点是和sleep方法不一样的。</p><p>　　5）join方法</p><p>　　join方法有三个重载版本：<br>    join()<br>    join(long millis)     //参数为毫秒<br>    join(long millis,int nanoseconds)    //第一参数为毫秒，第二个参数为纳秒<br> 　　假如在main线程中，调用thread.join方法，则main方法会等待thread线程执行完毕或者等待一定的时间。如果调用的是无参join方法，则等待thread执行完毕，如果调用的是指定了时间参数的join方法，则等待一定的事件。</p><p>　　看下面一个例子：<br>    public class Test {</p><pre><code>    public static void main(String[] args) throws IOException  {        System.out.println(&quot;进入线程&quot;+Thread.currentThread().getName());        Test test = new Test();        MyThread thread1 = test.new MyThread();        thread1.start();        try {            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;等待&quot;);            thread1.join();            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;继续执行&quot;);        } catch (InterruptedException e) {            // TODO Auto-generated catch block            e.printStackTrace();        }    }     class MyThread extends Thread{        @Override        public void run() {            System.out.println(&quot;进入线程&quot;+Thread.currentThread().getName());            try {                Thread.currentThread().sleep(5000);            } catch (InterruptedException e) {                // TODO: handle exception            }            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;);        }    }}</code></pre><p> 　　输出结果：<br><img src="http://op7wplti1.bkt.clouddn.com/191048580654866.jpg" alt="result2"></p><p>　　可以看出，当调用thread1.join()方法后，main线程会进入等待，然后等待thread1执行完之后再继续执行。</p><p>　　实际上调用join方法是调用了Object的wait方法，这个可以通过查看源码得知：<br><img src="http://op7wplti1.bkt.clouddn.com/191050522371780.jpg" alt="joinSource">　　</p><p>　　wait方法会让线程进入阻塞状态，并且会释放线程占有的锁，并交出CPU执行权限。</p><p>　　由于wait方法会让线程释放对象锁，所以join方法同样会让线程释放对一个对象持有的锁。具体的wait方法使用在后面文章中给出。</p><p>　　6）interrupt方法</p><p>　　interrupt，顾名思义，即中断的意思。单独调用interrupt方法可以使得处于阻塞状态的线程抛出一个异常，也就说，它可以用来中断一个正处于阻塞状态的线程；另外，通过interrupt方法和isInterrupted()方法来停止正在运行的线程。</p><p>　　下面看一个例子：<br>    public class Test {</p><pre><code>    public static void main(String[] args) throws IOException  {        Test test = new Test();        MyThread thread = test.new MyThread();        thread.start();        try {            Thread.currentThread().sleep(2000);        } catch (InterruptedException e) {        }        thread.interrupt();    }     class MyThread extends Thread{        @Override        public void run() {            try {                System.out.println(&quot;进入睡眠状态&quot;);                Thread.currentThread().sleep(10000);                System.out.println(&quot;睡眠完毕&quot;);            } catch (InterruptedException e) {                System.out.println(&quot;得到中断异常&quot;);            }            System.out.println(&quot;run方法执行完毕&quot;);        }    }}</code></pre><p> 　　输出结果：<br><img src="http://op7wplti1.bkt.clouddn.com/191129005348267.jpg" alt="result3">　　</p><p>　　从这里可以看出，通过interrupt方法可以中断处于阻塞状态的线程。那么能不能中断处于非阻塞状态的线程呢？看下面这个例子：<br>    public class Test {</p><pre><code>    public static void main(String[] args) throws IOException  {        Test test = new Test();        MyThread thread = test.new MyThread();        thread.start();        try {            Thread.currentThread().sleep(2000);        } catch (InterruptedException e) {        }        thread.interrupt();    }     class MyThread extends Thread{        @Override        public void run() {            int i = 0;            while(i&lt;Integer.MAX_VALUE){                System.out.println(i+&quot; while循环&quot;);                i++;            }        }    }}</code></pre><p> 　　运行该程序会发现，while循环会一直运行直到变量i的值超出Integer.MAX_VALUE。所以说直接调用interrupt方法不能中断正在运行中的线程。</p><p>　　但是如果配合isInterrupted()能够中断正在运行的线程，因为调用interrupt方法相当于将中断标志位置为true，那么可以通过调用isInterrupted()判断中断标志是否被置位来中断线程的执行。比如下面这段代码：</p><pre><code>public class Test {    public static void main(String[] args) throws IOException  {        Test test = new Test();        MyThread thread = test.new MyThread();        thread.start();        try {            Thread.currentThread().sleep(2000);        } catch (InterruptedException e) {        }        thread.interrupt();    }     class MyThread extends Thread{        @Override        public void run() {            int i = 0;            while(!isInterrupted() &amp;&amp; i&lt;Integer.MAX_VALUE){                System.out.println(i+&quot; while循环&quot;);                i++;            }        }    }}</code></pre><p> 　　运行会发现，打印若干个值之后，while循环就停止打印了。</p><p>　　但是一般情况下不建议通过这种方式来中断线程，一般会在MyThread类中增加一个属性 isStop来标志是否结束while循环，然后再在while循环中判断isStop的值。</p><pre><code>class MyThread extends Thread{        private volatile boolean isStop = false;        @Override        public void run() {            int i = 0;            while(!isStop){                i++;            }        }        public void setStop(boolean stop){            this.isStop = stop;        }    }</code></pre><p> 　那么就可以在外面通过调用setStop方法来终止while循环。</p><p>　　7）stop方法</p><p>　　stop方法已经是一个废弃的方法，它是一个不安全的方法。因为调用stop方法会直接终止run方法的调用，并且会抛出一个ThreadDeath错误，如果线程持有某个对象锁的话，会完全释放锁，导致对象状态不一致。所以stop方法基本是不会被用到的。</p><p>　　8）destroy方法</p><p>　　destroy方法也是废弃的方法。基本不会被使用到。</p><p>　　以下是关系到线程属性的几个方法：</p><p>　　1）getId</p><p>　　用来得到线程ID</p><p>　　2）getName和setName</p><p>　　用来得到或者设置线程名称。</p><p>　　3）getPriority和setPriority</p><p>　　用来获取和设置线程优先级。</p><p>　　4）setDaemon和isDaemon</p><p>　　用来设置线程是否成为守护线程和判断线程是否是守护线程。</p><p>　　守护线程和用户线程的区别在于：守护线程依赖于创建它的线程，而用户线程则不依赖。举个简单的例子：如果在main线程中创建了一个守护线程，当main方法运行完毕之后，守护线程也会随着消亡。而用户线程则不会，用户线程会一直运行直到其运行完毕。在JVM中，像垃圾收集器线程就是守护线程。</p><p>　　Thread类有一个比较常用的静态方法currentThread()用来获取当前线程。</p><p>　　在上面已经说到了Thread类中的大部分方法，那么Thread类中的方法调用到底会引起线程状态发生怎样的变化呢？下面一幅图就是在上面的图上进行改进而来的：</p><p><img src="http://op7wplti1.bkt.clouddn.com/061046391107893.jpg" alt="threadLife2"></p><p>　　参考资料：</p><p>　　《Java编程思想》</p><p>　　<a href="http://zy19982004.iteye.com/blog/1626916" target="_blank" rel="noopener">http://zy19982004.iteye.com/blog/1626916</a></p><p>　　<a href="http://www.cnblogs.com/DreamSea/archive/2012/01/11/JavaThread.html#navigation" target="_blank" rel="noopener">http://www.cnblogs.com/DreamSea/archive/2012/01/11/JavaThread.html#navigation</a></p><p>　　<a href="http://www.blogjava.net/vincent/archive/2008/08/23/223912.html" target="_blank" rel="noopener">http://www.blogjava.net/vincent/archive/2008/08/23/223912.html</a></p><p>　　<a href="http://iteye.blog.163.com/blog/static/1863080962012111424544215/" target="_blank" rel="noopener">http://iteye.blog.163.com/blog/static/1863080962012111424544215/</a></p><p>　　<a href="http://blog.csdn.net/lifei128/article/details/20363257" target="_blank" rel="noopener">http://blog.csdn.net/lifei128/article/details/20363257</a></p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> Thread </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java并发编程:如何创建线程</title>
      <link href="/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B/"/>
      <url>/2017/04/30/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B/</url>
      <content type="html"><![CDATA[<a id="more"></a><p>在前面一篇文章中已经讲述了在进程和线程的由来，今天就来讲一下在Java中如何创建线程，让线程去执行一个子任务。下面先讲述一下Java中的应用程序和进程相关的概念知识，然后再阐述如何创建线程以及如何创建进程。下面是本文的目录大纲：</p><p>　　一.Java中关于应用程序和进程相关的概念</p><p>　　二.Java中如何创建线程</p><p>　　三.Java中如何创建进程</p><p>　　若有不正之处，请多多谅解并欢迎批评指正。</p><p>　　请尊重作者劳动成果，转载请标明原文链接：</p><p> 　　<a href="http://www.cnblogs.com/dolphin0520/p/3913517.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3913517.html</a></p><h2 id="一-Java中关于应用程序和进程相关的概念"><a href="#一-Java中关于应用程序和进程相关的概念" class="headerlink" title="一.Java中关于应用程序和进程相关的概念"></a>一.Java中关于应用程序和进程相关的概念</h2><p>　　在Java中，一个应用程序对应着一个JVM实例（也有地方称为JVM进程），一般来说名字默认为java.exe或者javaw.exe（windows下可以通过任务管理器查看）。Java采用的是单线程编程模型，即在我们自己的程序中如果没有主动创建线程的话，只会创建一个线程，通常称为主线程。但是要注意，虽然只有一个线程来执行任务，不代表JVM中只有一个线程，JVM实例在创建的时候，同时会创建很多其他的线程（比如垃圾收集器线程）。</p><p>　　由于Java采用的是单线程编程模型，因此在进行UI编程时要注意将耗时的操作放在子线程中进行，以避免阻塞主线程（在UI编程时，主线程即UI线程，用来处理用户的交互事件）。</p><h2 id="二-Java中如何创建线程"><a href="#二-Java中如何创建线程" class="headerlink" title="二.Java中如何创建线程"></a>二.Java中如何创建线程</h2><p>　　在java中如果要创建线程的话，一般有两种方式：1）继承Thread类；2）实现Runnable接口。</p><p>　　1.继承Thread类</p><p>　　继承Thread类的话，必须重写run方法，在run方法中定义需要执行的任务。</p><pre><code>class MyThread extends Thread{    private static int num = 0;    public MyThread(){        num++;    }    @Override    public void run() {        System.out.println(&quot;主动创建的第&quot;+num+&quot;个线程&quot;);    }}</code></pre><p> 　　创建好了自己的线程类之后，就可以创建线程对象了，然后通过start()方法去启动线程。注意，不是调用run()方法启动线程，run方法中只是定义需要执行的任务，如果调用run方法，即相当于在主线程中执行run方法，跟普通的方法调用没有任何区别，此时并不会创建一个新的线程来执行定义的任务。</p><pre><code>public class Test {    public static void main(String[] args)  {        MyThread thread = new MyThread();        thread.start();    }}class MyThread extends Thread{    private static int num = 0;    public MyThread(){        num++;    }    @Override    public void run() {        System.out.println(&quot;主动创建的第&quot;+num+&quot;个线程&quot;);    }}</code></pre><p> 　　在上面代码中，通过调用start()方法，就会创建一个新的线程了。为了分清start()方法调用和run()方法调用的区别，请看下面一个例子：</p><pre><code>public class Test {    public static void main(String[] args)  {        System.out.println(&quot;主线程ID:&quot;+Thread.currentThread().getId());        MyThread thread1 = new MyThread(&quot;thread1&quot;);        thread1.start();        MyThread thread2 = new MyThread(&quot;thread2&quot;);        thread2.run();    }}class MyThread extends Thread{    private String name;    public MyThread(String name){        this.name = name;    }    @Override    public void run() {        System.out.println(&quot;name:&quot;+name+&quot; 子线程ID:&quot;+Thread.currentThread().getId());    }}</code></pre><p> 　　运行结果：</p><p><img src="http://op7wplti1.bkt.clouddn.com/151004139364653.jpg" alt="线程调用运行结果"></p><p>　　从输出结果可以得出以下结论：</p><p>　　1）thread1和thread2的线程ID不同，thread2和主线程ID相同，说明通过run方法调用并不会创建新的线程，而是在主线程中直接运行run方法，跟普通的方法调用没有任何区别；</p><p>　　2）虽然thread1的start方法调用在thread2的run方法前面调用，但是先输出的是thread2的run方法调用的相关信息，说明新线程创建的过程不会阻塞主线程的后续执行。</p><p>　　2.实现Runnable接口</p><p>　　在Java中创建线程除了继承Thread类之外，还可以通过实现Runnable接口来实现类似的功能。实现Runnable接口必须重写其run方法。</p><p>下面是一个例子：</p><pre><code>public class Test {    public static void main(String[] args)  {        System.out.println(&quot;主线程ID：&quot;+Thread.currentThread().getId());        MyRunnable runnable = new MyRunnable();        Thread thread = new Thread(runnable);        thread.start();    }}class MyRunnable implements Runnable{    public MyRunnable() {    }    @Override    public void run() {        System.out.println(&quot;子线程ID：&quot;+Thread.currentThread().getId());    }}</code></pre><p> 　　Runnable的中文意思是“任务”，顾名思义，通过实现Runnable接口，我们定义了一个子任务，然后将子任务交由Thread去执行。注意，这种方式必须将Runnable作为Thread类的参数，然后通过Thread的start方法来创建一个新线程来执行该子任务。如果调用Runnable的run方法的话，是不会创建新线程的，这根普通的方法调用没有任何区别。</p><p>　　事实上，查看Thread类的实现源代码会发现Thread类是实现了Runnable接口的。</p><p>　　在Java中，这2种方式都可以用来创建线程去执行子任务，具体选择哪一种方式要看自己的需求。直接继承Thread类的话，可能比实现Runnable接口看起来更加简洁，但是由于Java只允许单继承，所以如果自定义类需要继承其他类，则只能选择实现Runnable接口。</p><h2 id="三-Java中如何创建进程"><a href="#三-Java中如何创建进程" class="headerlink" title="三.Java中如何创建进程"></a>三.Java中如何创建进程</h2><p> 　　在Java中，可以通过两种方式来创建进程，总共涉及到5个主要的类。</p><p>　　第一种方式是通过Runtime.exec()方法来创建一个进程，第二种方法是通过ProcessBuilder的start方法来创建进程。下面就来讲一讲这2种方式的区别和联系。</p><p>　　首先要讲的是Process类，Process类是一个抽象类，在它里面主要有几个抽象的方法，这个可以通过查看Process类的源代码得知：</p><p>　　位于java.lang.Process路径下：</p><pre><code>public abstract class Process{    abstract public OutputStream getOutputStream();   //获取进程的输出流    abstract public InputStream getInputStream();    //获取进程的输入流    abstract public InputStream getErrorStream();   //获取进程的错误流    abstract public int waitFor() throws InterruptedException;   //让进程等待    abstract public int exitValue();   //获取进程的退出标志    abstract public void destroy();   //摧毁进程}</code></pre><p>　　1）通过ProcessBuilder创建进程</p><p>　　ProcessBuilder是一个final类，它有两个构造器：</p><pre><code>public final class ProcessBuilder{    private List&lt;String&gt; command;    private File directory;    private Map&lt;String,String&gt; environment;    private boolean redirectErrorStream;    public ProcessBuilder(List&lt;String&gt; command) {    if (command == null)        throw new NullPointerException();    this.command = command;    }    public ProcessBuilder(String... command) {    this.command = new ArrayList&lt;String&gt;(command.length);    for (String arg : command)        this.command.add(arg);    }...}</code></pre><p> 　　构造器中传递的是需要创建的进程的命令参数，第一个构造器是将命令参数放进List当中传进去，第二构造器是以不定长字符串的形式传进去。</p><p>　　那么我们接着往下看，前面提到是通过ProcessBuilder的start方法来创建一个新进程的，我们看一下start方法中具体做了哪些事情。下面是start方法的具体实现源代码：</p><pre><code>public Process start() throws IOException {// Must convert to array first -- a malicious user-supplied// list might try to circumvent the security check.String[] cmdarray = command.toArray(new String[command.size()]);for (String arg : cmdarray)    if (arg == null)    throw new NullPointerException();// Throws IndexOutOfBoundsException if command is emptyString prog = cmdarray[0];SecurityManager security = System.getSecurityManager();if (security != null)    security.checkExec(prog);String dir = directory == null ? null : directory.toString();try {    return ProcessImpl.start(cmdarray,                 environment,                 dir,                 redirectErrorStream);} catch (IOException e) {    // It&apos;s much easier for us to create a high-quality error    // message than the low-level C code which found the problem.    throw new IOException(    &quot;Cannot run program \&quot;&quot; + prog + &quot;\&quot;&quot;    + (dir == null ? &quot;&quot; : &quot; (in directory \&quot;&quot; + dir + &quot;\&quot;)&quot;)    + &quot;: &quot; + e.getMessage(),    e);}}</code></pre><p> 　　该方法返回一个Process对象，该方法的前面部分相当于是根据命令参数以及设置的工作目录进行一些参数设定，最重要的是try语句块里面的一句：</p><pre><code>return ProcessImpl.start(cmdarray,                    environment,                    dir,                    redirectErrorStream);</code></pre><p> 　　说明真正创建进程的是这一句，注意调用的是ProcessImpl类的start方法，此处可以知道start必然是一个静态方法。那么ProcessImpl又是什么类呢？该类同样位于java.lang.ProcessImpl路径下，看一下该类的具体实现：</p><p>　　ProcessImpl也是一个final类，它继承了Process类：<br>    final class ProcessImpl extends Process {</p><pre><code>    // System-dependent portion of ProcessBuilder.start()    static Process start(String cmdarray[],             java.util.Map&lt;String,String&gt; environment,             String dir,             boolean redirectErrorStream)    throws IOException    {    String envblock = ProcessEnvironment.toEnvironmentBlock(environment);    return new ProcessImpl(cmdarray, envblock, dir, redirectErrorStream);    } ....}</code></pre><p> 　　这是ProcessImpl类的start方法的具体实现，而事实上start方法中是通过这句来创建一个ProcessImpl对象的：</p><p>1<br>return new ProcessImpl(cmdarray, envblock, dir, redirectErrorStream);<br> 　　而在ProcessImpl中对Process类中的几个抽象方法进行了具体实现。</p><p>　　说明事实上通过ProcessBuilder的start方法创建的是一个ProcessImpl对象。</p><p>　　下面看一下具体使用ProcessBuilder创建进程的例子，比如我要通过ProcessBuilder来启动一个进程打开cmd，并获取ip地址信息，那么可以这么写：<br>    public class Test {<br>        public static void main(String[] args) throws IOException  {<br>            ProcessBuilder pb = new ProcessBuilder(“cmd”,”/c”,”ipconfig/all”);<br>            Process process = pb.start();<br>            Scanner scanner = new Scanner(process.getInputStream());</p><pre><code>        while(scanner.hasNextLine()){            System.out.println(scanner.nextLine());        }        scanner.close();    }}</code></pre><p> 　　第一步是最关键的，就是将命令字符串传给ProcessBuilder的构造器，一般来说，是把字符串中的每个独立的命令作为一个单独的参数，不过也可以按照顺序放入List中传进去。</p><p>　　至于其他很多具体的用法不在此进行赘述，比如通过ProcessBuilder的environment方法和directory(File directory)设置进程的环境变量以及工作目录等，感兴趣的朋友可以查看相关API文档。</p><p>　　2）通过Runtime的exec方法来创建进程</p><p>　　首先还是来看一下Runtime类和exec方法的具体实现，Runtime，顾名思义，即运行时，表示当前进程所在的虚拟机实例。</p><p>　　由于任何进程只会运行于一个虚拟机实例当中，所以在Runtime中采用了单例模式，即只会产生一个虚拟机实例：<br>    public class Runtime {<br>        private static Runtime currentRuntime = new Runtime();</p><pre><code>   /**    * Returns the runtime object associated with the current Java application.    * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance    * methods and must be invoked with respect to the current runtime object.    *    * @return  the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current    *          Java application.    */   public static Runtime getRuntime() {   return currentRuntime;   }   /** Don&apos;t let anyone else instantiate this class */   private Runtime() {}   ...}</code></pre><p> 　　从这里可以看出，由于Runtime类的构造器是private的，所以只有通过getRuntime去获取Runtime的实例。接下来着重看一下exec方法 实现，在Runtime中有多个exec的不同重载实现，但真正最后执行的是这个版本的exec方法：</p><pre><code>public Process exec(String[] cmdarray, String[] envp, File dir)   throws IOException {   return new ProcessBuilder(cmdarray)       .environment(envp)       .directory(dir)       .start();   }</code></pre><p> 　　可以发现，事实上通过Runtime类的exec创建进程的话，最终还是通过ProcessBuilder类的start方法来创建的。</p><p>　　下面看一个例子，看一下通过Runtime的exec如何创建进程，还是前面的例子，调用cmd，获取ip地址信息：</p><pre><code>public class Test {    public static void main(String[] args) throws IOException  {        String cmd = &quot;cmd &quot;+&quot;/c &quot;+&quot;ipconfig/all&quot;;        Process process = Runtime.getRuntime().exec(cmd);        Scanner scanner = new Scanner(process.getInputStream());        while(scanner.hasNextLine()){            System.out.println(scanner.nextLine());        }        scanner.close();    }}</code></pre><p> 　　要注意的是，exec方法不支持不定长参数（ProcessBuilder是支持不定长参数的），所以必须先把命令参数拼接好再传进去。</p><p>　　关于在Java中如何创建线程和进程的话，暂时就讲这么多了，感兴趣的朋友可以参考相关资料、</p><p>　　</p><blockquote><p>参考资料：</p><p><a href="http://luckykapok918.blog.163.com/blog/static/205865043201210272168556/" target="_blank" rel="noopener">http://luckykapok918.blog.163.com/blog/static/205865043201210272168556/</a></p><p><a href="http://www.cnblogs.com/ChrisWang/archive/2009/12/02/use-java-lang-process-&gt;" target="_blank" rel="noopener">http://www.cnblogs.com/ChrisWang/archive/2009/12/02/use-java-lang-process-&gt;</a><br>and-processbuilder-to-create-native-application-process.html</p><p><a href="http://lavasoft.blog.51cto.com/62575/15662/" target="_blank" rel="noopener">http://lavasoft.blog.51cto.com/62575/15662/</a></p><p>《Java编程思想》</p></blockquote>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java多线程基础：进程和线程之由来</title>
      <link href="/2017/04/28/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%94%B1%E6%9D%A5/"/>
      <url>/2017/04/28/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%EF%BC%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E4%B9%8B%E7%94%B1%E6%9D%A5/</url>
      <content type="html"><![CDATA[<p>　在前面，已经介绍了Java的基础知识，现在我们来讨论一点稍微难一点的问题：Java并发编程。当然，Java并发编程涉及到很多方面的内容，不是一朝一夕就能够融会贯通使用的，需要在实践中不断积累。由于并发肯定涉及到多线程，因此在进入并发编程主题之前，我们先来了解一下进程和线程的由来，这对后面对并发编程的理解将会有很大的帮助。</p><p>　　下面是本文的目录大纲：</p><p>　　一.操作系统中为什么会出现进程？</p><p>　　二.为什么会出现线程？</p><p>　　三.多线程并发</p><p>　　若有不正之处，请多多谅解并欢迎指正。</p><p>　　请尊重作者劳动成果，转载请标明原文地址：</p><p>　　<a href="http://www.cnblogs.com/dolphin0520/p/3910667.html" target="_blank" rel="noopener">http://www.cnblogs.com/dolphin0520/p/3910667.html</a></p><h2 id="一-操作系统中为什么会出现进程？"><a href="#一-操作系统中为什么会出现进程？" class="headerlink" title="一.操作系统中为什么会出现进程？"></a>一.操作系统中为什么会出现进程？</h2><p>　　说起进程的由来，我们需要从操作系统的发展历史谈起。</p><p>　　也许在今天，我们无法想象在很多年以前计算机是什么样子。我们现在可以用计算机来做很多事情：办公、娱乐、上网，但是在计算机刚出现的时候，是为了解决数学计算的问题，因为很多大量的计算通过人力去完成是很耗时间和人力成本的。在最初的时候，计算机只能接受一些特定的指令，用户输入一个指令，计算机就做一个操作。当用户在思考或者输入数据时，计算机就在等待。显然这样效率和很低下，因为很多时候，计算机处于等待用户输入的状态。</p><p>　　那么能不能把一系列需要操作的指令预先写下来，形成一个清单，然后一次性交给计算机，计算机不断地去读取指令来进行相应的操作？就这样，批处理操作系统诞生了。用户可以将需要执行的多个程序写在磁带上，然后交由计算机去读取并逐个地执行这些程序，并将输出结果写到另一个磁带上。</p><p>　　虽然批处理操作系统的诞生极大地提高了任务处理的便捷性，但是仍然存在一个很大的问题：</p><p>　　假如有两个任务A和B，任务A在执行到一半的过程中，需要读取大量的数据输入（I/O操作），而此时CPU只能静静地等待任务A读取完数据才能继续执行，这样就白白浪费了CPU资源。人们于是想，能否在任务A读取数据的过程中，让任务B去执行，当任务A读取完数据之后，让任务B暂停，然后让任务A继续执行？</p><p>　　但是这样就有一个问题，原来每次都是一个程序在计算机里面运行，也就说内存中始终只有一个程序的运行数据。而如果想要任务A执行I/O操作的时候，让任务B去执行，必然内存中要装入多个程序，那么如何处理呢？多个程序使用的数据如何进行辨别呢？并且当一个程序运行暂停后，后面如何恢复到它之前执行的状态呢？</p><p>　　这个时候人们就发明了进程，用进程来对应一个程序，每个进程对应一定的内存地址空间，并且只能使用它自己的内存空间，各个进程间互不干扰。并且进程保存了程序每个时刻的运行状态，这样就为进程切换提供了可能。当进程暂时时，它会保存当前进程的状态（比如进程标识、进程的使用的资源等），在下一次重新切换回来时，便根据之前保存的状态进行恢复，然后继续执行。</p><p>　　这就是并发，能够让操作系统从宏观上看起来同一个时间段有多个任务在执行。换句话说，进程让操作系统的并发成为了可能。</p><p>　　注意，虽然并发从宏观上看有多个任务在执行，但是事实上，任一个具体的时刻，只有一个任务在占用CPU资源（当然是对于单核CPU来说的）。</p><h2 id="二-为什么会出现线程？"><a href="#二-为什么会出现线程？" class="headerlink" title="二.为什么会出现线程？"></a>二.为什么会出现线程？</h2><p>　　在出现了进程之后，操作系统的性能得到了大大的提升。虽然进程的出现解决了操作系统的并发问题，但是人们仍然不满足，人们逐渐对实时性有了要求。因为一个进程在一个时间段内只能做一件事情，如果一个进程有多个子任务，只能逐个地去执行这些子任务。比如对于一个监控系统来说，它不仅要把图像数据显示在画面上，还要与服务端进行通信获取图像数据，还要处理人们的交互操作。如果某一个时刻该系统正在与服务器通信获取图像数据，而用户又在监控系统上点击了某个按钮，那么该系统就要等待获取完图像数据之后才能处理用户的操作，如果获取图像数据需要耗费10s，那么用户就只有一直在等待。显然，对于这样的系统，人们是无法满足的。</p><p>　　那么可不可以将这些子任务分开执行呢？即在系统获取图像数据的同时，如果用户点击了某个按钮，则会暂停获取图像数据，而先去响应用户的操作（因为用户的操作往往执行时间很短），在处理完用户操作之后，再继续获取图像数据。人们就发明了线程，让一个线程去执行一个子任务，这样一个进程就包括了多个线程，每个线程负责一个独立的子任务，这样在用户点击按钮的时候，就可以暂停获取图像数据的线程，让UI线程响应用户的操作，响应完之后再切换回来，让获取图像的线程得到CPU资源。从而让用户感觉系统是同时在做多件事情的，满足了用户对实时性的要求。</p><p>　　换句话说，进程让操作系统的并发性成为可能，而线程让进程的内部并发成为可能。</p><p>　　但是要注意，一个进程虽然包括多个线程，但是这些线程是共同享有进程占有的资源和地址空间的。进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位。</p><h2 id="三-多线程并发"><a href="#三-多线程并发" class="headerlink" title="三.多线程并发"></a>三.多线程并发</h2><p>　　由于多个线程是共同占有所属进程的资源和地址空间的，那么就会存在一个问题：</p><p>　　如果多个线程要同时访问某个资源，怎么处理？</p><p>　　这个问题就是后序文章中要重点讲述的同步问题。</p><p>　　那么可能有朋友会问，现在很多时候都采用多线程编程，那么是不是多线程的性能一定就由于单线程呢？</p><p>　　不一定，要看具体的任务以及计算机的配置。比如说：</p><p>　　对于单核CPU，如果是CPU密集型任务，如解压文件，多线程的性能反而不如单线程性能，因为解压文件需要一直占用CPU资源，如果采用多线程，线程切换导致的开销反而会让性能下降。</p><p>　　但是对于比如交互类型的任务，肯定是需要使用多线程的、</p><p>　　而对于多核CPU，对于解压文件来说，多线程肯定优于单线程，因为多个线程能够更加充分利用每个核的资源。</p><p>　　虽然多线程能够提升程序性能，但是相对于单线程来说，它的编程要复杂地多，要考虑线程安全问题。因此，在实际编程过程中，要根据实际情况具体选择。</p><p>　　关于进程和线程的由来，暂时就讲这么多了，感兴趣的朋友可以参考相关资料。</p>]]></content>
      
      <categories>
          
          <category> Java并发编程系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java多线程 </tag>
            
            <tag> 线程 </tag>
            
            <tag> 进程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>第一篇</title>
      <link href="/2017/04/28/%E7%AC%AC%E4%B8%80%E7%AF%87/"/>
      <url>/2017/04/28/%E7%AC%AC%E4%B8%80%E7%AF%87/</url>
      <content type="html"><![CDATA[<blockquote><p>花了点时间倒腾了下blog!!!</p></blockquote>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2017/04/28/hello-world/"/>
      <url>/2017/04/28/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to Hexo: This is your very first post.</p>]]></content>
      
      
    </entry>
    
  
  
</search>
